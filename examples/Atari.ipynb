{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walkers iteration 1271 Best reward: 11191.00 Dead walkers: 90.00% Cloned: 90.00%\n",
      "\n",
      "Walkers States: \n",
      "id_walkers shape (50,) Mean: 0.000, Std: 0.000, Max: 0.000 Min: 0.000\n",
      "compas_ix shape (50,) Mean: 12.640, Std: 9.804, Max: 26.000 Min: 0.000\n",
      "processed_rewards shape (50,) Mean: 1.000, Std: 0.000, Max: 1.000 Min: 1.000\n",
      "virtual_rewards shape (50,) Mean: 0.977, Std: 0.635, Max: 1.849 Min: 0.219\n",
      "cum_rewards shape (50,) Mean: 11191.000, Std: 0.000, Max: 11191.000 Min: 11191.000\n",
      "distances shape (50,) Mean: 0.977, Std: 0.635, Max: 1.849 Min: 0.219\n",
      "clone_probs shape (50,) Mean: -0.649, Std: 0.247, Max: 0.000 Min: -0.881\n",
      "will_clone shape (50,) Mean: 0.900, Std: 0.300, Max: 1.000 Min: 0.000\n",
      "alive_mask shape (50,) Mean: 0.100, Std: 0.300, Max: 1.000 Min: 0.000\n",
      "end_condition shape (50,) Mean: 0.900, Std: 0.300, Max: 1.000 Min: 0.000\n",
      "\n",
      "Env States: \n",
      "rewards shape (50,) Mean: 0.000, Std: 0.000, Max: 0.000 Min: 0.000\n",
      "ends shape (50,) Mean: 0.000, Std: 0.000, Max: 0.000 Min: 0.000\n",
      "\n",
      "Model States: \n",
      "dt shape (50,) Mean: 3.000, Std: 0.000, Max: 3.000 Min: 3.000\n",
      "actions shape (50,) Mean: 4.220, Std: 1.758, Max: 7.000 Min: 2.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plangym import AtariEnvironment, ParallelEnvironment\n",
    "\n",
    "from fragile.core.env import DiscreteEnv\n",
    "from fragile.core.models import RandomDiscrete\n",
    "from fragile.core.states import States\n",
    "from fragile.core.swarm import Swarm\n",
    "from fragile.core.walkers import Walkers\n",
    "\n",
    "env = ParallelEnvironment(\n",
    "        env_class=AtariEnvironment,\n",
    "        name=\"MsPacman-ram-v0\",\n",
    "        clone_seeds=True,\n",
    "        autoreset=True,\n",
    "        blocking=False,\n",
    "    )\n",
    "\n",
    "\n",
    "swarm = Swarm(\n",
    "    model=lambda x: RandomDiscrete(x),\n",
    "    walkers=Walkers,\n",
    "    env=lambda: DiscreteEnv(env),\n",
    "    n_walkers=50,\n",
    "    max_iters=300000000,\n",
    "    prune_tree=True,\n",
    "    reward_scale=2,\n",
    ")\n",
    "\n",
    "_ = swarm.run_swarm(print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm.run_swarm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, obs = env.reset()\n",
    "\n",
    "states = [state.copy() for _ in range(10)]\n",
    "actions = [env.action_space.sample() for _ in range(10)]\n",
    "\n",
    "data = env.step_batch(states=states, actions=actions)\n",
    "new_states, observs, rewards, ends, infos = data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
