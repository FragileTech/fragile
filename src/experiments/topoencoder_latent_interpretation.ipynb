{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopoEncoder Latent Interpretation\n",
    "\n",
    "This notebook loads a topoencoder checkpoint and optional benchmarks to interpret the latent space, routing, and reconstructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this notebook covers\n",
    "- Latent scatter by class (2D PCA + optional 3D view).\n",
    "- Chart assignments and code usage heatmap.\n",
    "- Reconstruction error distribution and per-chart error.\n",
    "- Chart prototypes (nearest samples to chart centroids).\n",
    "- z_n norm statistics and feature correlations.\n",
    "- Optional benchmark comparison (AE and VQ if available).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fragile.core.layers import TopoEncoderPrimitives, StandardVQ, VanillaAE\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Update this path to your checkpoint\n",
    "checkpoint_path = Path(\"outputs/topoencoder_mnist_cpu_adapt_lr7/topo_final.pt\")\n",
    "device = \"cpu\"\n",
    "\n",
    "output_dir = checkpoint_path.parent\n",
    "bench_path = output_dir / \"benchmarks.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_checkpoint(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {path}\")\n",
    "    try:\n",
    "        return torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        return torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "checkpoint = load_checkpoint(checkpoint_path)\n",
    "benchmarks = load_checkpoint(bench_path) if bench_path.exists() else None\n",
    "\n",
    "config = checkpoint[\"config\"]\n",
    "data = checkpoint.get(\"data\", {})\n",
    "metrics = checkpoint.get(\"metrics\", {})\n",
    "state = checkpoint[\"state\"]\n",
    "\n",
    "bench_state = benchmarks.get(\"state\", {}) if benchmarks else None\n",
    "bench_dims = benchmarks.get(\"dims\", {}) if benchmarks else None\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_models(config, state, metrics, bench_state, bench_dims, device):\n",
    "    model_atlas = TopoEncoderPrimitives(\n",
    "        input_dim=config[\"input_dim\"],\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        latent_dim=config[\"latent_dim\"],\n",
    "        num_charts=config[\"num_charts\"],\n",
    "        codes_per_chart=config[\"codes_per_chart\"],\n",
    "    ).to(device)\n",
    "    model_atlas.load_state_dict(state[\"atlas\"])\n",
    "    model_atlas.eval()\n",
    "\n",
    "    model_std = None\n",
    "    if state.get(\"std\") is not None and not config.get(\"disable_vq\", False):\n",
    "        std_hidden_dim = metrics.get(\"std_hidden_dim\", config[\"hidden_dim\"])\n",
    "        model_std = StandardVQ(\n",
    "            input_dim=config[\"input_dim\"],\n",
    "            hidden_dim=std_hidden_dim,\n",
    "            latent_dim=config[\"latent_dim\"],\n",
    "            num_codes=config[\"num_codes_standard\"],\n",
    "        ).to(device)\n",
    "        model_std.load_state_dict(state[\"std\"])\n",
    "        model_std.eval()\n",
    "    elif bench_state is not None and bench_state.get(\"std\") is not None:\n",
    "        std_hidden_dim = (\n",
    "            (bench_dims or {}).get(\"std_hidden_dim\")\n",
    "            or metrics.get(\"std_hidden_dim\")\n",
    "            or config[\"hidden_dim\"]\n",
    "        )\n",
    "        model_std = StandardVQ(\n",
    "            input_dim=config[\"input_dim\"],\n",
    "            hidden_dim=int(std_hidden_dim),\n",
    "            latent_dim=config[\"latent_dim\"],\n",
    "            num_codes=config[\"num_codes_standard\"],\n",
    "        ).to(device)\n",
    "        model_std.load_state_dict(bench_state[\"std\"])\n",
    "        model_std.eval()\n",
    "\n",
    "    model_ae = None\n",
    "    if state.get(\"ae\") is not None and not config.get(\"disable_ae\", False):\n",
    "        ae_hidden_dim = metrics.get(\"ae_hidden_dim\", config[\"hidden_dim\"])\n",
    "        model_ae = VanillaAE(\n",
    "            input_dim=config[\"input_dim\"],\n",
    "            hidden_dim=ae_hidden_dim,\n",
    "            latent_dim=config[\"latent_dim\"],\n",
    "        ).to(device)\n",
    "        model_ae.load_state_dict(state[\"ae\"])\n",
    "        model_ae.eval()\n",
    "    elif bench_state is not None and bench_state.get(\"ae\") is not None:\n",
    "        ae_hidden_dim = (\n",
    "            (bench_dims or {}).get(\"ae_hidden_dim\")\n",
    "            or metrics.get(\"ae_hidden_dim\")\n",
    "            or config[\"hidden_dim\"]\n",
    "        )\n",
    "        model_ae = VanillaAE(\n",
    "            input_dim=config[\"input_dim\"],\n",
    "            hidden_dim=int(ae_hidden_dim),\n",
    "            latent_dim=config[\"latent_dim\"],\n",
    "        ).to(device)\n",
    "        model_ae.load_state_dict(bench_state[\"ae\"])\n",
    "        model_ae.eval()\n",
    "\n",
    "    return model_atlas, model_std, model_ae\n",
    "\n",
    "model_atlas, model_std, model_ae = build_models(\n",
    "    config, state, metrics, bench_state, bench_dims, device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dataset_specs(dataset: str):\n",
    "    if dataset == \"mnist\":\n",
    "        return [str(i) for i in range(10)], (28, 28, 1)\n",
    "    if dataset == \"cifar10\":\n",
    "        from fragile.datasets import CIFAR10_CLASSES\n",
    "        return list(CIFAR10_CLASSES), (32, 32, 3)\n",
    "    raise ValueError(f\"Unsupported dataset: {dataset}\")\n",
    "\n",
    "class_names, image_shape = dataset_specs(config.get(\"dataset\", \"mnist\"))\n",
    "\n",
    "X_test = data.get(\"X_test\")\n",
    "labels_test = data.get(\"labels_test\")\n",
    "if X_test is None or labels_test is None:\n",
    "    raise RuntimeError(\"No test data in checkpoint. Re-run training with data saving enabled.\")\n",
    "\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "else:\n",
    "    X_test_tensor = X_test.float()\n",
    "\n",
    "if isinstance(labels_test, torch.Tensor):\n",
    "    labels_np = labels_test.cpu().numpy()\n",
    "else:\n",
    "    labels_np = np.asarray(labels_test)\n",
    "\n",
    "X_test_device = X_test_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    enc_out = model_atlas.encoder(X_test_device)\n",
    "    K_chart = enc_out[0]\n",
    "    K_code = enc_out[1]\n",
    "    z_n = enc_out[2]\n",
    "    z_tex = enc_out[3]\n",
    "    enc_w = enc_out[4]\n",
    "    z_geo = enc_out[5]\n",
    "    indices = enc_out[7]\n",
    "    z_n_all = enc_out[8]\n",
    "    c_bar = enc_out[9]\n",
    "\n",
    "    recon_atlas = model_atlas(X_test_device, use_hard_routing=False)[0]\n",
    "\n",
    "z_geo_np = z_geo.cpu().numpy()\n",
    "z_n_np = z_n.cpu().numpy()\n",
    "K_chart_np = K_chart.cpu().numpy()\n",
    "K_code_np = K_code.cpu().numpy()\n",
    "\n",
    "recon_atlas_cpu = recon_atlas.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pca_project(x: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "    x_centered = x - x.mean(axis=0, keepdims=True)\n",
    "    u, s, vt = np.linalg.svd(x_centered, full_matrices=False)\n",
    "    return x_centered @ vt[:n_components].T\n",
    "\n",
    "def scatter_2d(z: np.ndarray, c: np.ndarray, title: str, cmap: str = \"tab10\"):\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.scatter(z[:, 0], z[:, 1], c=c, cmap=cmap, s=6, alpha=0.7)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"z1\")\n",
    "    ax.set_ylabel(\"z2\")\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "def scatter_3d(z: np.ndarray, c: np.ndarray, title: str, cmap: str = \"tab10\"):\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(z[:, 0], z[:, 1], z[:, 2], c=c, cmap=cmap, s=6, alpha=0.7)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"z1\")\n",
    "    ax.set_ylabel(\"z2\")\n",
    "    ax.set_zlabel(\"z3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PCA view (2D) by class and by chart\n",
    "z_pca_2d = pca_project(z_geo_np, n_components=2)\n",
    "scatter_2d(z_pca_2d, labels_np, \"Latent (PCA 2D) by class\")\n",
    "scatter_2d(z_pca_2d, K_chart_np, \"Latent (PCA 2D) by chart\", cmap=\"tab20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3D view if latent_dim >= 3\n",
    "if z_geo_np.shape[1] >= 3:\n",
    "    z_pca_3d = pca_project(z_geo_np, n_components=3)\n",
    "    scatter_3d(z_pca_3d, labels_np, \"Latent (PCA 3D) by class\")\n",
    "    scatter_3d(z_pca_3d, K_chart_np, \"Latent (PCA 3D) by chart\", cmap=\"tab20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chart usage and code usage heatmap\n",
    "num_charts = config[\"num_charts\"]\n",
    "codes_per_chart = config[\"codes_per_chart\"]\n",
    "\n",
    "chart_counts = np.bincount(K_chart_np, minlength=num_charts)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(np.arange(num_charts), chart_counts)\n",
    "plt.title(\"Chart usage\")\n",
    "plt.xlabel(\"chart\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "code_counts = np.zeros((num_charts, codes_per_chart), dtype=np.int64)\n",
    "for c, k in zip(K_chart_np, K_code_np):\n",
    "    code_counts[c, k] += 1\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(code_counts, aspect=\"auto\", cmap=\"viridis\")\n",
    "plt.colorbar(label=\"count\")\n",
    "plt.title(\"Code usage per chart\")\n",
    "plt.xlabel(\"code index\")\n",
    "plt.ylabel(\"chart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reconstruction error distribution and per-chart mean\n",
    "mse_per_sample = ((recon_atlas_cpu - X_test_tensor) ** 2).mean(dim=1).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.hist(mse_per_sample, bins=40, color=\"steelblue\", alpha=0.8)\n",
    "plt.title(\"Reconstruction MSE distribution\")\n",
    "plt.xlabel(\"mse\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "per_chart_mse = []\n",
    "for c in range(num_charts):\n",
    "    mask = K_chart_np == c\n",
    "    per_chart_mse.append(mse_per_sample[mask].mean() if mask.any() else 0.0)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(np.arange(num_charts), per_chart_mse)\n",
    "plt.title(\"Mean reconstruction MSE per chart\")\n",
    "plt.xlabel(\"chart\")\n",
    "plt.ylabel(\"mean mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chart prototypes: nearest sample to each chart centroid\n",
    "def to_image(x, shape):\n",
    "    h, w, c = shape\n",
    "    img = x.detach().cpu().numpy().reshape(h, w, c)\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "top_charts = np.argsort(chart_counts)[::-1][: min(10, num_charts)]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(top_charts), figsize=(2 * len(top_charts), 4))\n",
    "if len(top_charts) == 1:\n",
    "    axes = np.array([[axes[0]], [axes[1]]])\n",
    "\n",
    "for i, chart in enumerate(top_charts):\n",
    "    mask = K_chart_np == chart\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    chart_z = z_geo_np[mask]\n",
    "    center = chart_z.mean(axis=0)\n",
    "    idx = np.where(mask)[0]\n",
    "    nearest = idx[np.argmin(((chart_z - center) ** 2).sum(axis=1))]\n",
    "\n",
    "    axes[0, i].imshow(to_image(X_test_tensor[nearest], image_shape), cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"chart {chart}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    axes[1, i].imshow(to_image(recon_atlas_cpu[nearest], image_shape), cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"input\")\n",
    "axes[1, 0].set_ylabel(\"recon\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# z_n norm by chart\n",
    "z_n_norm = np.linalg.norm(z_n_np, axis=1)\n",
    "data_by_chart = [z_n_norm[K_chart_np == c] for c in range(num_charts)]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.boxplot(data_by_chart, showfliers=False)\n",
    "plt.title(\"z_n norm by chart\")\n",
    "plt.xlabel(\"chart\")\n",
    "plt.ylabel(\"norm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Correlation between z_geo dims and mean pixel intensity\n",
    "mean_intensity = X_test_tensor.mean(dim=1).cpu().numpy()\n",
    "correlations = []\n",
    "for d in range(z_geo_np.shape[1]):\n",
    "    corr = np.corrcoef(z_geo_np[:, d], mean_intensity)[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(np.arange(len(correlations)), correlations)\n",
    "plt.title(\"Correlation of z_geo dims with mean intensity\")\n",
    "plt.xlabel(\"latent dim\")\n",
    "plt.ylabel(\"corr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Benchmark comparison (if available)\n",
    "if model_std is not None or model_ae is not None:\n",
    "    with torch.no_grad():\n",
    "        if model_std is not None:\n",
    "            z_std = model_std.encoder(X_test_device).cpu().numpy()\n",
    "            z_std_2d = pca_project(z_std, n_components=2)\n",
    "            scatter_2d(z_std_2d, labels_np, \"StandardVQ latent (PCA 2D)\")\n",
    "        if model_ae is not None:\n",
    "            recon_ae, z_ae = model_ae(X_test_device)\n",
    "            z_ae_2d = pca_project(z_ae.cpu().numpy(), n_components=2)\n",
    "            scatter_2d(z_ae_2d, labels_np, \"VanillaAE latent (PCA 2D)\")\n",
    "\n",
    "        if model_std is not None:\n",
    "            recon_std = model_std(X_test_device)[0].cpu()\n",
    "            mse_std = ((recon_std - X_test_tensor) ** 2).mean().item()\n",
    "            print(f\"StandardVQ MSE: {mse_std:.5f}\")\n",
    "        if model_ae is not None:\n",
    "            mse_ae = ((recon_ae.cpu() - X_test_tensor) ** 2).mean().item()\n",
    "            print(f\"VanillaAE MSE: {mse_ae:.5f}\")\n",
    "\n",
    "    mse_atlas = ((recon_atlas_cpu - X_test_tensor) ** 2).mean().item()\n",
    "    print(f\"TopoEncoder MSE: {mse_atlas:.5f}\")\n",
    "else:\n",
    "    print(\"No benchmark models found in this checkpoint directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}