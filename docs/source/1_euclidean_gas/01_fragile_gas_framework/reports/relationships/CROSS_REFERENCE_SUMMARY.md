# Cross-Reference Analysis Summary

## Objective

Fill dependency fields for all 81 theorem-like entities in `raw_data/`:
- `input_objects`: Mathematical objects this result depends on
- `input_axioms`: Required axioms
- `input_parameters`: Parameters used in bounds/expressions
- `output_type`: Type of result established
- `relations_established`: Specific relationships proven

## Current Status

### Entity Inventory

**Total Entities**: 81 files
- Theorems: 30 files (`raw_data/theorems/`)
- Lemmas: 45 files (`raw_data/lemmas/`)
- Propositions: 3 files (`raw_data/propositions/`)
- Corollaries: 3 files (`raw_data/corollaries/`)

**Entities with Valid Statements**: 69 (12 skipped due to missing statement text)

### Available Framework Entities

Loaded from `raw_data/`:
- **Objects**: 37 labels (e.g., `obj-algorithmic-space-generic`, `obj-perturbation-measure`)
- **Axioms**: 5 labels (e.g., `axiom-raw-value-mean-square-continuity`)
- **Parameters**: 2 labels (`param-kappa-variance`, `param-F-V-ms`)
- **Definitions**: 31 labels (used to map definitions to objects)

## Infrastructure Created

### 1. Cross-Reference Scripts

**Location**: `/home/guillem/fragile/scripts/`

#### `cross_reference_raw_data.py`
- Basic pattern-matching cross-referencer
- Identifies explicit dependencies from existing fields
- Uses simple keyword matching for implicit dependencies
- **Status**: ✅ Complete and tested
- **Usage**: `python scripts/cross_reference_raw_data.py /path/to/raw_data`
- **Results**: Filled 22 objects, 7 axioms across 81 entities

#### `llm_cross_reference.py`
- Generates prompts for LLM analysis
- Creates context from framework entities
- Saves prompts for batch processing
- **Status**: ✅ Complete
- **Usage**: `python scripts/llm_cross_reference.py /path/to/raw_data --output-prompts /output/dir`

#### `batch_cross_reference.py`
- Batch prompt generation
- Saves prompts with metadata
- **Status**: ✅ Complete
- **Usage**: `python scripts/batch_cross_reference.py /path/to/raw_data --save-prompts /dir`

#### `gemini_batch_processor.py`
- Full batch processing system
- Generates numbered batches (batch_000, batch_001, etc.)
- Creates batch_info.json with metadata
- **Status**: ✅ Complete and tested
- **Usage**: `python scripts/gemini_batch_processor.py /path/to/raw_data --generate-batch N`

#### `apply_cross_references.py`
- Applies JSON analysis results to entity files
- Merges with existing data
- Tracks statistics
- **Status**: ✅ Complete
- **Usage**: `python scripts/apply_cross_references.py results.json /path/to/raw_data`

### 2. Generated Batches

**Location**: `/tmp/gemini_batches/`

All 69 entities with valid statements have been organized into batches:

- **batch_000**: 10 entities (corollaries + early lemmas)
- **batch_001**: 6 entities
- **batch_002**: 10 entities
- **batch_003**: 9 entities
- **batch_004**: 6 entities
- **batch_005**: 9 entities
- **batch_006**: 10 entities
- **batch_007**: 9 entities
- **batch_008**: 0 entities (all processed)

Each batch contains:
- `<label>.txt` - Gemini prompt for each entity
- `batch_info.json` - Metadata (entity files, labels, indices)

### 3. Documentation

- **CROSS_REFERENCE_WORKFLOW.md**: Complete workflow guide
- **CROSS_REFERENCE_SUMMARY.md** (this file): Current status
- **CROSS_REFERENCE_REPORT.md**: Generated by initial pattern-matching run

## Sample Analysis

### Example: lem-boundary-heat-kernel

**Input Statement**:
> Let $E=\mathcal{X}_{\mathrm{invalid}}\subset\mathcal X$ have finite perimeter and let $p_{\sigma^2}$ be the heat kernel at scale $\sigma$. Define $P_\sigma(x)=\int \chi_E(y)\,p_{\sigma^2}(x,\mathrm dy)$. Then $|P_\sigma(x)-P_\sigma(y)| \le C_d'\,\frac{\mathrm{Per}(E)}{\sigma}\, d_{\mathcal X}(x,y)$...

**Gemini 2.5 Pro Analysis**:
```json
{
  "input_objects": [
    "obj-algorithmic-space-generic",
    "obj-alg-distance",
    "obj-smoothed-gaussian-measure",
    "obj-cemetery-state-measure",
    "obj-boundary-regularity-constants",
    "obj-perturbation-constants"
  ],
  "input_axioms": [],
  "input_parameters": [],
  "output_type": "Lipschitz",
  "relations_established": [
    "Establishes that the heat-kernel-smoothed probability of entering an invalid set (P_sigma(x)) is Lipschitz continuous.",
    "Bounds the Lipschitz constant of the death probability by a term proportional to Per(E)/σ.",
    "Relates the Lipschitz constant of the death probability (L_death) in the algorithmic metric to the perimeter of the invalid set and the Lipschitz constant of the coordinate map (L_phi)."
  ]
}
```

**Quality**: High - All labels valid, comprehensive dependency identification, specific relations.

## Processing Workflow

### Recommended Approach

For each batch (batch_000 through batch_007):

1. **Read batch_info.json** to get entity list
2. **For each entity**:
   a. Read prompt from `<label>.txt`
   b. Query Gemini 2.5 Pro via MCP: `mcp__gemini-cli__ask-gemini(model="gemini-2.5-pro", prompt=...)`
   c. Parse JSON response
   d. Validate labels against available entities
   e. Save to `<label>.result.json`
3. **Collect all results** into `batch_NNN_results.json`
4. **Apply to entity files**: `python scripts/apply_cross_references.py batch_NNN_results.json /path/to/raw_data`
5. **Generate statistics** and validation report

### Time Estimates

- **Per entity** (query + review): ~2-3 minutes
- **Batch of 10**: ~20-30 minutes
- **Complete analysis** (69 entities): ~2-3 hours

### Validation Checks

For each result:
- ✓ All `input_objects` labels exist in `refined_data/objects/`
- ✓ All `input_axioms` labels exist in `raw_data/axioms/`
- ✓ All `input_parameters` labels exist in `raw_data/parameters/`
- ✓ `output_type` is one of valid categories
- ✓ `relations_established` are specific (not generic)

## Next Steps

### Immediate (Batch 000)

Process the first 10 entities to validate workflow:

```bash
# For each entity in batch_000:
# 1. Read prompt
cat /tmp/gemini_batches/batch_000/cor-chain-rule-sigma-reg-var.txt

# 2. Query Gemini (via Claude Code MCP)
# mcp__gemini-cli__ask-gemini(model="gemini-2.5-pro", prompt=<content>)

# 3. Save result
# Save JSON to /tmp/gemini_batches/batch_000/cor-chain-rule-sigma-reg-var.result.json

# 4. Collect all 10 results into batch_000_results.json

# 5. Apply to entity files
python scripts/apply_cross_references.py /tmp/gemini_batches/batch_000_results.json \
  /home/guillem/fragile/docs/source/1_euclidean_gas/01_fragile_gas_framework/raw_data
```

### Complete Analysis (Batches 001-007)

Repeat workflow for remaining 59 entities.

### Final Report

Generate comprehensive cross-reference report:
- Total dependencies filled (objects, axioms, parameters)
- Output type distribution
- Missing dependencies (if any)
- Validation summary

## File Locations

### Input
- **Entity files**: `docs/source/1_euclidean_gas/01_fragile_gas_framework/raw_data/{theorems,lemmas,propositions,corollaries}/`
- **Framework context**: `raw_data/{objects,axioms,parameters,definitions}/`

### Intermediate
- **Prompts**: `/tmp/gemini_batches/batch_NNN/<label>.txt`
- **Batch metadata**: `/tmp/gemini_batches/batch_NNN/batch_info.json`
- **Results**: `/tmp/gemini_batches/batch_NNN_results.json`

### Output
- **Updated entities**: Same as input (modified in place)
- **Final report**: `raw_data/CROSS_REFERENCE_REPORT.md`

## Scripts Summary

| Script | Purpose | Status | Output |
|--------|---------|--------|---------|
| `cross_reference_raw_data.py` | Pattern matching | ✅ Complete | Initial dependencies filled |
| `llm_cross_reference.py` | Prompt generation | ✅ Complete | Prompts for manual processing |
| `batch_cross_reference.py` | Batch prompts | ✅ Complete | Organized prompts |
| `gemini_batch_processor.py` | Full batch system | ✅ Complete | Numbered batches with metadata |
| `apply_cross_references.py` | Apply results | ✅ Complete | Updated entity JSONs |

## Statistics

### Pattern-Matching Run (Initial)
- **Entities processed**: 81
- **Objects filled**: 22
- **Axioms filled**: 7
- **Parameters filled**: 0
- **Errors**: 0

### Target (After LLM Analysis)
- **Entities processed**: 69 (with valid statements)
- **Expected objects filled**: ~200-300
- **Expected axioms filled**: ~30-50
- **Expected parameters filled**: ~10-20
- **Expected output_types filled**: 69
- **Expected relations**: ~150-200

## Quality Metrics

- **Label Accuracy**: Use only existing framework labels
- **Completeness**: Identify ALL dependencies (not just obvious ones)
- **Specificity**: Relations should be concrete, not generic
- **Consistency**: Same entities should be identified across similar theorems

## Conclusion

**Infrastructure**: ✅ Complete
**Sample Processing**: ✅ Demonstrated
**Batch Generation**: ✅ All 69 entities ready
**Next Action**: Process batches 000-007 systematically

All tools, scripts, and infrastructure are in place. The remaining work is to systematically process the 69 entities using Gemini 2.5 Pro and apply the results.
