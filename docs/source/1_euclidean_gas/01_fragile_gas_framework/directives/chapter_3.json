{
  "chapter_index": 3,
  "section_id": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
  "directive_count": 23,
  "hints": [
    {
      "directive_type": "axiom",
      "label": "axiom-instep-independence",
      "title": "Conditional product structure within a step",
      "start_line": 554,
      "end_line": 564,
      "header_lines": [
        555
      ],
      "content_start": 557,
      "content_end": 563,
      "content": "557: :label: axiom-instep-independence\n558: \n559: Fix a time $t$ and swarm state $\\mathcal S_t$. For each walker $i\\in\\{1,\\dots,N\\}$, let\n560: \n561: $$\n562: X_i \\;:=\\;\\big(U_i^{\\mathrm{comp}},\\,U_i^{\\mathrm{pert}},\\,U_i^{\\mathrm{status}},\\,U_i^{\\mathrm{clone}}\\big)\n563: $$",
      "metadata": {
        "label": "axiom-instep-independence"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "554: #### Assumption A (In\u2011Step Independence)\n555: \n556: :::{prf:axiom} Conditional product structure within a step\n557: :label: axiom-instep-independence\n558: \n559: Fix a time $t$ and swarm state $\\mathcal S_t$. For each walker $i\\in\\{1,\\dots,N\\}$, let\n560: \n561: $$\n562: X_i \\;:=\\;\\big(U_i^{\\mathrm{comp}},\\,U_i^{\\mathrm{pert}},\\,U_i^{\\mathrm{status}},\\,U_i^{\\mathrm{clone}}\\big)\n563: $$\n564: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-guaranteed-revival",
      "title": "Axiom of Guaranteed Revival",
      "start_line": 603,
      "end_line": 617,
      "header_lines": [
        604
      ],
      "content_start": 606,
      "content_end": 616,
      "content": "606: :label: axiom-guaranteed-revival\n607: \n608: *   **Core Assumption:** The cloning score generated by a dead walker must be guaranteed to exceed the maximum possible random threshold, $p_{\\max}$.\n609: *   **Axiomatic Parameter ($\\kappa_{\\text{revival}}$ - The Revival Score Ratio):** The user must provide the value of the revival score ratio, computed from their chosen parameters:\n610: \n611: \n612: \n613: $$\n614: \\kappa_{\\text{revival}} := \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}} \\cdot p_{\\max}}\n615: $$\n616: ",
      "metadata": {
        "label": "axiom-guaranteed-revival"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "603: :::\n604: \n605: :::{prf:axiom} Axiom of Guaranteed Revival\n606: :label: axiom-guaranteed-revival\n607: \n608: *   **Core Assumption:** The cloning score generated by a dead walker must be guaranteed to exceed the maximum possible random threshold, $p_{\\max}$.\n609: *   **Axiomatic Parameter ($\\kappa_{\\text{revival}}$ - The Revival Score Ratio):** The user must provide the value of the revival score ratio, computed from their chosen parameters:\n610: \n611: \n612: \n613: $$\n614: \\kappa_{\\text{revival}} := \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}} \\cdot p_{\\max}}\n615: $$\n616: \n617: *   **Condition:** For the axiom to be satisfied, the user must ensure **$\\kappa_{\\text{revival}} > 1$**."
    },
    {
      "directive_type": "theorem",
      "label": "thm-revival-guarantee",
      "title": "Almost\u2011sure revival under the global constraint",
      "start_line": 619,
      "end_line": 628,
      "header_lines": [
        620
      ],
      "content_start": 621,
      "content_end": 627,
      "content": "621: :::{prf:theorem} Almost\u2011sure revival under the global constraint\n622: :label: thm-revival-guarantee\n623: Assume the global constraint $\\varepsilon_{\\text{clone}}\\,p_{\\max} < \\eta^{\\alpha+\\beta}$. Let $\\mathcal S$ be any swarm with at least one alive walker ($|\\mathcal A(\\mathcal S)|\\ge 1$) and let $i\\in\\mathcal D(\\mathcal S)$ be dead. Then, under the cloning rule with threshold $T_{\\text{clone}}\\sim\\mathrm{Unif}(0,p_{\\max})$ and a per\u2011dead\u2011walker score $S_i$ computed from an alive companion as in \u00a716.1, we have\n624: \n625: $$\n626: \\mathbb P\\big[\\text{$i$ is revived in the cloning stage}\\big] \\;=\\;1.\n627: $$",
      "metadata": {
        "label": "thm-revival-guarantee"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "619: :::\n620: \n621: :::{prf:theorem} Almost\u2011sure revival under the global constraint\n622: :label: thm-revival-guarantee\n623: Assume the global constraint $\\varepsilon_{\\text{clone}}\\,p_{\\max} < \\eta^{\\alpha+\\beta}$. Let $\\mathcal S$ be any swarm with at least one alive walker ($|\\mathcal A(\\mathcal S)|\\ge 1$) and let $i\\in\\mathcal D(\\mathcal S)$ be dead. Then, under the cloning rule with threshold $T_{\\text{clone}}\\sim\\mathrm{Unif}(0,p_{\\max})$ and a per\u2011dead\u2011walker score $S_i$ computed from an alive companion as in \u00a716.1, we have\n624: \n625: $$\n626: \\mathbb P\\big[\\text{$i$ is revived in the cloning stage}\\big] \\;=\\;1.\n627: $$\n628: "
    },
    {
      "directive_type": "proof",
      "label": "proof-thm-revival-guarantee",
      "title": null,
      "start_line": 633,
      "end_line": 644,
      "header_lines": [
        634
      ],
      "content_start": 635,
      "content_end": 643,
      "content": "635: :::{prf:proof}\n636: :label: proof-thm-revival-guarantee\n637: Let $j\\in\\mathcal A(\\mathcal S)$ be any alive companion. By construction of the fitness potential with rescale floor $\\eta$ and weights $(\\alpha,\\beta)$, we have $V_{\\text{fit},j} \\ge \\eta^{\\alpha+\\beta}$. The cloning score of a dead walker $i$ satisfies the lower bound\n638: \n639: $$\n640: S_i \\;\\ge\\; \\frac{V_{\\text{fit},j}}{\\varepsilon_{\\text{clone}}} \\;\\ge\\; \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}.\n641: $$\n642: \n643: By the stated constraint, $\\eta^{\\alpha+\\beta}/\\varepsilon_{\\text{clone}} > p_{\\max}$, hence deterministically $S_i>p_{\\max}$. Since $T_{\\text{clone}}\\in[0,p_{\\max}]$, we have $S_i>T_{\\text{clone}}$ for every threshold draw, so $i$ is cloned with probability one. When $|\\mathcal A(\\mathcal S)|=1$, the companion of every dead walker is the unique alive index by [](#def-companion-selection-measure), and the same bound applies. This proves the claim.",
      "metadata": {
        "label": "proof-thm-revival-guarantee"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "633: This mean\u2011square continuity result is for the $k\\ge 2$ regime. The $k=1$ discontinuity is handled by the single\u2011survivor revival mechanism in \u00a716, after which analysis resumes with $k\\ge 2$.\n634: ```\n635: :::{prf:proof}\n636: :label: proof-thm-revival-guarantee\n637: Let $j\\in\\mathcal A(\\mathcal S)$ be any alive companion. By construction of the fitness potential with rescale floor $\\eta$ and weights $(\\alpha,\\beta)$, we have $V_{\\text{fit},j} \\ge \\eta^{\\alpha+\\beta}$. The cloning score of a dead walker $i$ satisfies the lower bound\n638: \n639: $$\n640: S_i \\;\\ge\\; \\frac{V_{\\text{fit},j}}{\\varepsilon_{\\text{clone}}} \\;\\ge\\; \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}.\n641: $$\n642: \n643: By the stated constraint, $\\eta^{\\alpha+\\beta}/\\varepsilon_{\\text{clone}} > p_{\\max}$, hence deterministically $S_i>p_{\\max}$. Since $T_{\\text{clone}}\\in[0,p_{\\max}]$, we have $S_i>T_{\\text{clone}}$ for every threshold draw, so $i$ is cloned with probability one. When $|\\mathcal A(\\mathcal S)|=1$, the companion of every dead walker is the unique alive index by [](#def-companion-selection-measure), and the same bound applies. This proves the claim.\n644: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-boundary-regularity",
      "title": "Axiom of Boundary Regularity",
      "start_line": 668,
      "end_line": 694,
      "header_lines": [
        669
      ],
      "content_start": 671,
      "content_end": 693,
      "content": "671: :label: axiom-boundary-regularity\n672: \n673: *   **Core Assumption:** The marginal probability of a single walker becoming invalid after the perturbation and status update stages must be a smooth (H\u00f6lder continuous) function of the initial N-particle swarm state. This axiom applies to any valid noise measure, including those with state-dependent coupling between walkers.\n674: \n675: *   **Axiomatic Parameters:** The user must provide the constants that bound this relationship, derived from their choice of **Noise Measure**, **Valid Domain**, and **Projection Map**:\n676:     1.  **$L_{\\text{death}}$ > 0 (The Boundary Instability Factor):** The H\u00f6lder constant for the marginal death probability function.\n677:     2.  **$\\alpha_B$ \u2208 (0, 1] (The Boundary Smoothing Exponent):** The H\u00f6lder exponent.\n678: \n679: *   **Condition:** Let $P(s_{\\text{out},i}=0 | \\mathcal{S})$ be the marginal probability that walker $i$ has a status of 0 after the application of the composed operator $\\Psi_{\\text{status}} \\circ \\Psi_{\\text{pert}}$ to an initial swarm state $\\mathcal{S}$. These constants must satisfy the following inequality for any two swarm states $\\mathcal{S}_1, \\mathcal{S}_2 \\in \\Sigma_N$ and for all walkers $i \\in \\{1, \\dots, N\\}$:\n680: \n681: \n682: \n683: $$\n684: |P(s_{\\text{out},i}=0 | \\mathcal{S}_1) - P(s_{\\text{out},i}=0 | \\mathcal{S}_2)| \\le L_{\\text{death}} \\cdot d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1, \\mathcal{S}_2)^{\\alpha_B}\n685: $$\n686: \n687: *   **Canonical Bounds:** When the invalid set has finite perimeter and the perturbation kernel satisfies the smoothness assumptions below, we may take explicit constants:\n688:     - **Uniform ball kernels.** Section 4.2.3 shows that for $\\mathcal P_\\sigma(x,\\cdot)$ uniform on $B(x,\\sigma)$ the death probability is Lipschitz with constant $L_{\\text{death}} \\le C_d\\,\\mathrm{Per}(\\mathcal X_{\\mathrm{invalid}})/\\sigma$ and exponent $\\alpha_B=1$ ([](#lem-boundary-uniform-ball)).\n689:     - **Gaussian/heat kernels.** Section 4.2.4 proves the analogous bound $L_{\\text{death}} \\le C'_d\\,\\mathrm{Per}(\\mathcal X_{\\mathrm{invalid}})/\\sigma$ with $\\alpha_B=1$ by convolution with the heat kernel ([](#lem-boundary-heat-kernel))).\n690:     - **Projections.** If a nontrivial projection $\\varphi$ is used, include the distortion factor from its Lipschitz constant as discussed after these lemmas.\n691: \n692: *   **Failure Mode Analysis:** A large **$L_{\\text{death}}$** indicates a \"sharp\" or unpredictable boundary in the N-particle state space. A small change in the overall swarm's configuration (either a small shift in walker positions or a single status change) could lead to a drastic change in a walker's individual survival probability. This makes the swarm's behavior near the boundary highly unstable and risks unexpected, large-scale death events that are not well-correlated with the simple displacement of individual walkers.\n693: ",
      "metadata": {
        "label": "axiom-boundary-regularity"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "668: :::\n669: \n670: :::{prf:axiom} Axiom of Boundary Regularity\n671: :label: axiom-boundary-regularity\n672: \n673: *   **Core Assumption:** The marginal probability of a single walker becoming invalid after the perturbation and status update stages must be a smooth (H\u00f6lder continuous) function of the initial N-particle swarm state. This axiom applies to any valid noise measure, including those with state-dependent coupling between walkers.\n674: \n675: *   **Axiomatic Parameters:** The user must provide the constants that bound this relationship, derived from their choice of **Noise Measure**, **Valid Domain**, and **Projection Map**:\n676:     1.  **$L_{\\text{death}}$ > 0 (The Boundary Instability Factor):** The H\u00f6lder constant for the marginal death probability function.\n677:     2.  **$\\alpha_B$ \u2208 (0, 1] (The Boundary Smoothing Exponent):** The H\u00f6lder exponent.\n678: \n679: *   **Condition:** Let $P(s_{\\text{out},i}=0 | \\mathcal{S})$ be the marginal probability that walker $i$ has a status of 0 after the application of the composed operator $\\Psi_{\\text{status}} \\circ \\Psi_{\\text{pert}}$ to an initial swarm state $\\mathcal{S}$. These constants must satisfy the following inequality for any two swarm states $\\mathcal{S}_1, \\mathcal{S}_2 \\in \\Sigma_N$ and for all walkers $i \\in \\{1, \\dots, N\\}$:\n680: \n681: \n682: \n683: $$\n684: |P(s_{\\text{out},i}=0 | \\mathcal{S}_1) - P(s_{\\text{out},i}=0 | \\mathcal{S}_2)| \\le L_{\\text{death}} \\cdot d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1, \\mathcal{S}_2)^{\\alpha_B}\n685: $$\n686: \n687: *   **Canonical Bounds:** When the invalid set has finite perimeter and the perturbation kernel satisfies the smoothness assumptions below, we may take explicit constants:\n688:     - **Uniform ball kernels.** Section 4.2.3 shows that for $\\mathcal P_\\sigma(x,\\cdot)$ uniform on $B(x,\\sigma)$ the death probability is Lipschitz with constant $L_{\\text{death}} \\le C_d\\,\\mathrm{Per}(\\mathcal X_{\\mathrm{invalid}})/\\sigma$ and exponent $\\alpha_B=1$ ([](#lem-boundary-uniform-ball)).\n689:     - **Gaussian/heat kernels.** Section 4.2.4 proves the analogous bound $L_{\\text{death}} \\le C'_d\\,\\mathrm{Per}(\\mathcal X_{\\mathrm{invalid}})/\\sigma$ with $\\alpha_B=1$ by convolution with the heat kernel ([](#lem-boundary-heat-kernel))).\n690:     - **Projections.** If a nontrivial projection $\\varphi$ is used, include the distortion factor from its Lipschitz constant as discussed after these lemmas.\n691: \n692: *   **Failure Mode Analysis:** A large **$L_{\\text{death}}$** indicates a \"sharp\" or unpredictable boundary in the N-particle state space. A small change in the overall swarm's configuration (either a small shift in walker positions or a single status change) could lead to a drastic change in a walker's individual survival probability. This makes the swarm's behavior near the boundary highly unstable and risks unexpected, large-scale death events that are not well-correlated with the simple displacement of individual walkers.\n693: \n694: :::{warning}"
    },
    {
      "directive_type": "axiom",
      "label": "axiom-boundary-smoothness",
      "title": "Axiom of Boundary Smoothness",
      "start_line": 706,
      "end_line": 717,
      "header_lines": [
        707
      ],
      "content_start": 709,
      "content_end": 716,
      "content": "709: :label: axiom-boundary-smoothness\n710: \n711: *   **Core Assumption:** The boundary of the valid domain, $\\partial \\mathcal{X}_{\\mathrm{valid}}$, must be a $(d-1)$\u2011dimensional continuously differentiable ($C^1$) submanifold of the $d$\u2011dimensional state space $\\mathcal{X}$.\n712: \n713: *   **Rationale:** This is the standard condition in geometric measure theory ensuring the boundary has Lebesgue measure zero in the ambient space. It is a critical prerequisite for proving that $\\partial \\mathcal{X}_{\\mathrm{valid}}$ is a null set for any absolutely continuous perturbation kernel, which is a key step in validating the **Axiom of Boundary Regularity**.\n714: \n715: *   **Framework Application:** This axiom serves as the formal prerequisite for establishing that the integral defining the death probability is a continuous function of the swarm state, thereby supporting the **Axiom of Boundary Regularity** ([](#axiom-boundary-regularity)).\n716: ",
      "metadata": {
        "label": "axiom-boundary-smoothness"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "706: :::\n707: \n708: :::{prf:axiom} Axiom of Boundary Smoothness\n709: :label: axiom-boundary-smoothness\n710: \n711: *   **Core Assumption:** The boundary of the valid domain, $\\partial \\mathcal{X}_{\\mathrm{valid}}$, must be a $(d-1)$\u2011dimensional continuously differentiable ($C^1$) submanifold of the $d$\u2011dimensional state space $\\mathcal{X}$.\n712: \n713: *   **Rationale:** This is the standard condition in geometric measure theory ensuring the boundary has Lebesgue measure zero in the ambient space. It is a critical prerequisite for proving that $\\partial \\mathcal{X}_{\\mathrm{valid}}$ is a null set for any absolutely continuous perturbation kernel, which is a key step in validating the **Axiom of Boundary Regularity**.\n714: \n715: *   **Framework Application:** This axiom serves as the formal prerequisite for establishing that the integral defining the death probability is a continuous function of the swarm state, thereby supporting the **Axiom of Boundary Regularity** ([](#axiom-boundary-regularity)).\n716: \n717: *   **Failure Mode Analysis:** If the boundary is not a $C^1$ submanifold (e.g., fractal or space\u2011filling), it may have positive Lebesgue measure. Then the probability of a walker landing exactly on the boundary can be non\u2011zero, the death\u2011probability function may fail to be continuous, and the continuity analysis of the swarm update operator breaks down."
    },
    {
      "directive_type": "axiom",
      "label": "axiom-environmental-richness",
      "title": "Axiom of Environmental Richness",
      "start_line": 743,
      "end_line": 761,
      "header_lines": [
        744
      ],
      "content_start": 746,
      "content_end": 760,
      "content": "746: :label: axiom-environmental-richness\n747: \n748: *   **Core Assumption:** The reward function $R$ must not be pathologically flat at a user-defined minimum length scale. The algorithm requires a guaranteed level of reward variation to learn.\n749: *   **Axiomatic Parameters:** The user must provide two parameters that quantify the learnability of the reward landscape:\n750:     1.  **$r_{\\min}$ > 0 (The Minimum Richness Scale):** The minimum radius in the algorithmic space above which the reward function is guaranteed to exhibit variance. This parameter quantifies the resolution at which the user expects to find a learnable signal.\n751:     2.  **$\\kappa_{\\text{richness}}$ (The Environmental Richness Floor):** A value that acts as a guaranteed lower bound on the variance of the reward function within any localized region of the projected valid domain *with a radius greater than or equal to $r_{\\min}$*.\n752: \n753: *   **Condition:** The user must choose $r_{\\min}$ and determine $\\kappa_{\\text{richness}}$ such that they satisfy the following inequality, which formally links the two parameters:\n754: \n755: \n756: \n757: $$\n758: \\kappa_{\\text{richness}} \\le \\inf_{y \\in \\varphi(\\mathcal{X}_{\\mathrm{valid}}), r \\ge r_{\\min}} \\left( \\text{Var}_{y' \\in B(y,r) \\cap \\varphi(\\mathcal{X}_{\\mathrm{valid}})} [R_{\\mathcal{Y}}(y')] \\right)\n759: $$\n760: ",
      "metadata": {
        "label": "axiom-environmental-richness"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "743: The algorithm cannot learn if the reward landscape is flat. The user must provide a parameter that guarantees the environment is sufficiently interesting to provide a learning signal.\n744: \n745: :::{prf:axiom} Axiom of Environmental Richness\n746: :label: axiom-environmental-richness\n747: \n748: *   **Core Assumption:** The reward function $R$ must not be pathologically flat at a user-defined minimum length scale. The algorithm requires a guaranteed level of reward variation to learn.\n749: *   **Axiomatic Parameters:** The user must provide two parameters that quantify the learnability of the reward landscape:\n750:     1.  **$r_{\\min}$ > 0 (The Minimum Richness Scale):** The minimum radius in the algorithmic space above which the reward function is guaranteed to exhibit variance. This parameter quantifies the resolution at which the user expects to find a learnable signal.\n751:     2.  **$\\kappa_{\\text{richness}}$ (The Environmental Richness Floor):** A value that acts as a guaranteed lower bound on the variance of the reward function within any localized region of the projected valid domain *with a radius greater than or equal to $r_{\\min}$*.\n752: \n753: *   **Condition:** The user must choose $r_{\\min}$ and determine $\\kappa_{\\text{richness}}$ such that they satisfy the following inequality, which formally links the two parameters:\n754: \n755: \n756: \n757: $$\n758: \\kappa_{\\text{richness}} \\le \\inf_{y \\in \\varphi(\\mathcal{X}_{\\mathrm{valid}}), r \\ge r_{\\min}} \\left( \\text{Var}_{y' \\in B(y,r) \\cap \\varphi(\\mathcal{X}_{\\mathrm{valid}})} [R_{\\mathcal{Y}}(y')] \\right)\n759: $$\n760: \n761:     The user must then ensure that their chosen scale yields a positive floor: **$\\kappa_{\\text{richness}}$ > 0**."
    },
    {
      "directive_type": "axiom",
      "label": "axiom-reward-regularity",
      "title": "Axiom of Reward Regularity",
      "start_line": 769,
      "end_line": 786,
      "header_lines": [
        770
      ],
      "content_start": 772,
      "content_end": 785,
      "content": "772: :label: axiom-reward-regularity\n773: \n774: *   **Core Assumption:** The reward function, when viewed in the algorithmic space, must be H\u00f6lder continuous.\n775: \n776: *   **Axiomatic Parameters:** The user must provide the constants that bound the reward function's smoothness:\n777:     1.  **$L_{R,\\mathcal{Y}} > 0$ (The Reward Volatility Factor):** The H\u00f6lder constant of the reward function in the algorithmic space.\n778:     2.  **$\\alpha_R \\in (0, 1]$ (The Reward Smoothing Exponent):** The H\u00f6lder exponent for the reward function on $(\\mathcal{Y},d_{\\mathcal{Y}})$.\n779: \n780: *   **Condition:** These constants must satisfy, for any $y_1, y_2 \\in \\mathcal{Y}$,\n781: \n782: \n783: $$\n784: |R_{\\mathcal{Y}}(y_1) - R_{\\mathcal{Y}}(y_2)| \\le L_{R,\\mathcal{Y}} \\cdot d_{\\mathcal{Y}}(y_1, y_2)^{\\alpha_R}.\n785: $$",
      "metadata": {
        "label": "axiom-reward-regularity"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "769: :::\n770: \n771: :::{prf:axiom} Axiom of Reward Regularity\n772: :label: axiom-reward-regularity\n773: \n774: *   **Core Assumption:** The reward function, when viewed in the algorithmic space, must be H\u00f6lder continuous.\n775: \n776: *   **Axiomatic Parameters:** The user must provide the constants that bound the reward function's smoothness:\n777:     1.  **$L_{R,\\mathcal{Y}} > 0$ (The Reward Volatility Factor):** The H\u00f6lder constant of the reward function in the algorithmic space.\n778:     2.  **$\\alpha_R \\in (0, 1]$ (The Reward Smoothing Exponent):** The H\u00f6lder exponent for the reward function on $(\\mathcal{Y},d_{\\mathcal{Y}})$.\n779: \n780: *   **Condition:** These constants must satisfy, for any $y_1, y_2 \\in \\mathcal{Y}$,\n781: \n782: \n783: $$\n784: |R_{\\mathcal{Y}}(y_1) - R_{\\mathcal{Y}}(y_2)| \\le L_{R,\\mathcal{Y}} \\cdot d_{\\mathcal{Y}}(y_1, y_2)^{\\alpha_R}.\n785: $$\n786: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-projection-compatibility",
      "title": "Projection compatibility",
      "start_line": 794,
      "end_line": 797,
      "header_lines": [
        795
      ],
      "content_start": 796,
      "content_end": 796,
      "content": "796: :::{prf:axiom} Projection compatibility",
      "metadata": {
        "label": "axiom-projection-compatibility"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "794: #### 2.2.3 Axiom of Bounded Algorithmic Diameter\n795: \n796: :::{prf:axiom} Projection compatibility\n797: :label: axiom-projection-compatibility"
    },
    {
      "directive_type": "axiom",
      "label": "axiom-bounded-algorithmic-diameter",
      "title": "Axiom of Bounded Algorithmic Diameter",
      "start_line": 804,
      "end_line": 811,
      "header_lines": [
        805
      ],
      "content_start": 807,
      "content_end": 810,
      "content": "807: :label: axiom-bounded-algorithmic-diameter\n808: \n809: - The algorithmic space $(\\mathcal{Y}, d_{\\mathcal{Y}})$ is Polish (complete, separable metric space).\n810: - Its diameter is finite: $D_{\\mathcal{Y}} := \\operatorname{diam}_{d_{\\mathcal{Y}}}(\\mathcal{Y}) < \\infty$.",
      "metadata": {
        "label": "axiom-bounded-algorithmic-diameter"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "804: :::\n805: \n806: :::{prf:axiom} Axiom of Bounded Algorithmic Diameter\n807: :label: axiom-bounded-algorithmic-diameter\n808: \n809: - The algorithmic space $(\\mathcal{Y}, d_{\\mathcal{Y}})$ is Polish (complete, separable metric space).\n810: - Its diameter is finite: $D_{\\mathcal{Y}} := \\operatorname{diam}_{d_{\\mathcal{Y}}}(\\mathcal{Y}) < \\infty$.\n811: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-range-respecting-mean",
      "title": "Range\u2011Respecting Mean",
      "start_line": 815,
      "end_line": 824,
      "header_lines": [
        816
      ],
      "content_start": 817,
      "content_end": 823,
      "content": "817: :::{prf:axiom} Range\u2011Respecting Mean\n818: :label: axiom-range-respecting-mean\n819: For any finite collection of inputs $\\{v_i\\}$, the aggregator\u2019s mean output $\\mu$ satisfies\n820: \n821: $$\n822: \\min_i v_i \\;\\le\\; \\mu \\;\\le\\; \\max_i v_i.\n823: $$",
      "metadata": {
        "label": "axiom-range-respecting-mean"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "815: #### 2.2.4 Axiom of Range\u2011Respecting Mean (Aggregators)\n816: \n817: :::{prf:axiom} Range\u2011Respecting Mean\n818: :label: axiom-range-respecting-mean\n819: For any finite collection of inputs $\\{v_i\\}$, the aggregator\u2019s mean output $\\mu$ satisfies\n820: \n821: $$\n822: \\min_i v_i \\;\\le\\; \\mu \\;\\le\\; \\max_i v_i.\n823: $$\n824: "
    },
    {
      "directive_type": "definition",
      "label": "def-valid-noise-measure",
      "title": "Valid Noise Measure",
      "start_line": 828,
      "end_line": 835,
      "header_lines": [
        829
      ],
      "content_start": 830,
      "content_end": 834,
      "content": "830: :::{prf:definition} Valid Noise Measure\n831: :label: def-valid-noise-measure\n832: A kernel $\\mathcal P_\\sigma$ (and analogously $\\mathcal Q_\\delta$) is valid if it is Feller and satisfies:\n833: - Bounded second moment in $\\mathcal Y$ with constant $M_{\\mathrm{pert}}^2$ (as used in the perturbation continuity bounds);\n834: - Boundary regularity assumptions required by the status\u2011continuity theorem (Section 14);",
      "metadata": {
        "label": "def-valid-noise-measure"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "828: ### 2.3 Algorithmic & Operator Axioms: Parameters of Dynamic Behavior\n829: \n830: :::{prf:definition} Valid Noise Measure\n831: :label: def-valid-noise-measure\n832: A kernel $\\mathcal P_\\sigma$ (and analogously $\\mathcal Q_\\delta$) is valid if it is Feller and satisfies:\n833: - Bounded second moment in $\\mathcal Y$ with constant $M_{\\mathrm{pert}}^2$ (as used in the perturbation continuity bounds);\n834: - Boundary regularity assumptions required by the status\u2011continuity theorem (Section 14);\n835: - Non\u2011degeneracy as stipulated where needed."
    },
    {
      "directive_type": "axiom",
      "label": "axiom-sufficient-amplification",
      "title": "Axiom of Sufficient Amplification",
      "start_line": 843,
      "end_line": 857,
      "header_lines": [
        844
      ],
      "content_start": 846,
      "content_end": 856,
      "content": "846: :label: axiom-sufficient-amplification\n847: \n848: *   **Core Assumption:** The dynamics weights must be configured to actively process measurement signals.\n849: *   **Axiomatic Parameter ($\\kappa_{\\text{amplification}}$ - The Amplification Strength):** The user must provide the dynamics weights $\\alpha$ and $\\beta$, from which the amplification strength is defined as:\n850: \n851: \n852: \n853: $$\n854: \\kappa_{\\text{amplification}} := \\alpha + \\beta\n855: $$\n856: ",
      "metadata": {
        "label": "axiom-sufficient-amplification"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "843: The algorithm's dynamics are driven by transforming reward and distance measurements into fitness potential. If this transformation is turned off, the algorithm stalls.\n844: \n845: :::{prf:axiom} Axiom of Sufficient Amplification\n846: :label: axiom-sufficient-amplification\n847: \n848: *   **Core Assumption:** The dynamics weights must be configured to actively process measurement signals.\n849: *   **Axiomatic Parameter ($\\kappa_{\\text{amplification}}$ - The Amplification Strength):** The user must provide the dynamics weights $\\alpha$ and $\\beta$, from which the amplification strength is defined as:\n850: \n851: \n852: \n853: $$\n854: \\kappa_{\\text{amplification}} := \\alpha + \\beta\n855: $$\n856: \n857: *   **Condition:** The user must ensure **$\\kappa_{\\text{amplification}}$ > 0**."
    },
    {
      "directive_type": "axiom",
      "label": "axiom-non-degenerate-noise",
      "title": "Axiom of Non-Degenerate Noise",
      "start_line": 863,
      "end_line": 870,
      "header_lines": [
        864
      ],
      "content_start": 866,
      "content_end": 869,
      "content": "866: :label: axiom-non-degenerate-noise\n867: \n868: *   **Core Assumption:** The **Perturbation** and **Cloning** measures must not be the Dirac delta measure.\n869: *   **Axiomatic Parameters ($\\sigma$, $\\delta$ - The Noise Scales):** The user provides these parameters directly.",
      "metadata": {
        "label": "axiom-non-degenerate-noise"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "863: The swarm relies on noise to explore the state space and prevent collapsing to a single point.\n864: \n865: :::{prf:axiom} Axiom of Non-Degenerate Noise\n866: :label: axiom-non-degenerate-noise\n867: \n868: *   **Core Assumption:** The **Perturbation** and **Cloning** measures must not be the Dirac delta measure.\n869: *   **Axiomatic Parameters ($\\sigma$, $\\delta$ - The Noise Scales):** The user provides these parameters directly.\n870: *   **Condition:** The user must ensure **$\\sigma > 0$** and **$\\delta > 0$**."
    },
    {
      "directive_type": "definition",
      "label": "def-components-mean-square-standardization-error",
      "title": "Components of Mean-Square Standardization Error",
      "start_line": 878,
      "end_line": 886,
      "header_lines": [
        879
      ],
      "content_start": 881,
      "content_end": 885,
      "content": "881: :label: def-components-mean-square-standardization-error\n882: \n883: The total expected squared error of the standardization operator, $\\mathbb{E}[\\|\\mathbf{z}(\\mathcal{S}_1, V, M) - \\mathbf{z}(\\mathcal{S}_2, V, M)\\|_2^2]$, is bounded by the sum of two components:\n884: \n885: 1.  **The Expected Squared Value Error ($E^2_{V,ms}$):** The error arising from the change in the raw value vector's probability distribution (from $V(\\mathcal{S}_1)$ to $V(\\mathcal{S}_2)$) while the swarm's structure is held fixed at $\\mathcal{S}_1$. This component quantifies the propagation of measurement stochasticity.",
      "metadata": {
        "label": "def-components-mean-square-standardization-error"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "878: To formalize this analysis, we first define the two fundamental and independent sources of error that contribute to the total mean-square error.\n879: \n880: :::{prf:definition} Components of Mean-Square Standardization Error\n881: :label: def-components-mean-square-standardization-error\n882: \n883: The total expected squared error of the standardization operator, $\\mathbb{E}[\\|\\mathbf{z}(\\mathcal{S}_1, V, M) - \\mathbf{z}(\\mathcal{S}_2, V, M)\\|_2^2]$, is bounded by the sum of two components:\n884: \n885: 1.  **The Expected Squared Value Error ($E^2_{V,ms}$):** The error arising from the change in the raw value vector's probability distribution (from $V(\\mathcal{S}_1)$ to $V(\\mathcal{S}_2)$) while the swarm's structure is held fixed at $\\mathcal{S}_1$. This component quantifies the propagation of measurement stochasticity.\n886: "
    },
    {
      "directive_type": "theorem",
      "label": "thm-mean-square-standardization-error",
      "title": "Asymptotic Behavior of the Mean-Square Standardization Error",
      "start_line": 890,
      "end_line": 910,
      "header_lines": [
        891
      ],
      "content_start": 893,
      "content_end": 909,
      "content": "893: :label: thm-mean-square-standardization-error\n894: \n895: The continuity of the **N-Dimensional Standardization Operator** $z(\\mathcal{S})$ depends on the coupled effects of two distinct error sources whose expected growth rates are summed.\n896: \n897: *   **Core Principle:** The total **expected** squared error in the standardization operator's output, $\\mathbb{E}[\\| \\mathbf{z}_1 - \\mathbf{z}_2 \\|_2^2]$, is bounded by the sum of the **Expected Squared Value Error** ($E^2_{V,ms}$) and the **Expected Squared Structural Error** ($E^2_{S,ms}$).\n898: \n899: *   **Mathematical Result (General Form):** For a large number of alive walkers, $k_1 = |\\mathcal{A}(\\mathcal{S}_1)|$, the total expected error has an asymptotic growth rate given by the sum of the growth rates of its two components:\n900: \n901: \n902: \n903: $$\n904: \\boxed{\n905:     \\mathbb{E}[\\| \\mathbf{z}_1 - \\mathbf{z}_2 \\|_2^2] \\in O(E_{V,ms}^2(k_1)) + O(E_{S,ms}^2(k_1))\n906:     }\n907: $$\n908: \n909: *   **Implications & Failure Modes:** The overall mean-square continuity of the standardization pipeline is governed by the operational regime of the swarm. The analysis reveals a critical distinction between normal operation and catastrophic collapse.",
      "metadata": {
        "label": "thm-mean-square-standardization-error"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "890: The following theorem, which is a key result of the analysis in Section 11, establishes the asymptotic behavior of these error components.\n891: \n892: :::{prf:theorem} Asymptotic Behavior of the Mean-Square Standardization Error\n893: :label: thm-mean-square-standardization-error\n894: \n895: The continuity of the **N-Dimensional Standardization Operator** $z(\\mathcal{S})$ depends on the coupled effects of two distinct error sources whose expected growth rates are summed.\n896: \n897: *   **Core Principle:** The total **expected** squared error in the standardization operator's output, $\\mathbb{E}[\\| \\mathbf{z}_1 - \\mathbf{z}_2 \\|_2^2]$, is bounded by the sum of the **Expected Squared Value Error** ($E^2_{V,ms}$) and the **Expected Squared Structural Error** ($E^2_{S,ms}$).\n898: \n899: *   **Mathematical Result (General Form):** For a large number of alive walkers, $k_1 = |\\mathcal{A}(\\mathcal{S}_1)|$, the total expected error has an asymptotic growth rate given by the sum of the growth rates of its two components:\n900: \n901: \n902: \n903: $$\n904: \\boxed{\n905:     \\mathbb{E}[\\| \\mathbf{z}_1 - \\mathbf{z}_2 \\|_2^2] \\in O(E_{V,ms}^2(k_1)) + O(E_{S,ms}^2(k_1))\n906:     }\n907: $$\n908: \n909: *   **Implications & Failure Modes:** The overall mean-square continuity of the standardization pipeline is governed by the operational regime of the swarm. The analysis reveals a critical distinction between normal operation and catastrophic collapse.\n910:     1.  **Regime 1: Normal Operation (Asymptotically Stable):** Under normal conditions where walker attrition is low and the number of status changes ($n_c$) is small, the structural error term is negligible. The dominant error is the **expected value error**, which, for the benchmark case of an empirical aggregator and distance-to-companion measurement, **is constant with respect to swarm size** ($E^2_{V,ms} \\in O(1)$). This is a powerful result, indicating that under stable conditions, the algorithm's average measurement process **does not become noisier as the swarm gets larger**. The primary bottleneck for stability in this regime is not swarm size but the **extreme sensitivity to the regularization parameter**, as all error sources are amplified by a factor of up to **$O(\\varepsilon_{\\text{std}}^{-6})$**."
    },
    {
      "directive_type": "axiom",
      "label": "axiom-bounded-relative-collapse",
      "title": "Axiom of Bounded Relative Collapse",
      "start_line": 916,
      "end_line": 928,
      "header_lines": [
        917
      ],
      "content_start": 919,
      "content_end": 927,
      "content": "919: :label: axiom-bounded-relative-collapse\n920: \n921: *   **Core Assumption:** The scaling analysis for structural error is valid only for transitions that are not catastrophically large relative to the initial swarm size.\n922: *   **Axiomatic Parameter ($c_{\\min}$ - The Relative Collapse Tolerance):** The user must provide a constant $c_{\\min} \\in (0, 1]$ that defines the minimum fraction of the swarm that must survive a transition for the structural growth exponent analysis to be considered valid.\n923: *   **Condition:** A transition from a swarm $S_1$ to $S_2$ is considered **non-catastrophic** if it satisfies:\n924: \n925: $$\n926: \\frac{|\\mathcal{A}(\\mathcal{S}_2)|}{|\\mathcal{A}(\\mathcal{S}_1)|} \\ge c_{\\min}\n927: $$",
      "metadata": {
        "label": "axiom-bounded-relative-collapse"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "916: For the framework's stability analysis to be sound, any chosen aggregation operator must satisfy the following axioms, and the user must provide the corresponding axiomatic parameters.\n917: \n918: :::{prf:axiom} Axiom of Bounded Relative Collapse\n919: :label: axiom-bounded-relative-collapse\n920: \n921: *   **Core Assumption:** The scaling analysis for structural error is valid only for transitions that are not catastrophically large relative to the initial swarm size.\n922: *   **Axiomatic Parameter ($c_{\\min}$ - The Relative Collapse Tolerance):** The user must provide a constant $c_{\\min} \\in (0, 1]$ that defines the minimum fraction of the swarm that must survive a transition for the structural growth exponent analysis to be considered valid.\n923: *   **Condition:** A transition from a swarm $S_1$ to $S_2$ is considered **non-catastrophic** if it satisfies:\n924: \n925: $$\n926: \\frac{|\\mathcal{A}(\\mathcal{S}_2)|}{|\\mathcal{A}(\\mathcal{S}_1)|} \\ge c_{\\min}\n927: $$\n928: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-bounded-deviation-variance",
      "title": "Axiom of Bounded Deviation from Aggregated Variance",
      "start_line": 930,
      "end_line": 944,
      "header_lines": [
        931
      ],
      "content_start": 933,
      "content_end": 943,
      "content": "933: :label: axiom-bounded-deviation-variance\n934: \n935: *   **Core Assumption:** The sum of squared deviations of the raw input values from the aggregator's computed mean must be controllably related to the variance computed by the aggregator itself. This prevents aggregators from producing statistical moments that are pathologically decoupled from the input data.\n936: *   **Axiomatic Parameter ($\\kappa_{\\text{var}}$ - The Variance Deviation Factor):** The user must provide a constant $\\kappa_{\\text{var}} \\geq 1$ that bounds this relationship.\n937: *   **Condition:** For any swarm state $S$ with alive set $A$ and any raw value vector $v_A$, the following must hold:\n938: \n939: $$\n940: \\sum_{i \\in \\mathcal{A}} (v_i - \\mu(\\mathcal{S}, \\mathbf{v}_{\\mathcal{A}}))^2 \\le \\kappa_{\\text{var}} \\cdot |\\mathcal{A}| \\cdot \\text{Var}[M(\\mathcal{S}, \\mathbf{v}_{\\mathcal{A}})]\n941: $$\n942: \n943: where $\\text{Var}[M]$ is the variance of the aggregator's output measure.",
      "metadata": {
        "label": "axiom-bounded-deviation-variance"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "930: :::\n931: \n932: :::{prf:axiom} Axiom of Bounded Deviation from Aggregated Variance\n933: :label: axiom-bounded-deviation-variance\n934: \n935: *   **Core Assumption:** The sum of squared deviations of the raw input values from the aggregator's computed mean must be controllably related to the variance computed by the aggregator itself. This prevents aggregators from producing statistical moments that are pathologically decoupled from the input data.\n936: *   **Axiomatic Parameter ($\\kappa_{\\text{var}}$ - The Variance Deviation Factor):** The user must provide a constant $\\kappa_{\\text{var}} \\geq 1$ that bounds this relationship.\n937: *   **Condition:** For any swarm state $S$ with alive set $A$ and any raw value vector $v_A$, the following must hold:\n938: \n939: $$\n940: \\sum_{i \\in \\mathcal{A}} (v_i - \\mu(\\mathcal{S}, \\mathbf{v}_{\\mathcal{A}}))^2 \\le \\kappa_{\\text{var}} \\cdot |\\mathcal{A}| \\cdot \\text{Var}[M(\\mathcal{S}, \\mathbf{v}_{\\mathcal{A}})]\n941: $$\n942: \n943: where $\\text{Var}[M]$ is the variance of the aggregator's output measure.\n944: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-bounded-variance-production",
      "title": "Axiom of Bounded Variance Production",
      "start_line": 946,
      "end_line": 958,
      "header_lines": [
        947
      ],
      "content_start": 949,
      "content_end": 957,
      "content": "949: :label: axiom-bounded-variance-production\n950: \n951: *   **Core Assumption:** The variance of the measure produced by the aggregation operator must itself be bounded by a function of the input value range. This prevents an aggregator from creating arbitrarily large variance from bounded inputs.\n952: *   **Axiomatic Parameter ($\\kappa_{\\text{range}}$ - The Range-to-Variance Factor):** The user must provide a constant $\\kappa_{\\text{range}} \\geq 0$.\n953: *   **Condition:** For any swarm $S$ and any value vector $v$ with components bounded by $V_{\\max}$, the aggregator $M$ must satisfy:\n954: \n955: $$\n956: \\text{Var}[M(\\mathcal{S}, \\mathbf{v})] \\le \\kappa_{\\text{range}} \\cdot V_{\\max}^2\n957: $$",
      "metadata": {
        "label": "axiom-bounded-variance-production"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "946: :::\n947: \n948: :::{prf:axiom} Axiom of Bounded Variance Production\n949: :label: axiom-bounded-variance-production\n950: \n951: *   **Core Assumption:** The variance of the measure produced by the aggregation operator must itself be bounded by a function of the input value range. This prevents an aggregator from creating arbitrarily large variance from bounded inputs.\n952: *   **Axiomatic Parameter ($\\kappa_{\\text{range}}$ - The Range-to-Variance Factor):** The user must provide a constant $\\kappa_{\\text{range}} \\geq 0$.\n953: *   **Condition:** For any swarm $S$ and any value vector $v$ with components bounded by $V_{\\max}$, the aggregator $M$ must satisfy:\n954: \n955: $$\n956: \\text{Var}[M(\\mathcal{S}, \\mathbf{v})] \\le \\kappa_{\\text{range}} \\cdot V_{\\max}^2\n957: $$\n958: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-geometric-consistency",
      "title": "Axiom of Geometric Consistency",
      "start_line": 966,
      "end_line": 989,
      "header_lines": [
        967
      ],
      "content_start": 969,
      "content_end": 988,
      "content": "969: :label: axiom-geometric-consistency\n970: \n971: *   **Core Assumption:** The algorithmic noise should be unbiased and isotropic, unless intentionally designed otherwise.\n972: *   **Axiomatic Parameters (Practical Proxies):**\n973:     1.  **$\\kappa_{\\text{drift}}$ (Anomalous Drift):** The maximum magnitude of any local drift introduced by the noise measure:\n974: \n975: \n976: \n977: $$\n978: \\kappa_{\\text{drift}} := \\sup_{x \\in \\mathcal{X}} \\|\\mathbb{E}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x' - x]\\|\n979: $$\n980: \n981:     2.  **$\\kappa_{\\text{anisotropy}}$ (Diffusion Anisotropy):** The maximum condition number of the displacement's covariance matrix:\n982: \n983: \n984: \n985: $$\n986: \\kappa_{\\text{anisotropy}} := \\sup_{x \\in \\mathcal{X}} \\frac{\\lambda_{\\max}(\\text{Cov}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x'])}{\\lambda_{\\min}(\\text{Cov}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x'])}\n987: $$\n988: ",
      "metadata": {
        "label": "axiom-geometric-consistency"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "966: This axiom requires the user to quantify how much their chosen noise measure deviates from the \"natural\" diffusion of the state space, benchmarked by the heat kernel.\n967: \n968: :::{prf:axiom} Axiom of Geometric Consistency\n969: :label: axiom-geometric-consistency\n970: \n971: *   **Core Assumption:** The algorithmic noise should be unbiased and isotropic, unless intentionally designed otherwise.\n972: *   **Axiomatic Parameters (Practical Proxies):**\n973:     1.  **$\\kappa_{\\text{drift}}$ (Anomalous Drift):** The maximum magnitude of any local drift introduced by the noise measure:\n974: \n975: \n976: \n977: $$\n978: \\kappa_{\\text{drift}} := \\sup_{x \\in \\mathcal{X}} \\|\\mathbb{E}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x' - x]\\|\n979: $$\n980: \n981:     2.  **$\\kappa_{\\text{anisotropy}}$ (Diffusion Anisotropy):** The maximum condition number of the displacement's covariance matrix:\n982: \n983: \n984: \n985: $$\n986: \\kappa_{\\text{anisotropy}} := \\sup_{x \\in \\mathcal{X}} \\frac{\\lambda_{\\max}(\\text{Cov}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x'])}{\\lambda_{\\min}(\\text{Cov}_{x' \\sim \\mathcal{P}_\\sigma(x, \\cdot)}[x'])}\n987: $$\n988: \n989: *   **Condition:** For ideal geometric consistency, **$\\kappa_{\\text{drift}}$ = 0** and **$\\kappa_{\\text{anisotropy}}$ = 1**."
    },
    {
      "directive_type": "theorem",
      "label": "thm-forced-activity",
      "title": "Theorem of Forced Activity",
      "start_line": 995,
      "end_line": 1014,
      "header_lines": [
        996,
        999,
        1000
      ],
      "content_start": 1001,
      "content_end": 1013,
      "content": "1001: :class: important\n1002: :open:\n1003: This theorem is beautiful because it guarantees the swarm can never get completely stuck! Here's the intuition:\n1004: \n1005: **The Setup**: If you have:\n1006: 1. **Spread out walkers** (covering enough space to sense reward differences)\n1007: 2. **Rich environment** (reward actually varies across space)\n1008: 3. **Non-zero amplification** (the algorithm pays attention to rewards)\n1009: 4. **Some noise** (walkers can explore)\n1010: \n1011: **The Conclusion**: Then some cloning MUST happen - the swarm can't just sit still.\n1012: \n1013: **Why it works**: Spread-out walkers in a rich environment will experience different rewards. This creates fitness differences. With amplification > 0, these differences get magnified into different cloning probabilities. Someone will always be \"fit enough\" to clone, keeping the swarm active.",
      "metadata": {
        "label": "thm-forced-activity",
        "class": "important",
        "open": ""
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "995: For the algorithm's adaptive and contractive forces to function, a swarm that is not collapsed to a single point must generate a non-zero probability of cloning. This is the engine of adaptation.\n996: \n997: :::{prf:theorem} Theorem of Forced Activity\n998: :label: thm-forced-activity\n999: \n1000: :::{admonition} The \"No Stagnation\" Guarantee\n1001: :class: important\n1002: :open:\n1003: This theorem is beautiful because it guarantees the swarm can never get completely stuck! Here's the intuition:\n1004: \n1005: **The Setup**: If you have:\n1006: 1. **Spread out walkers** (covering enough space to sense reward differences)\n1007: 2. **Rich environment** (reward actually varies across space)\n1008: 3. **Non-zero amplification** (the algorithm pays attention to rewards)\n1009: 4. **Some noise** (walkers can explore)\n1010: \n1011: **The Conclusion**: Then some cloning MUST happen - the swarm can't just sit still.\n1012: \n1013: **Why it works**: Spread-out walkers in a rich environment will experience different rewards. This creates fitness differences. With amplification > 0, these differences get magnified into different cloning probabilities. Someone will always be \"fit enough\" to clone, keeping the swarm active.\n1014: "
    },
    {
      "directive_type": "axiom",
      "label": "axiom-margin-stability",
      "title": "Axiom of Position\u2011Only Status Margin",
      "start_line": 1069,
      "end_line": 1084,
      "header_lines": [
        1070
      ],
      "content_start": 1071,
      "content_end": 1083,
      "content": "1071: :::{prf:axiom} Axiom of Position\u2011Only Status Margin\n1072: :label: axiom-margin-stability\n1073: There exists a uniform margin $r_{\\mathrm{pos}}>0$ such that for any two swarms $\\mathcal{S}_1,\\mathcal{S}_2\\in\\Sigma_N$ with\n1074: \n1075: $$\n1076: \\frac{1}{N}\\sum_{i=1}^N d_{\\mathcal Y}\\!\\big(\\varphi(x_{1,i}),\\varphi(x_{2,i})\\big)^2\\;\\le\\; r_{\\mathrm{pos}},\n1077: $$\n1078: \n1079: the alive/dead decisions are invariant under the status update:\n1080: \n1081: $$\n1082: n_c(\\mathcal{S}_1,\\mathcal{S}_2)=0.\n1083: $$",
      "metadata": {
        "label": "axiom-margin-stability"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "1069: #### 2.4.3 Axiom of Position\u2011Only Status Margin\n1070: \n1071: :::{prf:axiom} Axiom of Position\u2011Only Status Margin\n1072: :label: axiom-margin-stability\n1073: There exists a uniform margin $r_{\\mathrm{pos}}>0$ such that for any two swarms $\\mathcal{S}_1,\\mathcal{S}_2\\in\\Sigma_N$ with\n1074: \n1075: $$\n1076: \\frac{1}{N}\\sum_{i=1}^N d_{\\mathcal Y}\\!\\big(\\varphi(x_{1,i}),\\varphi(x_{2,i})\\big)^2\\;\\le\\; r_{\\mathrm{pos}},\n1077: $$\n1078: \n1079: the alive/dead decisions are invariant under the status update:\n1080: \n1081: $$\n1082: n_c(\\mathcal{S}_1,\\mathcal{S}_2)=0.\n1083: $$\n1084: "
    },
    {
      "directive_type": "remark",
      "label": "rem-margin-stability",
      "title": null,
      "start_line": 1086,
      "end_line": 1100,
      "header_lines": [
        1087
      ],
      "content_start": 1088,
      "content_end": 1099,
      "content": "1088: :::{prf:remark}\n1089: :label: rem-margin-stability\n1090: This axiom expresses a deterministic stability of the status update in terms of the positional component alone. It is strictly stronger than the trivial consequence of the identity\n1091: \n1092: $$\n1093: d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^2 = \\tfrac{1}{N}\\,\\Delta_{\\text{pos}}^2 + \\tfrac{\\lambda_{\\mathrm{status}}}{N}\\,n_c,\n1094: $$\n1095: \n1096: which would otherwise allow a tautological \u201cmargin\u201d by tuning $\\lambda_{\\mathrm{status}}$.\n1097: n_c\\;\\le\\; \\frac{N}{\\lambda_{\\mathrm{status}}}\\, d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^2,\\qquad\n1098: n_c^2\\;\\le\\; \\left(\\frac{N}{\\lambda_{\\mathrm{status}}}\\right)^2 d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^4.\n1099: ",
      "metadata": {
        "label": "rem-margin-stability"
      },
      "section": "## 3. Axiomatic Foundations: A Parametric Debugging Framework",
      "references": [],
      "raw_directive": "1086: :::\n1087: \n1088: :::{prf:remark}\n1089: :label: rem-margin-stability\n1090: This axiom expresses a deterministic stability of the status update in terms of the positional component alone. It is strictly stronger than the trivial consequence of the identity\n1091: \n1092: $$\n1093: d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^2 = \\tfrac{1}{N}\\,\\Delta_{\\text{pos}}^2 + \\tfrac{\\lambda_{\\mathrm{status}}}{N}\\,n_c,\n1094: $$\n1095: \n1096: which would otherwise allow a tautological \u201cmargin\u201d by tuning $\\lambda_{\\mathrm{status}}$.\n1097: n_c\\;\\le\\; \\frac{N}{\\lambda_{\\mathrm{status}}}\\, d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^2,\\qquad\n1098: n_c^2\\;\\le\\; \\left(\\frac{N}{\\lambda_{\\mathrm{status}}}\\right)^2 d_{\\text{Disp},\\mathcal{Y}}(\\mathcal{S}_1,\\mathcal{S}_2)^4.\n1099: \n1100: $$"
    }
  ],
  "validation": {
    "ok": true,
    "errors": []
  }
}