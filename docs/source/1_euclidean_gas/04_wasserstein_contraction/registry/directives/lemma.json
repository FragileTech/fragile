{
  "document_id": "04_wasserstein_contraction",
  "stage": "directives",
  "directive_type": "lemma",
  "generated_at": "2025-11-10T13:24:29.468565+00:00",
  "count": 7,
  "items": [
    {
      "directive_type": "lemma",
      "label": "lem-variance-decomposition",
      "title": "Variance Decomposition by Clusters",
      "start_line": 276,
      "end_line": 346,
      "header_lines": [
        277
      ],
      "content_start": 279,
      "content_end": 345,
      "content": "279: :label: lem-variance-decomposition\n280: \n281: For a swarm $S_k$ partitioned into $I_k$ (target) and $J_k$ (complement) with population fractions $f_I = |I_k|/k$ and $f_J = |J_k|/k$:\n282: \n283: $$\n284: \\text{Var}_x(S_k) = f_I \\text{Var}_x(I_k) + f_J \\text{Var}_x(J_k) + f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n285: \n286: $$\n287: \n288: where:\n289: - $\\text{Var}_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2$ (within-target variance)\n290: - $\\text{Var}_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2$ (within-complement variance)\n291: - $\\mu_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} x_i$ (target barycenter)\n292: - $\\mu_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} x_j$ (complement barycenter)\n293: \n294: **Proof:**\n295: \n296: Standard variance decomposition. The total variance is:\n297: \n298: $$\n299: \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n300: \n301: $$\n302: \n303: where $\\bar{x}_k = \\frac{1}{k}\\sum_{i=1}^k x_i = f_I \\mu_x(I_k) + f_J \\mu_x(J_k)$.\n304: \n305: Expand:\n306: \n307: $$\n308: \\begin{aligned}\n309: k \\cdot \\text{Var}_x(S_k) &= \\sum_{i \\in I_k} \\|x_i - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\bar{x}_k\\|^2 \\\\\n310: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k) + \\mu_x(I_k) - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k) + \\mu_x(J_k) - \\bar{x}_k\\|^2\n311: \\end{aligned}\n312: \n313: $$\n314: \n315: Using $\\|a + b\\|^2 = \\|a\\|^2 + 2\\langle a, b\\rangle + \\|b\\|^2$ and $\\sum_{i \\in I_k} (x_i - \\mu_x(I_k)) = 0$:\n316: \n317: $$\n318: \\begin{aligned}\n319: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2 + |I_k| \\|\\mu_x(I_k) - \\bar{x}_k\\|^2 \\\\\n320: &\\quad + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2 + |J_k| \\|\\mu_x(J_k) - \\bar{x}_k\\|^2\n321: \\end{aligned}\n322: \n323: $$\n324: \n325: Now, $\\mu_x(I_k) - \\bar{x}_k = \\mu_x(I_k) - f_I \\mu_x(I_k) - f_J \\mu_x(J_k) = f_J (\\mu_x(I_k) - \\mu_x(J_k))$.\n326: \n327: Similarly, $\\mu_x(J_k) - \\bar{x}_k = -f_I (\\mu_x(I_k) - \\mu_x(J_k))$.\n328: \n329: Therefore:\n330: \n331: $$\n332: \\begin{aligned}\n333: k \\cdot \\text{Var}_x(S_k) &= |I_k| \\text{Var}_x(I_k) + |I_k| f_J^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n334: &\\quad + |J_k| \\text{Var}_x(J_k) + |J_k| f_I^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n335: &= |I_k| \\text{Var}_x(I_k) + |J_k| \\text{Var}_x(J_k) + (|I_k| f_J^2 + |J_k| f_I^2) \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n336: \\end{aligned}\n337: \n338: $$\n339: \n340: Using $|I_k| = f_I k$ and $|J_k| = f_J k$:\n341: \n342: $$\n343: |I_k| f_J^2 + |J_k| f_I^2 = k f_I f_J^2 + k f_J f_I^2 = k f_I f_J (f_J + f_I) = k f_I f_J\n344: \n345: $$",
      "metadata": {
        "label": "lem-variance-decomposition"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "276: We first establish how variance decomposes with respect to the cluster partition.\n277: \n278: :::{prf:lemma} Variance Decomposition by Clusters\n279: :label: lem-variance-decomposition\n280: \n281: For a swarm $S_k$ partitioned into $I_k$ (target) and $J_k$ (complement) with population fractions $f_I = |I_k|/k$ and $f_J = |J_k|/k$:\n282: \n283: $$\n284: \\text{Var}_x(S_k) = f_I \\text{Var}_x(I_k) + f_J \\text{Var}_x(J_k) + f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n285: \n286: $$\n287: \n288: where:\n289: - $\\text{Var}_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2$ (within-target variance)\n290: - $\\text{Var}_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2$ (within-complement variance)\n291: - $\\mu_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} x_i$ (target barycenter)\n292: - $\\mu_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} x_j$ (complement barycenter)\n293: \n294: **Proof:**\n295: \n296: Standard variance decomposition. The total variance is:\n297: \n298: $$\n299: \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n300: \n301: $$\n302: \n303: where $\\bar{x}_k = \\frac{1}{k}\\sum_{i=1}^k x_i = f_I \\mu_x(I_k) + f_J \\mu_x(J_k)$.\n304: \n305: Expand:\n306: \n307: $$\n308: \\begin{aligned}\n309: k \\cdot \\text{Var}_x(S_k) &= \\sum_{i \\in I_k} \\|x_i - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\bar{x}_k\\|^2 \\\\\n310: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k) + \\mu_x(I_k) - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k) + \\mu_x(J_k) - \\bar{x}_k\\|^2\n311: \\end{aligned}\n312: \n313: $$\n314: \n315: Using $\\|a + b\\|^2 = \\|a\\|^2 + 2\\langle a, b\\rangle + \\|b\\|^2$ and $\\sum_{i \\in I_k} (x_i - \\mu_x(I_k)) = 0$:\n316: \n317: $$\n318: \\begin{aligned}\n319: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2 + |I_k| \\|\\mu_x(I_k) - \\bar{x}_k\\|^2 \\\\\n320: &\\quad + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2 + |J_k| \\|\\mu_x(J_k) - \\bar{x}_k\\|^2\n321: \\end{aligned}\n322: \n323: $$\n324: \n325: Now, $\\mu_x(I_k) - \\bar{x}_k = \\mu_x(I_k) - f_I \\mu_x(I_k) - f_J \\mu_x(J_k) = f_J (\\mu_x(I_k) - \\mu_x(J_k))$.\n326: \n327: Similarly, $\\mu_x(J_k) - \\bar{x}_k = -f_I (\\mu_x(I_k) - \\mu_x(J_k))$.\n328: \n329: Therefore:\n330: \n331: $$\n332: \\begin{aligned}\n333: k \\cdot \\text{Var}_x(S_k) &= |I_k| \\text{Var}_x(I_k) + |I_k| f_J^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n334: &\\quad + |J_k| \\text{Var}_x(J_k) + |J_k| f_I^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n335: &= |I_k| \\text{Var}_x(I_k) + |J_k| \\text{Var}_x(J_k) + (|I_k| f_J^2 + |J_k| f_I^2) \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n336: \\end{aligned}\n337: \n338: $$\n339: \n340: Using $|I_k| = f_I k$ and $|J_k| = f_J k$:\n341: \n342: $$\n343: |I_k| f_J^2 + |J_k| f_I^2 = k f_I f_J^2 + k f_J f_I^2 = k f_I f_J (f_J + f_I) = k f_I f_J\n344: \n345: $$\n346: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 3. Variance Decomposition and Cross-Swarm Analysis"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-cross-swarm-distance",
      "title": "Cross-Swarm Distance Decomposition",
      "start_line": 399,
      "end_line": 443,
      "header_lines": [
        400
      ],
      "content_start": 402,
      "content_end": 442,
      "content": "402: :label: lem-cross-swarm-distance\n403: \n404: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$, and separation $L = \\|\\bar{x}_1 - \\bar{x}_2\\|$, define the **population-level cross-distances**:\n405: \n406: $$\n407: \\begin{aligned}\n408: D_{II} &:= \\frac{1}{|I_1||I_2|} \\sum_{i \\in I_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n409: D_{IJ} &:= \\frac{1}{|I_1||J_2|} \\sum_{i \\in I_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2 \\\\\n410: D_{JI} &:= \\frac{1}{|J_1||I_2|} \\sum_{i \\in J_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n411: D_{JJ} &:= \\frac{1}{|J_1||J_2|} \\sum_{i \\in J_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2\n412: \\end{aligned}\n413: \n414: $$\n415: \n416: Then:\n417: \n418: $$\n419: D_{II} \\approx L^2 + \\text{Var}_x(I_1) + \\text{Var}_x(I_2) + O(L \\cdot R_I)\n420: \n421: $$\n422: \n423: where $R_I = \\max(\\text{diam}(I_1), \\text{diam}(I_2))$ and \"diam\" denotes spatial diameter.\n424: \n425: **Proof:**\n426: \n427: Expand $D_{II}$ using $\\bar{x}_1 = f_{I,1} \\mu_x(I_1) + f_{J,1} \\mu_x(J_1)$ and similarly for $\\bar{x}_2$:\n428: \n429: $$\n430: \\begin{aligned}\n431: \\|x_i - x_j\\|^2 &= \\|(x_i - \\mu_x(I_1)) + (\\mu_x(I_1) - \\bar{x}_1) + (\\bar{x}_1 - \\bar{x}_2) + (\\bar{x}_2 - \\mu_x(I_2)) + (\\mu_x(I_2) - x_j)\\|^2\n432: \\end{aligned}\n433: \n434: $$\n435: \n436: The dominant term is $\\|\\bar{x}_1 - \\bar{x}_2\\|^2 = L^2$.\n437: \n438: The cross-terms involving $(x_i - \\mu_x(I_1))$ and $(\\bar{x}_1 - \\bar{x}_2)$ vanish when averaged over $i \\in I_1$ (since $\\sum_{i \\in I_1} (x_i - \\mu_x(I_1)) = 0$).\n439: \n440: The variance terms $\\|x_i - \\mu_x(I_1)\\|^2$ and $\\|x_j - \\mu_x(I_2)\\|^2$ average to $\\text{Var}_x(I_1)$ and $\\text{Var}_x(I_2)$.\n441: \n442: The remaining terms $\\|\\mu_x(I_k) - \\bar{x}_k\\|^2 = f_{J,k}^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2$ are $O(R_I^2)$ where $R_I$ is the within-swarm separation scale.",
      "metadata": {
        "label": "lem-cross-swarm-distance"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "399: Now we analyze the Wasserstein distance between two separated swarms.\n400: \n401: :::{prf:lemma} Cross-Swarm Distance Decomposition\n402: :label: lem-cross-swarm-distance\n403: \n404: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$, and separation $L = \\|\\bar{x}_1 - \\bar{x}_2\\|$, define the **population-level cross-distances**:\n405: \n406: $$\n407: \\begin{aligned}\n408: D_{II} &:= \\frac{1}{|I_1||I_2|} \\sum_{i \\in I_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n409: D_{IJ} &:= \\frac{1}{|I_1||J_2|} \\sum_{i \\in I_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2 \\\\\n410: D_{JI} &:= \\frac{1}{|J_1||I_2|} \\sum_{i \\in J_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n411: D_{JJ} &:= \\frac{1}{|J_1||J_2|} \\sum_{i \\in J_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2\n412: \\end{aligned}\n413: \n414: $$\n415: \n416: Then:\n417: \n418: $$\n419: D_{II} \\approx L^2 + \\text{Var}_x(I_1) + \\text{Var}_x(I_2) + O(L \\cdot R_I)\n420: \n421: $$\n422: \n423: where $R_I = \\max(\\text{diam}(I_1), \\text{diam}(I_2))$ and \"diam\" denotes spatial diameter.\n424: \n425: **Proof:**\n426: \n427: Expand $D_{II}$ using $\\bar{x}_1 = f_{I,1} \\mu_x(I_1) + f_{J,1} \\mu_x(J_1)$ and similarly for $\\bar{x}_2$:\n428: \n429: $$\n430: \\begin{aligned}\n431: \\|x_i - x_j\\|^2 &= \\|(x_i - \\mu_x(I_1)) + (\\mu_x(I_1) - \\bar{x}_1) + (\\bar{x}_1 - \\bar{x}_2) + (\\bar{x}_2 - \\mu_x(I_2)) + (\\mu_x(I_2) - x_j)\\|^2\n432: \\end{aligned}\n433: \n434: $$\n435: \n436: The dominant term is $\\|\\bar{x}_1 - \\bar{x}_2\\|^2 = L^2$.\n437: \n438: The cross-terms involving $(x_i - \\mu_x(I_1))$ and $(\\bar{x}_1 - \\bar{x}_2)$ vanish when averaged over $i \\in I_1$ (since $\\sum_{i \\in I_1} (x_i - \\mu_x(I_1)) = 0$).\n439: \n440: The variance terms $\\|x_i - \\mu_x(I_1)\\|^2$ and $\\|x_j - \\mu_x(I_2)\\|^2$ average to $\\text{Var}_x(I_1)$ and $\\text{Var}_x(I_2)$.\n441: \n442: The remaining terms $\\|\\mu_x(I_k) - \\bar{x}_k\\|^2 = f_{J,k}^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2$ are $O(R_I^2)$ where $R_I$ is the within-swarm separation scale.\n443: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 3. Variance Decomposition and Cross-Swarm Analysis"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-variance-wasserstein-link",
      "title": "Structural Variance and Wasserstein Distance Relationship",
      "start_line": 445,
      "end_line": 507,
      "header_lines": [
        446
      ],
      "content_start": 448,
      "content_end": 506,
      "content": "448: :label: lem-variance-wasserstein-link\n449: \n450: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$ satisfying the separation condition $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$, the structural variance $V_{\\text{struct}}$ and squared Wasserstein-2 distance $W_2^2(\\mu_1, \\mu_2)$ satisfy:\n451: \n452: $$\n453: c_{\\text{link}}^{-} W_2^2(\\mu_1, \\mu_2) \\leq V_{\\text{struct}} \\leq c_{\\text{link}}^{+} W_2^2(\\mu_1, \\mu_2)\n454: $$\n455: \n456: where $c_{\\text{link}}^{\\pm}$ are positive constants depending on $\\varepsilon$ but not on $N$.\n457: \n458: **Proof:**\n459: \n460: **Upper bound**: By definition from [03_cloning](03_cloning) (ยง3.2), the structural variance is the position component of the hypocoercive error:\n461: \n462: $$\n463: V_{\\text{struct}} = \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n464: $$\n465: \n466: For the cluster-preserving coupling, the Wasserstein-2 distance satisfies:\n467: \n468: $$\n469: W_2^2(\\mu_1, \\mu_2) \\geq \\frac{1}{N} \\sum_{(i,j) \\text{ matched}} \\|x_{1,i} - x_{2,j}\\|^2\n470: $$\n471: \n472: For any matching, the average squared distance between matched pairs can be decomposed using the law of cosines. For separated swarms with $L \\gg R_{\\text{spread}}$:\n473: \n474: $$\n475: \\frac{1}{N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 \\approx L^2 + \\text{Var}_x(S_1) + \\text{Var}_x(S_2)\n476: $$\n477: \n478: Since both swarms have similar structural variance (by construction of the separation condition), we have $V_{\\text{struct}} \\leq 2 W_2^2(\\mu_1, \\mu_2)$ for $L$ sufficiently large.\n479: \n480: **Lower bound**: From Lemma {prf:ref}`lem-variance-decomposition` (variance decomposition) and Corollary {prf:ref}`cor-between-group-dominance` (between-group dominance), we have:\n481: \n482: $$\n483: V_{\\text{struct}} \\geq f_I f_J \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2\n484: $$\n485: \n486: For separated swarms, the Wasserstein distance is bounded below by the distance between cluster barycenters. Using the optimal transport formulation:\n487: \n488: $$\n489: W_2^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int \\|x - y\\|^2 d\\gamma(x, y)\n490: $$\n491: \n492: Since $f_I > f_{UH}(\\varepsilon) > 0$ (Theorem 7.6.1 in [03_cloning](03_cloning)), a positive fraction of both swarms' mass is in the target sets. Any coupling $\\gamma$ must transport mass from $I_1$ to $I_2$ with average squared distance at least $\\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2$.\n493: \n494: By the triangle inequality and cluster separation:\n495: \n496: $$\n497: \\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2 \\geq \\frac{1}{2}(\\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + \\|\\mu_x(I_2) - \\mu_x(J_2)\\|^2) - O(L \\cdot R_{\\text{spread}})\n498: $$\n499: \n500: For $L \\gg R_{\\text{spread}}$, combining these inequalities gives:\n501: \n502: $$\n503: W_2^2(\\mu_1, \\mu_2) \\geq f_{UH}^2 \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq \\frac{f_{UH}^2}{c_{\\text{sep}}(\\varepsilon)} V_{\\text{struct}}\n504: $$\n505: \n506: Defining $c_{\\text{link}}^{-} := f_{UH}^2 / c_{\\text{sep}}(\\varepsilon)$ and $c_{\\text{link}}^{+} := 2$ completes the proof.",
      "metadata": {
        "label": "lem-variance-wasserstein-link"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [
        "lem-variance-decomposition",
        "cor-between-group-dominance"
      ],
      "raw_directive": "445: :::\n446: \n447: :::{prf:lemma} Structural Variance and Wasserstein Distance Relationship\n448: :label: lem-variance-wasserstein-link\n449: \n450: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$ satisfying the separation condition $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$, the structural variance $V_{\\text{struct}}$ and squared Wasserstein-2 distance $W_2^2(\\mu_1, \\mu_2)$ satisfy:\n451: \n452: $$\n453: c_{\\text{link}}^{-} W_2^2(\\mu_1, \\mu_2) \\leq V_{\\text{struct}} \\leq c_{\\text{link}}^{+} W_2^2(\\mu_1, \\mu_2)\n454: $$\n455: \n456: where $c_{\\text{link}}^{\\pm}$ are positive constants depending on $\\varepsilon$ but not on $N$.\n457: \n458: **Proof:**\n459: \n460: **Upper bound**: By definition from [03_cloning](03_cloning) (ยง3.2), the structural variance is the position component of the hypocoercive error:\n461: \n462: $$\n463: V_{\\text{struct}} = \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n464: $$\n465: \n466: For the cluster-preserving coupling, the Wasserstein-2 distance satisfies:\n467: \n468: $$\n469: W_2^2(\\mu_1, \\mu_2) \\geq \\frac{1}{N} \\sum_{(i,j) \\text{ matched}} \\|x_{1,i} - x_{2,j}\\|^2\n470: $$\n471: \n472: For any matching, the average squared distance between matched pairs can be decomposed using the law of cosines. For separated swarms with $L \\gg R_{\\text{spread}}$:\n473: \n474: $$\n475: \\frac{1}{N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 \\approx L^2 + \\text{Var}_x(S_1) + \\text{Var}_x(S_2)\n476: $$\n477: \n478: Since both swarms have similar structural variance (by construction of the separation condition), we have $V_{\\text{struct}} \\leq 2 W_2^2(\\mu_1, \\mu_2)$ for $L$ sufficiently large.\n479: \n480: **Lower bound**: From Lemma {prf:ref}`lem-variance-decomposition` (variance decomposition) and Corollary {prf:ref}`cor-between-group-dominance` (between-group dominance), we have:\n481: \n482: $$\n483: V_{\\text{struct}} \\geq f_I f_J \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2\n484: $$\n485: \n486: For separated swarms, the Wasserstein distance is bounded below by the distance between cluster barycenters. Using the optimal transport formulation:\n487: \n488: $$\n489: W_2^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int \\|x - y\\|^2 d\\gamma(x, y)\n490: $$\n491: \n492: Since $f_I > f_{UH}(\\varepsilon) > 0$ (Theorem 7.6.1 in [03_cloning](03_cloning)), a positive fraction of both swarms' mass is in the target sets. Any coupling $\\gamma$ must transport mass from $I_1$ to $I_2$ with average squared distance at least $\\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2$.\n493: \n494: By the triangle inequality and cluster separation:\n495: \n496: $$\n497: \\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2 \\geq \\frac{1}{2}(\\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + \\|\\mu_x(I_2) - \\mu_x(J_2)\\|^2) - O(L \\cdot R_{\\text{spread}})\n498: $$\n499: \n500: For $L \\gg R_{\\text{spread}}$, combining these inequalities gives:\n501: \n502: $$\n503: W_2^2(\\mu_1, \\mu_2) \\geq f_{UH}^2 \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq \\frac{f_{UH}^2}{c_{\\text{sep}}(\\varepsilon)} V_{\\text{struct}}\n504: $$\n505: \n506: Defining $c_{\\text{link}}^{-} := f_{UH}^2 / c_{\\text{sep}}(\\varepsilon)$ and $c_{\\text{link}}^{+} := 2$ completes the proof.\n507: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 3. Variance Decomposition and Cross-Swarm Analysis"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-cluster-alignment",
      "title": "Cluster-Level Outlier Alignment",
      "start_line": 528,
      "end_line": 546,
      "header_lines": [
        529
      ],
      "content_start": 531,
      "content_end": 545,
      "content": "531: :label: lem-cluster-alignment\n532: \n533: For two swarms $S_1, S_2$ satisfying:\n534: 1. Structural error: $V_{\\text{struct}} > R^2_{\\text{spread}}$\n535: 2. Stability Condition holds (Theorem 7.5.2.4 in [03_cloning](03_cloning))\n536: 3. Separation: $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$\n537: \n538: The target set barycenters exhibit spatial alignment:\n539: \n540: $$\n541: \\langle \\mu_x(I_1) - \\mu_x(J_1), \\bar{x}_1 - \\bar{x}_2 \\rangle \\geq c_{\\text{align}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\| \\cdot L\n542: \n543: $$\n544: \n545: for some N-uniform constant $c_{\\text{align}}(\\varepsilon) > 0$.",
      "metadata": {
        "label": "lem-cluster-alignment"
      },
      "section": "## 4. Cluster-Level Outlier Alignment",
      "references": [],
      "raw_directive": "528: ### 4.1. Static Proof Using Framework Axioms\n529: \n530: :::{prf:lemma} Cluster-Level Outlier Alignment\n531: :label: lem-cluster-alignment\n532: \n533: For two swarms $S_1, S_2$ satisfying:\n534: 1. Structural error: $V_{\\text{struct}} > R^2_{\\text{spread}}$\n535: 2. Stability Condition holds (Theorem 7.5.2.4 in [03_cloning](03_cloning))\n536: 3. Separation: $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$\n537: \n538: The target set barycenters exhibit spatial alignment:\n539: \n540: $$\n541: \\langle \\mu_x(I_1) - \\mu_x(J_1), \\bar{x}_1 - \\bar{x}_2 \\rangle \\geq c_{\\text{align}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\| \\cdot L\n542: \n543: $$\n544: \n545: for some N-uniform constant $c_{\\text{align}}(\\varepsilon) > 0$.\n546: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 4,
        "chapter_file": "chapter_4.json",
        "section_id": "## 4. Cluster-Level Outlier Alignment"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-expected-distance-change",
      "title": "Expected Cross-Distance Change",
      "start_line": 711,
      "end_line": 764,
      "header_lines": [
        712
      ],
      "content_start": 714,
      "content_end": 763,
      "content": "714: :label: lem-expected-distance-change\n715: \n716: Under the cluster-preserving coupling {prf:ref}`def-cluster-coupling`, the expected change in population-level cross-distance $D_{IJ}$ after cloning in swarm 1 is:\n717: \n718: $$\n719: \\mathbb{E}[\\Delta D_{IJ}] \\leq -\\bar{p}_I \\cdot c_{\\text{geom}} \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + O(\\delta^2)\n720: \n721: $$\n722: \n723: where:\n724: - $\\bar{p}_I = \\frac{1}{|I_1|} \\sum_{i \\in I_1} p_{1,i}$ is the average cloning probability in target set\n725: - $c_{\\text{geom}} > 0$ is a geometric constant from the cluster alignment\n726: \n727: **Proof:**\n728: \n729: Consider a walker $i \\in I_1$ (target set) with cloning probability $p_{1,i}$.\n730: \n731: If $i$ clones from a walker $j_1 \\in J_1$ (companion in complement set), the position updates:\n732: \n733: $$\n734: x'_{1,i} = x_{1,j_1} + \\zeta_i\n735: \n736: $$\n737: \n738: where $\\zeta_i \\sim \\mathcal{N}(0, \\delta^2 I_d)$.\n739: \n740: The change in squared distance to a walker $j_2 \\in I_2$ (target set in swarm 2) is:\n741: \n742: $$\n743: \\begin{aligned}\n744: \\Delta_{ij_2} &:= \\|x'_{1,i} - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2 \\\\\n745: &= \\|x_{1,j_1} + \\zeta_i - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2\n746: \\end{aligned}\n747: \n748: $$\n749: \n750: Taking expectation over $\\zeta_i$:\n751: \n752: $$\n753: \\mathbb{E}_{\\zeta_i}[\\Delta_{ij_2}] = \\|x_{1,j_1} - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2 + d\\delta^2\n754: \n755: $$\n756: \n757: Using the identity $\\|a - c\\|^2 - \\|b - c\\|^2 = \\|a - b\\|^2 + 2\\langle a - b, b - c\\rangle$:\n758: \n759: $$\n760: \\mathbb{E}_{\\zeta_i}[\\Delta_{ij_2}] = \\|x_{1,j_1} - x_{1,i}\\|^2 + 2\\langle x_{1,j_1} - x_{1,i}, x_{1,i} - x_{2,j_2}\\rangle + d\\delta^2\n761: \n762: $$\n763: ",
      "metadata": {
        "label": "lem-expected-distance-change"
      },
      "section": "## 5. Expected Distance Change Under Cloning",
      "references": [
        "def-cluster-coupling"
      ],
      "raw_directive": "711: ### 5.1. Population-Level Cloning Dynamics\n712: \n713: :::{prf:lemma} Expected Cross-Distance Change\n714: :label: lem-expected-distance-change\n715: \n716: Under the cluster-preserving coupling {prf:ref}`def-cluster-coupling`, the expected change in population-level cross-distance $D_{IJ}$ after cloning in swarm 1 is:\n717: \n718: $$\n719: \\mathbb{E}[\\Delta D_{IJ}] \\leq -\\bar{p}_I \\cdot c_{\\text{geom}} \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + O(\\delta^2)\n720: \n721: $$\n722: \n723: where:\n724: - $\\bar{p}_I = \\frac{1}{|I_1|} \\sum_{i \\in I_1} p_{1,i}$ is the average cloning probability in target set\n725: - $c_{\\text{geom}} > 0$ is a geometric constant from the cluster alignment\n726: \n727: **Proof:**\n728: \n729: Consider a walker $i \\in I_1$ (target set) with cloning probability $p_{1,i}$.\n730: \n731: If $i$ clones from a walker $j_1 \\in J_1$ (companion in complement set), the position updates:\n732: \n733: $$\n734: x'_{1,i} = x_{1,j_1} + \\zeta_i\n735: \n736: $$\n737: \n738: where $\\zeta_i \\sim \\mathcal{N}(0, \\delta^2 I_d)$.\n739: \n740: The change in squared distance to a walker $j_2 \\in I_2$ (target set in swarm 2) is:\n741: \n742: $$\n743: \\begin{aligned}\n744: \\Delta_{ij_2} &:= \\|x'_{1,i} - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2 \\\\\n745: &= \\|x_{1,j_1} + \\zeta_i - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2\n746: \\end{aligned}\n747: \n748: $$\n749: \n750: Taking expectation over $\\zeta_i$:\n751: \n752: $$\n753: \\mathbb{E}_{\\zeta_i}[\\Delta_{ij_2}] = \\|x_{1,j_1} - x_{2,j_2}\\|^2 - \\|x_{1,i} - x_{2,j_2}\\|^2 + d\\delta^2\n754: \n755: $$\n756: \n757: Using the identity $\\|a - c\\|^2 - \\|b - c\\|^2 = \\|a - b\\|^2 + 2\\langle a - b, b - c\\rangle$:\n758: \n759: $$\n760: \\mathbb{E}_{\\zeta_i}[\\Delta_{ij_2}] = \\|x_{1,j_1} - x_{1,i}\\|^2 + 2\\langle x_{1,j_1} - x_{1,i}, x_{1,i} - x_{2,j_2}\\rangle + d\\delta^2\n761: \n762: $$\n763: \n764: :::{note}",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 5,
        "chapter_file": "chapter_5.json",
        "section_id": "## 5. Expected Distance Change Under Cloning"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-target-cloning-pressure",
      "title": "Cloning Pressure on Target Set",
      "start_line": 803,
      "end_line": 833,
      "header_lines": [
        804
      ],
      "content_start": 806,
      "content_end": 832,
      "content": "806: :label: lem-target-cloning-pressure\n807: \n808: For any walker $i \\in I_k$ (target set), the cloning probability satisfies:\n809: \n810: $$\n811: p_{k,i} \\geq p_u(\\varepsilon) > 0\n812: \n813: $$\n814: \n815: where $p_u(\\varepsilon)$ is the N-uniform constant from Lemma 8.3.2 in [03_cloning](03_cloning), line 4881.\n816: \n817: **Proof:**\n818: \n819: By definition, $I_k = U_k \\cap H_k$ where $U_k$ is the unfit set.\n820: \n821: Lemma 8.3.2 ([03_cloning](03_cloning), line 4881) states:\n822: \n823: > For any walker $i$ in the unfit set $U_k$, its total cloning probability is bounded below by a positive, N-uniform, and $\\varepsilon$-dependent constant $p_u(\\varepsilon) > 0$.\n824: \n825: Since $I_k \\subseteq U_k$, the bound applies to all $i \\in I_k$.\n826: \n827: The explicit formula (from Section 8.6.1.1, line 5334):\n828: \n829: $$\n830: p_u(\\varepsilon) = \\min\\left(1, \\frac{1}{p_{\\max}(V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}})} \\cdot \\frac{f_F f_U \\kappa_{V,\\text{gap}}(\\varepsilon)}{(k-1)(f_F + f_U^2/f_F)}\\right)\n831: \n832: $$",
      "metadata": {
        "label": "lem-target-cloning-pressure"
      },
      "section": "## 5. Expected Distance Change Under Cloning",
      "references": [],
      "raw_directive": "803: ### 5.2. Lower Bound on Average Cloning Probability\n804: \n805: :::{prf:lemma} Cloning Pressure on Target Set\n806: :label: lem-target-cloning-pressure\n807: \n808: For any walker $i \\in I_k$ (target set), the cloning probability satisfies:\n809: \n810: $$\n811: p_{k,i} \\geq p_u(\\varepsilon) > 0\n812: \n813: $$\n814: \n815: where $p_u(\\varepsilon)$ is the N-uniform constant from Lemma 8.3.2 in [03_cloning](03_cloning), line 4881.\n816: \n817: **Proof:**\n818: \n819: By definition, $I_k = U_k \\cap H_k$ where $U_k$ is the unfit set.\n820: \n821: Lemma 8.3.2 ([03_cloning](03_cloning), line 4881) states:\n822: \n823: > For any walker $i$ in the unfit set $U_k$, its total cloning probability is bounded below by a positive, N-uniform, and $\\varepsilon$-dependent constant $p_u(\\varepsilon) > 0$.\n824: \n825: Since $I_k \\subseteq U_k$, the bound applies to all $i \\in I_k$.\n826: \n827: The explicit formula (from Section 8.6.1.1, line 5334):\n828: \n829: $$\n830: p_u(\\varepsilon) = \\min\\left(1, \\frac{1}{p_{\\max}(V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}})} \\cdot \\frac{f_F f_U \\kappa_{V,\\text{gap}}(\\varepsilon)}{(k-1)(f_F + f_U^2/f_F)}\\right)\n831: \n832: $$\n833: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 5,
        "chapter_file": "chapter_5.json",
        "section_id": "## 5. Expected Distance Change Under Cloning"
      }
    },
    {
      "directive_type": "lemma",
      "label": "lem-wasserstein-population-bound",
      "title": "Wasserstein Distance and Population Cross-Distances",
      "start_line": 854,
      "end_line": 887,
      "header_lines": [
        855
      ],
      "content_start": 857,
      "content_end": 886,
      "content": "857: :label: lem-wasserstein-population-bound\n858: \n859: For two swarms with partitions $(I_1, J_1)$ and $(I_2, J_2)$, the Wasserstein-2 squared distance satisfies:\n860: \n861: $$\n862: W_2^2(\\mu_1, \\mu_2) \\leq f_{I,1} f_{I,2} D_{II} + f_{I,1} f_{J,2} D_{IJ} + f_{J,1} f_{I,2} D_{JI} + f_{J,1} f_{J,2} D_{JJ}\n863: \n864: $$\n865: \n866: where $f_{I,k} = |I_k|/N$ and $D_{AB}$ are the population cross-distances from Lemma {prf:ref}`lem-cross-swarm-distance`.\n867: \n868: **Proof:**\n869: \n870: The Wasserstein-2 distance for empirical measures is:\n871: \n872: $$\n873: W_2^2(\\mu_1, \\mu_2) = \\frac{1}{N} \\min_{\\pi \\in S_N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2\n874: \n875: $$\n876: \n877: where $S_N$ is the set of permutations.\n878: \n879: Any specific matching (not necessarily optimal) provides an upper bound. Consider the **cluster-respecting matching** that pairs $(I_1, I_2)$ internally and $(J_1, J_2)$ internally.\n880: \n881: The total squared distance for this matching is:\n882: \n883: $$\n884: \\sum_{\\text{pairs}} \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 = \\sum_{i \\in I_1, \\pi(i) \\in I_2} \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 + \\ldots\n885: \n886: $$",
      "metadata": {
        "label": "lem-wasserstein-population-bound"
      },
      "section": "## 6. Main Theorem: Wasserstein-2 Contraction",
      "references": [
        "lem-cross-swarm-distance"
      ],
      "raw_directive": "854: ### 6.1. Preliminary: Wasserstein Distance Bound\n855: \n856: :::{prf:lemma} Wasserstein Distance and Population Cross-Distances\n857: :label: lem-wasserstein-population-bound\n858: \n859: For two swarms with partitions $(I_1, J_1)$ and $(I_2, J_2)$, the Wasserstein-2 squared distance satisfies:\n860: \n861: $$\n862: W_2^2(\\mu_1, \\mu_2) \\leq f_{I,1} f_{I,2} D_{II} + f_{I,1} f_{J,2} D_{IJ} + f_{J,1} f_{I,2} D_{JI} + f_{J,1} f_{J,2} D_{JJ}\n863: \n864: $$\n865: \n866: where $f_{I,k} = |I_k|/N$ and $D_{AB}$ are the population cross-distances from Lemma {prf:ref}`lem-cross-swarm-distance`.\n867: \n868: **Proof:**\n869: \n870: The Wasserstein-2 distance for empirical measures is:\n871: \n872: $$\n873: W_2^2(\\mu_1, \\mu_2) = \\frac{1}{N} \\min_{\\pi \\in S_N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2\n874: \n875: $$\n876: \n877: where $S_N$ is the set of permutations.\n878: \n879: Any specific matching (not necessarily optimal) provides an upper bound. Consider the **cluster-respecting matching** that pairs $(I_1, I_2)$ internally and $(J_1, J_2)$ internally.\n880: \n881: The total squared distance for this matching is:\n882: \n883: $$\n884: \\sum_{\\text{pairs}} \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 = \\sum_{i \\in I_1, \\pi(i) \\in I_2} \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 + \\ldots\n885: \n886: $$\n887: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "04_wasserstein_contraction",
        "chapter_index": 6,
        "chapter_file": "chapter_6.json",
        "section_id": "## 6. Main Theorem: Wasserstein-2 Contraction"
      }
    }
  ]
}