{
  "chapter_index": 3,
  "section_id": "## 3. Variance Decomposition and Cross-Swarm Analysis",
  "directive_count": 5,
  "hints": [
    {
      "directive_type": "lemma",
      "label": "lem-variance-decomposition",
      "title": "Variance Decomposition by Clusters",
      "start_line": 276,
      "end_line": 346,
      "header_lines": [
        277
      ],
      "content_start": 279,
      "content_end": 345,
      "content": "279: :label: lem-variance-decomposition\n280: \n281: For a swarm $S_k$ partitioned into $I_k$ (target) and $J_k$ (complement) with population fractions $f_I = |I_k|/k$ and $f_J = |J_k|/k$:\n282: \n283: $$\n284: \\text{Var}_x(S_k) = f_I \\text{Var}_x(I_k) + f_J \\text{Var}_x(J_k) + f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n285: \n286: $$\n287: \n288: where:\n289: - $\\text{Var}_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2$ (within-target variance)\n290: - $\\text{Var}_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2$ (within-complement variance)\n291: - $\\mu_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} x_i$ (target barycenter)\n292: - $\\mu_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} x_j$ (complement barycenter)\n293: \n294: **Proof:**\n295: \n296: Standard variance decomposition. The total variance is:\n297: \n298: $$\n299: \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n300: \n301: $$\n302: \n303: where $\\bar{x}_k = \\frac{1}{k}\\sum_{i=1}^k x_i = f_I \\mu_x(I_k) + f_J \\mu_x(J_k)$.\n304: \n305: Expand:\n306: \n307: $$\n308: \\begin{aligned}\n309: k \\cdot \\text{Var}_x(S_k) &= \\sum_{i \\in I_k} \\|x_i - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\bar{x}_k\\|^2 \\\\\n310: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k) + \\mu_x(I_k) - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k) + \\mu_x(J_k) - \\bar{x}_k\\|^2\n311: \\end{aligned}\n312: \n313: $$\n314: \n315: Using $\\|a + b\\|^2 = \\|a\\|^2 + 2\\langle a, b\\rangle + \\|b\\|^2$ and $\\sum_{i \\in I_k} (x_i - \\mu_x(I_k)) = 0$:\n316: \n317: $$\n318: \\begin{aligned}\n319: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2 + |I_k| \\|\\mu_x(I_k) - \\bar{x}_k\\|^2 \\\\\n320: &\\quad + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2 + |J_k| \\|\\mu_x(J_k) - \\bar{x}_k\\|^2\n321: \\end{aligned}\n322: \n323: $$\n324: \n325: Now, $\\mu_x(I_k) - \\bar{x}_k = \\mu_x(I_k) - f_I \\mu_x(I_k) - f_J \\mu_x(J_k) = f_J (\\mu_x(I_k) - \\mu_x(J_k))$.\n326: \n327: Similarly, $\\mu_x(J_k) - \\bar{x}_k = -f_I (\\mu_x(I_k) - \\mu_x(J_k))$.\n328: \n329: Therefore:\n330: \n331: $$\n332: \\begin{aligned}\n333: k \\cdot \\text{Var}_x(S_k) &= |I_k| \\text{Var}_x(I_k) + |I_k| f_J^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n334: &\\quad + |J_k| \\text{Var}_x(J_k) + |J_k| f_I^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n335: &= |I_k| \\text{Var}_x(I_k) + |J_k| \\text{Var}_x(J_k) + (|I_k| f_J^2 + |J_k| f_I^2) \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n336: \\end{aligned}\n337: \n338: $$\n339: \n340: Using $|I_k| = f_I k$ and $|J_k| = f_J k$:\n341: \n342: $$\n343: |I_k| f_J^2 + |J_k| f_I^2 = k f_I f_J^2 + k f_J f_I^2 = k f_I f_J (f_J + f_I) = k f_I f_J\n344: \n345: $$",
      "metadata": {
        "label": "lem-variance-decomposition"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "276: We first establish how variance decomposes with respect to the cluster partition.\n277: \n278: :::{prf:lemma} Variance Decomposition by Clusters\n279: :label: lem-variance-decomposition\n280: \n281: For a swarm $S_k$ partitioned into $I_k$ (target) and $J_k$ (complement) with population fractions $f_I = |I_k|/k$ and $f_J = |J_k|/k$:\n282: \n283: $$\n284: \\text{Var}_x(S_k) = f_I \\text{Var}_x(I_k) + f_J \\text{Var}_x(J_k) + f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n285: \n286: $$\n287: \n288: where:\n289: - $\\text{Var}_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2$ (within-target variance)\n290: - $\\text{Var}_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2$ (within-complement variance)\n291: - $\\mu_x(I_k) = \\frac{1}{|I_k|} \\sum_{i \\in I_k} x_i$ (target barycenter)\n292: - $\\mu_x(J_k) = \\frac{1}{|J_k|} \\sum_{j \\in J_k} x_j$ (complement barycenter)\n293: \n294: **Proof:**\n295: \n296: Standard variance decomposition. The total variance is:\n297: \n298: $$\n299: \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n300: \n301: $$\n302: \n303: where $\\bar{x}_k = \\frac{1}{k}\\sum_{i=1}^k x_i = f_I \\mu_x(I_k) + f_J \\mu_x(J_k)$.\n304: \n305: Expand:\n306: \n307: $$\n308: \\begin{aligned}\n309: k \\cdot \\text{Var}_x(S_k) &= \\sum_{i \\in I_k} \\|x_i - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\bar{x}_k\\|^2 \\\\\n310: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k) + \\mu_x(I_k) - \\bar{x}_k\\|^2 + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k) + \\mu_x(J_k) - \\bar{x}_k\\|^2\n311: \\end{aligned}\n312: \n313: $$\n314: \n315: Using $\\|a + b\\|^2 = \\|a\\|^2 + 2\\langle a, b\\rangle + \\|b\\|^2$ and $\\sum_{i \\in I_k} (x_i - \\mu_x(I_k)) = 0$:\n316: \n317: $$\n318: \\begin{aligned}\n319: &= \\sum_{i \\in I_k} \\|x_i - \\mu_x(I_k)\\|^2 + |I_k| \\|\\mu_x(I_k) - \\bar{x}_k\\|^2 \\\\\n320: &\\quad + \\sum_{j \\in J_k} \\|x_j - \\mu_x(J_k)\\|^2 + |J_k| \\|\\mu_x(J_k) - \\bar{x}_k\\|^2\n321: \\end{aligned}\n322: \n323: $$\n324: \n325: Now, $\\mu_x(I_k) - \\bar{x}_k = \\mu_x(I_k) - f_I \\mu_x(I_k) - f_J \\mu_x(J_k) = f_J (\\mu_x(I_k) - \\mu_x(J_k))$.\n326: \n327: Similarly, $\\mu_x(J_k) - \\bar{x}_k = -f_I (\\mu_x(I_k) - \\mu_x(J_k))$.\n328: \n329: Therefore:\n330: \n331: $$\n332: \\begin{aligned}\n333: k \\cdot \\text{Var}_x(S_k) &= |I_k| \\text{Var}_x(I_k) + |I_k| f_J^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n334: &\\quad + |J_k| \\text{Var}_x(J_k) + |J_k| f_I^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\\\\n335: &= |I_k| \\text{Var}_x(I_k) + |J_k| \\text{Var}_x(J_k) + (|I_k| f_J^2 + |J_k| f_I^2) \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2\n336: \\end{aligned}\n337: \n338: $$\n339: \n340: Using $|I_k| = f_I k$ and $|J_k| = f_J k$:\n341: \n342: $$\n343: |I_k| f_J^2 + |J_k| f_I^2 = k f_I f_J^2 + k f_J f_I^2 = k f_I f_J (f_J + f_I) = k f_I f_J\n344: \n345: $$\n346: "
    },
    {
      "directive_type": "corollary",
      "label": "cor-between-group-dominance",
      "title": "Between-Group Variance Dominance",
      "start_line": 352,
      "end_line": 389,
      "header_lines": [
        353
      ],
      "content_start": 355,
      "content_end": 388,
      "content": "355: :label: cor-between-group-dominance\n356: \n357: For a high-error swarm satisfying $V_{\\text{struct}} > R^2_{\\text{spread}}$, the between-group variance term dominates:\n358: \n359: $$\n360: f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) V_{\\text{struct}}\n361: \n362: $$\n363: \n364: for some N-uniform constant $c_{\\text{sep}}(\\varepsilon) > 0$.\n365: \n366: **Proof:**\n367: \n368: This follows from the Phase-Space Packing Lemma (Lemma 6.4.1 in [03_cloning](03_cloning), line 2409).\n369: \n370: By the clustering construction (Definition 6.3, line 2351), the high-error set $H_k$ consists of outlier clusters with high between-cluster variance contribution. Since $I_k \\subseteq H_k$ (target set is subset of high-error), the spatial separation between $I_k$ and $J_k$ (which contains all low-error walkers $L_k$) must be substantial.\n371: \n372: Specifically, from the Phase-Space Packing Lemma with $d_{\\text{close}} = D_{\\text{diam}}(\\varepsilon) = c_d \\varepsilon$:\n373: \n374: If $\\text{Var}_h(S_k) > R^2_{\\text{pack}} := \\varepsilon^2 / 2$, then not all pairs can be close in phase space. This forces:\n375: \n376: $$\n377: \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq c_{\\text{pack}}(\\varepsilon) \\text{Var}_x(S_k)\n378: \n379: $$\n380: \n381: for some geometric constant $c_{\\text{pack}}(\\varepsilon) > 0$.\n382: \n383: Using $\\text{Var}_x(S_k) \\geq V_{\\text{struct}} / (1 + \\lambda_v)$ (position component of hypocoercive variance) and $f_I f_J \\geq f_{UH} (1 - f_{UH}) \\geq f_{UH}/2$ (for $f_{UH} \\leq 1/2$):\n384: \n385: $$\n386: f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq \\frac{f_{UH}}{2} \\cdot c_{\\text{pack}}(\\varepsilon) \\cdot \\frac{V_{\\text{struct}}}{1 + \\lambda_v} =: c_{\\text{sep}}(\\varepsilon) V_{\\text{struct}}\n387: \n388: $$",
      "metadata": {
        "label": "cor-between-group-dominance"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "352: :::\n353: \n354: :::{prf:corollary} Between-Group Variance Dominance\n355: :label: cor-between-group-dominance\n356: \n357: For a high-error swarm satisfying $V_{\\text{struct}} > R^2_{\\text{spread}}$, the between-group variance term dominates:\n358: \n359: $$\n360: f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) V_{\\text{struct}}\n361: \n362: $$\n363: \n364: for some N-uniform constant $c_{\\text{sep}}(\\varepsilon) > 0$.\n365: \n366: **Proof:**\n367: \n368: This follows from the Phase-Space Packing Lemma (Lemma 6.4.1 in [03_cloning](03_cloning), line 2409).\n369: \n370: By the clustering construction (Definition 6.3, line 2351), the high-error set $H_k$ consists of outlier clusters with high between-cluster variance contribution. Since $I_k \\subseteq H_k$ (target set is subset of high-error), the spatial separation between $I_k$ and $J_k$ (which contains all low-error walkers $L_k$) must be substantial.\n371: \n372: Specifically, from the Phase-Space Packing Lemma with $d_{\\text{close}} = D_{\\text{diam}}(\\varepsilon) = c_d \\varepsilon$:\n373: \n374: If $\\text{Var}_h(S_k) > R^2_{\\text{pack}} := \\varepsilon^2 / 2$, then not all pairs can be close in phase space. This forces:\n375: \n376: $$\n377: \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq c_{\\text{pack}}(\\varepsilon) \\text{Var}_x(S_k)\n378: \n379: $$\n380: \n381: for some geometric constant $c_{\\text{pack}}(\\varepsilon) > 0$.\n382: \n383: Using $\\text{Var}_x(S_k) \\geq V_{\\text{struct}} / (1 + \\lambda_v)$ (position component of hypocoercive variance) and $f_I f_J \\geq f_{UH} (1 - f_{UH}) \\geq f_{UH}/2$ (for $f_{UH} \\leq 1/2$):\n384: \n385: $$\n386: f_I f_J \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2 \\geq \\frac{f_{UH}}{2} \\cdot c_{\\text{pack}}(\\varepsilon) \\cdot \\frac{V_{\\text{struct}}}{1 + \\lambda_v} =: c_{\\text{sep}}(\\varepsilon) V_{\\text{struct}}\n387: \n388: $$\n389: "
    },
    {
      "directive_type": "lemma",
      "label": "lem-cross-swarm-distance",
      "title": "Cross-Swarm Distance Decomposition",
      "start_line": 399,
      "end_line": 443,
      "header_lines": [
        400
      ],
      "content_start": 402,
      "content_end": 442,
      "content": "402: :label: lem-cross-swarm-distance\n403: \n404: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$, and separation $L = \\|\\bar{x}_1 - \\bar{x}_2\\|$, define the **population-level cross-distances**:\n405: \n406: $$\n407: \\begin{aligned}\n408: D_{II} &:= \\frac{1}{|I_1||I_2|} \\sum_{i \\in I_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n409: D_{IJ} &:= \\frac{1}{|I_1||J_2|} \\sum_{i \\in I_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2 \\\\\n410: D_{JI} &:= \\frac{1}{|J_1||I_2|} \\sum_{i \\in J_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n411: D_{JJ} &:= \\frac{1}{|J_1||J_2|} \\sum_{i \\in J_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2\n412: \\end{aligned}\n413: \n414: $$\n415: \n416: Then:\n417: \n418: $$\n419: D_{II} \\approx L^2 + \\text{Var}_x(I_1) + \\text{Var}_x(I_2) + O(L \\cdot R_I)\n420: \n421: $$\n422: \n423: where $R_I = \\max(\\text{diam}(I_1), \\text{diam}(I_2))$ and \"diam\" denotes spatial diameter.\n424: \n425: **Proof:**\n426: \n427: Expand $D_{II}$ using $\\bar{x}_1 = f_{I,1} \\mu_x(I_1) + f_{J,1} \\mu_x(J_1)$ and similarly for $\\bar{x}_2$:\n428: \n429: $$\n430: \\begin{aligned}\n431: \\|x_i - x_j\\|^2 &= \\|(x_i - \\mu_x(I_1)) + (\\mu_x(I_1) - \\bar{x}_1) + (\\bar{x}_1 - \\bar{x}_2) + (\\bar{x}_2 - \\mu_x(I_2)) + (\\mu_x(I_2) - x_j)\\|^2\n432: \\end{aligned}\n433: \n434: $$\n435: \n436: The dominant term is $\\|\\bar{x}_1 - \\bar{x}_2\\|^2 = L^2$.\n437: \n438: The cross-terms involving $(x_i - \\mu_x(I_1))$ and $(\\bar{x}_1 - \\bar{x}_2)$ vanish when averaged over $i \\in I_1$ (since $\\sum_{i \\in I_1} (x_i - \\mu_x(I_1)) = 0$).\n439: \n440: The variance terms $\\|x_i - \\mu_x(I_1)\\|^2$ and $\\|x_j - \\mu_x(I_2)\\|^2$ average to $\\text{Var}_x(I_1)$ and $\\text{Var}_x(I_2)$.\n441: \n442: The remaining terms $\\|\\mu_x(I_k) - \\bar{x}_k\\|^2 = f_{J,k}^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2$ are $O(R_I^2)$ where $R_I$ is the within-swarm separation scale.",
      "metadata": {
        "label": "lem-cross-swarm-distance"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "399: Now we analyze the Wasserstein distance between two separated swarms.\n400: \n401: :::{prf:lemma} Cross-Swarm Distance Decomposition\n402: :label: lem-cross-swarm-distance\n403: \n404: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$, and separation $L = \\|\\bar{x}_1 - \\bar{x}_2\\|$, define the **population-level cross-distances**:\n405: \n406: $$\n407: \\begin{aligned}\n408: D_{II} &:= \\frac{1}{|I_1||I_2|} \\sum_{i \\in I_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n409: D_{IJ} &:= \\frac{1}{|I_1||J_2|} \\sum_{i \\in I_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2 \\\\\n410: D_{JI} &:= \\frac{1}{|J_1||I_2|} \\sum_{i \\in J_1} \\sum_{j \\in I_2} \\|x_i - x_j\\|^2 \\\\\n411: D_{JJ} &:= \\frac{1}{|J_1||J_2|} \\sum_{i \\in J_1} \\sum_{j \\in J_2} \\|x_i - x_j\\|^2\n412: \\end{aligned}\n413: \n414: $$\n415: \n416: Then:\n417: \n418: $$\n419: D_{II} \\approx L^2 + \\text{Var}_x(I_1) + \\text{Var}_x(I_2) + O(L \\cdot R_I)\n420: \n421: $$\n422: \n423: where $R_I = \\max(\\text{diam}(I_1), \\text{diam}(I_2))$ and \"diam\" denotes spatial diameter.\n424: \n425: **Proof:**\n426: \n427: Expand $D_{II}$ using $\\bar{x}_1 = f_{I,1} \\mu_x(I_1) + f_{J,1} \\mu_x(J_1)$ and similarly for $\\bar{x}_2$:\n428: \n429: $$\n430: \\begin{aligned}\n431: \\|x_i - x_j\\|^2 &= \\|(x_i - \\mu_x(I_1)) + (\\mu_x(I_1) - \\bar{x}_1) + (\\bar{x}_1 - \\bar{x}_2) + (\\bar{x}_2 - \\mu_x(I_2)) + (\\mu_x(I_2) - x_j)\\|^2\n432: \\end{aligned}\n433: \n434: $$\n435: \n436: The dominant term is $\\|\\bar{x}_1 - \\bar{x}_2\\|^2 = L^2$.\n437: \n438: The cross-terms involving $(x_i - \\mu_x(I_1))$ and $(\\bar{x}_1 - \\bar{x}_2)$ vanish when averaged over $i \\in I_1$ (since $\\sum_{i \\in I_1} (x_i - \\mu_x(I_1)) = 0$).\n439: \n440: The variance terms $\\|x_i - \\mu_x(I_1)\\|^2$ and $\\|x_j - \\mu_x(I_2)\\|^2$ average to $\\text{Var}_x(I_1)$ and $\\text{Var}_x(I_2)$.\n441: \n442: The remaining terms $\\|\\mu_x(I_k) - \\bar{x}_k\\|^2 = f_{J,k}^2 \\|\\mu_x(I_k) - \\mu_x(J_k)\\|^2$ are $O(R_I^2)$ where $R_I$ is the within-swarm separation scale.\n443: "
    },
    {
      "directive_type": "lemma",
      "label": "lem-variance-wasserstein-link",
      "title": "Structural Variance and Wasserstein Distance Relationship",
      "start_line": 445,
      "end_line": 507,
      "header_lines": [
        446
      ],
      "content_start": 448,
      "content_end": 506,
      "content": "448: :label: lem-variance-wasserstein-link\n449: \n450: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$ satisfying the separation condition $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$, the structural variance $V_{\\text{struct}}$ and squared Wasserstein-2 distance $W_2^2(\\mu_1, \\mu_2)$ satisfy:\n451: \n452: $$\n453: c_{\\text{link}}^{-} W_2^2(\\mu_1, \\mu_2) \\leq V_{\\text{struct}} \\leq c_{\\text{link}}^{+} W_2^2(\\mu_1, \\mu_2)\n454: $$\n455: \n456: where $c_{\\text{link}}^{\\pm}$ are positive constants depending on $\\varepsilon$ but not on $N$.\n457: \n458: **Proof:**\n459: \n460: **Upper bound**: By definition from [03_cloning](03_cloning) (\u00a73.2), the structural variance is the position component of the hypocoercive error:\n461: \n462: $$\n463: V_{\\text{struct}} = \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n464: $$\n465: \n466: For the cluster-preserving coupling, the Wasserstein-2 distance satisfies:\n467: \n468: $$\n469: W_2^2(\\mu_1, \\mu_2) \\geq \\frac{1}{N} \\sum_{(i,j) \\text{ matched}} \\|x_{1,i} - x_{2,j}\\|^2\n470: $$\n471: \n472: For any matching, the average squared distance between matched pairs can be decomposed using the law of cosines. For separated swarms with $L \\gg R_{\\text{spread}}$:\n473: \n474: $$\n475: \\frac{1}{N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 \\approx L^2 + \\text{Var}_x(S_1) + \\text{Var}_x(S_2)\n476: $$\n477: \n478: Since both swarms have similar structural variance (by construction of the separation condition), we have $V_{\\text{struct}} \\leq 2 W_2^2(\\mu_1, \\mu_2)$ for $L$ sufficiently large.\n479: \n480: **Lower bound**: From Lemma {prf:ref}`lem-variance-decomposition` (variance decomposition) and Corollary {prf:ref}`cor-between-group-dominance` (between-group dominance), we have:\n481: \n482: $$\n483: V_{\\text{struct}} \\geq f_I f_J \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2\n484: $$\n485: \n486: For separated swarms, the Wasserstein distance is bounded below by the distance between cluster barycenters. Using the optimal transport formulation:\n487: \n488: $$\n489: W_2^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int \\|x - y\\|^2 d\\gamma(x, y)\n490: $$\n491: \n492: Since $f_I > f_{UH}(\\varepsilon) > 0$ (Theorem 7.6.1 in [03_cloning](03_cloning)), a positive fraction of both swarms' mass is in the target sets. Any coupling $\\gamma$ must transport mass from $I_1$ to $I_2$ with average squared distance at least $\\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2$.\n493: \n494: By the triangle inequality and cluster separation:\n495: \n496: $$\n497: \\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2 \\geq \\frac{1}{2}(\\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + \\|\\mu_x(I_2) - \\mu_x(J_2)\\|^2) - O(L \\cdot R_{\\text{spread}})\n498: $$\n499: \n500: For $L \\gg R_{\\text{spread}}$, combining these inequalities gives:\n501: \n502: $$\n503: W_2^2(\\mu_1, \\mu_2) \\geq f_{UH}^2 \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq \\frac{f_{UH}^2}{c_{\\text{sep}}(\\varepsilon)} V_{\\text{struct}}\n504: $$\n505: \n506: Defining $c_{\\text{link}}^{-} := f_{UH}^2 / c_{\\text{sep}}(\\varepsilon)$ and $c_{\\text{link}}^{+} := 2$ completes the proof.",
      "metadata": {
        "label": "lem-variance-wasserstein-link"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [
        "lem-variance-decomposition",
        "cor-between-group-dominance"
      ],
      "raw_directive": "445: :::\n446: \n447: :::{prf:lemma} Structural Variance and Wasserstein Distance Relationship\n448: :label: lem-variance-wasserstein-link\n449: \n450: For two swarms $S_1, S_2$ with partitions $(I_1, J_1)$ and $(I_2, J_2)$ satisfying the separation condition $L = \\|\\bar{x}_1 - \\bar{x}_2\\| > D_{\\min}(\\varepsilon)$, the structural variance $V_{\\text{struct}}$ and squared Wasserstein-2 distance $W_2^2(\\mu_1, \\mu_2)$ satisfy:\n451: \n452: $$\n453: c_{\\text{link}}^{-} W_2^2(\\mu_1, \\mu_2) \\leq V_{\\text{struct}} \\leq c_{\\text{link}}^{+} W_2^2(\\mu_1, \\mu_2)\n454: $$\n455: \n456: where $c_{\\text{link}}^{\\pm}$ are positive constants depending on $\\varepsilon$ but not on $N$.\n457: \n458: **Proof:**\n459: \n460: **Upper bound**: By definition from [03_cloning](03_cloning) (\u00a73.2), the structural variance is the position component of the hypocoercive error:\n461: \n462: $$\n463: V_{\\text{struct}} = \\text{Var}_x(S_k) = \\frac{1}{k} \\sum_{i=1}^k \\|x_i - \\bar{x}_k\\|^2\n464: $$\n465: \n466: For the cluster-preserving coupling, the Wasserstein-2 distance satisfies:\n467: \n468: $$\n469: W_2^2(\\mu_1, \\mu_2) \\geq \\frac{1}{N} \\sum_{(i,j) \\text{ matched}} \\|x_{1,i} - x_{2,j}\\|^2\n470: $$\n471: \n472: For any matching, the average squared distance between matched pairs can be decomposed using the law of cosines. For separated swarms with $L \\gg R_{\\text{spread}}$:\n473: \n474: $$\n475: \\frac{1}{N} \\sum_{i=1}^N \\|x_{1,i} - x_{2,\\pi(i)}\\|^2 \\approx L^2 + \\text{Var}_x(S_1) + \\text{Var}_x(S_2)\n476: $$\n477: \n478: Since both swarms have similar structural variance (by construction of the separation condition), we have $V_{\\text{struct}} \\leq 2 W_2^2(\\mu_1, \\mu_2)$ for $L$ sufficiently large.\n479: \n480: **Lower bound**: From Lemma {prf:ref}`lem-variance-decomposition` (variance decomposition) and Corollary {prf:ref}`cor-between-group-dominance` (between-group dominance), we have:\n481: \n482: $$\n483: V_{\\text{struct}} \\geq f_I f_J \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq c_{\\text{sep}}(\\varepsilon) \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2\n484: $$\n485: \n486: For separated swarms, the Wasserstein distance is bounded below by the distance between cluster barycenters. Using the optimal transport formulation:\n487: \n488: $$\n489: W_2^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int \\|x - y\\|^2 d\\gamma(x, y)\n490: $$\n491: \n492: Since $f_I > f_{UH}(\\varepsilon) > 0$ (Theorem 7.6.1 in [03_cloning](03_cloning)), a positive fraction of both swarms' mass is in the target sets. Any coupling $\\gamma$ must transport mass from $I_1$ to $I_2$ with average squared distance at least $\\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2$.\n493: \n494: By the triangle inequality and cluster separation:\n495: \n496: $$\n497: \\|\\mu_x(I_1) - \\mu_x(I_2)\\|^2 \\geq \\frac{1}{2}(\\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 + \\|\\mu_x(I_2) - \\mu_x(J_2)\\|^2) - O(L \\cdot R_{\\text{spread}})\n498: $$\n499: \n500: For $L \\gg R_{\\text{spread}}$, combining these inequalities gives:\n501: \n502: $$\n503: W_2^2(\\mu_1, \\mu_2) \\geq f_{UH}^2 \\|\\mu_x(I_1) - \\mu_x(J_1)\\|^2 \\geq \\frac{f_{UH}^2}{c_{\\text{sep}}(\\varepsilon)} V_{\\text{struct}}\n504: $$\n505: \n506: Defining $c_{\\text{link}}^{-} := f_{UH}^2 / c_{\\text{sep}}(\\varepsilon)$ and $c_{\\text{link}}^{+} := 2$ completes the proof.\n507: "
    },
    {
      "directive_type": "remark",
      "label": "rem-variance-wasserstein-interpretation",
      "title": "Interpretation of the Link",
      "start_line": 509,
      "end_line": 518,
      "header_lines": [
        510
      ],
      "content_start": 512,
      "content_end": 517,
      "content": "512: :label: rem-variance-wasserstein-interpretation\n513: \n514: This lemma establishes that for separated swarms, the structural variance (internal swarm spread) and the Wasserstein distance (between-swarm measure distance) are of the same order. Both quantify the \"distance\" between the two empirical distributions, but from different perspectives:\n515: \n516: - $V_{\\text{struct}}$: Measures variance/spread of the swarm configuration\n517: - $W_2^2$: Measures optimal transport cost between measures",
      "metadata": {
        "label": "rem-variance-wasserstein-interpretation"
      },
      "section": "## 3. Variance Decomposition and Cross-Swarm Analysis",
      "references": [],
      "raw_directive": "509: :::\n510: \n511: :::{prf:remark} Interpretation of the Link\n512: :label: rem-variance-wasserstein-interpretation\n513: \n514: This lemma establishes that for separated swarms, the structural variance (internal swarm spread) and the Wasserstein distance (between-swarm measure distance) are of the same order. Both quantify the \"distance\" between the two empirical distributions, but from different perspectives:\n515: \n516: - $V_{\\text{struct}}$: Measures variance/spread of the swarm configuration\n517: - $W_2^2$: Measures optimal transport cost between measures\n518: "
    }
  ],
  "validation": {
    "ok": true,
    "errors": []
  }
}