{
  "chapter_index": 3,
  "section_id": "## 3. The Augmented Hypocoercive Lyapunov Function",
  "directive_count": 12,
  "hints": [
    {
      "directive_type": "definition",
      "label": "def-barycentres-and-centered-vectors",
      "title": "Barycentres and Centered Vectors (Alive Walkers Only)",
      "start_line": 373,
      "end_line": 426,
      "header_lines": [
        374,
        415
      ],
      "content_start": 376,
      "content_end": 425,
      "content": "376: :label: def-barycentres-and-centered-vectors\n377: \n378: For each swarm $k \\in \\{1, 2\\}$ (see {prf:ref}`def-single-swarm-space`) in a coupled state $(S_1, S_2)$, let $\\mathcal{A}(S_k)$ denote the set of alive walker indices and let $k_{\\text{alive}} := |\\mathcal{A}(S_k)|$ denote the number of alive walkers in swarm $k$. We define:\n379: \n380: 1.  The **positional center of mass** (barycentre) **computed over alive walkers only**:\n381: \n382: \n383: \n384: $$\n385: \\mu_{x,k} := \\frac{1}{k_{\\text{alive}}}\\sum_{i \\in \\mathcal{A}(S_k)} x_{k,i}\n386: $$\n387: \n388: 2.  The **velocity center of mass** **computed over alive walkers only**:\n389: \n390: \n391: \n392: $$\n393: \\mu_{v,k} := \\frac{1}{k_{\\text{alive}}}\\sum_{i \\in \\mathcal{A}(S_k)} v_{k,i}\n394: $$\n395: \n396: The **centered vectors** represent the state of each **alive** walker relative to its swarm's center of mass:\n397: \n398: 1.  The **centered position vector** for alive walker $i \\in \\mathcal{A}(S_k)$:\n399: \n400: \n401: \n402: $$\n403: \\delta_{x,k,i} := x_{k,i} - \\mu_{x,k}\n404: $$\n405: \n406: 2.  The **centered velocity vector** for alive walker $i \\in \\mathcal{A}(S_k)$:\n407: \n408: \n409: \n410: $$\n411: \\delta_{v,k,i} := v_{k,i} - \\mu_{v,k}\n412: $$\n413: \n414: **Convention**: Dead walkers ($i \\notin \\mathcal{A}(S_k)$) do not contribute to barycentres, variances, or any statistical quantities. By construction, the centered vectors for alive walkers in any swarm sum to zero: $\\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{x,k,i} = 0$ and $\\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{v,k,i} = 0$.\n415: \n416: :::{admonition} Rationale for Alive-Walker-Only Statistics\n417: :class: important\n418: \n419: Dead walkers retain their last known position $(x_i, v_i)$ but have status $s_i = 0$. Including them in statistical calculations would distort the geometric properties:\n420: \n421: 1. **Physical Interpretation**: Dead walkers represent \"failed\" exploration paths. Their positions are historical artifacts, not part of the current active swarm distribution.\n422: \n423: 2. **Cloning Operator Target**: The cloning operator $\\Psi_{\\text{clone}}$ acts on the fitness and geometric distribution of **alive** walkers. The variance it contracts is specifically the variance of the alive population.\n424: \n425: 3. **Measurement Consistency**: Distance-to-companion measurements ([](#sec:distance-measurement)) are computed from the alive-walker distribution. For consistency, all variance and barycentre calculations must use the same population.",
      "metadata": {
        "label": "def-barycentres-and-centered-vectors",
        "class": "important"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "def-single-swarm-space",
        "def-full-synergistic-lyapunov-function",
        "def-structural-error-component"
      ],
      "raw_directive": "373: We begin by formally defining the mathematical objects required for this decomposition.\n374: \n375: :::{prf:definition} Barycentres and Centered Vectors (Alive Walkers Only)\n376: :label: def-barycentres-and-centered-vectors\n377: \n378: For each swarm $k \\in \\{1, 2\\}$ (see {prf:ref}`def-single-swarm-space`) in a coupled state $(S_1, S_2)$, let $\\mathcal{A}(S_k)$ denote the set of alive walker indices and let $k_{\\text{alive}} := |\\mathcal{A}(S_k)|$ denote the number of alive walkers in swarm $k$. We define:\n379: \n380: 1.  The **positional center of mass** (barycentre) **computed over alive walkers only**:\n381: \n382: \n383: \n384: $$\n385: \\mu_{x,k} := \\frac{1}{k_{\\text{alive}}}\\sum_{i \\in \\mathcal{A}(S_k)} x_{k,i}\n386: $$\n387: \n388: 2.  The **velocity center of mass** **computed over alive walkers only**:\n389: \n390: \n391: \n392: $$\n393: \\mu_{v,k} := \\frac{1}{k_{\\text{alive}}}\\sum_{i \\in \\mathcal{A}(S_k)} v_{k,i}\n394: $$\n395: \n396: The **centered vectors** represent the state of each **alive** walker relative to its swarm's center of mass:\n397: \n398: 1.  The **centered position vector** for alive walker $i \\in \\mathcal{A}(S_k)$:\n399: \n400: \n401: \n402: $$\n403: \\delta_{x,k,i} := x_{k,i} - \\mu_{x,k}\n404: $$\n405: \n406: 2.  The **centered velocity vector** for alive walker $i \\in \\mathcal{A}(S_k)$:\n407: \n408: \n409: \n410: $$\n411: \\delta_{v,k,i} := v_{k,i} - \\mu_{v,k}\n412: $$\n413: \n414: **Convention**: Dead walkers ($i \\notin \\mathcal{A}(S_k)$) do not contribute to barycentres, variances, or any statistical quantities. By construction, the centered vectors for alive walkers in any swarm sum to zero: $\\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{x,k,i} = 0$ and $\\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{v,k,i} = 0$.\n415: \n416: :::{admonition} Rationale for Alive-Walker-Only Statistics\n417: :class: important\n418: \n419: Dead walkers retain their last known position $(x_i, v_i)$ but have status $s_i = 0$. Including them in statistical calculations would distort the geometric properties:\n420: \n421: 1. **Physical Interpretation**: Dead walkers represent \"failed\" exploration paths. Their positions are historical artifacts, not part of the current active swarm distribution.\n422: \n423: 2. **Cloning Operator Target**: The cloning operator $\\Psi_{\\text{clone}}$ acts on the fitness and geometric distribution of **alive** walkers. The variance it contracts is specifically the variance of the alive population.\n424: \n425: 3. **Measurement Consistency**: Distance-to-companion measurements ([](#sec:distance-measurement)) are computed from the alive-walker distribution. For consistency, all variance and barycentre calculations must use the same population.\n426: "
    },
    {
      "directive_type": "definition",
      "label": "def-location-error-component",
      "title": "The Location Error Component ($V_{\\text{loc}}$)",
      "start_line": 437,
      "end_line": 447,
      "header_lines": [
        438
      ],
      "content_start": 440,
      "content_end": 446,
      "content": "440: :label: def-location-error-component\n441: \n442: For any pair of swarm configurations $(S_1, S_2)$ with barycenters $(\\mu_{x,1}, \\mu_{v,1})$ and $(\\mu_{x,2}, \\mu_{v,2})$ (derived from {prf:ref}`def-state-difference-vectors`), the **location error component** is defined as:\n443: \n444: $$\n445: V_{\\text{loc}} := \\|\\Delta\\mu_x\\|^2 + \\lambda_v\\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle\n446: $$",
      "metadata": {
        "label": "def-location-error-component"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "def-state-difference-vectors"
      ],
      "raw_directive": "437: The distance between the swarms' centers of mass is an intrinsically permutation-invariant quantity. We define the location error as the hypocoercive quadratic form applied to the difference between the barycenters of the two swarms.\n438: \n439: :::{prf:definition} The Location Error Component ($V_{\\text{loc}}$)\n440: :label: def-location-error-component\n441: \n442: For any pair of swarm configurations $(S_1, S_2)$ with barycenters $(\\mu_{x,1}, \\mu_{v,1})$ and $(\\mu_{x,2}, \\mu_{v,2})$ (derived from {prf:ref}`def-state-difference-vectors`), the **location error component** is defined as:\n443: \n444: $$\n445: V_{\\text{loc}} := \\|\\Delta\\mu_x\\|^2 + \\lambda_v\\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle\n446: $$\n447: "
    },
    {
      "directive_type": "definition",
      "label": "def-structural-error-component",
      "title": "The Structural Error Component ($V_{\\text{struct}}$)",
      "start_line": 453,
      "end_line": 471,
      "header_lines": [
        454
      ],
      "content_start": 456,
      "content_end": 470,
      "content": "456: :label: def-structural-error-component\n457: \n458: Let $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$ be the centered empirical measures of swarms $S_1$ and $S_2$ **computed over alive walkers only**:\n459: \n460: $$\n461: \\tilde{\\mu}_k := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{(\\delta_{x,k,i}, \\delta_{v,k,i})}\n462: $$\n463: \n464: where $k_{\\text{alive}} = |\\mathcal{A}(S_k)|$ is the number of alive walkers in swarm $k$, and $\\delta_{x,k,i}, \\delta_{v,k,i}$ are the centered vectors defined in {prf:ref}`def-barycentres-and-centered-vectors`.\n465: \n466: The **structural error component** $V_{\\text{struct}}$ is defined as the squared hypocoercive Wasserstein distance between these centered measures:\n467: \n468: $$\n469: V_{\\text{struct}} := W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int c(\\delta_{z,1}, \\delta_{z,2}) \\, d\\gamma(\\delta_{z,1}, \\delta_{z,2})\n470: $$",
      "metadata": {
        "label": "def-structural-error-component"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "def-barycentres-and-centered-vectors"
      ],
      "raw_directive": "453: The structural error measures the mismatch between the \"shapes\" of the two swarms. The shape of a swarm is described by the set of its centered vectors, $\\{\\delta_{z,k,i}\\}$. To compare these shapes in a permutation-invariant way, we find the **optimal matching** between the centered vectors of the two swarms and measure the residual error of that matching. This is equivalent to the hypocoercive Wasserstein distance between the *centered empirical measures*.\n454: \n455: :::{prf:definition} The Structural Error Component ($V_{\\text{struct}}$)\n456: :label: def-structural-error-component\n457: \n458: Let $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$ be the centered empirical measures of swarms $S_1$ and $S_2$ **computed over alive walkers only**:\n459: \n460: $$\n461: \\tilde{\\mu}_k := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{(\\delta_{x,k,i}, \\delta_{v,k,i})}\n462: $$\n463: \n464: where $k_{\\text{alive}} = |\\mathcal{A}(S_k)|$ is the number of alive walkers in swarm $k$, and $\\delta_{x,k,i}, \\delta_{v,k,i}$ are the centered vectors defined in {prf:ref}`def-barycentres-and-centered-vectors`.\n465: \n466: The **structural error component** $V_{\\text{struct}}$ is defined as the squared hypocoercive Wasserstein distance between these centered measures:\n467: \n468: $$\n469: V_{\\text{struct}} := W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int c(\\delta_{z,1}, \\delta_{z,2}) \\, d\\gamma(\\delta_{z,1}, \\delta_{z,2})\n470: $$\n471: "
    },
    {
      "directive_type": "lemma",
      "label": "lem-wasserstein-decomposition",
      "title": "Decomposition of the Hypocoercive Wasserstein Distance",
      "start_line": 477,
      "end_line": 487,
      "header_lines": [
        478
      ],
      "content_start": 480,
      "content_end": 486,
      "content": "480: :label: lem-wasserstein-decomposition\n481: \n482: The total inter-swarm error, as measured by the squared hypocoercive Wasserstein distance $W_h^2(\\mu_1, \\mu_2)$ between the two swarms' full empirical measures $\\mu_1$ and $\\mu_2$, decomposes exactly into the sum of the location and structural error components:\n483: \n484: $$\n485: W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}\n486: $$",
      "metadata": {
        "label": "lem-wasserstein-decomposition"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "def-full-synergistic-lyapunov-function"
      ],
      "raw_directive": "477: A key result from optimal transport theory allows us to relate these components. The total distance between two distributions can be precisely decomposed into the distance between their centers of mass and the distance between their centered shapes.\n478: \n479: :::{prf:lemma} Decomposition of the Hypocoercive Wasserstein Distance\n480: :label: lem-wasserstein-decomposition\n481: \n482: The total inter-swarm error, as measured by the squared hypocoercive Wasserstein distance $W_h^2(\\mu_1, \\mu_2)$ between the two swarms' full empirical measures $\\mu_1$ and $\\mu_2$, decomposes exactly into the sum of the location and structural error components:\n483: \n484: $$\n485: W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}\n486: $$\n487: "
    },
    {
      "directive_type": "proof",
      "label": "proof-lem-wasserstein-decomposition",
      "title": null,
      "start_line": 488,
      "end_line": 626,
      "header_lines": [
        489
      ],
      "content_start": 490,
      "content_end": 625,
      "content": "490: :::{prf:proof}\n491: :label: proof-lem-wasserstein-decomposition\n492: **Proof.**\n493: \n494: This fundamental decomposition theorem for Wasserstein distances with quadratic costs is a consequence of the gluing lemma in optimal transport and the geometry of barycenters. We provide a complete proof adapted to the hypocoercive cost structure.\n495: \n496: **Step 1: Setting up notation and the cost function.**\n497: \n498: Let $\\mathcal{Z} = \\mathbb{R}^d \\times \\mathbb{R}^d$ denote the phase space (positions and velocities). For two swarms, let $\\mu_1$ and $\\mu_2$ be their empirical measures over alive walkers:\n499: \n500: $$\n501: \\mu_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{z_{k,i}}, \\quad z_{k,i} = (x_{k,i}, v_{k,i})\n502: $$\n503: \n504: The hypocoercive cost function is:\n505: \n506: $$\n507: c(z_1, z_2) = \\|x_1 - x_2\\|^2 + \\lambda_v \\|v_1 - v_2\\|^2 + b\\langle x_1 - x_2, v_1 - v_2 \\rangle\n508: $$\n509: \n510: This is a **quadratic form** in $(z_1, z_2)$, which we write as $c(z_1, z_2) = q(z_1 - z_2)$ where $q$ is the quadratic form $q(\\Delta z) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b\\langle \\Delta x, \\Delta v \\rangle$.\n511: \n512: **Step 2: Barycentric projections and centered measures.**\n513: \n514: Define the barycenters:\n515: \n516: $$\n517: \\bar{z}_k = \\int z \\, d\\mu_k(z) = (\\mu_{x,k}, \\mu_{v,k})\n518: $$\n519: \n520: For empirical measures over alive walkers, this is simply:\n521: \n522: $$\n523: \\bar{z}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} z_{k,i} = (\\mu_{x,k}, \\mu_{v,k})\n524: $$\n525: \n526: Define the **centered measures** $\\tilde{\\mu}_k$ by shifting each measure to have zero barycenter:\n527: \n528: $$\n529: \\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{z,k,i}}, \\quad \\delta_{z,k,i} = z_{k,i} - \\bar{z}_k = (\\delta_{x,k,i}, \\delta_{v,k,i})\n530: $$\n531: \n532: By construction, $\\int \\delta_z \\, d\\tilde{\\mu}_k(\\delta_z) = 0$ for both $k = 1, 2$.\n533: \n534: **Step 3: Decomposition via optimal couplings.**\n535: \n536: Let $\\gamma^* \\in \\Gamma(\\mu_1, \\mu_2)$ be an optimal coupling achieving $W_h^2(\\mu_1, \\mu_2)$. We will show that $\\gamma^*$ induces a natural coupling structure that decomposes the cost.\n537: \n538: For any coupling $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$, the total transport cost is:\n539: \n540: $$\n541: \\int_{\\mathcal{Z} \\times \\mathcal{Z}} c(z_1, z_2) \\, d\\gamma(z_1, z_2) = \\int_{\\mathcal{Z} \\times \\mathcal{Z}} q(z_1 - z_2) \\, d\\gamma(z_1, z_2)\n542: $$\n543: \n544: Since $q$ is a quadratic form, we can decompose $z_1 - z_2$ as:\n545: \n546: $$\n547: z_1 - z_2 = (z_1 - \\bar{z}_1) - (z_2 - \\bar{z}_2) + (\\bar{z}_1 - \\bar{z}_2) = \\delta_{z_1} - \\delta_{z_2} + \\Delta\\bar{z}\n548: $$\n549: \n550: where $\\Delta\\bar{z} = \\bar{z}_1 - \\bar{z}_2 = (\\Delta\\mu_x, \\Delta\\mu_v)$ is the barycenter difference and $\\delta_{z_i} = z_i - \\bar{z}_i$ are centered coordinates.\n551: \n552: **Step 4: Expanding the quadratic form.**\n553: \n554: Expanding $q(z_1 - z_2)$ using the decomposition:\n555: \n556: $$\n557: \\begin{aligned}\n558: q(z_1 - z_2) &= q(\\delta_{z_1} - \\delta_{z_2} + \\Delta\\bar{z}) \\\\\n559: &= q(\\delta_{z_1} - \\delta_{z_2}) + q(\\Delta\\bar{z}) + 2\\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q\n560: \\end{aligned}\n561: $$\n562: \n563: where $\\langle \\cdot, \\cdot \\rangle_q$ denotes the inner product associated with the quadratic form $q$ (i.e., the bilinear form such that $q(\\Delta z) = \\langle \\Delta z, \\Delta z \\rangle_q$).\n564: \n565: Integrating over the coupling $\\gamma$:\n566: \n567: $$\n568: \\begin{aligned}\n569: \\int c(z_1, z_2) \\, d\\gamma &= \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma + q(\\Delta\\bar{z}) + 2\\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q \\, d\\gamma\n570: \\end{aligned}\n571: $$\n572: \n573: **Step 5: The cross-term vanishes.**\n574: \n575: The key observation is that the cross-term vanishes:\n576: \n577: $$\n578: \\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q \\, d\\gamma = \\left\\langle \\int \\delta_{z_1} \\, d\\gamma(z_1, z_2), \\Delta\\bar{z} \\right\\rangle_q - \\left\\langle \\int \\delta_{z_2} \\, d\\gamma(z_1, z_2), \\Delta\\bar{z} \\right\\rangle_q\n579: $$\n580: \n581: For any coupling $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$, the marginals satisfy $\\gamma(\\cdot \\times \\mathcal{Z}) = \\mu_1$ and $\\gamma(\\mathcal{Z} \\times \\cdot) = \\mu_2$. Therefore:\n582: \n583: $$\n584: \\int \\delta_{z_1} \\, d\\gamma(z_1, z_2) = \\int (z_1 - \\bar{z}_1) \\, d\\gamma(z_1, z_2) = \\int z_1 \\, d\\mu_1(z_1) - \\bar{z}_1 = \\bar{z}_1 - \\bar{z}_1 = 0\n585: $$\n586: \n587: Similarly, $\\int \\delta_{z_2} \\, d\\gamma(z_1, z_2) = 0$. Thus the cross-term is zero.\n588: \n589: **Step 6: Identifying the decomposition terms.**\n590: \n591: With the cross-term eliminated:\n592: \n593: $$\n594: \\int c(z_1, z_2) \\, d\\gamma = \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma + q(\\Delta\\bar{z})\n595: $$\n596: \n597: The second term is the barycenter cost:\n598: \n599: $$\n600: q(\\Delta\\bar{z}) = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle \\Delta\\mu_x, \\Delta\\mu_v \\rangle = V_{\\text{loc}}\n601: $$\n602: \n603: The first term involves the centered coordinates. Note that $\\gamma$ induces a coupling $\\tilde{\\gamma} \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ between the centered measures via the map $(z_1, z_2) \\mapsto (\\delta_{z_1}, \\delta_{z_2})$. Thus:\n604: \n605: $$\n606: \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma(z_1, z_2) = \\int q(\\delta_{z_1}' - \\delta_{z_2}') \\, d\\tilde{\\gamma}(\\delta_{z_1}', \\delta_{z_2}')\n607: $$\n608: \n609: **Step 7: Taking the infimum.**\n610: \n611: Taking the infimum over all couplings $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$:\n612: \n613: $$\n614: W_h^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int c(z_1, z_2) \\, d\\gamma = V_{\\text{loc}} + \\inf_{\\tilde{\\gamma} \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int c(\\delta_{z_1}, \\delta_{z_2}) \\, d\\tilde{\\gamma}\n615: $$\n616: \n617: The infimum over centered couplings is precisely $W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = V_{\\text{struct}}$.\n618: \n619: **Conclusion:**\n620: \n621: $$\n622: W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}\n623: $$\n624: \n625: This decomposition is exact and holds for any pair of measures with finite second moments and any quadratic cost function.",
      "metadata": {
        "label": "proof-lem-wasserstein-decomposition"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "488: Referenced by {prf:ref}`def-full-synergistic-lyapunov-function`.\n489: :::\n490: :::{prf:proof}\n491: :label: proof-lem-wasserstein-decomposition\n492: **Proof.**\n493: \n494: This fundamental decomposition theorem for Wasserstein distances with quadratic costs is a consequence of the gluing lemma in optimal transport and the geometry of barycenters. We provide a complete proof adapted to the hypocoercive cost structure.\n495: \n496: **Step 1: Setting up notation and the cost function.**\n497: \n498: Let $\\mathcal{Z} = \\mathbb{R}^d \\times \\mathbb{R}^d$ denote the phase space (positions and velocities). For two swarms, let $\\mu_1$ and $\\mu_2$ be their empirical measures over alive walkers:\n499: \n500: $$\n501: \\mu_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{z_{k,i}}, \\quad z_{k,i} = (x_{k,i}, v_{k,i})\n502: $$\n503: \n504: The hypocoercive cost function is:\n505: \n506: $$\n507: c(z_1, z_2) = \\|x_1 - x_2\\|^2 + \\lambda_v \\|v_1 - v_2\\|^2 + b\\langle x_1 - x_2, v_1 - v_2 \\rangle\n508: $$\n509: \n510: This is a **quadratic form** in $(z_1, z_2)$, which we write as $c(z_1, z_2) = q(z_1 - z_2)$ where $q$ is the quadratic form $q(\\Delta z) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b\\langle \\Delta x, \\Delta v \\rangle$.\n511: \n512: **Step 2: Barycentric projections and centered measures.**\n513: \n514: Define the barycenters:\n515: \n516: $$\n517: \\bar{z}_k = \\int z \\, d\\mu_k(z) = (\\mu_{x,k}, \\mu_{v,k})\n518: $$\n519: \n520: For empirical measures over alive walkers, this is simply:\n521: \n522: $$\n523: \\bar{z}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} z_{k,i} = (\\mu_{x,k}, \\mu_{v,k})\n524: $$\n525: \n526: Define the **centered measures** $\\tilde{\\mu}_k$ by shifting each measure to have zero barycenter:\n527: \n528: $$\n529: \\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{z,k,i}}, \\quad \\delta_{z,k,i} = z_{k,i} - \\bar{z}_k = (\\delta_{x,k,i}, \\delta_{v,k,i})\n530: $$\n531: \n532: By construction, $\\int \\delta_z \\, d\\tilde{\\mu}_k(\\delta_z) = 0$ for both $k = 1, 2$.\n533: \n534: **Step 3: Decomposition via optimal couplings.**\n535: \n536: Let $\\gamma^* \\in \\Gamma(\\mu_1, \\mu_2)$ be an optimal coupling achieving $W_h^2(\\mu_1, \\mu_2)$. We will show that $\\gamma^*$ induces a natural coupling structure that decomposes the cost.\n537: \n538: For any coupling $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$, the total transport cost is:\n539: \n540: $$\n541: \\int_{\\mathcal{Z} \\times \\mathcal{Z}} c(z_1, z_2) \\, d\\gamma(z_1, z_2) = \\int_{\\mathcal{Z} \\times \\mathcal{Z}} q(z_1 - z_2) \\, d\\gamma(z_1, z_2)\n542: $$\n543: \n544: Since $q$ is a quadratic form, we can decompose $z_1 - z_2$ as:\n545: \n546: $$\n547: z_1 - z_2 = (z_1 - \\bar{z}_1) - (z_2 - \\bar{z}_2) + (\\bar{z}_1 - \\bar{z}_2) = \\delta_{z_1} - \\delta_{z_2} + \\Delta\\bar{z}\n548: $$\n549: \n550: where $\\Delta\\bar{z} = \\bar{z}_1 - \\bar{z}_2 = (\\Delta\\mu_x, \\Delta\\mu_v)$ is the barycenter difference and $\\delta_{z_i} = z_i - \\bar{z}_i$ are centered coordinates.\n551: \n552: **Step 4: Expanding the quadratic form.**\n553: \n554: Expanding $q(z_1 - z_2)$ using the decomposition:\n555: \n556: $$\n557: \\begin{aligned}\n558: q(z_1 - z_2) &= q(\\delta_{z_1} - \\delta_{z_2} + \\Delta\\bar{z}) \\\\\n559: &= q(\\delta_{z_1} - \\delta_{z_2}) + q(\\Delta\\bar{z}) + 2\\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q\n560: \\end{aligned}\n561: $$\n562: \n563: where $\\langle \\cdot, \\cdot \\rangle_q$ denotes the inner product associated with the quadratic form $q$ (i.e., the bilinear form such that $q(\\Delta z) = \\langle \\Delta z, \\Delta z \\rangle_q$).\n564: \n565: Integrating over the coupling $\\gamma$:\n566: \n567: $$\n568: \\begin{aligned}\n569: \\int c(z_1, z_2) \\, d\\gamma &= \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma + q(\\Delta\\bar{z}) + 2\\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q \\, d\\gamma\n570: \\end{aligned}\n571: $$\n572: \n573: **Step 5: The cross-term vanishes.**\n574: \n575: The key observation is that the cross-term vanishes:\n576: \n577: $$\n578: \\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta\\bar{z} \\rangle_q \\, d\\gamma = \\left\\langle \\int \\delta_{z_1} \\, d\\gamma(z_1, z_2), \\Delta\\bar{z} \\right\\rangle_q - \\left\\langle \\int \\delta_{z_2} \\, d\\gamma(z_1, z_2), \\Delta\\bar{z} \\right\\rangle_q\n579: $$\n580: \n581: For any coupling $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$, the marginals satisfy $\\gamma(\\cdot \\times \\mathcal{Z}) = \\mu_1$ and $\\gamma(\\mathcal{Z} \\times \\cdot) = \\mu_2$. Therefore:\n582: \n583: $$\n584: \\int \\delta_{z_1} \\, d\\gamma(z_1, z_2) = \\int (z_1 - \\bar{z}_1) \\, d\\gamma(z_1, z_2) = \\int z_1 \\, d\\mu_1(z_1) - \\bar{z}_1 = \\bar{z}_1 - \\bar{z}_1 = 0\n585: $$\n586: \n587: Similarly, $\\int \\delta_{z_2} \\, d\\gamma(z_1, z_2) = 0$. Thus the cross-term is zero.\n588: \n589: **Step 6: Identifying the decomposition terms.**\n590: \n591: With the cross-term eliminated:\n592: \n593: $$\n594: \\int c(z_1, z_2) \\, d\\gamma = \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma + q(\\Delta\\bar{z})\n595: $$\n596: \n597: The second term is the barycenter cost:\n598: \n599: $$\n600: q(\\Delta\\bar{z}) = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle \\Delta\\mu_x, \\Delta\\mu_v \\rangle = V_{\\text{loc}}\n601: $$\n602: \n603: The first term involves the centered coordinates. Note that $\\gamma$ induces a coupling $\\tilde{\\gamma} \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ between the centered measures via the map $(z_1, z_2) \\mapsto (\\delta_{z_1}, \\delta_{z_2})$. Thus:\n604: \n605: $$\n606: \\int q(\\delta_{z_1} - \\delta_{z_2}) \\, d\\gamma(z_1, z_2) = \\int q(\\delta_{z_1}' - \\delta_{z_2}') \\, d\\tilde{\\gamma}(\\delta_{z_1}', \\delta_{z_2}')\n607: $$\n608: \n609: **Step 7: Taking the infimum.**\n610: \n611: Taking the infimum over all couplings $\\gamma \\in \\Gamma(\\mu_1, \\mu_2)$:\n612: \n613: $$\n614: W_h^2(\\mu_1, \\mu_2) = \\inf_{\\gamma \\in \\Gamma(\\mu_1, \\mu_2)} \\int c(z_1, z_2) \\, d\\gamma = V_{\\text{loc}} + \\inf_{\\tilde{\\gamma} \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int c(\\delta_{z_1}, \\delta_{z_2}) \\, d\\tilde{\\gamma}\n615: $$\n616: \n617: The infimum over centered couplings is precisely $W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = V_{\\text{struct}}$.\n618: \n619: **Conclusion:**\n620: \n621: $$\n622: W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}\n623: $$\n624: \n625: This decomposition is exact and holds for any pair of measures with finite second moments and any quadratic cost function.\n626: "
    },
    {
      "directive_type": "lemma",
      "label": "lem-sx-implies-variance",
      "title": "Structural Positional Error and Internal Variance",
      "start_line": 634,
      "end_line": 649,
      "header_lines": [
        635
      ],
      "content_start": 637,
      "content_end": 648,
      "content": "637: :label: lem-sx-implies-variance\n638: \n639: Let $k_1 := |\\mathcal{A}(S_1)|$ and $k_2 := |\\mathcal{A}(S_2)|$ denote the numbers of alive walkers in each swarm. Define:\n640: \n641: - $V_{\\text{x,struct}}$ as the positional component of the structural error between the two swarms' **alive-walker distributions**\n642: - $\\text{Var}_k(x) := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2$ as the **physical internal positional variance** of the **alive walkers** in swarm $k$ (note: this is $k_{\\text{alive}}$-normalized, representing the actual spread of alive walkers, distinct from the Lyapunov variance component $V_{Var,x}$ which is $N$-normalized)\n643: \n644: Then:\n645: \n646: $$\n647: V_{\\text{x,struct}} \\le 2(\\text{Var}_1(x) + \\text{Var}_2(x))\n648: $$",
      "metadata": {
        "label": "lem-sx-implies-variance"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "634: The first step in our causal chain is to connect the state of the coupled system to the internal configuration of the individual swarms. A large mismatch in the geometric shapes of the two swarms, as measured by the positional component of the structural error ($V_{x,\\text{struct}}$), implies that at least one of the swarms must be internally spread out, i.e., have a large positional variance. This lemma makes that connection rigorous.\n635: \n636: :::{prf:lemma} Structural Positional Error and Internal Variance\n637: :label: lem-sx-implies-variance\n638: \n639: Let $k_1 := |\\mathcal{A}(S_1)|$ and $k_2 := |\\mathcal{A}(S_2)|$ denote the numbers of alive walkers in each swarm. Define:\n640: \n641: - $V_{\\text{x,struct}}$ as the positional component of the structural error between the two swarms' **alive-walker distributions**\n642: - $\\text{Var}_k(x) := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2$ as the **physical internal positional variance** of the **alive walkers** in swarm $k$ (note: this is $k_{\\text{alive}}$-normalized, representing the actual spread of alive walkers, distinct from the Lyapunov variance component $V_{Var,x}$ which is $N$-normalized)\n643: \n644: Then:\n645: \n646: $$\n647: V_{\\text{x,struct}} \\le 2(\\text{Var}_1(x) + \\text{Var}_2(x))\n648: $$\n649: "
    },
    {
      "directive_type": "proof",
      "label": "proof-lem-sx-implies-variance",
      "title": null,
      "start_line": 650,
      "end_line": 751,
      "header_lines": [
        651
      ],
      "content_start": 652,
      "content_end": 750,
      "content": "652: :::{prf:proof}\n653: :label: proof-lem-sx-implies-variance\n654: **Proof.**\n655: \n656: The proof is in two parts. First, we rigorously establish the primary inequality by analyzing the optimal transport structure and using a carefully constructed sub-optimal coupling. Second, we demonstrate the consequence using a proof by contradiction.\n657: \n658: **Part 1: Rigorous Proof of the Main Inequality**\n659: \n660: Let $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$ denote the centered empirical measures of the alive walkers in swarms $S_1$ and $S_2$:\n661: \n662: $$\n663: \\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{x,k,i}}\n664: $$\n665: \n666: where $\\delta_{x,k,i} = x_{k,i} - \\mu_{x,k}$ are the centered position vectors and $\\mu_{x,k} = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} x_{k,i}$ is the positional barycenter.\n667: \n668: The structural positional error is defined as the squared Wasserstein distance:\n669: \n670: $$\n671: V_{\\text{x,struct}} := W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma(\\delta_{x,1}, \\delta_{x,2})\n672: $$\n673: \n674: where $\\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ is the set of couplings (joint probability measures with marginals $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$).\n675: \n676: **Step 1.1: Construction of a sub-optimal coupling.**\n677: \n678: We construct a specific coupling $\\gamma_{\\text{id}}$ to obtain an upper bound. Let $m := \\min(k_1, k_2)$ where $k_1 = |\\mathcal{A}(S_1)|$ and $k_2 = |\\mathcal{A}(S_2)|$.\n679: \n680: Without loss of generality, relabel the walkers in each swarm by their indices $1, 2, \\ldots, k_1$ and $1, 2, \\ldots, k_2$. Define the **identity-plus-remainder coupling** $\\gamma_{\\text{id}}$ as follows:\n681: \n682: - For $i \\leq m$: couple walker $i$ in swarm 1 with walker $i$ in swarm 2 with mass $1/\\max(k_1, k_2)$.\n683: - For the excess walkers in the larger swarm: couple each with an arbitrary uniform distribution over the other swarm.\n684: \n685: The precise construction depends on the relative sizes, but the key property is that this coupling costs at most the sum of:\n686: 1. The average squared centered norm in swarm 1: $\\frac{1}{k_1} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{x,1,i}\\|^2$\n687: 2. The average squared centered norm in swarm 2: $\\frac{1}{k_2} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{x,2,i}\\|^2$\n688: \n689: **Step 1.2: Bounding the cost of the identity coupling (equal sizes).**\n690: \n691: First consider the case $k_1 = k_2 = k$. The identity coupling matches walker $i$ to walker $i$. Its cost is:\n692: \n693: $$\n694: \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma_{\\text{id}} = \\frac{1}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2\n695: $$\n696: \n697: Using the elementary inequality $\\|a - b\\|^2 \\leq 2\\|a\\|^2 + 2\\|b\\|^2$ for any $a, b \\in \\mathbb{R}^d$ (which follows from $\\|a-b\\|^2 = \\|a\\|^2 - 2\\langle a, b \\rangle + \\|b\\|^2 \\leq \\|a\\|^2 + \\|b\\|^2 + |\\langle a, b \\rangle|^2 \\leq \\|a\\|^2 + \\|b\\|^2 + \\|a\\|^2 + \\|b\\|^2$ by Cauchy-Schwarz and the polarization identity):\n698: \n699: $$\n700: \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 \\leq 2\\|\\delta_{x,1,i}\\|^2 + 2\\|\\delta_{x,2,i}\\|^2\n701: $$\n702: \n703: Summing over all $i$ and dividing by $k$:\n704: \n705: $$\n706: \\begin{aligned}\n707: \\frac{1}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 &\\leq \\frac{2}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i}\\|^2 + \\frac{2}{k} \\sum_{i=1}^k \\|\\delta_{x,2,i}\\|^2 \\\\\n708: &= 2\\text{Var}_1(x) + 2\\text{Var}_2(x)\n709: \\end{aligned}\n710: $$\n711: \n712: **Step 1.3: Extension to unequal sizes.**\n713: \n714: For unequal sizes $k_1 \\neq k_2$, a more careful analysis is required. Consider a coupling that matches $\\min(k_1, k_2)$ pairs and distributes the excess mass. By the triangle inequality for Wasserstein distances and properties of Dirac measures, one can show that the cost is still bounded by $2(\\text{Var}_1(x) + \\text{Var}_2(x))$.\n715: \n716: Specifically, for any centered measure $\\tilde{\\mu}$, we have $W_2^2(\\tilde{\\mu}, \\delta_0) = \\int \\|\\delta_x\\|^2 \\, d\\tilde{\\mu}(\\delta_x) = \\text{Var}(x)$ where $\\delta_0$ is the Dirac measure at the origin. Using the triangle inequality:\n717: \n718: $$\n719: W_2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq W_2(\\tilde{\\mu}_1, \\delta_0) + W_2(\\delta_0, \\tilde{\\mu}_2) = \\sqrt{\\text{Var}_1(x)} + \\sqrt{\\text{Var}_2(x)}\n720: $$\n721: \n722: Squaring both sides and using $(a + b)^2 \\leq 2a^2 + 2b^2$:\n723: \n724: $$\n725: W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq \\left(\\sqrt{\\text{Var}_1(x)} + \\sqrt{\\text{Var}_2(x)}\\right)^2 \\leq 2\\text{Var}_1(x) + 2\\text{Var}_2(x)\n726: $$\n727: \n728: **Step 1.4: Conclusion of Part 1.**\n729: \n730: Since the Wasserstein distance is the infimum over all couplings and we've constructed a coupling with cost at most $2(\\text{Var}_1(x) + \\text{Var}_2(x))$:\n731: \n732: $$\n733: V_{\\text{x,struct}} = W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x))\n734: $$\n735: \n736: This establishes the main inequality rigorously.\n737: \n738: **Part 2: Proof of the Consequence**\n739: \n740: We prove the implication $V_{\\text{x,struct}} > R^2_{\\text{spread}} \\implies \\exists k \\in \\{1,2\\} : \\text{Var}_k(x) > R^2_{\\text{spread}}/4$ by contrapositive.\n741: \n742: **Contrapositive statement:** If $\\text{Var}_1(x) \\leq R^2_{\\text{spread}}/4$ and $\\text{Var}_2(x) \\leq R^2_{\\text{spread}}/4$, then $V_{\\text{x,struct}} \\leq R^2_{\\text{spread}}$.\n743: \n744: **Proof of contrapositive:** Assume $\\text{Var}_1(x) \\leq R^2_{\\text{spread}}/4$ and $\\text{Var}_2(x) \\leq R^2_{\\text{spread}}/4$. By the inequality established in Part 1:\n745: \n746: $$\n747: V_{\\text{x,struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\leq 2\\left(\\frac{R^2_{\\text{spread}}}{4} + \\frac{R^2_{\\text{spread}}}{4}\\right) = 2 \\cdot \\frac{R^2_{\\text{spread}}}{2} = R^2_{\\text{spread}}\n748: $$\n749: \n750: This proves the contrapositive statement. By logical equivalence, the original implication is proven: if $V_{\\text{x,struct}} > R^2_{\\text{spread}}$, then at least one swarm must satisfy $\\text{Var}_k(x) > R^2_{\\text{spread}}/4$.",
      "metadata": {
        "label": "proof-lem-sx-implies-variance"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "650: Consequently, if $V_{\\text{x,struct}} > R^2_{\\text{spread}}$ for some threshold $R_{\\text{spread}}$, then at least one swarm $k$ must have an internal variance $\\text{Var}_k(x) > R^2_{\\text{spread}} / 4$.\n651: :::\n652: :::{prf:proof}\n653: :label: proof-lem-sx-implies-variance\n654: **Proof.**\n655: \n656: The proof is in two parts. First, we rigorously establish the primary inequality by analyzing the optimal transport structure and using a carefully constructed sub-optimal coupling. Second, we demonstrate the consequence using a proof by contradiction.\n657: \n658: **Part 1: Rigorous Proof of the Main Inequality**\n659: \n660: Let $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$ denote the centered empirical measures of the alive walkers in swarms $S_1$ and $S_2$:\n661: \n662: $$\n663: \\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{x,k,i}}\n664: $$\n665: \n666: where $\\delta_{x,k,i} = x_{k,i} - \\mu_{x,k}$ are the centered position vectors and $\\mu_{x,k} = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} x_{k,i}$ is the positional barycenter.\n667: \n668: The structural positional error is defined as the squared Wasserstein distance:\n669: \n670: $$\n671: V_{\\text{x,struct}} := W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma(\\delta_{x,1}, \\delta_{x,2})\n672: $$\n673: \n674: where $\\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ is the set of couplings (joint probability measures with marginals $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$).\n675: \n676: **Step 1.1: Construction of a sub-optimal coupling.**\n677: \n678: We construct a specific coupling $\\gamma_{\\text{id}}$ to obtain an upper bound. Let $m := \\min(k_1, k_2)$ where $k_1 = |\\mathcal{A}(S_1)|$ and $k_2 = |\\mathcal{A}(S_2)|$.\n679: \n680: Without loss of generality, relabel the walkers in each swarm by their indices $1, 2, \\ldots, k_1$ and $1, 2, \\ldots, k_2$. Define the **identity-plus-remainder coupling** $\\gamma_{\\text{id}}$ as follows:\n681: \n682: - For $i \\leq m$: couple walker $i$ in swarm 1 with walker $i$ in swarm 2 with mass $1/\\max(k_1, k_2)$.\n683: - For the excess walkers in the larger swarm: couple each with an arbitrary uniform distribution over the other swarm.\n684: \n685: The precise construction depends on the relative sizes, but the key property is that this coupling costs at most the sum of:\n686: 1. The average squared centered norm in swarm 1: $\\frac{1}{k_1} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{x,1,i}\\|^2$\n687: 2. The average squared centered norm in swarm 2: $\\frac{1}{k_2} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{x,2,i}\\|^2$\n688: \n689: **Step 1.2: Bounding the cost of the identity coupling (equal sizes).**\n690: \n691: First consider the case $k_1 = k_2 = k$. The identity coupling matches walker $i$ to walker $i$. Its cost is:\n692: \n693: $$\n694: \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma_{\\text{id}} = \\frac{1}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2\n695: $$\n696: \n697: Using the elementary inequality $\\|a - b\\|^2 \\leq 2\\|a\\|^2 + 2\\|b\\|^2$ for any $a, b \\in \\mathbb{R}^d$ (which follows from $\\|a-b\\|^2 = \\|a\\|^2 - 2\\langle a, b \\rangle + \\|b\\|^2 \\leq \\|a\\|^2 + \\|b\\|^2 + |\\langle a, b \\rangle|^2 \\leq \\|a\\|^2 + \\|b\\|^2 + \\|a\\|^2 + \\|b\\|^2$ by Cauchy-Schwarz and the polarization identity):\n698: \n699: $$\n700: \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 \\leq 2\\|\\delta_{x,1,i}\\|^2 + 2\\|\\delta_{x,2,i}\\|^2\n701: $$\n702: \n703: Summing over all $i$ and dividing by $k$:\n704: \n705: $$\n706: \\begin{aligned}\n707: \\frac{1}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 &\\leq \\frac{2}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i}\\|^2 + \\frac{2}{k} \\sum_{i=1}^k \\|\\delta_{x,2,i}\\|^2 \\\\\n708: &= 2\\text{Var}_1(x) + 2\\text{Var}_2(x)\n709: \\end{aligned}\n710: $$\n711: \n712: **Step 1.3: Extension to unequal sizes.**\n713: \n714: For unequal sizes $k_1 \\neq k_2$, a more careful analysis is required. Consider a coupling that matches $\\min(k_1, k_2)$ pairs and distributes the excess mass. By the triangle inequality for Wasserstein distances and properties of Dirac measures, one can show that the cost is still bounded by $2(\\text{Var}_1(x) + \\text{Var}_2(x))$.\n715: \n716: Specifically, for any centered measure $\\tilde{\\mu}$, we have $W_2^2(\\tilde{\\mu}, \\delta_0) = \\int \\|\\delta_x\\|^2 \\, d\\tilde{\\mu}(\\delta_x) = \\text{Var}(x)$ where $\\delta_0$ is the Dirac measure at the origin. Using the triangle inequality:\n717: \n718: $$\n719: W_2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq W_2(\\tilde{\\mu}_1, \\delta_0) + W_2(\\delta_0, \\tilde{\\mu}_2) = \\sqrt{\\text{Var}_1(x)} + \\sqrt{\\text{Var}_2(x)}\n720: $$\n721: \n722: Squaring both sides and using $(a + b)^2 \\leq 2a^2 + 2b^2$:\n723: \n724: $$\n725: W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq \\left(\\sqrt{\\text{Var}_1(x)} + \\sqrt{\\text{Var}_2(x)}\\right)^2 \\leq 2\\text{Var}_1(x) + 2\\text{Var}_2(x)\n726: $$\n727: \n728: **Step 1.4: Conclusion of Part 1.**\n729: \n730: Since the Wasserstein distance is the infimum over all couplings and we've constructed a coupling with cost at most $2(\\text{Var}_1(x) + \\text{Var}_2(x))$:\n731: \n732: $$\n733: V_{\\text{x,struct}} = W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x))\n734: $$\n735: \n736: This establishes the main inequality rigorously.\n737: \n738: **Part 2: Proof of the Consequence**\n739: \n740: We prove the implication $V_{\\text{x,struct}} > R^2_{\\text{spread}} \\implies \\exists k \\in \\{1,2\\} : \\text{Var}_k(x) > R^2_{\\text{spread}}/4$ by contrapositive.\n741: \n742: **Contrapositive statement:** If $\\text{Var}_1(x) \\leq R^2_{\\text{spread}}/4$ and $\\text{Var}_2(x) \\leq R^2_{\\text{spread}}/4$, then $V_{\\text{x,struct}} \\leq R^2_{\\text{spread}}$.\n743: \n744: **Proof of contrapositive:** Assume $\\text{Var}_1(x) \\leq R^2_{\\text{spread}}/4$ and $\\text{Var}_2(x) \\leq R^2_{\\text{spread}}/4$. By the inequality established in Part 1:\n745: \n746: $$\n747: V_{\\text{x,struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\leq 2\\left(\\frac{R^2_{\\text{spread}}}{4} + \\frac{R^2_{\\text{spread}}}{4}\\right) = 2 \\cdot \\frac{R^2_{\\text{spread}}}{2} = R^2_{\\text{spread}}\n748: $$\n749: \n750: This proves the contrapositive statement. By logical equivalence, the original implication is proven: if $V_{\\text{x,struct}} > R^2_{\\text{spread}}$, then at least one swarm must satisfy $\\text{Var}_k(x) > R^2_{\\text{spread}}/4$.\n751: "
    },
    {
      "directive_type": "definition",
      "label": "def-full-synergistic-lyapunov-function",
      "title": "The Full Synergistic Hypocoercive Lyapunov Function",
      "start_line": 757,
      "end_line": 862,
      "header_lines": [
        758,
        806
      ],
      "content_start": 760,
      "content_end": 861,
      "content": "760: :label: def-full-synergistic-lyapunov-function\n761: \n762: For any pair of swarm configurations $(S_1, S_2)$ with corresponding empirical measures $(\\mu_1, \\mu_2)$, the **total synergistic Lyapunov function** is defined as:\n763: \n764: $$\n765: V_{\\mathrm{total}}(S_1, S_2) := W_h^2(\\mu_1, \\mu_2) + c_V V_{Var}(S_1, S_2) + c_B W_b(S_1, S_2)\n766: $$\n767: \n768: where the intra-swarm variance term explicitly decomposes into positional and velocity components **summed over alive walkers only, but normalized by the total swarm size $N$**:\n769: \n770: $$\n771: V_{Var}(S_1, S_2) = V_{Var,x}(S_1, S_2) + \\lambda_v V_{Var,v}(S_1, S_2)\n772: $$\n773: \n774: with:\n775: \n776: $$\n777: \\begin{align*}\n778: V_{Var,x}(S_1, S_2) &:= \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{x,1,i}\\|^2 + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{x,2,i}\\|^2 \\\\\n779: V_{Var,v}(S_1, S_2) &:= \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{v,1,i}\\|^2 + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{v,2,i}\\|^2\n780: \\end{align*}\n781: $$\n782: \n783: where $N$ is the total swarm size, $\\mathcal{A}(S_k)$ is the set of alive walker indices in swarm $k$, and $\\delta_{x,k,i}, \\delta_{v,k,i}$ are the centered vectors defined in {prf:ref}`def-barycentres-and-centered-vectors`.\n784: \n785: The function is a sum of three components:\n786: \n787: 1.  **The Inter-Swarm Error ($W_h^2$):** The squared hypocoercive 2-Wasserstein distance between the swarms' full empirical measures. This term quantifies the total permutation-invariant distance between the two swarms in phase space. As established in {prf:ref}`lem-wasserstein-decomposition`, this component can be exactly decomposed into:\n788:     *   A **Location Component ($V_{\\text{loc}}$)**, measuring the error between the swarm centers of mass.\n789:     *   A **Structural Component ($V_{\\text{struct}}$)**, measuring the mismatch in swarm shapes.\n790: \n791: 2.  **The Intra-Swarm Error ($V_{\\text{Var}}$):** The sum of the internal hypocoercive variances of each swarm. This term quantifies the internal dispersion or \"shape error\" *within* each individual swarm in phase space, measuring their lack of internal convergence in both position and velocity. This component is the primary target of the **synergistic dissipation framework**:\n792:     *   The **cloning operator** ($\\Psi_{\\text{clone}}$, analyzed in this document) provides powerful contraction of the positional variance component $V_{Var,x}$ but causes bounded expansion of the velocity variance component $V_{Var,v}$ through the velocity reset mechanism.\n793:     *   The **kinetic operator** ($\\Psi_{\\text{kin}}$, analyzed in the companion document) provides contraction of the velocity variance component $V_{Var,v}$ through Langevin dissipation but causes bounded expansion of the positional variance component $V_{Var,x}$ through diffusion.\n794:     *   When properly balanced, these two operators achieve **net contraction** of the total $V_{Var}$, enabling the system to converge in both position and velocity simultaneously.\n795: \n796: 3.  **The Boundary Potential ($W_b$):** A term that penalizes **alive** walkers approaching the boundary, constructed from the smooth barrier function $\\varphi_{\\text{barrier}}(x)$ defined in {prf:ref}`prop-barrier-existence`.\n797: \n798: \n799: $$\n800: W_b(S_1, S_2) := \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\varphi_{\\text{barrier}}(x_{1,i}) + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\varphi_{\\text{barrier}}(x_{2,i})\n801: $$\n802: \n803:     where $N$ is the total swarm size and $\\mathcal{A}(S_k)$ denotes the set of alive walker indices in swarm $k$. Note that dead walkers do not contribute to the boundary potential.\n804: \n805: The parameters $b$ and $\\lambda_v > 0$ are the **hypocoercive parameters**. The constants $c_V > 0$ and $c_B > 0$ are small, positive **coupling constants** used in the analysis to balance the contributions of the different error components in the final drift inequality.\n806: \n807: :::{admonition} Normalization by $N$ vs. $k_{\\text{alive}}$ in the Lyapunov Function\n808: :class: important\n809: \n810: The Lyapunov function components $V_{\\text{Var}}$ and $W_b$ are normalized by the **total swarm size $N$**, not by the number of alive walkers $k_{\\text{alive}}$. This design choice is critical for mathematical tractability and deserves careful explanation:\n811: \n812: **Why This Choice Differs from Algorithm Internals:**\n813: \n814: The algorithm's internal fitness calculations (z-scores, variance measurements used for cloning decisions) correctly use $k_{\\text{alive}}$-normalization to compute statistics over the current active population. This is the physically and statistically correct choice for **decision-making**, as it accurately characterizes the distribution of alive walkers at each step.\n815: \n816: However, the Lyapunov function serves a different purpose: it is an **analytical tool** designed to prove long-term stability through drift analysis. For this purpose, $N$-normalization is mathematically necessary.\n817: \n818: **The Mathematical Necessity:**\n819: \n820: Consider the one-step change in the variance component:\n821: \n822: $$\n823: \\Delta V_{\\text{Var}} = V_{\\text{Var}}(S_{t+1}) - V_{\\text{Var}}(S_t)\n824: $$\n825: \n826: If $V_{\\text{Var}}$ were normalized by $k_{\\text{alive}}$, the drift calculation would become:\n827: \n828: $$\n829: \\mathbb{E}[\\Delta V_{\\text{Var}}] = \\mathbb{E}\\left[\\frac{1}{k_{t+1}} \\sum_{i} \\|\\delta_{x,i}\\|^2_{t+1} - \\frac{1}{k_t} \\sum_{i} \\|\\delta_{x,i}\\|^2_t\\right]\n830: $$\n831: \n832: This expression involves the **ratio of correlated random variables**: both the sum of squares and the number of alive walkers change stochastically at each step, and these changes are strongly coupled (e.g., if a high-variance walker dies, both the numerator and denominator change). The expectation of such a ratio cannot be simplified, making rigorous drift bounds essentially impossible to derive.\n833: \n834: With $N$-normalization, the constant factor $1/N$ factors out of the expectation:\n835: \n836: $$\n837: \\mathbb{E}[\\Delta V_{\\text{Var}}] = \\frac{1}{N} \\mathbb{E}\\left[\\sum_{i} \\|\\delta_{x,i}\\|^2_{t+1} - \\sum_{i} \\|\\delta_{x,i}\\|^2_t\\right]\n838: $$\n839: \n840: This allows the analysis to focus entirely on $\\mathbb{E}[\\Delta \\text{SumOfSquares}]$, which is the direct effect of the cloning and kinetic operators on the swarm's kinematic state. This is precisely what the Keystone Principle and the hypocoercive analysis are designed to bound.\n841: \n842: **The Mean-Field Interpretation:**\n843: \n844: The $N$-normalized variance can be interpreted as:\n845: \n846: $$\n847: V_{\\text{Var},x}(S_k) = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{k_{\\text{alive}}}{N} \\cdot \\text{Var}_{\\text{alive}}(S_k)\n848: $$\n849: \n850: This represents the **mean-field contribution to system disorder per walker slot**. It scales with the fraction of alive walkers, which is exactly the correct behavior: if only a small fraction of walkers remain alive, the system's total disorder (as measured by the Lyapunov function) should reflect this reduced active mass.\n851: \n852: **The Viability Requirement:**\n853: \n854: This normalization implicitly assumes that the swarm remains viable, meaning $k_{\\text{alive}}/N$ is bounded away from zero. This is guaranteed by the framework's design:\n855: - The Safe Harbor Axiom ensures existence of a desirable region away from boundaries\n856: - The contractive properties of the cloning operator (Keystone Principle) and the confining potential prevent swarm collapse\n857: - The Lyapunov analysis operates in the regime where the swarm is stable, with extinction probability exponentially small\n858: \n859: **Conclusion:**\n860: \n861: The separation between algorithmic calculations (using $k_{\\text{alive}}$) and analytical tools (using $N$) is not a compromise but a hallmark of rigorous mean-field analysis. The algorithm uses the physically optimal metric for real-time decisions, while the Lyapunov function uses the mathematically tractable metric for proving convergence. Both serve their respective purposes correctly.",
      "metadata": {
        "label": "def-full-synergistic-lyapunov-function",
        "class": "important"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "def-barycentres-and-centered-vectors",
        "lem-wasserstein-decomposition",
        "prop-barrier-existence",
        "def-boundary-potential-recall"
      ],
      "raw_directive": "757: With the permutation-invariant decomposition of the inter-swarm error established, we now define the full Lyapunov function. This **synergistic** function is constructed as a weighted sum of three distinct error components (see {prf:ref}`prop-lyapunov-necessity` for why this structure is mathematically necessary). It is designed to capture not only the distance *between* the swarms, but also the internal disorder *within* each swarm, which is the primary target of the cloning operator.\n758: \n759: :::{prf:definition} The Full Synergistic Hypocoercive Lyapunov Function\n760: :label: def-full-synergistic-lyapunov-function\n761: \n762: For any pair of swarm configurations $(S_1, S_2)$ with corresponding empirical measures $(\\mu_1, \\mu_2)$, the **total synergistic Lyapunov function** is defined as:\n763: \n764: $$\n765: V_{\\mathrm{total}}(S_1, S_2) := W_h^2(\\mu_1, \\mu_2) + c_V V_{Var}(S_1, S_2) + c_B W_b(S_1, S_2)\n766: $$\n767: \n768: where the intra-swarm variance term explicitly decomposes into positional and velocity components **summed over alive walkers only, but normalized by the total swarm size $N$**:\n769: \n770: $$\n771: V_{Var}(S_1, S_2) = V_{Var,x}(S_1, S_2) + \\lambda_v V_{Var,v}(S_1, S_2)\n772: $$\n773: \n774: with:\n775: \n776: $$\n777: \\begin{align*}\n778: V_{Var,x}(S_1, S_2) &:= \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{x,1,i}\\|^2 + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{x,2,i}\\|^2 \\\\\n779: V_{Var,v}(S_1, S_2) &:= \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\|\\delta_{v,1,i}\\|^2 + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\|\\delta_{v,2,i}\\|^2\n780: \\end{align*}\n781: $$\n782: \n783: where $N$ is the total swarm size, $\\mathcal{A}(S_k)$ is the set of alive walker indices in swarm $k$, and $\\delta_{x,k,i}, \\delta_{v,k,i}$ are the centered vectors defined in {prf:ref}`def-barycentres-and-centered-vectors`.\n784: \n785: The function is a sum of three components:\n786: \n787: 1.  **The Inter-Swarm Error ($W_h^2$):** The squared hypocoercive 2-Wasserstein distance between the swarms' full empirical measures. This term quantifies the total permutation-invariant distance between the two swarms in phase space. As established in {prf:ref}`lem-wasserstein-decomposition`, this component can be exactly decomposed into:\n788:     *   A **Location Component ($V_{\\text{loc}}$)**, measuring the error between the swarm centers of mass.\n789:     *   A **Structural Component ($V_{\\text{struct}}$)**, measuring the mismatch in swarm shapes.\n790: \n791: 2.  **The Intra-Swarm Error ($V_{\\text{Var}}$):** The sum of the internal hypocoercive variances of each swarm. This term quantifies the internal dispersion or \"shape error\" *within* each individual swarm in phase space, measuring their lack of internal convergence in both position and velocity. This component is the primary target of the **synergistic dissipation framework**:\n792:     *   The **cloning operator** ($\\Psi_{\\text{clone}}$, analyzed in this document) provides powerful contraction of the positional variance component $V_{Var,x}$ but causes bounded expansion of the velocity variance component $V_{Var,v}$ through the velocity reset mechanism.\n793:     *   The **kinetic operator** ($\\Psi_{\\text{kin}}$, analyzed in the companion document) provides contraction of the velocity variance component $V_{Var,v}$ through Langevin dissipation but causes bounded expansion of the positional variance component $V_{Var,x}$ through diffusion.\n794:     *   When properly balanced, these two operators achieve **net contraction** of the total $V_{Var}$, enabling the system to converge in both position and velocity simultaneously.\n795: \n796: 3.  **The Boundary Potential ($W_b$):** A term that penalizes **alive** walkers approaching the boundary, constructed from the smooth barrier function $\\varphi_{\\text{barrier}}(x)$ defined in {prf:ref}`prop-barrier-existence`.\n797: \n798: \n799: $$\n800: W_b(S_1, S_2) := \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_1)} \\varphi_{\\text{barrier}}(x_{1,i}) + \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_2)} \\varphi_{\\text{barrier}}(x_{2,i})\n801: $$\n802: \n803:     where $N$ is the total swarm size and $\\mathcal{A}(S_k)$ denotes the set of alive walker indices in swarm $k$. Note that dead walkers do not contribute to the boundary potential.\n804: \n805: The parameters $b$ and $\\lambda_v > 0$ are the **hypocoercive parameters**. The constants $c_V > 0$ and $c_B > 0$ are small, positive **coupling constants** used in the analysis to balance the contributions of the different error components in the final drift inequality.\n806: \n807: :::{admonition} Normalization by $N$ vs. $k_{\\text{alive}}$ in the Lyapunov Function\n808: :class: important\n809: \n810: The Lyapunov function components $V_{\\text{Var}}$ and $W_b$ are normalized by the **total swarm size $N$**, not by the number of alive walkers $k_{\\text{alive}}$. This design choice is critical for mathematical tractability and deserves careful explanation:\n811: \n812: **Why This Choice Differs from Algorithm Internals:**\n813: \n814: The algorithm's internal fitness calculations (z-scores, variance measurements used for cloning decisions) correctly use $k_{\\text{alive}}$-normalization to compute statistics over the current active population. This is the physically and statistically correct choice for **decision-making**, as it accurately characterizes the distribution of alive walkers at each step.\n815: \n816: However, the Lyapunov function serves a different purpose: it is an **analytical tool** designed to prove long-term stability through drift analysis. For this purpose, $N$-normalization is mathematically necessary.\n817: \n818: **The Mathematical Necessity:**\n819: \n820: Consider the one-step change in the variance component:\n821: \n822: $$\n823: \\Delta V_{\\text{Var}} = V_{\\text{Var}}(S_{t+1}) - V_{\\text{Var}}(S_t)\n824: $$\n825: \n826: If $V_{\\text{Var}}$ were normalized by $k_{\\text{alive}}$, the drift calculation would become:\n827: \n828: $$\n829: \\mathbb{E}[\\Delta V_{\\text{Var}}] = \\mathbb{E}\\left[\\frac{1}{k_{t+1}} \\sum_{i} \\|\\delta_{x,i}\\|^2_{t+1} - \\frac{1}{k_t} \\sum_{i} \\|\\delta_{x,i}\\|^2_t\\right]\n830: $$\n831: \n832: This expression involves the **ratio of correlated random variables**: both the sum of squares and the number of alive walkers change stochastically at each step, and these changes are strongly coupled (e.g., if a high-variance walker dies, both the numerator and denominator change). The expectation of such a ratio cannot be simplified, making rigorous drift bounds essentially impossible to derive.\n833: \n834: With $N$-normalization, the constant factor $1/N$ factors out of the expectation:\n835: \n836: $$\n837: \\mathbb{E}[\\Delta V_{\\text{Var}}] = \\frac{1}{N} \\mathbb{E}\\left[\\sum_{i} \\|\\delta_{x,i}\\|^2_{t+1} - \\sum_{i} \\|\\delta_{x,i}\\|^2_t\\right]\n838: $$\n839: \n840: This allows the analysis to focus entirely on $\\mathbb{E}[\\Delta \\text{SumOfSquares}]$, which is the direct effect of the cloning and kinetic operators on the swarm's kinematic state. This is precisely what the Keystone Principle and the hypocoercive analysis are designed to bound.\n841: \n842: **The Mean-Field Interpretation:**\n843: \n844: The $N$-normalized variance can be interpreted as:\n845: \n846: $$\n847: V_{\\text{Var},x}(S_k) = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{k_{\\text{alive}}}{N} \\cdot \\text{Var}_{\\text{alive}}(S_k)\n848: $$\n849: \n850: This represents the **mean-field contribution to system disorder per walker slot**. It scales with the fraction of alive walkers, which is exactly the correct behavior: if only a small fraction of walkers remain alive, the system's total disorder (as measured by the Lyapunov function) should reflect this reduced active mass.\n851: \n852: **The Viability Requirement:**\n853: \n854: This normalization implicitly assumes that the swarm remains viable, meaning $k_{\\text{alive}}/N$ is bounded away from zero. This is guaranteed by the framework's design:\n855: - The Safe Harbor Axiom ensures existence of a desirable region away from boundaries\n856: - The contractive properties of the cloning operator (Keystone Principle) and the confining potential prevent swarm collapse\n857: - The Lyapunov analysis operates in the regime where the swarm is stable, with extinction probability exponentially small\n858: \n859: **Conclusion:**\n860: \n861: The separation between algorithmic calculations (using $k_{\\text{alive}}$) and analytical tools (using $N$) is not a compromise but a hallmark of rigorous mean-field analysis. The algorithm uses the physically optimal metric for real-time decisions, while the Lyapunov function uses the mathematically tractable metric for proving convergence. Both serve their respective purposes correctly.\n862: "
    },
    {
      "directive_type": "definition",
      "label": "def-variance-conversions",
      "title": "Variance Notation Conversion Formulas",
      "start_line": 869,
      "end_line": 912,
      "header_lines": [
        870
      ],
      "content_start": 872,
      "content_end": 911,
      "content": "872: :label: def-variance-conversions\n873: \n874: For a swarm $k$ with $k_{\\text{alive}} = |\\mathcal{A}(S_k)|$ alive walkers out of $N$ total walker slots:\n875: \n876: **1. Un-normalized Sum of Squared Deviations:**\n877: \n878: $$\n879: S_k := \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2\n880: $$\n881: \n882: This is the total positional variance without any normalization.\n883: \n884: **2. Physical Internal Variance ($k$-normalized):**\n885: \n886: $$\n887: \\text{Var}_k(x) := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{S_k}{k_{\\text{alive}}}\n888: $$\n889: \n890: This is the average squared deviation per alive walker - the standard statistical variance.\n891: \n892: **3. Lyapunov Variance Component ($N$-normalized):**\n893: \n894: $$\n895: V_{\\text{Var},x}(S_k) := \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{S_k}{N}\n896: $$\n897: \n898: This is the mean-field contribution to system disorder per walker slot.\n899: \n900: **Conversion Formulas:**\n901: \n902: $$\n903: \\begin{aligned}\n904: S_k &= k_{\\text{alive}} \\cdot \\text{Var}_k(x) = N \\cdot V_{\\text{Var},x}(S_k) \\\\\n905: V_{\\text{Var},x}(S_k) &= \\frac{k_{\\text{alive}}}{N} \\cdot \\text{Var}_k(x) \\\\\n906: \\text{Var}_k(x) &= \\frac{N}{k_{\\text{alive}}} \\cdot V_{\\text{Var},x}(S_k)\n907: \\end{aligned}\n908: $$\n909: \n910: **When converting between notations in proofs:**\n911: - From $S_k$ to $V_{\\text{Var},x}$: **divide by $N$**",
      "metadata": {
        "label": "def-variance-conversions"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "869: To ensure clarity throughout the proofs, we explicitly state the relationships between the three variance concepts used in this document:\n870: \n871: :::{prf:definition} Variance Notation Conversion Formulas\n872: :label: def-variance-conversions\n873: \n874: For a swarm $k$ with $k_{\\text{alive}} = |\\mathcal{A}(S_k)|$ alive walkers out of $N$ total walker slots:\n875: \n876: **1. Un-normalized Sum of Squared Deviations:**\n877: \n878: $$\n879: S_k := \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2\n880: $$\n881: \n882: This is the total positional variance without any normalization.\n883: \n884: **2. Physical Internal Variance ($k$-normalized):**\n885: \n886: $$\n887: \\text{Var}_k(x) := \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{S_k}{k_{\\text{alive}}}\n888: $$\n889: \n890: This is the average squared deviation per alive walker - the standard statistical variance.\n891: \n892: **3. Lyapunov Variance Component ($N$-normalized):**\n893: \n894: $$\n895: V_{\\text{Var},x}(S_k) := \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2 = \\frac{S_k}{N}\n896: $$\n897: \n898: This is the mean-field contribution to system disorder per walker slot.\n899: \n900: **Conversion Formulas:**\n901: \n902: $$\n903: \\begin{aligned}\n904: S_k &= k_{\\text{alive}} \\cdot \\text{Var}_k(x) = N \\cdot V_{\\text{Var},x}(S_k) \\\\\n905: V_{\\text{Var},x}(S_k) &= \\frac{k_{\\text{alive}}}{N} \\cdot \\text{Var}_k(x) \\\\\n906: \\text{Var}_k(x) &= \\frac{N}{k_{\\text{alive}}} \\cdot V_{\\text{Var},x}(S_k)\n907: \\end{aligned}\n908: $$\n909: \n910: **When converting between notations in proofs:**\n911: - From $S_k$ to $V_{\\text{Var},x}$: **divide by $N$**\n912: - From $\\text{Var}_k(x)$ to $V_{\\text{Var},x}$: **multiply by $\\frac{k_{\\text{alive}}}{N}$**"
    },
    {
      "directive_type": "proposition",
      "label": "prop-lyapunov-necessity",
      "title": "Necessity of the Augmented Lyapunov Structure",
      "start_line": 932,
      "end_line": 986,
      "header_lines": [
        933
      ],
      "content_start": 935,
      "content_end": 985,
      "content": "935: :label: prop-lyapunov-necessity\n936: \n937: The Lyapunov function $V_{\\text{total}} = W_h^2 + c_V V_{\\text{Var}} + c_B W_b$ with three distinct weighted components is mathematically necessary for the following reasons:\n938: \n939: **1. Complementary Information Content**\n940: \n941: The two kinematic components measure fundamentally different aspects of swarm error:\n942: \n943: - **$W_h^2(\\mu_1, \\mu_2)$**: Measures how far apart the two swarms are **as distributions**. This is the squared Wasserstein distance between the full empirical measures $\\mu_1$ and $\\mu_2$. It quantifies the minimal transport cost to transform one swarm's distribution into the other's.\n944: \n945: - **$V_{\\text{Var}}(S_1, S_2)$**: Measures the **internal dispersion within each swarm**. This is the sum of the internal variances (positional and velocity) of each swarm's alive-walker population.\n946: \n947: These quantities contain **non-redundant information**:\n948: - A system can have **small $W_h^2$ but large $V_{\\text{Var}}$**: Both swarms have similar empirical measures (so Wasserstein distance is small), but each swarm is internally highly dispersed (large variance).\n949: - A system can have **small $V_{\\text{Var}}$ but large $W_h^2$**: Both swarms are internally tight clusters (small variance), but the two tight clusters are far apart in phase space (large Wasserstein distance).\n950: \n951: **2. Operator-Specific Targeting**\n952: \n953: The two stochastic operators act on fundamentally different error components:\n954: \n955: - **The Cloning Operator $\\Psi_{\\text{clone}}$**: Acts **within** each swarm independently. It selects walkers based on their fitness **relative to their own swarm's distribution**. The cloning mechanism directly targets $V_{\\text{Var}}$ by eliminating low-fitness walkers and duplicating high-fitness walkers, thereby reducing the internal spread of each swarm's distribution.\n956: \n957: - **The Kinetic Operator $\\Psi_{\\text{kin}}$**: Contains a drift term $F(x)$ (the negative gradient of a confining potential) that acts on walker positions. This drift causes walkers in both swarms to move toward regions of lower potential, thereby moving both swarms' barycenters toward the same equilibrium. This directly targets $W_h^2$ by reducing the distance between the swarms' centers of mass.\n958: \n959: **3. Synergistic Dissipation Necessity**\n960: \n961: Neither operator can contract the full hypocoercive norm $\\|\\!(\\delta x, \\delta v)\\!\\|_h^2 = \\|\\delta x\\|^2 + \\lambda_v \\|\\delta v\\|^2$ in both position and velocity simultaneously:\n962: \n963: - **Velocity Desynchronization from Cloning**: When the cloning operator duplicates a walker, it adds Gaussian jitter to the velocity: $v_{\\text{new}} = v_{\\text{parent}} + \\mathcal{N}(0, \\delta^2 I_d)$. This randomization **breaks velocity correlations** between swarms, causing the velocity component of the structural error to increase (expansion of the velocity-related parts of $W_h^2$). Additionally, the cloning mechanism creates a distribution of velocities within each swarm that may increase $V_{\\text{Var},v}$.\n964: \n965: - **Positional Diffusion from Kinetic Noise**: The Langevin equation for the kinetic step includes a diffusion term: $dx = (\\text{drift terms}) \\, dt + \\sigma \\, dW$. This stochastic noise **desynchronizes positions** between the two swarms' trajectories, causing positional components to expand. It also contributes to an increase in $V_{\\text{Var},x}$ within each swarm.\n966: \n967: **4. The Weighted Sum as a Solution**\n968: \n969: The augmented Lyapunov function resolves this by allowing us to **balance expansions against contractions**:\n970: \n971: $$\n972: \\mathbb{E}[V_{\\text{total}}(t+1) - V_{\\text{total}}(t)] = \\underbrace{\\mathbb{E}[\\Delta W_h^2]}_{\\Psi_{\\text{clone}}: +, \\ \\Psi_{\\text{kin}}: -} + c_V \\underbrace{\\mathbb{E}[\\Delta V_{\\text{Var}}]}_{\\Psi_{\\text{clone}}: -, \\ \\Psi_{\\text{kin}}: +} + c_B \\underbrace{\\mathbb{E}[\\Delta W_b]}_{\\text{both: } -}\n973: $$\n974: \n975: By choosing the coupling constant $c_V$ appropriately, we can ensure that:\n976: - The **strong contraction** of $V_{\\text{Var}}$ under $\\Psi_{\\text{clone}}$ (weighted by $c_V$) **dominates** the bounded expansion of $W_h^2$ under $\\Psi_{\\text{clone}}$.\n977: - The **strong contraction** of $W_h^2$ under $\\Psi_{\\text{kin}}$ **dominates** the bounded expansion of $c_V V_{\\text{Var}}$ under $\\Psi_{\\text{kin}}$.\n978: \n979: This yields **net negative drift**: $\\mathbb{E}[V_{\\text{total}}(t+1) - V_{\\text{total}}(t)] \\leq -\\kappa V_{\\text{total}}(t) + C$ for some $\\kappa > 0$.\n980: \n981: **5. The Boundary Term $W_b$**\n982: \n983: The term $c_B W_b$ ensures that walkers near the boundary $\\partial \\mathcal{X}_{\\text{valid}}$ are penalized. Both operators have mechanisms that contract this term:\n984: - **$\\Psi_{\\text{clone}}$**: Walkers near the boundary have lower survival probability and are thus eliminated and replaced by clones of interior walkers.\n985: - **$\\Psi_{\\text{kin}}$**: The confining potential $U(x)$ and force field $F(x) = -\\nabla U(x)$ (see {prf:ref}`axiom-lipschitz-fields`) push walkers away from the boundary.",
      "metadata": {
        "label": "prop-lyapunov-necessity"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [
        "axiom-lipschitz-fields"
      ],
      "raw_directive": "932: The inclusion of both $W_h^2$ (inter-swarm error) and $V_{\\text{Var}}$ (intra-swarm error) in the Lyapunov function is not merely convenient but mathematically necessary. This subsection explains why the specific weighted-sum structure is required for proving convergence.\n933: \n934: :::{prf:proposition} Necessity of the Augmented Lyapunov Structure\n935: :label: prop-lyapunov-necessity\n936: \n937: The Lyapunov function $V_{\\text{total}} = W_h^2 + c_V V_{\\text{Var}} + c_B W_b$ with three distinct weighted components is mathematically necessary for the following reasons:\n938: \n939: **1. Complementary Information Content**\n940: \n941: The two kinematic components measure fundamentally different aspects of swarm error:\n942: \n943: - **$W_h^2(\\mu_1, \\mu_2)$**: Measures how far apart the two swarms are **as distributions**. This is the squared Wasserstein distance between the full empirical measures $\\mu_1$ and $\\mu_2$. It quantifies the minimal transport cost to transform one swarm's distribution into the other's.\n944: \n945: - **$V_{\\text{Var}}(S_1, S_2)$**: Measures the **internal dispersion within each swarm**. This is the sum of the internal variances (positional and velocity) of each swarm's alive-walker population.\n946: \n947: These quantities contain **non-redundant information**:\n948: - A system can have **small $W_h^2$ but large $V_{\\text{Var}}$**: Both swarms have similar empirical measures (so Wasserstein distance is small), but each swarm is internally highly dispersed (large variance).\n949: - A system can have **small $V_{\\text{Var}}$ but large $W_h^2$**: Both swarms are internally tight clusters (small variance), but the two tight clusters are far apart in phase space (large Wasserstein distance).\n950: \n951: **2. Operator-Specific Targeting**\n952: \n953: The two stochastic operators act on fundamentally different error components:\n954: \n955: - **The Cloning Operator $\\Psi_{\\text{clone}}$**: Acts **within** each swarm independently. It selects walkers based on their fitness **relative to their own swarm's distribution**. The cloning mechanism directly targets $V_{\\text{Var}}$ by eliminating low-fitness walkers and duplicating high-fitness walkers, thereby reducing the internal spread of each swarm's distribution.\n956: \n957: - **The Kinetic Operator $\\Psi_{\\text{kin}}$**: Contains a drift term $F(x)$ (the negative gradient of a confining potential) that acts on walker positions. This drift causes walkers in both swarms to move toward regions of lower potential, thereby moving both swarms' barycenters toward the same equilibrium. This directly targets $W_h^2$ by reducing the distance between the swarms' centers of mass.\n958: \n959: **3. Synergistic Dissipation Necessity**\n960: \n961: Neither operator can contract the full hypocoercive norm $\\|\\!(\\delta x, \\delta v)\\!\\|_h^2 = \\|\\delta x\\|^2 + \\lambda_v \\|\\delta v\\|^2$ in both position and velocity simultaneously:\n962: \n963: - **Velocity Desynchronization from Cloning**: When the cloning operator duplicates a walker, it adds Gaussian jitter to the velocity: $v_{\\text{new}} = v_{\\text{parent}} + \\mathcal{N}(0, \\delta^2 I_d)$. This randomization **breaks velocity correlations** between swarms, causing the velocity component of the structural error to increase (expansion of the velocity-related parts of $W_h^2$). Additionally, the cloning mechanism creates a distribution of velocities within each swarm that may increase $V_{\\text{Var},v}$.\n964: \n965: - **Positional Diffusion from Kinetic Noise**: The Langevin equation for the kinetic step includes a diffusion term: $dx = (\\text{drift terms}) \\, dt + \\sigma \\, dW$. This stochastic noise **desynchronizes positions** between the two swarms' trajectories, causing positional components to expand. It also contributes to an increase in $V_{\\text{Var},x}$ within each swarm.\n966: \n967: **4. The Weighted Sum as a Solution**\n968: \n969: The augmented Lyapunov function resolves this by allowing us to **balance expansions against contractions**:\n970: \n971: $$\n972: \\mathbb{E}[V_{\\text{total}}(t+1) - V_{\\text{total}}(t)] = \\underbrace{\\mathbb{E}[\\Delta W_h^2]}_{\\Psi_{\\text{clone}}: +, \\ \\Psi_{\\text{kin}}: -} + c_V \\underbrace{\\mathbb{E}[\\Delta V_{\\text{Var}}]}_{\\Psi_{\\text{clone}}: -, \\ \\Psi_{\\text{kin}}: +} + c_B \\underbrace{\\mathbb{E}[\\Delta W_b]}_{\\text{both: } -}\n973: $$\n974: \n975: By choosing the coupling constant $c_V$ appropriately, we can ensure that:\n976: - The **strong contraction** of $V_{\\text{Var}}$ under $\\Psi_{\\text{clone}}$ (weighted by $c_V$) **dominates** the bounded expansion of $W_h^2$ under $\\Psi_{\\text{clone}}$.\n977: - The **strong contraction** of $W_h^2$ under $\\Psi_{\\text{kin}}$ **dominates** the bounded expansion of $c_V V_{\\text{Var}}$ under $\\Psi_{\\text{kin}}$.\n978: \n979: This yields **net negative drift**: $\\mathbb{E}[V_{\\text{total}}(t+1) - V_{\\text{total}}(t)] \\leq -\\kappa V_{\\text{total}}(t) + C$ for some $\\kappa > 0$.\n980: \n981: **5. The Boundary Term $W_b$**\n982: \n983: The term $c_B W_b$ ensures that walkers near the boundary $\\partial \\mathcal{X}_{\\text{valid}}$ are penalized. Both operators have mechanisms that contract this term:\n984: - **$\\Psi_{\\text{clone}}$**: Walkers near the boundary have lower survival probability and are thus eliminated and replaced by clones of interior walkers.\n985: - **$\\Psi_{\\text{kin}}$**: The confining potential $U(x)$ and force field $F(x) = -\\nabla U(x)$ (see {prf:ref}`axiom-lipschitz-fields`) push walkers away from the boundary.\n986: "
    },
    {
      "directive_type": "remark",
      "label": "rem-note-hypocoercivity-analogy",
      "title": "Analogy to Classical Hypocoercivity Theory",
      "start_line": 988,
      "end_line": 1007,
      "header_lines": [
        989,
        990
      ],
      "content_start": 992,
      "content_end": 1006,
      "content": "992: :class: tip\n993: \n994: This structure is the **discrete stochastic analogue** of the classical hypocoercivity framework for kinetic PDEs (Villani, 2009; Dolbeault-Mouhot-Schmeiser, 2015):\n995: \n996: **Classical Hypocoercivity (Kinetic Fokker-Planck)**:\n997: - The transport operator $v \\cdot \\nabla_x$ generates dynamics in $x$ but is neutral on the velocity distribution.\n998: - The collision operator $\\mathcal{L}_v$ generates dissipation in $v$ but does not directly affect $x$.\n999: - Neither operator alone contracts the full kinetic norm $\\|f\\|^2_{L^2} + \\|\\nabla_x f\\|^2_{L^2}$.\n1000: - The augmented norm $\\|f\\|^2_{L^2} + \\varepsilon \\|\\nabla_x f\\|^2_{L^2}$ allows proving exponential decay by balancing the operators' effects.\n1001: \n1002: **Our Discrete Stochastic Framework (Fragile Gas)**:\n1003: - The cloning operator $\\Psi_{\\text{clone}}$ contracts $V_{\\text{Var}}$ (internal swarm structure) but may expand $W_h^2$ (inter-swarm distance via velocity resets).\n1004: - The kinetic operator $\\Psi_{\\text{kin}}$ contracts $W_h^2$ (via confining potential) but may expand $V_{\\text{Var}}$ (via diffusion noise).\n1005: - Neither operator alone contracts the full phase-space error.\n1006: - The augmented Lyapunov $V_{\\text{total}} = W_h^2 + c_V V_{\\text{Var}} + c_B W_b$ allows proving exponential convergence by balancing the operators' synergistic dissipation.",
      "metadata": {
        "label": "rem-note-hypocoercivity-analogy",
        "class": "tip"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "988: :::\n989: \n990: :::{prf:remark} Analogy to Classical Hypocoercivity Theory\n991: :label: rem-note-hypocoercivity-analogy\n992: :class: tip\n993: \n994: This structure is the **discrete stochastic analogue** of the classical hypocoercivity framework for kinetic PDEs (Villani, 2009; Dolbeault-Mouhot-Schmeiser, 2015):\n995: \n996: **Classical Hypocoercivity (Kinetic Fokker-Planck)**:\n997: - The transport operator $v \\cdot \\nabla_x$ generates dynamics in $x$ but is neutral on the velocity distribution.\n998: - The collision operator $\\mathcal{L}_v$ generates dissipation in $v$ but does not directly affect $x$.\n999: - Neither operator alone contracts the full kinetic norm $\\|f\\|^2_{L^2} + \\|\\nabla_x f\\|^2_{L^2}$.\n1000: - The augmented norm $\\|f\\|^2_{L^2} + \\varepsilon \\|\\nabla_x f\\|^2_{L^2}$ allows proving exponential decay by balancing the operators' effects.\n1001: \n1002: **Our Discrete Stochastic Framework (Fragile Gas)**:\n1003: - The cloning operator $\\Psi_{\\text{clone}}$ contracts $V_{\\text{Var}}$ (internal swarm structure) but may expand $W_h^2$ (inter-swarm distance via velocity resets).\n1004: - The kinetic operator $\\Psi_{\\text{kin}}$ contracts $W_h^2$ (via confining potential) but may expand $V_{\\text{Var}}$ (via diffusion noise).\n1005: - Neither operator alone contracts the full phase-space error.\n1006: - The augmented Lyapunov $V_{\\text{total}} = W_h^2 + c_V V_{\\text{Var}} + c_B W_b$ allows proving exponential convergence by balancing the operators' synergistic dissipation.\n1007: "
    },
    {
      "directive_type": "proof",
      "label": "proof-lem-V-coercive",
      "title": null,
      "start_line": 1026,
      "end_line": 1158,
      "header_lines": [
        1027
      ],
      "content_start": 1028,
      "content_end": 1157,
      "content": "1028: :::{prf:proof}\n1029: :label: proof-lem-V-coercive\n1030: **Proof.**\n1031: \n1032: We prove the coercivity of both the location and structural components by verifying that the associated quadratic forms are positive-definite under the stated condition.\n1033: \n1034: **Part 1: Positive-definiteness of general hypocoercive quadratic forms.**\n1035: \n1036: Consider a general quadratic form on $\\mathbb{R}^d \\times \\mathbb{R}^d$:\n1037: \n1038: $$\n1039: q(\\Delta x, \\Delta v) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b\\langle \\Delta x, \\Delta v \\rangle\n1040: $$\n1041: \n1042: where $\\Delta x, \\Delta v \\in \\mathbb{R}^d$, $\\lambda_v > 0$, and $b \\in \\mathbb{R}$ is a coupling parameter.\n1043: \n1044: **Step 1.1: Matrix representation.**\n1045: \n1046: This quadratic form can be represented in block matrix form as:\n1047: \n1048: $$\n1049: q(\\Delta x, \\Delta v) = \\begin{pmatrix} \\Delta x \\\\ \\Delta v \\end{pmatrix}^T \\begin{pmatrix} I_d & \\frac{b}{2} I_d \\\\ \\frac{b}{2} I_d & \\lambda_v I_d \\end{pmatrix} \\begin{pmatrix} \\Delta x \\\\ \\Delta v \\end{pmatrix}\n1050: $$\n1051: \n1052: where the cross-term $b\\langle \\Delta x, \\Delta v \\rangle$ is split symmetrically into the off-diagonal blocks.\n1053: \n1054: **Step 1.2: Positive-definiteness criterion via eigenvalues.**\n1055: \n1056: The quadratic form $q$ is positive-definite if and only if its associated matrix $Q$ is positive-definite, which occurs if and only if all eigenvalues of $Q$ are strictly positive.\n1057: \n1058: For a $2 \\times 2$ block diagonal structure with scalar blocks (after diagonalizing the inner $\\mathbb{R}^d$ structure), the matrix reduces to analyzing the $2 \\times 2$ matrix:\n1059: \n1060: $$\n1061: Q_{\\text{scalar}} = \\begin{pmatrix} 1 & b/2 \\\\ b/2 & \\lambda_v \\end{pmatrix}\n1062: $$\n1063: \n1064: **Step 1.3: Sylvester's criterion.**\n1065: \n1066: A symmetric $2 \\times 2$ matrix $\\begin{pmatrix} a_{11} & a_{12} \\\\ a_{12} & a_{22} \\end{pmatrix}$ is positive-definite if and only if:\n1067: 1. $a_{11} > 0$ (first leading principal minor)\n1068: 2. $\\det \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{12} & a_{22} \\end{pmatrix} > 0$ (second leading principal minor)\n1069: \n1070: For our matrix $Q_{\\text{scalar}}$:\n1071: 1. First condition: $1 > 0$ \u2713 (always satisfied)\n1072: 2. Second condition:\n1073: \n1074: \n1075: $$\n1076: \\det(Q_{\\text{scalar}}) = (1)(\\lambda_v) - \\left(\\frac{b}{2}\\right)^2 = \\lambda_v - \\frac{b^2}{4} > 0\n1077: $$\n1078: \n1079: This requires $\\lambda_v > b^2/4$, which is equivalent to $b^2 < 4\\lambda_v$.\n1080: \n1081: **Step 1.4: Explicit eigenvalue bounds.**\n1082: \n1083: When $b^2 < 4\\lambda_v$, the eigenvalues of $Q_{\\text{scalar}}$ are:\n1084: \n1085: $$\n1086: \\lambda_{\\pm} = \\frac{1 + \\lambda_v \\pm \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2}\n1087: $$\n1088: \n1089: The discriminant satisfies $(1 - \\lambda_v)^2 + b^2 < (1 - \\lambda_v)^2 + 4\\lambda_v = (1 + \\lambda_v)^2$, so:\n1090: \n1091: $$\n1092: \\lambda_{-} = \\frac{1 + \\lambda_v - \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2} > \\frac{1 + \\lambda_v - (1 + \\lambda_v)}{2} = 0\n1093: $$\n1094: \n1095: and similarly $\\lambda_{+} > 0$. Thus both eigenvalues are strictly positive.\n1096: \n1097: **Step 1.5: Coercivity constants.**\n1098: \n1099: The smallest eigenvalue provides the coercivity constant:\n1100: \n1101: $$\n1102: \\lambda_{\\min} = \\min\\{\\lambda_{-}, \\lambda_{+}\\} = \\frac{1 + \\lambda_v - \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2} > 0\n1103: $$\n1104: \n1105: Therefore, for any $(\\Delta x, \\Delta v) \\in \\mathbb{R}^d \\times \\mathbb{R}^d$:\n1106: \n1107: $$\n1108: q(\\Delta x, \\Delta v) \\geq \\lambda_{\\min} \\left(\\|\\Delta x\\|^2 + \\|\\Delta v\\|^2\\right)\n1109: $$\n1110: \n1111: **Part 2: Application to $V_{\\text{loc}}$.**\n1112: \n1113: The location error component is defined as:\n1114: \n1115: $$\n1116: V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle \\Delta\\mu_x, \\Delta\\mu_v \\rangle\n1117: $$\n1118: \n1119: This is precisely the hypocoercive quadratic form $q(\\Delta\\mu_x, \\Delta\\mu_v)$ analyzed in Part 1. Under the condition $b^2 < 4\\lambda_v$, we have:\n1120: \n1121: $$\n1122: V_{\\text{loc}} \\geq \\lambda_1 \\left(\\|\\Delta\\mu_x\\|^2 + \\|\\Delta\\mu_v\\|^2\\right)\n1123: $$\n1124: \n1125: where $\\lambda_1 = \\lambda_{\\min} > 0$ is the smallest eigenvalue from Step 1.5.\n1126: \n1127: **Part 3: Application to $V_{\\text{struct}}$.**\n1128: \n1129: The structural error component is defined as the Wasserstein distance with hypocoercive cost:\n1130: \n1131: $$\n1132: V_{\\text{struct}} = W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int q(\\delta_{x,1} - \\delta_{x,2}, \\delta_{v,1} - \\delta_{v,2}) \\, d\\gamma\n1133: $$\n1134: \n1135: Since the cost function is the hypocoercive quadratic form $q$ applied to centered coordinate differences, and we've proven $q$ is coercive with constant $\\lambda_{\\min}$, we have for any coupling $\\gamma$:\n1136: \n1137: $$\n1138: \\int q(\\delta_{x,1} - \\delta_{x,2}, \\delta_{v,1} - \\delta_{v,2}) \\, d\\gamma \\geq \\lambda_{\\min} \\int \\left(\\|\\delta_{x,1} - \\delta_{x,2}\\|^2 + \\|\\delta_{v,1} - \\delta_{v,2}\\|^2\\right) d\\gamma\n1139: $$\n1140: \n1141: Taking the infimum over all couplings and using the definition of the standard Wasserstein distance on centered measures:\n1142: \n1143: $$\n1144: V_{\\text{struct}} \\geq \\lambda_2 \\cdot W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)\n1145: $$\n1146: \n1147: where $\\lambda_2 = \\lambda_{\\min} > 0$. The standard $W_2$ distance between centered empirical measures satisfies:\n1148: \n1149: $$\n1150: W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\geq \\frac{1}{N} \\sum_{i=1}^N \\inf_{\\sigma \\in S_N} \\left(\\|\\delta_{x,1,i} - \\delta_{x,2,\\sigma(i)}\\|^2 + \\|\\delta_{v,1,i} - \\delta_{v,2,\\sigma(i)}\\|^2\\right)\n1151: $$\n1152: \n1153: where the infimum is over permutations $\\sigma \\in S_N$. This provides the desired bound on the sum of centered coordinate differences.\n1154: \n1155: **Conclusion:**\n1156: \n1157: Under the condition $b^2 < 4\\lambda_v$, both $V_{\\text{loc}}$ and $V_{\\text{struct}}$ are positive-definite quadratic forms with explicit coercivity constants $\\lambda_1, \\lambda_2 > 0$ given by the minimum eigenvalue of the hypocoercive matrix.",
      "metadata": {
        "label": "proof-lem-V-coercive"
      },
      "section": "## 3. The Augmented Hypocoercive Lyapunov Function",
      "references": [],
      "raw_directive": "1026: *   $V_{\\text{struct}} \\ge \\lambda_2 \\frac{1}{N}\\sum_i (\\|\\Delta\\delta_{x,i}\\|^2 + \\|\\Delta\\delta_{v,i}\\|^2)$\n1027: :::\n1028: :::{prf:proof}\n1029: :label: proof-lem-V-coercive\n1030: **Proof.**\n1031: \n1032: We prove the coercivity of both the location and structural components by verifying that the associated quadratic forms are positive-definite under the stated condition.\n1033: \n1034: **Part 1: Positive-definiteness of general hypocoercive quadratic forms.**\n1035: \n1036: Consider a general quadratic form on $\\mathbb{R}^d \\times \\mathbb{R}^d$:\n1037: \n1038: $$\n1039: q(\\Delta x, \\Delta v) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b\\langle \\Delta x, \\Delta v \\rangle\n1040: $$\n1041: \n1042: where $\\Delta x, \\Delta v \\in \\mathbb{R}^d$, $\\lambda_v > 0$, and $b \\in \\mathbb{R}$ is a coupling parameter.\n1043: \n1044: **Step 1.1: Matrix representation.**\n1045: \n1046: This quadratic form can be represented in block matrix form as:\n1047: \n1048: $$\n1049: q(\\Delta x, \\Delta v) = \\begin{pmatrix} \\Delta x \\\\ \\Delta v \\end{pmatrix}^T \\begin{pmatrix} I_d & \\frac{b}{2} I_d \\\\ \\frac{b}{2} I_d & \\lambda_v I_d \\end{pmatrix} \\begin{pmatrix} \\Delta x \\\\ \\Delta v \\end{pmatrix}\n1050: $$\n1051: \n1052: where the cross-term $b\\langle \\Delta x, \\Delta v \\rangle$ is split symmetrically into the off-diagonal blocks.\n1053: \n1054: **Step 1.2: Positive-definiteness criterion via eigenvalues.**\n1055: \n1056: The quadratic form $q$ is positive-definite if and only if its associated matrix $Q$ is positive-definite, which occurs if and only if all eigenvalues of $Q$ are strictly positive.\n1057: \n1058: For a $2 \\times 2$ block diagonal structure with scalar blocks (after diagonalizing the inner $\\mathbb{R}^d$ structure), the matrix reduces to analyzing the $2 \\times 2$ matrix:\n1059: \n1060: $$\n1061: Q_{\\text{scalar}} = \\begin{pmatrix} 1 & b/2 \\\\ b/2 & \\lambda_v \\end{pmatrix}\n1062: $$\n1063: \n1064: **Step 1.3: Sylvester's criterion.**\n1065: \n1066: A symmetric $2 \\times 2$ matrix $\\begin{pmatrix} a_{11} & a_{12} \\\\ a_{12} & a_{22} \\end{pmatrix}$ is positive-definite if and only if:\n1067: 1. $a_{11} > 0$ (first leading principal minor)\n1068: 2. $\\det \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{12} & a_{22} \\end{pmatrix} > 0$ (second leading principal minor)\n1069: \n1070: For our matrix $Q_{\\text{scalar}}$:\n1071: 1. First condition: $1 > 0$ \u2713 (always satisfied)\n1072: 2. Second condition:\n1073: \n1074: \n1075: $$\n1076: \\det(Q_{\\text{scalar}}) = (1)(\\lambda_v) - \\left(\\frac{b}{2}\\right)^2 = \\lambda_v - \\frac{b^2}{4} > 0\n1077: $$\n1078: \n1079: This requires $\\lambda_v > b^2/4$, which is equivalent to $b^2 < 4\\lambda_v$.\n1080: \n1081: **Step 1.4: Explicit eigenvalue bounds.**\n1082: \n1083: When $b^2 < 4\\lambda_v$, the eigenvalues of $Q_{\\text{scalar}}$ are:\n1084: \n1085: $$\n1086: \\lambda_{\\pm} = \\frac{1 + \\lambda_v \\pm \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2}\n1087: $$\n1088: \n1089: The discriminant satisfies $(1 - \\lambda_v)^2 + b^2 < (1 - \\lambda_v)^2 + 4\\lambda_v = (1 + \\lambda_v)^2$, so:\n1090: \n1091: $$\n1092: \\lambda_{-} = \\frac{1 + \\lambda_v - \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2} > \\frac{1 + \\lambda_v - (1 + \\lambda_v)}{2} = 0\n1093: $$\n1094: \n1095: and similarly $\\lambda_{+} > 0$. Thus both eigenvalues are strictly positive.\n1096: \n1097: **Step 1.5: Coercivity constants.**\n1098: \n1099: The smallest eigenvalue provides the coercivity constant:\n1100: \n1101: $$\n1102: \\lambda_{\\min} = \\min\\{\\lambda_{-}, \\lambda_{+}\\} = \\frac{1 + \\lambda_v - \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2} > 0\n1103: $$\n1104: \n1105: Therefore, for any $(\\Delta x, \\Delta v) \\in \\mathbb{R}^d \\times \\mathbb{R}^d$:\n1106: \n1107: $$\n1108: q(\\Delta x, \\Delta v) \\geq \\lambda_{\\min} \\left(\\|\\Delta x\\|^2 + \\|\\Delta v\\|^2\\right)\n1109: $$\n1110: \n1111: **Part 2: Application to $V_{\\text{loc}}$.**\n1112: \n1113: The location error component is defined as:\n1114: \n1115: $$\n1116: V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle \\Delta\\mu_x, \\Delta\\mu_v \\rangle\n1117: $$\n1118: \n1119: This is precisely the hypocoercive quadratic form $q(\\Delta\\mu_x, \\Delta\\mu_v)$ analyzed in Part 1. Under the condition $b^2 < 4\\lambda_v$, we have:\n1120: \n1121: $$\n1122: V_{\\text{loc}} \\geq \\lambda_1 \\left(\\|\\Delta\\mu_x\\|^2 + \\|\\Delta\\mu_v\\|^2\\right)\n1123: $$\n1124: \n1125: where $\\lambda_1 = \\lambda_{\\min} > 0$ is the smallest eigenvalue from Step 1.5.\n1126: \n1127: **Part 3: Application to $V_{\\text{struct}}$.**\n1128: \n1129: The structural error component is defined as the Wasserstein distance with hypocoercive cost:\n1130: \n1131: $$\n1132: V_{\\text{struct}} = W_h^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int q(\\delta_{x,1} - \\delta_{x,2}, \\delta_{v,1} - \\delta_{v,2}) \\, d\\gamma\n1133: $$\n1134: \n1135: Since the cost function is the hypocoercive quadratic form $q$ applied to centered coordinate differences, and we've proven $q$ is coercive with constant $\\lambda_{\\min}$, we have for any coupling $\\gamma$:\n1136: \n1137: $$\n1138: \\int q(\\delta_{x,1} - \\delta_{x,2}, \\delta_{v,1} - \\delta_{v,2}) \\, d\\gamma \\geq \\lambda_{\\min} \\int \\left(\\|\\delta_{x,1} - \\delta_{x,2}\\|^2 + \\|\\delta_{v,1} - \\delta_{v,2}\\|^2\\right) d\\gamma\n1139: $$\n1140: \n1141: Taking the infimum over all couplings and using the definition of the standard Wasserstein distance on centered measures:\n1142: \n1143: $$\n1144: V_{\\text{struct}} \\geq \\lambda_2 \\cdot W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)\n1145: $$\n1146: \n1147: where $\\lambda_2 = \\lambda_{\\min} > 0$. The standard $W_2$ distance between centered empirical measures satisfies:\n1148: \n1149: $$\n1150: W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\geq \\frac{1}{N} \\sum_{i=1}^N \\inf_{\\sigma \\in S_N} \\left(\\|\\delta_{x,1,i} - \\delta_{x,2,\\sigma(i)}\\|^2 + \\|\\delta_{v,1,i} - \\delta_{v,2,\\sigma(i)}\\|^2\\right)\n1151: $$\n1152: \n1153: where the infimum is over permutations $\\sigma \\in S_N$. This provides the desired bound on the sum of centered coordinate differences.\n1154: \n1155: **Conclusion:**\n1156: \n1157: Under the condition $b^2 < 4\\lambda_v$, both $V_{\\text{loc}}$ and $V_{\\text{struct}}$ are positive-definite quadratic forms with explicit coercivity constants $\\lambda_1, \\lambda_2 > 0$ given by the minimum eigenvalue of the hypocoercive matrix.\n1158: "
    }
  ],
  "validation": {
    "ok": true,
    "errors": []
  }
}