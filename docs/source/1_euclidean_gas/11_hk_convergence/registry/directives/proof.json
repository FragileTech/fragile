{
  "document_id": "11_hk_convergence",
  "stage": "directives",
  "directive_type": "proof",
  "generated_at": "2025-11-12T22:37:33.938786+00:00",
  "count": 5,
  "items": [
    {
      "directive_type": "proof",
      "label": "proof-lem-mass-contraction-revival-death",
      "title": null,
      "start_line": 225,
      "end_line": 986,
      "header_lines": [
        226
      ],
      "content_start": 228,
      "content_end": 985,
      "content": "228: :label: proof-lem-mass-contraction-revival-death\n229: \n230: **Constants and Assumptions**\n231: \n232: The proof uses the following constants and assumptions:\n233: \n234: - **$\\lambda_{\\max}$**: Upper bound on the cloning rate: $\\lambda_{\\text{clone}}(k) \\leq \\lambda_{\\max}$ for all $k$\n235: - **$\\bar{p}_{\\max}$**: Upper bound on the killing probability: $\\bar{p}_{\\text{kill}}(k') \\leq \\bar{p}_{\\max}$ for all $k'$\n236: - **$L_\\lambda$**: Lipschitz constant of the cloning rate: $|\\lambda_{\\text{clone}}(k_1) - \\lambda_{\\text{clone}}(k_2)| \\leq L_\\lambda |k_1 - k_2|$\n237: - **$L_p$**: Lipschitz constant of the killing probability: $|\\bar{p}_{\\text{kill}}(k'_1) - \\bar{p}_{\\text{kill}}(k'_2)| \\leq L_p |k'_1 - k'_2|$\n238: - **$L_g^{(1)}$**: Bound on the first derivative of $g(c) = \\bar{p}_{\\text{kill}}(N+c)(N+c)$: $|g'(c)| \\leq L_g^{(1)}$\n239: - **$L_g^{(2)}$**: Bound on the second derivative of $g(c)$: $|g''(c)| \\leq L_g^{(2)}$\n240: \n241: **Assumption on density-dependent scaling:** For rates that depend on densities $\\rho = k/N$, we have $L_g^{(2)} = O(N^{-1})$.\n242: \n243: \n244: \n245: **Explicit Model Definition: Two-Stage Process**\n246: \n247: The Fragile Gas update from time $t$ to $t+1$ consists of two sequential stages:\n248: \n249: 1. **Stage 1 - Births (Cloning + Revival)**: Starting with $k_t$ alive walkers, apply the cloning operator $\\Psi_{\\text{clone}}$ which includes:\n250:    - Guaranteed revival of all $(N - k_t)$ dead walkers (Axiom of Guaranteed Revival)\n251:    - Stochastic cloning of alive walkers, creating $C_t$ new walkers\n252: \n253:    After Stage 1, the intermediate population size is:\n254: \n255:    $$\n256:    k'_t := N + C_t\n257:    $$\n258: \n259: 2. **Stage 2 - Deaths (Kinetic + Boundary)**: Apply the kinetic operator $\\Psi_{\\text{kin}}$ to the intermediate population of size $k'_t$:\n260:    - Langevin diffusion moves walkers\n261:    - Boundary killing removes $D_t$ walkers that exit $\\mathcal{X}_{\\text{valid}}$\n262: \n263:    After Stage 2, the final population size is:\n264: \n265:    $$\n266:    k_{t+1} = k'_t - D_t = N + C_t - D_t\n267:    $$\n268: \n269: **Key Insight:** Deaths $D_t$ are drawn from the intermediate population $k'_t = N + C_t$, NOT from the initial population $k_t$. This temporal ordering is critical for the correct drift calculation.\n270: \n271: **Setup: Mass Balance Equation**\n272: \n273: The mass evolution is:\n274: \n275: $$\n276: k_{t+1} = N + C_t - D_t\n277: \n278: $$\n279: \n280: where:\n281: - $C_t \\geq 0$ is the number of cloning events from Stage 1 (random variable)\n282: - $D_t \\geq 0$ is the number of deaths from Stage 2 (random variable, dependent on $C_t$)\n283: \n284: **Step 1: Expected Deaths (Two-Stage Expectation)**\n285: \n286: Deaths occur when walkers from the intermediate population $k'_t = N + C_t$ exit the valid domain during the kinetic stage.\n287: \n288: Let $\\bar{p}_{\\text{kill}}(k')$ denote the average per-walker killing probability when the population size is $k'$. Then, conditioned on $C_t$:\n289: \n290: $$\n291: \\mathbb{E}[D_t | C_t, k_t] = \\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t)\n292: \n293: $$\n294: \n295: Taking the expectation over $C_t$:\n296: \n297: $$\n298: \\mathbb{E}[D_t | k_t] = \\mathbb{E}_{C_t}[\\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t) | k_t]\n299: \n300: $$\n301: \n302: **Step 2: Expected Cloning Events**\n303: \n304: Cloning events occur in Stage 1. Let $\\lambda_{\\text{clone}}(k_t)$ denote the expected per-walker cloning rate when there are $k_t$ alive walkers:\n305: \n306: $$\n307: \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) \\cdot k_t\n308: \n309: $$\n310: \n311: **Assumption (Lipschitz Continuity of Cloning Rate):** The cloning rate is Lipschitz continuous:\n312: \n313: $$\n314: |\\lambda_{\\text{clone}}(k_1) - \\lambda_{\\text{clone}}(k_2)| \\leq L_\\lambda |k_1 - k_2|\n315: \n316: $$\n317: \n318: **Step 3: Define the Equilibrium**\n319: \n320: At equilibrium, the expected mass change is zero: $\\mathbb{E}[k_{t+1} - k_* | k_t = k_*] = 0$.\n321: \n322: From the mass balance $k_{t+1} = N + C_t - D_t$:\n323: \n324: $$\n325: \\mathbb{E}[N + C_t - D_t | k_* ] = k_*\n326: \n327: $$\n328: \n329: Using the two-stage expectation for deaths:\n330: \n331: $$\n332: N + \\mathbb{E}[C_t | k_*] - \\mathbb{E}_{C_t}[\\mathbb{E}[D_t | C_t, k_*]] = k_*\n333: \n334: $$\n335: \n336: Let $\\lambda_{\\text{clone}}^* := \\lambda_{\\text{clone}}(k_*)$ and $C_* := \\mathbb{E}[C_t | k_*] = \\lambda_{\\text{clone}}^* k_*$.\n337: \n338: At equilibrium, the intermediate population is $k'^* = N + C_*$, and:\n339: \n340: $$\n341: \\bar{p}_{\\text{kill}}^* := \\bar{p}_{\\text{kill}}(k'^*) = \\bar{p}_{\\text{kill}}(N + \\lambda_{\\text{clone}}^* k_*)\n342: \n343: $$\n344: \n345: The equilibrium condition becomes:\n346: \n347: $$\n348: N + \\lambda_{\\text{clone}}^* k_* - \\bar{p}_{\\text{kill}}^* \\cdot (N + \\lambda_{\\text{clone}}^* k_*) = k_*\n349: \n350: $$\n351: \n352: Simplifying:\n353: \n354: $$\n355: (N + \\lambda_{\\text{clone}}^* k_*)(1 - \\bar{p}_{\\text{kill}}^*) = k_*\n356: \n357: $$\n358: \n359: $$\n360: N + \\lambda_{\\text{clone}}^* k_* = \\frac{k_*}{1 - \\bar{p}_{\\text{kill}}^*}\n361: \n362: $$\n363: \n364: **Clarification on the Equilibrium Condition:**\n365: \n366: This equilibrium condition may appear circular since both $k_*$ and $\\bar{p}_{\\text{kill}}^*$ depend on the equilibrium state. However, it is **not circular**—it is a **self-consistency equation** that uniquely determines $k_*$.\n367: \n368: To see this, note that $\\bar{p}_{\\text{kill}}^*$ is evaluated at the **intermediate population** $k'^* = N + \\lambda_{\\text{clone}}^* k_*$, which itself depends on $k_*$. The equilibrium condition can be rewritten as:\n369: \n370: $$\n371: f(k_*) := (N + \\lambda_{\\text{clone}}(k_*) k_*)(1 - \\bar{p}_{\\text{kill}}(N + \\lambda_{\\text{clone}}(k_*) k_*)) - k_* = 0\n372: \n373: $$\n374: \n375: For physically reasonable rate functions $\\lambda_{\\text{clone}}(k)$ and $\\bar{p}_{\\text{kill}}(k')$, this equation has a unique positive solution $k_* \\in (0, N)$, which defines the QSD equilibrium mass. The proof of {prf:ref}`lem-mass-contraction-revival-death` then shows that this equilibrium is **stable**: the mass $k_t$ converges to $k_*$ exponentially fast.\n376: \n377: **Step 4: Expected Mass Change (Two-Stage Calculation with Taylor Expansion)**\n378: \n379: The deviation from equilibrium is:\n380: \n381: $$\n382: k_{t+1} - k_* = N + C_t - D_t - k_*\n383: \n384: $$\n385: \n386: Taking expectations:\n387: \n388: $$\n389: \\mathbb{E}[k_{t+1} - k_* | k_t] = N + \\mathbb{E}[C_t | k_t] - \\mathbb{E}[D_t | k_t] - k_*\n390: \n391: $$\n392: \n393: From Step 2: $\\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$.\n394: \n395: From Step 1, using the law of total expectation:\n396: \n397: $$\n398: \\mathbb{E}[D_t | k_t] = \\mathbb{E}_{C_t}[\\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t) | k_t]\n399: \n400: $$\n401: \n402: **Rigorous expectation calculation via Taylor expansion:**\n403: \n404: Define the death function:\n405: \n406: $$\n407: g(c) := \\bar{p}_{\\text{kill}}(N + c) \\cdot (N + c)\n408: \n409: $$\n410: \n411: **Assumption:** $\\bar{p}_{\\text{kill}}(k')$ is twice continuously differentiable with bounded derivatives:\n412: - $|g'(c)| \\leq L_g^{(1)} < \\infty$\n413: - $|g''(c)| \\leq L_g^{(2)} < \\infty$\n414: \n415: Let $\\bar{C}_t := \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$. By Taylor's theorem:\n416: \n417: $$\n418: g(C_t) = g(\\bar{C}_t) + g'(\\bar{C}_t)(C_t - \\bar{C}_t) + \\frac{1}{2}g''(\\xi_t)(C_t - \\bar{C}_t)^2\n419: \n420: $$\n421: \n422: where $\\xi_t$ is between $C_t$ and $\\bar{C}_t$.\n423: \n424: Taking expectations:\n425: \n426: $$\n427: \\mathbb{E}[D_t | k_t] = \\mathbb{E}[g(C_t) | k_t] = g(\\bar{C}_t) + \\frac{1}{2}\\mathbb{E}[g''(\\xi_t)(C_t - \\bar{C}_t)^2 | k_t]\n428: \n429: $$\n430: \n431: The second-order term is bounded:\n432: \n433: $$\n434: \\left|\\frac{1}{2}\\mathbb{E}[g''(\\xi_t)(C_t - \\bar{C}_t)^2 | k_t]\\right| \\leq \\frac{L_g^{(2)}}{2} \\text{Var}(C_t | k_t)\n435: \n436: $$\n437: \n438: **Model for cloning variance:** Assume cloning events are independent Bernoulli trials, giving:\n439: \n440: $$\n441: \\text{Var}(C_t | k_t) \\leq \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t \\leq \\lambda_{\\max} N\n442: \n443: $$\n444: \n445: where $\\lambda_{\\max} := \\sup_{k} \\lambda_{\\text{clone}}(k)$.\n446: \n447: Thus:\n448: \n449: $$\n450: \\mathbb{E}[D_t | k_t] = g(\\bar{C}_t) + \\mathcal{E}_{\\text{drift}}\n451: \n452: $$\n453: \n454: where the drift error satisfies:\n455: \n456: $$\n457: |\\mathcal{E}_{\\text{drift}}| \\leq \\frac{L_g^{(2)} \\lambda_{\\max} N}{2}\n458: \n459: $$\n460: \n461: Define the intermediate population mean:\n462: \n463: $$\n464: \\bar{k}'_t := N + \\bar{C}_t = N + \\lambda_{\\text{clone}}(k_t) k_t\n465: \n466: $$\n467: \n468: Then:\n469: \n470: $$\n471: \\mathbb{E}[D_t | k_t] = \\bar{p}_{\\text{kill}}(\\bar{k}'_t) \\cdot \\bar{k}'_t + \\mathcal{E}_{\\text{drift}}\n472: \n473: $$\n474: \n475: **Step 5: Drift Analysis Using Equilibrium (with Error Term)**\n476: \n477: Substituting into the expected mass change:\n478: \n479: $$\n480: \\mathbb{E}[k_{t+1} - k_* | k_t] = N + \\lambda_{\\text{clone}}(k_t) k_t - \\bar{p}_{\\text{kill}}(\\bar{k}'_t) \\cdot \\bar{k}'_t - \\mathcal{E}_{\\text{drift}} - k_*\n481: \n482: $$\n483: \n484: $$\n485: = \\bar{k}'_t (1 - \\bar{p}_{\\text{kill}}(\\bar{k}'_t)) - k_* - \\mathcal{E}_{\\text{drift}}\n486: \n487: $$\n488: \n489: From Step 3, at equilibrium $k'^* (1 - \\bar{p}_{\\text{kill}}^*) = k_*$. Thus:\n490: \n491: $$\n492: \\mathbb{E}[k_{t+1} - k_* | k_t] = f(\\bar{k}'_t) - f(k'^*) - \\mathcal{E}_{\\text{drift}}\n493: \n494: $$\n495: \n496: where $f(k') := k'(1 - \\bar{p}_{\\text{kill}}(k'))$.\n497: \n498: **Lipschitz continuity of $f$:** By the same calculation as before, $f$ has Lipschitz constant:\n499: \n500: $$\n501: L_f = 1 + 2L_p N + \\bar{p}_{\\text{kill}}^*\n502: \n503: $$\n504: \n505: From Step 2: $|\\bar{k}'_t - k'^*| \\leq (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*|$.\n506: \n507: Therefore:\n508: \n509: $$\n510: |f(\\bar{k}'_t) - f(k'^*)| \\leq L_f \\cdot (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*|\n511: \n512: $$\n513: \n514: Combining with the drift error from Step 4:\n515: \n516: $$\n517: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq L_f \\cdot (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*| + \\frac{L_g^{(2)} \\lambda_{\\max} N}{2}\n518: \n519: $$\n520: \n521: Define:\n522: - $\\epsilon := L_f (L_\\lambda N + \\lambda_{\\text{clone}}^*) = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$\n523: - $\\mathcal{E}_{\\max} := L_g^{(2)} \\lambda_{\\max} N / 2$\n524: \n525: **Step 6: Lyapunov Function - Squared Error Contraction**\n526: \n527: To properly handle the stochastic fluctuations, we use a **Lyapunov function** approach. Define:\n528: \n529: $$\n530: V(k_t) := (k_t - k_*)^2\n531: \n532: $$\n533: \n534: We will prove a drift inequality:\n535: \n536: $$\n537: \\mathbb{E}[V(k_{t+1}) | k_t] \\leq (1 - \\kappa_{\\text{mass}}) V(k_t) + C_{\\text{mass}}\n538: \n539: $$\n540: \n541: for some constants $\\kappa_{\\text{mass}} > 0$ and $C_{\\text{mass}} < \\infty$.\n542: \n543: **Step 6a: Expansion of Expected Squared Error**\n544: \n545: The mass deviation at time $t+1$ is:\n546: \n547: $$\n548: k_{t+1} - k_* = N + C_t - D_t - k_*\n549: \n550: $$\n551: \n552: From Step 4, using the equilibrium condition:\n553: \n554: $$\n555: k_{t+1} - k_* = (\\bar{p}_{\\text{kill}}^* - \\lambda_{\\text{clone}}^*) k_* - (k_t - k_*) + C_t - D_t\n556: \n557: $$\n558: \n559: Define:\n560: - $\\Delta C_t := C_t - \\mathbb{E}[C_t | k_t]$ (cloning fluctuation)\n561: - $\\Delta D_t := D_t - \\mathbb{E}[D_t | k_t]$ (death fluctuation)\n562: \n563: Then:\n564: \n565: $$\n566: k_{t+1} - k_* = \\mathbb{E}[k_{t+1} - k_* | k_t] + \\Delta C_t - \\Delta D_t\n567: \n568: $$\n569: \n570: Squaring:\n571: \n572: $$\n573: (k_{t+1} - k_*)^2 = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + 2\\mathbb{E}[k_{t+1} - k_* | k_t](\\Delta C_t - \\Delta D_t) + (\\Delta C_t - \\Delta D_t)^2\n574: \n575: $$\n576: \n577: Taking expectations (and using $\\mathbb{E}[\\Delta C_t | k_t] = \\mathbb{E}[\\Delta D_t | k_t] = 0$):\n578: \n579: $$\n580: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + \\text{Var}(C_t - D_t | k_t)\n581: \n582: $$\n583: \n584: **Step 6b: Rigorous Variance Bound Using Law of Total Variance**\n585: \n586: Since $D_t$ depends on $C_t$ (deaths are drawn from the intermediate population), we use the law of total variance:\n587: \n588: $$\n589: \\text{Var}(C_t - D_t | k_t) = \\mathbb{E}[\\text{Var}(C_t - D_t | C_t, k_t)] + \\text{Var}(\\mathbb{E}[C_t - D_t | C_t, k_t])\n590: \n591: $$\n592: \n593: **Term 1: Conditional variance**\n594: \n595: From the two-stage model, conditioned on $C_t$:\n596: \n597: $$\n598: \\text{Var}(C_t - D_t | C_t, k_t) = \\text{Var}(D_t | C_t, k_t)\n599: \n600: $$\n601: \n602: For binomial-like death processes:\n603: \n604: $$\n605: \\text{Var}(D_t | C_t, k_t) \\leq \\mathbb{E}[D_t | C_t, k_t] = \\bar{p}_{\\text{kill}}(N + C_t)(N + C_t)\n606: \n607: $$\n608: \n609: Taking expectations over $C_t$:\n610: \n611: $$\n612: \\mathbb{E}[\\text{Var}(D_t | C_t, k_t)] \\leq \\mathbb{E}[\\bar{p}_{\\text{kill}}(N + C_t)(N + C_t)] \\leq \\bar{p}_{\\max} \\mathbb{E}[N + C_t] = \\bar{p}_{\\max}(N + \\lambda_{\\text{clone}}(k_t) k_t)\n613: \n614: $$\n615: \n616: where $\\bar{p}_{\\max} := \\sup_{k'} \\bar{p}_{\\text{kill}}(k')$. Thus:\n617: \n618: $$\n619: \\mathbb{E}[\\text{Var}(C_t - D_t | C_t, k_t)] \\leq \\bar{p}_{\\max} N (1 + \\lambda_{\\max})\n620: \n621: $$\n622: \n623: **Term 2: Variance of conditional expectation**\n624: \n625: Define $h(c) := c - g(c) = c - \\bar{p}_{\\text{kill}}(N + c)(N + c)$ where $g$ is the death function from Step 4.\n626: \n627: Then:\n628: \n629: $$\n630: \\text{Var}(\\mathbb{E}[C_t - D_t | C_t, k_t]) = \\text{Var}(h(C_t) | k_t)\n631: \n632: $$\n633: \n634: **Rigorous bound via Taylor expansion:**\n635: \n636: Let $\\mu_c := \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$. Expand $h(C_t)$ around $\\mu_c$ using Taylor's theorem:\n637: \n638: $$\n639: h(C_t) = h(\\mu_c) + h'(\\mu_c)(C_t - \\mu_c) + \\frac{1}{2}h''(\\xi_t)(C_t - \\mu_c)^2\n640: \n641: $$\n642: \n643: where $\\xi_t$ is between $C_t$ and $\\mu_c$.\n644: \n645: Taking the variance (noting that $\\mathbb{E}[C_t - \\mu_c | k_t] = 0$):\n646: \n647: $$\n648: \\text{Var}(h(C_t) | k_t) = \\mathbb{E}\\left[\\left(h'(\\mu_c)(C_t - \\mu_c) + \\frac{1}{2}h''(\\xi_t)(C_t - \\mu_c)^2\\right)^2 \\bigg| k_t\\right]\n649: \n650: $$\n651: \n652: Expanding the square and using $(a+b)^2 \\leq 2a^2 + 2b^2$:\n653: \n654: $$\n655: \\text{Var}(h(C_t) | k_t) \\leq 2[h'(\\mu_c)]^2 \\text{Var}(C_t | k_t) + 2\\mathbb{E}\\left[\\frac{1}{4}[h''(\\xi_t)]^2(C_t - \\mu_c)^4 \\bigg| k_t\\right]\n656: \n657: $$\n658: \n659: **Bounding the derivatives:**\n660: \n661: The function $h$ has derivatives:\n662: - $h'(c) = 1 - g'(c)$, with $|h'(c)| \\leq 1 + L_g^{(1)}$ (from Lipschitz property of $g$)\n663: - $h''(c) = -g''(c)$, with $|h''(c)| \\leq L_g^{(2)}$\n664: \n665: **Bounding the fourth moment:**\n666: \n667: For Bernoulli cloning, $C_t$ is distributed as a sum of $k_t$ independent Bernoulli trials with individual success probability $p_t = \\lambda_{\\text{clone}}(k_t)$. Thus $C_t \\sim \\text{Binomial}(k_t, p_t)$ with mean $\\mu_c = k_t p_t$ and variance $\\sigma_c^2 = k_t p_t(1-p_t) \\leq \\mu_c$.\n668: \n669: The fourth central moment of a binomial distribution is:\n670: \n671: $$\n672: \\mu_4 = \\mathbb{E}[(C_t - \\mu_c)^4 | k_t] = 3\\sigma_c^4 + \\sigma_c^2(1 - 6p_t(1-p_t))\n673: \n674: $$\n675: \n676: Since $0 \\leq p_t \\leq 1$, we have $6p_t(1-p_t) \\leq 3/2$, so $1 - 6p_t(1-p_t) \\geq -1/2$. Therefore:\n677: \n678: $$\n679: \\mu_4 \\leq 3\\sigma_c^4 + \\sigma_c^2 \\leq 3\\mu_c^2 + \\mu_c\n680: \n681: $$\n682: \n683: Since $\\mu_c = \\lambda_{\\text{clone}}(k_t) k_t \\leq \\lambda_{\\max} N$, this gives:\n684: \n685: $$\n686: \\mu_4 \\leq 3(\\lambda_{\\max} N)^2 + \\lambda_{\\max} N\n687: \n688: $$\n689: \n690: where we used $\\sigma_c^2 \\leq \\mu_c$.\n691: \n692: Therefore:\n693: \n694: $$\n695: \\text{Var}(h(C_t) | k_t) \\leq 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{1}{2}(L_g^{(2)})^2 (3(\\lambda_{\\max} N)^2 + \\lambda_{\\max} N)\n696: \n697: $$\n698: \n699: $$\n700: = 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{3}{2}(L_g^{(2)})^2 (\\lambda_{\\max} N)^2 + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} N\n701: \n702: $$\n703: \n704: **Combined variance bound:**\n705: \n706: Combining the two terms from the law of total variance:\n707: \n708: $$\n709: \\text{Var}(C_t - D_t | k_t) \\leq \\bar{p}_{\\max} N (1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{3}{2}(L_g^{(2)})^2 (\\lambda_{\\max} N)^2 + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} N\n710: \n711: $$\n712: \n713: Collecting the $O(N)$ terms:\n714: \n715: $$\n716: = N\\left[\\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max}\\right] + \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2\n717: \n718: $$\n719: \n720: Define the variance constant and the $O(1)$ remainder:\n721: \n722: $$\n723: C_{\\text{var}} := \\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} = O(1)\n724: \n725: $$\n726: \n727: $$\n728: C_2 := \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2 = O(1) \\quad \\text{(for density-dependent rates with } L_g^{(2)} = O(N^{-1}))\n729: \n730: $$\n731: \n732: Then:\n733: \n734: $$\n735: \\text{Var}(C_t - D_t | k_t) \\leq C_{\\text{var}} N + C_2\n736: \n737: $$\n738: \n739: **Step 6c: Bound the Drift Term**\n740: \n741: From Step 5, we have:\n742: \n743: $$\n744: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq \\epsilon |k_t - k_*|\n745: \n746: $$\n747: \n748: where $\\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$.\n749: \n750: **Key requirement:** For contraction, we need $\\epsilon < 1$. Expanding:\n751: \n752: $$\n753: \\epsilon = L_\\lambda N + \\lambda_{\\text{clone}}^* + 2L_p L_\\lambda N^2 + O(N)\n754: \n755: $$\n756: \n757: The dominant term is $2L_p L_\\lambda N^2$. Thus, $\\epsilon < 1$ requires:\n758: \n759: $$\n760: L_p L_\\lambda \\ll \\frac{1}{N^2}\n761: \n762: $$\n763: \n764: **Physical interpretation:** This condition states that the product of Lipschitz constants must scale as $O(1/N^2)$. This is natural if rates depend on densities $k/N$ rather than absolute counts, giving $L_p, L_\\lambda \\sim O(1/N)$.\n765: \n766: **Step 6d: Final Lyapunov Inequality (with Error Term)**\n767: \n768: From Step 6a:\n769: \n770: $$\n771: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + \\text{Var}(C_t - D_t | k_t)\n772: \n773: $$\n774: \n775: From Step 5, we have:\n776: \n777: $$\n778: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq \\epsilon |k_t - k_*| + \\mathcal{E}_{\\max}\n779: \n780: $$\n781: \n782: Thus:\n783: \n784: $$\n785: (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 \\leq (\\epsilon |k_t - k_*| + \\mathcal{E}_{\\max})^2 = \\epsilon^2 (k_t - k_*)^2 + 2\\epsilon \\mathcal{E}_{\\max} |k_t - k_*| + \\mathcal{E}_{\\max}^2\n786: \n787: $$\n788: \n789: From Step 6b:\n790: \n791: $$\n792: \\text{Var}(C_t - D_t | k_t) \\leq C_{\\text{var}} N + C_2\n793: \n794: $$\n795: \n796: Combining:\n797: \n798: $$\n799: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq \\epsilon^2 (k_t - k_*)^2 + 2\\epsilon \\mathcal{E}_{\\max} |k_t - k_*| + \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N + C_2\n800: \n801: $$\n802: \n803: **Bounding the cross-term using Young's inequality:**\n804: \n805: We use the general Young's inequality for products: $2ab \\leq \\delta a^2 + (1/\\delta)b^2$ for any $\\delta > 0$.\n806: \n807: The squared drift term is $(A + B)^2$ where $A = \\epsilon |k_t - k_*|$ and $B = \\mathcal{E}_{\\max}$:\n808: \n809: $$\n810: (A + B)^2 = A^2 + 2AB + B^2 \\leq A^2 + \\delta A^2 + \\frac{1}{\\delta}B^2 + B^2 = (1 + \\delta)A^2 + \\left(1 + \\frac{1}{\\delta}\\right)B^2\n811: \n812: $$\n813: \n814: Choosing $\\delta = 1/\\epsilon$ (valid since $\\epsilon > 0$):\n815: \n816: $$\n817: (A + B)^2 \\leq \\left(1 + \\frac{1}{\\epsilon}\\right)\\epsilon^2 (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 = (\\epsilon^2 + \\epsilon)(k_t - k_*)^2 + (1 + \\epsilon)\\mathcal{E}_{\\max}^2\n818: \n819: $$\n820: \n821: Combining all terms:\n822: \n823: $$\n824: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (\\epsilon^2 + \\epsilon) (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N + C_2\n825: \n826: $$\n827: \n828: **Contraction condition:** For contraction, we require:\n829: \n830: $$\n831: \\epsilon^2 + \\epsilon < 1\n832: \n833: $$\n834: \n835: Solving: $\\epsilon < \\frac{\\sqrt{5} - 1}{2} \\approx 0.618$ (golden ratio minus 1).\n836: \n837: **Derivation of the contraction rate $\\kappa_{\\text{mass}}$:**\n838: \n839: From the inequality above, we have shown:\n840: \n841: $$\n842: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (\\epsilon^2 + \\epsilon) (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N\n843: \n844: $$\n845: \n846: To express this in the standard form of a Lyapunov drift inequality:\n847: \n848: $$\n849: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (1 - 2\\kappa_{\\text{mass}}) (k_t - k_*)^2 + C_{\\text{mass}}\n850: \n851: $$\n852: \n853: we require the contraction coefficient to satisfy:\n854: \n855: $$\n856: 1 - 2\\kappa_{\\text{mass}} = \\epsilon^2 + \\epsilon\n857: \n858: $$\n859: \n860: Solving for $\\kappa_{\\text{mass}}$:\n861: \n862: $$\n863: 2\\kappa_{\\text{mass}} = 1 - (\\epsilon^2 + \\epsilon) = 1 - \\epsilon(1 + \\epsilon)\n864: \n865: $$\n866: \n867: Thus:\n868: \n869: $$\n870: \\kappa_{\\text{mass}} = \\frac{1 - \\epsilon - \\epsilon^2}{2}\n871: \n872: $$\n873: \n874: For positivity of $\\kappa_{\\text{mass}}$, we need $\\epsilon^2 + \\epsilon < 1$, which is satisfied when $\\epsilon < \\frac{\\sqrt{5}-1}{2}$.\n875: \n876: The final Lyapunov inequality is:\n877: \n878: $$\n879: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (1 - 2\\kappa_{\\text{mass}}) (k_t - k_*)^2 + C_{\\text{mass}}\n880: \n881: $$\n882: \n883: where:\n884: \n885: $$\n886: C_{\\text{mass}} := C_{\\text{var}} N + C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2\n887: \n888: $$\n889: \n890: **Scaling of $C_{\\text{mass}}$:** For density-dependent death rates $\\bar{p}_{\\text{kill}}(k') = p(k'/N)$, the second derivative satisfies $L_g^{(2)} = O(N^{-1})$ (as established in the Constants and Assumptions section at the beginning of this proof). Therefore:\n891: \n892: $$\n893: \\mathcal{E}_{\\max} = \\frac{L_g^{(2)} \\lambda_{\\max} N}{2} = O(1), \\quad \\mathcal{E}_{\\max}^2 = O(1)\n894: \n895: $$\n896: \n897: From Step 6b, $C_2 = \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2 = O(1)$ as well.\n898: \n899: The constant term is:\n900: \n901: $$\n902: C_{\\text{mass}} = C_{\\text{var}} N + C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 = O(N)\n903: \n904: $$\n905: \n906: The $O(N)$ scaling is dominated by the variance term $C_{\\text{var}} N$ from Step 6b, with both $C_2 = O(1)$ and $(1 + \\epsilon) \\mathcal{E}_{\\max}^2 = O(1)$ contributing to the overall constant but not affecting the leading-order scaling.\n907: \n908: We write $C_{\\text{mass}} = C_N \\cdot N$ where:\n909: \n910: $$\n911: C_N := C_{\\text{var}} + \\frac{C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2}{N} = O(1)\n912: \n913: $$\n914: \n915: **Step 7: Final Result and Physical Interpretation**\n916: \n917: Taking total expectation:\n918: \n919: $$\n920: \\mathbb{E}[(k_{t+1} - k_*)^2] \\leq (1 - 2\\kappa_{\\text{mass}}) \\mathbb{E}[(k_t - k_*)^2] + C_{\\text{mass}}\n921: \n922: $$\n923: \n924: where:\n925: - $\\kappa_{\\text{mass}} = \\frac{1 - \\epsilon - \\epsilon^2}{2}$ with $\\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$\n926: - $C_{\\text{mass}} = C_N \\cdot N$ where $C_N = C_{\\text{var}} + O(1/N)$\n927: - $C_{\\text{var}} = \\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max}$ (variance constant from Step 6b)\n928: - $L_\\lambda$ is the Lipschitz constant of the cloning rate $\\lambda_{\\text{clone}}(k)$\n929: - $L_p$ is the Lipschitz constant of the killing rate $\\bar{p}_{\\text{kill}}(k')$\n930: - $L_g^{(2)}$ is the bound on the second derivative of $g(c) = \\bar{p}_{\\text{kill}}(N + c)(N + c)$\n931: - $N$ is the total number of walkers (alive + dead)\n932: \n933: **Assumption for positivity of $\\kappa_{\\text{mass}}$:** We require $\\epsilon^2 + \\epsilon < 1$, which gives $\\epsilon < \\frac{\\sqrt{5} - 1}{2} \\approx 0.618$. From Step 6c, this requires:\n934: \n935: $$\n936: L_p L_\\lambda = O(N^{-2})\n937: \n938: $$\n939: \n940: **Physical plausibility of the assumption:** This condition is natural when birth/death rates depend on **densities** rather than absolute counts. If:\n941: \n942: $$\n943: \\lambda_{\\text{clone}}(k) = \\lambda(\\rho) \\quad \\text{where } \\rho = k/N\n944: \n945: $$\n946: \n947: $$\n948: \\bar{p}_{\\text{kill}}(k') = p(\\rho') \\quad \\text{where } \\rho' = k'/N\n949: \n950: $$\n951: \n952: Then the Lipschitz constants with respect to $k$ are:\n953: \n954: $$\n955: L_\\lambda = \\frac{1}{N} \\sup_\\rho |\\lambda'(\\rho)|, \\quad L_p = \\frac{1}{N} \\sup_{\\rho'} |p'(\\rho')|\n956: \n957: $$\n958: \n959: Thus $L_p L_\\lambda = O(N^{-2})$, and the condition is automatically satisfied for any smooth density-dependent rates.\n960: \n961: **Complete parameter regime:** The full expression for $\\epsilon$ is:\n962: \n963: $$\n964: \\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)\n965: \n966: $$\n967: \n968: Expanding this with the density-dependent scaling $L_p = O(1/N)$, $L_\\lambda = O(1/N)$:\n969: \n970: $$\n971: \\epsilon = (1 + O(1) + \\bar{p}^*)(O(1) + \\lambda^*) = (1+\\bar{p}^*)\\lambda^* + O(N^{-1})\n972: \n973: $$\n974: \n975: For $\\epsilon < 0.618$, we require:\n976: \n977: $$\n978: (1 + \\bar{p}_{\\text{kill}}^*) \\lambda_{\\text{clone}}^* < 0.6\n979: \n980: $$\n981: \n982: **Physical interpretation:** This condition requires that the product of equilibrium cloning rate and killing probability is not too large. For typical QSD parameters where $\\bar{p}^* \\sim 0.1$ (10% death probability per step) and $\\lambda^* \\sim 0.5$ (50% cloning rate), we have $(1.1)(0.5) = 0.55 < 0.618$. The condition is satisfied for reasonable algorithm parameters and becomes easier to satisfy as $N \\to \\infty$ due to the $O(1/N)$ corrections.\n983: \n984: **Convergence:** This is the standard drift inequality for squared error, which implies exponential convergence of $\\mathbb{E}[(k_t - k_*)^2]$ to the stationary distribution with $\\mathbb{E}[(k_\\infty - k_*)^2] = O(C_{\\text{mass}}/\\kappa_{\\text{mass}}) = O(N/\\kappa_{\\text{mass}})$.\n985: ",
      "metadata": {
        "label": "proof-lem-mass-contraction-revival-death"
      },
      "section": "## 2. Lemma A: Mass Contraction from Revival and Death",
      "references": [
        "lem-mass-contraction-revival-death"
      ],
      "raw_directive": "225: ### Proof of Lemma A\n226: \n227: :::{prf:proof}\n228: :label: proof-lem-mass-contraction-revival-death\n229: \n230: **Constants and Assumptions**\n231: \n232: The proof uses the following constants and assumptions:\n233: \n234: - **$\\lambda_{\\max}$**: Upper bound on the cloning rate: $\\lambda_{\\text{clone}}(k) \\leq \\lambda_{\\max}$ for all $k$\n235: - **$\\bar{p}_{\\max}$**: Upper bound on the killing probability: $\\bar{p}_{\\text{kill}}(k') \\leq \\bar{p}_{\\max}$ for all $k'$\n236: - **$L_\\lambda$**: Lipschitz constant of the cloning rate: $|\\lambda_{\\text{clone}}(k_1) - \\lambda_{\\text{clone}}(k_2)| \\leq L_\\lambda |k_1 - k_2|$\n237: - **$L_p$**: Lipschitz constant of the killing probability: $|\\bar{p}_{\\text{kill}}(k'_1) - \\bar{p}_{\\text{kill}}(k'_2)| \\leq L_p |k'_1 - k'_2|$\n238: - **$L_g^{(1)}$**: Bound on the first derivative of $g(c) = \\bar{p}_{\\text{kill}}(N+c)(N+c)$: $|g'(c)| \\leq L_g^{(1)}$\n239: - **$L_g^{(2)}$**: Bound on the second derivative of $g(c)$: $|g''(c)| \\leq L_g^{(2)}$\n240: \n241: **Assumption on density-dependent scaling:** For rates that depend on densities $\\rho = k/N$, we have $L_g^{(2)} = O(N^{-1})$.\n242: \n243: \n244: \n245: **Explicit Model Definition: Two-Stage Process**\n246: \n247: The Fragile Gas update from time $t$ to $t+1$ consists of two sequential stages:\n248: \n249: 1. **Stage 1 - Births (Cloning + Revival)**: Starting with $k_t$ alive walkers, apply the cloning operator $\\Psi_{\\text{clone}}$ which includes:\n250:    - Guaranteed revival of all $(N - k_t)$ dead walkers (Axiom of Guaranteed Revival)\n251:    - Stochastic cloning of alive walkers, creating $C_t$ new walkers\n252: \n253:    After Stage 1, the intermediate population size is:\n254: \n255:    $$\n256:    k'_t := N + C_t\n257:    $$\n258: \n259: 2. **Stage 2 - Deaths (Kinetic + Boundary)**: Apply the kinetic operator $\\Psi_{\\text{kin}}$ to the intermediate population of size $k'_t$:\n260:    - Langevin diffusion moves walkers\n261:    - Boundary killing removes $D_t$ walkers that exit $\\mathcal{X}_{\\text{valid}}$\n262: \n263:    After Stage 2, the final population size is:\n264: \n265:    $$\n266:    k_{t+1} = k'_t - D_t = N + C_t - D_t\n267:    $$\n268: \n269: **Key Insight:** Deaths $D_t$ are drawn from the intermediate population $k'_t = N + C_t$, NOT from the initial population $k_t$. This temporal ordering is critical for the correct drift calculation.\n270: \n271: **Setup: Mass Balance Equation**\n272: \n273: The mass evolution is:\n274: \n275: $$\n276: k_{t+1} = N + C_t - D_t\n277: \n278: $$\n279: \n280: where:\n281: - $C_t \\geq 0$ is the number of cloning events from Stage 1 (random variable)\n282: - $D_t \\geq 0$ is the number of deaths from Stage 2 (random variable, dependent on $C_t$)\n283: \n284: **Step 1: Expected Deaths (Two-Stage Expectation)**\n285: \n286: Deaths occur when walkers from the intermediate population $k'_t = N + C_t$ exit the valid domain during the kinetic stage.\n287: \n288: Let $\\bar{p}_{\\text{kill}}(k')$ denote the average per-walker killing probability when the population size is $k'$. Then, conditioned on $C_t$:\n289: \n290: $$\n291: \\mathbb{E}[D_t | C_t, k_t] = \\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t)\n292: \n293: $$\n294: \n295: Taking the expectation over $C_t$:\n296: \n297: $$\n298: \\mathbb{E}[D_t | k_t] = \\mathbb{E}_{C_t}[\\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t) | k_t]\n299: \n300: $$\n301: \n302: **Step 2: Expected Cloning Events**\n303: \n304: Cloning events occur in Stage 1. Let $\\lambda_{\\text{clone}}(k_t)$ denote the expected per-walker cloning rate when there are $k_t$ alive walkers:\n305: \n306: $$\n307: \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) \\cdot k_t\n308: \n309: $$\n310: \n311: **Assumption (Lipschitz Continuity of Cloning Rate):** The cloning rate is Lipschitz continuous:\n312: \n313: $$\n314: |\\lambda_{\\text{clone}}(k_1) - \\lambda_{\\text{clone}}(k_2)| \\leq L_\\lambda |k_1 - k_2|\n315: \n316: $$\n317: \n318: **Step 3: Define the Equilibrium**\n319: \n320: At equilibrium, the expected mass change is zero: $\\mathbb{E}[k_{t+1} - k_* | k_t = k_*] = 0$.\n321: \n322: From the mass balance $k_{t+1} = N + C_t - D_t$:\n323: \n324: $$\n325: \\mathbb{E}[N + C_t - D_t | k_* ] = k_*\n326: \n327: $$\n328: \n329: Using the two-stage expectation for deaths:\n330: \n331: $$\n332: N + \\mathbb{E}[C_t | k_*] - \\mathbb{E}_{C_t}[\\mathbb{E}[D_t | C_t, k_*]] = k_*\n333: \n334: $$\n335: \n336: Let $\\lambda_{\\text{clone}}^* := \\lambda_{\\text{clone}}(k_*)$ and $C_* := \\mathbb{E}[C_t | k_*] = \\lambda_{\\text{clone}}^* k_*$.\n337: \n338: At equilibrium, the intermediate population is $k'^* = N + C_*$, and:\n339: \n340: $$\n341: \\bar{p}_{\\text{kill}}^* := \\bar{p}_{\\text{kill}}(k'^*) = \\bar{p}_{\\text{kill}}(N + \\lambda_{\\text{clone}}^* k_*)\n342: \n343: $$\n344: \n345: The equilibrium condition becomes:\n346: \n347: $$\n348: N + \\lambda_{\\text{clone}}^* k_* - \\bar{p}_{\\text{kill}}^* \\cdot (N + \\lambda_{\\text{clone}}^* k_*) = k_*\n349: \n350: $$\n351: \n352: Simplifying:\n353: \n354: $$\n355: (N + \\lambda_{\\text{clone}}^* k_*)(1 - \\bar{p}_{\\text{kill}}^*) = k_*\n356: \n357: $$\n358: \n359: $$\n360: N + \\lambda_{\\text{clone}}^* k_* = \\frac{k_*}{1 - \\bar{p}_{\\text{kill}}^*}\n361: \n362: $$\n363: \n364: **Clarification on the Equilibrium Condition:**\n365: \n366: This equilibrium condition may appear circular since both $k_*$ and $\\bar{p}_{\\text{kill}}^*$ depend on the equilibrium state. However, it is **not circular**—it is a **self-consistency equation** that uniquely determines $k_*$.\n367: \n368: To see this, note that $\\bar{p}_{\\text{kill}}^*$ is evaluated at the **intermediate population** $k'^* = N + \\lambda_{\\text{clone}}^* k_*$, which itself depends on $k_*$. The equilibrium condition can be rewritten as:\n369: \n370: $$\n371: f(k_*) := (N + \\lambda_{\\text{clone}}(k_*) k_*)(1 - \\bar{p}_{\\text{kill}}(N + \\lambda_{\\text{clone}}(k_*) k_*)) - k_* = 0\n372: \n373: $$\n374: \n375: For physically reasonable rate functions $\\lambda_{\\text{clone}}(k)$ and $\\bar{p}_{\\text{kill}}(k')$, this equation has a unique positive solution $k_* \\in (0, N)$, which defines the QSD equilibrium mass. The proof of {prf:ref}`lem-mass-contraction-revival-death` then shows that this equilibrium is **stable**: the mass $k_t$ converges to $k_*$ exponentially fast.\n376: \n377: **Step 4: Expected Mass Change (Two-Stage Calculation with Taylor Expansion)**\n378: \n379: The deviation from equilibrium is:\n380: \n381: $$\n382: k_{t+1} - k_* = N + C_t - D_t - k_*\n383: \n384: $$\n385: \n386: Taking expectations:\n387: \n388: $$\n389: \\mathbb{E}[k_{t+1} - k_* | k_t] = N + \\mathbb{E}[C_t | k_t] - \\mathbb{E}[D_t | k_t] - k_*\n390: \n391: $$\n392: \n393: From Step 2: $\\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$.\n394: \n395: From Step 1, using the law of total expectation:\n396: \n397: $$\n398: \\mathbb{E}[D_t | k_t] = \\mathbb{E}_{C_t}[\\bar{p}_{\\text{kill}}(N + C_t) \\cdot (N + C_t) | k_t]\n399: \n400: $$\n401: \n402: **Rigorous expectation calculation via Taylor expansion:**\n403: \n404: Define the death function:\n405: \n406: $$\n407: g(c) := \\bar{p}_{\\text{kill}}(N + c) \\cdot (N + c)\n408: \n409: $$\n410: \n411: **Assumption:** $\\bar{p}_{\\text{kill}}(k')$ is twice continuously differentiable with bounded derivatives:\n412: - $|g'(c)| \\leq L_g^{(1)} < \\infty$\n413: - $|g''(c)| \\leq L_g^{(2)} < \\infty$\n414: \n415: Let $\\bar{C}_t := \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$. By Taylor's theorem:\n416: \n417: $$\n418: g(C_t) = g(\\bar{C}_t) + g'(\\bar{C}_t)(C_t - \\bar{C}_t) + \\frac{1}{2}g''(\\xi_t)(C_t - \\bar{C}_t)^2\n419: \n420: $$\n421: \n422: where $\\xi_t$ is between $C_t$ and $\\bar{C}_t$.\n423: \n424: Taking expectations:\n425: \n426: $$\n427: \\mathbb{E}[D_t | k_t] = \\mathbb{E}[g(C_t) | k_t] = g(\\bar{C}_t) + \\frac{1}{2}\\mathbb{E}[g''(\\xi_t)(C_t - \\bar{C}_t)^2 | k_t]\n428: \n429: $$\n430: \n431: The second-order term is bounded:\n432: \n433: $$\n434: \\left|\\frac{1}{2}\\mathbb{E}[g''(\\xi_t)(C_t - \\bar{C}_t)^2 | k_t]\\right| \\leq \\frac{L_g^{(2)}}{2} \\text{Var}(C_t | k_t)\n435: \n436: $$\n437: \n438: **Model for cloning variance:** Assume cloning events are independent Bernoulli trials, giving:\n439: \n440: $$\n441: \\text{Var}(C_t | k_t) \\leq \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t \\leq \\lambda_{\\max} N\n442: \n443: $$\n444: \n445: where $\\lambda_{\\max} := \\sup_{k} \\lambda_{\\text{clone}}(k)$.\n446: \n447: Thus:\n448: \n449: $$\n450: \\mathbb{E}[D_t | k_t] = g(\\bar{C}_t) + \\mathcal{E}_{\\text{drift}}\n451: \n452: $$\n453: \n454: where the drift error satisfies:\n455: \n456: $$\n457: |\\mathcal{E}_{\\text{drift}}| \\leq \\frac{L_g^{(2)} \\lambda_{\\max} N}{2}\n458: \n459: $$\n460: \n461: Define the intermediate population mean:\n462: \n463: $$\n464: \\bar{k}'_t := N + \\bar{C}_t = N + \\lambda_{\\text{clone}}(k_t) k_t\n465: \n466: $$\n467: \n468: Then:\n469: \n470: $$\n471: \\mathbb{E}[D_t | k_t] = \\bar{p}_{\\text{kill}}(\\bar{k}'_t) \\cdot \\bar{k}'_t + \\mathcal{E}_{\\text{drift}}\n472: \n473: $$\n474: \n475: **Step 5: Drift Analysis Using Equilibrium (with Error Term)**\n476: \n477: Substituting into the expected mass change:\n478: \n479: $$\n480: \\mathbb{E}[k_{t+1} - k_* | k_t] = N + \\lambda_{\\text{clone}}(k_t) k_t - \\bar{p}_{\\text{kill}}(\\bar{k}'_t) \\cdot \\bar{k}'_t - \\mathcal{E}_{\\text{drift}} - k_*\n481: \n482: $$\n483: \n484: $$\n485: = \\bar{k}'_t (1 - \\bar{p}_{\\text{kill}}(\\bar{k}'_t)) - k_* - \\mathcal{E}_{\\text{drift}}\n486: \n487: $$\n488: \n489: From Step 3, at equilibrium $k'^* (1 - \\bar{p}_{\\text{kill}}^*) = k_*$. Thus:\n490: \n491: $$\n492: \\mathbb{E}[k_{t+1} - k_* | k_t] = f(\\bar{k}'_t) - f(k'^*) - \\mathcal{E}_{\\text{drift}}\n493: \n494: $$\n495: \n496: where $f(k') := k'(1 - \\bar{p}_{\\text{kill}}(k'))$.\n497: \n498: **Lipschitz continuity of $f$:** By the same calculation as before, $f$ has Lipschitz constant:\n499: \n500: $$\n501: L_f = 1 + 2L_p N + \\bar{p}_{\\text{kill}}^*\n502: \n503: $$\n504: \n505: From Step 2: $|\\bar{k}'_t - k'^*| \\leq (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*|$.\n506: \n507: Therefore:\n508: \n509: $$\n510: |f(\\bar{k}'_t) - f(k'^*)| \\leq L_f \\cdot (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*|\n511: \n512: $$\n513: \n514: Combining with the drift error from Step 4:\n515: \n516: $$\n517: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq L_f \\cdot (L_\\lambda N + \\lambda_{\\text{clone}}^*) |k_t - k_*| + \\frac{L_g^{(2)} \\lambda_{\\max} N}{2}\n518: \n519: $$\n520: \n521: Define:\n522: - $\\epsilon := L_f (L_\\lambda N + \\lambda_{\\text{clone}}^*) = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$\n523: - $\\mathcal{E}_{\\max} := L_g^{(2)} \\lambda_{\\max} N / 2$\n524: \n525: **Step 6: Lyapunov Function - Squared Error Contraction**\n526: \n527: To properly handle the stochastic fluctuations, we use a **Lyapunov function** approach. Define:\n528: \n529: $$\n530: V(k_t) := (k_t - k_*)^2\n531: \n532: $$\n533: \n534: We will prove a drift inequality:\n535: \n536: $$\n537: \\mathbb{E}[V(k_{t+1}) | k_t] \\leq (1 - \\kappa_{\\text{mass}}) V(k_t) + C_{\\text{mass}}\n538: \n539: $$\n540: \n541: for some constants $\\kappa_{\\text{mass}} > 0$ and $C_{\\text{mass}} < \\infty$.\n542: \n543: **Step 6a: Expansion of Expected Squared Error**\n544: \n545: The mass deviation at time $t+1$ is:\n546: \n547: $$\n548: k_{t+1} - k_* = N + C_t - D_t - k_*\n549: \n550: $$\n551: \n552: From Step 4, using the equilibrium condition:\n553: \n554: $$\n555: k_{t+1} - k_* = (\\bar{p}_{\\text{kill}}^* - \\lambda_{\\text{clone}}^*) k_* - (k_t - k_*) + C_t - D_t\n556: \n557: $$\n558: \n559: Define:\n560: - $\\Delta C_t := C_t - \\mathbb{E}[C_t | k_t]$ (cloning fluctuation)\n561: - $\\Delta D_t := D_t - \\mathbb{E}[D_t | k_t]$ (death fluctuation)\n562: \n563: Then:\n564: \n565: $$\n566: k_{t+1} - k_* = \\mathbb{E}[k_{t+1} - k_* | k_t] + \\Delta C_t - \\Delta D_t\n567: \n568: $$\n569: \n570: Squaring:\n571: \n572: $$\n573: (k_{t+1} - k_*)^2 = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + 2\\mathbb{E}[k_{t+1} - k_* | k_t](\\Delta C_t - \\Delta D_t) + (\\Delta C_t - \\Delta D_t)^2\n574: \n575: $$\n576: \n577: Taking expectations (and using $\\mathbb{E}[\\Delta C_t | k_t] = \\mathbb{E}[\\Delta D_t | k_t] = 0$):\n578: \n579: $$\n580: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + \\text{Var}(C_t - D_t | k_t)\n581: \n582: $$\n583: \n584: **Step 6b: Rigorous Variance Bound Using Law of Total Variance**\n585: \n586: Since $D_t$ depends on $C_t$ (deaths are drawn from the intermediate population), we use the law of total variance:\n587: \n588: $$\n589: \\text{Var}(C_t - D_t | k_t) = \\mathbb{E}[\\text{Var}(C_t - D_t | C_t, k_t)] + \\text{Var}(\\mathbb{E}[C_t - D_t | C_t, k_t])\n590: \n591: $$\n592: \n593: **Term 1: Conditional variance**\n594: \n595: From the two-stage model, conditioned on $C_t$:\n596: \n597: $$\n598: \\text{Var}(C_t - D_t | C_t, k_t) = \\text{Var}(D_t | C_t, k_t)\n599: \n600: $$\n601: \n602: For binomial-like death processes:\n603: \n604: $$\n605: \\text{Var}(D_t | C_t, k_t) \\leq \\mathbb{E}[D_t | C_t, k_t] = \\bar{p}_{\\text{kill}}(N + C_t)(N + C_t)\n606: \n607: $$\n608: \n609: Taking expectations over $C_t$:\n610: \n611: $$\n612: \\mathbb{E}[\\text{Var}(D_t | C_t, k_t)] \\leq \\mathbb{E}[\\bar{p}_{\\text{kill}}(N + C_t)(N + C_t)] \\leq \\bar{p}_{\\max} \\mathbb{E}[N + C_t] = \\bar{p}_{\\max}(N + \\lambda_{\\text{clone}}(k_t) k_t)\n613: \n614: $$\n615: \n616: where $\\bar{p}_{\\max} := \\sup_{k'} \\bar{p}_{\\text{kill}}(k')$. Thus:\n617: \n618: $$\n619: \\mathbb{E}[\\text{Var}(C_t - D_t | C_t, k_t)] \\leq \\bar{p}_{\\max} N (1 + \\lambda_{\\max})\n620: \n621: $$\n622: \n623: **Term 2: Variance of conditional expectation**\n624: \n625: Define $h(c) := c - g(c) = c - \\bar{p}_{\\text{kill}}(N + c)(N + c)$ where $g$ is the death function from Step 4.\n626: \n627: Then:\n628: \n629: $$\n630: \\text{Var}(\\mathbb{E}[C_t - D_t | C_t, k_t]) = \\text{Var}(h(C_t) | k_t)\n631: \n632: $$\n633: \n634: **Rigorous bound via Taylor expansion:**\n635: \n636: Let $\\mu_c := \\mathbb{E}[C_t | k_t] = \\lambda_{\\text{clone}}(k_t) k_t$. Expand $h(C_t)$ around $\\mu_c$ using Taylor's theorem:\n637: \n638: $$\n639: h(C_t) = h(\\mu_c) + h'(\\mu_c)(C_t - \\mu_c) + \\frac{1}{2}h''(\\xi_t)(C_t - \\mu_c)^2\n640: \n641: $$\n642: \n643: where $\\xi_t$ is between $C_t$ and $\\mu_c$.\n644: \n645: Taking the variance (noting that $\\mathbb{E}[C_t - \\mu_c | k_t] = 0$):\n646: \n647: $$\n648: \\text{Var}(h(C_t) | k_t) = \\mathbb{E}\\left[\\left(h'(\\mu_c)(C_t - \\mu_c) + \\frac{1}{2}h''(\\xi_t)(C_t - \\mu_c)^2\\right)^2 \\bigg| k_t\\right]\n649: \n650: $$\n651: \n652: Expanding the square and using $(a+b)^2 \\leq 2a^2 + 2b^2$:\n653: \n654: $$\n655: \\text{Var}(h(C_t) | k_t) \\leq 2[h'(\\mu_c)]^2 \\text{Var}(C_t | k_t) + 2\\mathbb{E}\\left[\\frac{1}{4}[h''(\\xi_t)]^2(C_t - \\mu_c)^4 \\bigg| k_t\\right]\n656: \n657: $$\n658: \n659: **Bounding the derivatives:**\n660: \n661: The function $h$ has derivatives:\n662: - $h'(c) = 1 - g'(c)$, with $|h'(c)| \\leq 1 + L_g^{(1)}$ (from Lipschitz property of $g$)\n663: - $h''(c) = -g''(c)$, with $|h''(c)| \\leq L_g^{(2)}$\n664: \n665: **Bounding the fourth moment:**\n666: \n667: For Bernoulli cloning, $C_t$ is distributed as a sum of $k_t$ independent Bernoulli trials with individual success probability $p_t = \\lambda_{\\text{clone}}(k_t)$. Thus $C_t \\sim \\text{Binomial}(k_t, p_t)$ with mean $\\mu_c = k_t p_t$ and variance $\\sigma_c^2 = k_t p_t(1-p_t) \\leq \\mu_c$.\n668: \n669: The fourth central moment of a binomial distribution is:\n670: \n671: $$\n672: \\mu_4 = \\mathbb{E}[(C_t - \\mu_c)^4 | k_t] = 3\\sigma_c^4 + \\sigma_c^2(1 - 6p_t(1-p_t))\n673: \n674: $$\n675: \n676: Since $0 \\leq p_t \\leq 1$, we have $6p_t(1-p_t) \\leq 3/2$, so $1 - 6p_t(1-p_t) \\geq -1/2$. Therefore:\n677: \n678: $$\n679: \\mu_4 \\leq 3\\sigma_c^4 + \\sigma_c^2 \\leq 3\\mu_c^2 + \\mu_c\n680: \n681: $$\n682: \n683: Since $\\mu_c = \\lambda_{\\text{clone}}(k_t) k_t \\leq \\lambda_{\\max} N$, this gives:\n684: \n685: $$\n686: \\mu_4 \\leq 3(\\lambda_{\\max} N)^2 + \\lambda_{\\max} N\n687: \n688: $$\n689: \n690: where we used $\\sigma_c^2 \\leq \\mu_c$.\n691: \n692: Therefore:\n693: \n694: $$\n695: \\text{Var}(h(C_t) | k_t) \\leq 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{1}{2}(L_g^{(2)})^2 (3(\\lambda_{\\max} N)^2 + \\lambda_{\\max} N)\n696: \n697: $$\n698: \n699: $$\n700: = 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{3}{2}(L_g^{(2)})^2 (\\lambda_{\\max} N)^2 + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} N\n701: \n702: $$\n703: \n704: **Combined variance bound:**\n705: \n706: Combining the two terms from the law of total variance:\n707: \n708: $$\n709: \\text{Var}(C_t - D_t | k_t) \\leq \\bar{p}_{\\max} N (1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} N + \\frac{3}{2}(L_g^{(2)})^2 (\\lambda_{\\max} N)^2 + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} N\n710: \n711: $$\n712: \n713: Collecting the $O(N)$ terms:\n714: \n715: $$\n716: = N\\left[\\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max}\\right] + \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2\n717: \n718: $$\n719: \n720: Define the variance constant and the $O(1)$ remainder:\n721: \n722: $$\n723: C_{\\text{var}} := \\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max} = O(1)\n724: \n725: $$\n726: \n727: $$\n728: C_2 := \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2 = O(1) \\quad \\text{(for density-dependent rates with } L_g^{(2)} = O(N^{-1}))\n729: \n730: $$\n731: \n732: Then:\n733: \n734: $$\n735: \\text{Var}(C_t - D_t | k_t) \\leq C_{\\text{var}} N + C_2\n736: \n737: $$\n738: \n739: **Step 6c: Bound the Drift Term**\n740: \n741: From Step 5, we have:\n742: \n743: $$\n744: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq \\epsilon |k_t - k_*|\n745: \n746: $$\n747: \n748: where $\\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$.\n749: \n750: **Key requirement:** For contraction, we need $\\epsilon < 1$. Expanding:\n751: \n752: $$\n753: \\epsilon = L_\\lambda N + \\lambda_{\\text{clone}}^* + 2L_p L_\\lambda N^2 + O(N)\n754: \n755: $$\n756: \n757: The dominant term is $2L_p L_\\lambda N^2$. Thus, $\\epsilon < 1$ requires:\n758: \n759: $$\n760: L_p L_\\lambda \\ll \\frac{1}{N^2}\n761: \n762: $$\n763: \n764: **Physical interpretation:** This condition states that the product of Lipschitz constants must scale as $O(1/N^2)$. This is natural if rates depend on densities $k/N$ rather than absolute counts, giving $L_p, L_\\lambda \\sim O(1/N)$.\n765: \n766: **Step 6d: Final Lyapunov Inequality (with Error Term)**\n767: \n768: From Step 6a:\n769: \n770: $$\n771: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] = (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 + \\text{Var}(C_t - D_t | k_t)\n772: \n773: $$\n774: \n775: From Step 5, we have:\n776: \n777: $$\n778: |\\mathbb{E}[k_{t+1} - k_* | k_t]| \\leq \\epsilon |k_t - k_*| + \\mathcal{E}_{\\max}\n779: \n780: $$\n781: \n782: Thus:\n783: \n784: $$\n785: (\\mathbb{E}[k_{t+1} - k_* | k_t])^2 \\leq (\\epsilon |k_t - k_*| + \\mathcal{E}_{\\max})^2 = \\epsilon^2 (k_t - k_*)^2 + 2\\epsilon \\mathcal{E}_{\\max} |k_t - k_*| + \\mathcal{E}_{\\max}^2\n786: \n787: $$\n788: \n789: From Step 6b:\n790: \n791: $$\n792: \\text{Var}(C_t - D_t | k_t) \\leq C_{\\text{var}} N + C_2\n793: \n794: $$\n795: \n796: Combining:\n797: \n798: $$\n799: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq \\epsilon^2 (k_t - k_*)^2 + 2\\epsilon \\mathcal{E}_{\\max} |k_t - k_*| + \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N + C_2\n800: \n801: $$\n802: \n803: **Bounding the cross-term using Young's inequality:**\n804: \n805: We use the general Young's inequality for products: $2ab \\leq \\delta a^2 + (1/\\delta)b^2$ for any $\\delta > 0$.\n806: \n807: The squared drift term is $(A + B)^2$ where $A = \\epsilon |k_t - k_*|$ and $B = \\mathcal{E}_{\\max}$:\n808: \n809: $$\n810: (A + B)^2 = A^2 + 2AB + B^2 \\leq A^2 + \\delta A^2 + \\frac{1}{\\delta}B^2 + B^2 = (1 + \\delta)A^2 + \\left(1 + \\frac{1}{\\delta}\\right)B^2\n811: \n812: $$\n813: \n814: Choosing $\\delta = 1/\\epsilon$ (valid since $\\epsilon > 0$):\n815: \n816: $$\n817: (A + B)^2 \\leq \\left(1 + \\frac{1}{\\epsilon}\\right)\\epsilon^2 (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 = (\\epsilon^2 + \\epsilon)(k_t - k_*)^2 + (1 + \\epsilon)\\mathcal{E}_{\\max}^2\n818: \n819: $$\n820: \n821: Combining all terms:\n822: \n823: $$\n824: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (\\epsilon^2 + \\epsilon) (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N + C_2\n825: \n826: $$\n827: \n828: **Contraction condition:** For contraction, we require:\n829: \n830: $$\n831: \\epsilon^2 + \\epsilon < 1\n832: \n833: $$\n834: \n835: Solving: $\\epsilon < \\frac{\\sqrt{5} - 1}{2} \\approx 0.618$ (golden ratio minus 1).\n836: \n837: **Derivation of the contraction rate $\\kappa_{\\text{mass}}$:**\n838: \n839: From the inequality above, we have shown:\n840: \n841: $$\n842: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (\\epsilon^2 + \\epsilon) (k_t - k_*)^2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 + C_{\\text{var}} N\n843: \n844: $$\n845: \n846: To express this in the standard form of a Lyapunov drift inequality:\n847: \n848: $$\n849: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (1 - 2\\kappa_{\\text{mass}}) (k_t - k_*)^2 + C_{\\text{mass}}\n850: \n851: $$\n852: \n853: we require the contraction coefficient to satisfy:\n854: \n855: $$\n856: 1 - 2\\kappa_{\\text{mass}} = \\epsilon^2 + \\epsilon\n857: \n858: $$\n859: \n860: Solving for $\\kappa_{\\text{mass}}$:\n861: \n862: $$\n863: 2\\kappa_{\\text{mass}} = 1 - (\\epsilon^2 + \\epsilon) = 1 - \\epsilon(1 + \\epsilon)\n864: \n865: $$\n866: \n867: Thus:\n868: \n869: $$\n870: \\kappa_{\\text{mass}} = \\frac{1 - \\epsilon - \\epsilon^2}{2}\n871: \n872: $$\n873: \n874: For positivity of $\\kappa_{\\text{mass}}$, we need $\\epsilon^2 + \\epsilon < 1$, which is satisfied when $\\epsilon < \\frac{\\sqrt{5}-1}{2}$.\n875: \n876: The final Lyapunov inequality is:\n877: \n878: $$\n879: \\mathbb{E}[(k_{t+1} - k_*)^2 | k_t] \\leq (1 - 2\\kappa_{\\text{mass}}) (k_t - k_*)^2 + C_{\\text{mass}}\n880: \n881: $$\n882: \n883: where:\n884: \n885: $$\n886: C_{\\text{mass}} := C_{\\text{var}} N + C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2\n887: \n888: $$\n889: \n890: **Scaling of $C_{\\text{mass}}$:** For density-dependent death rates $\\bar{p}_{\\text{kill}}(k') = p(k'/N)$, the second derivative satisfies $L_g^{(2)} = O(N^{-1})$ (as established in the Constants and Assumptions section at the beginning of this proof). Therefore:\n891: \n892: $$\n893: \\mathcal{E}_{\\max} = \\frac{L_g^{(2)} \\lambda_{\\max} N}{2} = O(1), \\quad \\mathcal{E}_{\\max}^2 = O(1)\n894: \n895: $$\n896: \n897: From Step 6b, $C_2 = \\frac{3}{2}(L_g^{(2)} \\lambda_{\\max} N)^2 = O(1)$ as well.\n898: \n899: The constant term is:\n900: \n901: $$\n902: C_{\\text{mass}} = C_{\\text{var}} N + C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2 = O(N)\n903: \n904: $$\n905: \n906: The $O(N)$ scaling is dominated by the variance term $C_{\\text{var}} N$ from Step 6b, with both $C_2 = O(1)$ and $(1 + \\epsilon) \\mathcal{E}_{\\max}^2 = O(1)$ contributing to the overall constant but not affecting the leading-order scaling.\n907: \n908: We write $C_{\\text{mass}} = C_N \\cdot N$ where:\n909: \n910: $$\n911: C_N := C_{\\text{var}} + \\frac{C_2 + (1 + \\epsilon) \\mathcal{E}_{\\max}^2}{N} = O(1)\n912: \n913: $$\n914: \n915: **Step 7: Final Result and Physical Interpretation**\n916: \n917: Taking total expectation:\n918: \n919: $$\n920: \\mathbb{E}[(k_{t+1} - k_*)^2] \\leq (1 - 2\\kappa_{\\text{mass}}) \\mathbb{E}[(k_t - k_*)^2] + C_{\\text{mass}}\n921: \n922: $$\n923: \n924: where:\n925: - $\\kappa_{\\text{mass}} = \\frac{1 - \\epsilon - \\epsilon^2}{2}$ with $\\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)$\n926: - $C_{\\text{mass}} = C_N \\cdot N$ where $C_N = C_{\\text{var}} + O(1/N)$\n927: - $C_{\\text{var}} = \\bar{p}_{\\max}(1 + \\lambda_{\\max}) + 2(1 + L_g^{(1)})^2 \\lambda_{\\max} + \\frac{1}{2}(L_g^{(2)})^2 \\lambda_{\\max}$ (variance constant from Step 6b)\n928: - $L_\\lambda$ is the Lipschitz constant of the cloning rate $\\lambda_{\\text{clone}}(k)$\n929: - $L_p$ is the Lipschitz constant of the killing rate $\\bar{p}_{\\text{kill}}(k')$\n930: - $L_g^{(2)}$ is the bound on the second derivative of $g(c) = \\bar{p}_{\\text{kill}}(N + c)(N + c)$\n931: - $N$ is the total number of walkers (alive + dead)\n932: \n933: **Assumption for positivity of $\\kappa_{\\text{mass}}$:** We require $\\epsilon^2 + \\epsilon < 1$, which gives $\\epsilon < \\frac{\\sqrt{5} - 1}{2} \\approx 0.618$. From Step 6c, this requires:\n934: \n935: $$\n936: L_p L_\\lambda = O(N^{-2})\n937: \n938: $$\n939: \n940: **Physical plausibility of the assumption:** This condition is natural when birth/death rates depend on **densities** rather than absolute counts. If:\n941: \n942: $$\n943: \\lambda_{\\text{clone}}(k) = \\lambda(\\rho) \\quad \\text{where } \\rho = k/N\n944: \n945: $$\n946: \n947: $$\n948: \\bar{p}_{\\text{kill}}(k') = p(\\rho') \\quad \\text{where } \\rho' = k'/N\n949: \n950: $$\n951: \n952: Then the Lipschitz constants with respect to $k$ are:\n953: \n954: $$\n955: L_\\lambda = \\frac{1}{N} \\sup_\\rho |\\lambda'(\\rho)|, \\quad L_p = \\frac{1}{N} \\sup_{\\rho'} |p'(\\rho')|\n956: \n957: $$\n958: \n959: Thus $L_p L_\\lambda = O(N^{-2})$, and the condition is automatically satisfied for any smooth density-dependent rates.\n960: \n961: **Complete parameter regime:** The full expression for $\\epsilon$ is:\n962: \n963: $$\n964: \\epsilon = (1 + 2L_p N + \\bar{p}_{\\text{kill}}^*)(L_\\lambda N + \\lambda_{\\text{clone}}^*)\n965: \n966: $$\n967: \n968: Expanding this with the density-dependent scaling $L_p = O(1/N)$, $L_\\lambda = O(1/N)$:\n969: \n970: $$\n971: \\epsilon = (1 + O(1) + \\bar{p}^*)(O(1) + \\lambda^*) = (1+\\bar{p}^*)\\lambda^* + O(N^{-1})\n972: \n973: $$\n974: \n975: For $\\epsilon < 0.618$, we require:\n976: \n977: $$\n978: (1 + \\bar{p}_{\\text{kill}}^*) \\lambda_{\\text{clone}}^* < 0.6\n979: \n980: $$\n981: \n982: **Physical interpretation:** This condition requires that the product of equilibrium cloning rate and killing probability is not too large. For typical QSD parameters where $\\bar{p}^* \\sim 0.1$ (10% death probability per step) and $\\lambda^* \\sim 0.5$ (50% cloning rate), we have $(1.1)(0.5) = 0.55 < 0.618$. The condition is satisfied for reasonable algorithm parameters and becomes easier to satisfy as $N \\to \\infty$ due to the $O(1/N)$ corrections.\n983: \n984: **Convergence:** This is the standard drift inequality for squared error, which implies exponential convergence of $\\mathbb{E}[(k_t - k_*)^2]$ to the stationary distribution with $\\mathbb{E}[(k_\\infty - k_*)^2] = O(C_{\\text{mass}}/\\kappa_{\\text{mass}}) = O(N/\\kappa_{\\text{mass}})$.\n985: \n986: This completes the proof of {prf:ref}`lem-mass-contraction-revival-death`.",
      "_registry_context": {
        "stage": "directives",
        "document_id": "11_hk_convergence",
        "chapter_index": 2,
        "chapter_file": "chapter_2.json",
        "section_id": "## 2. Lemma A: Mass Contraction from Revival and Death"
      }
    },
    {
      "directive_type": "proof",
      "label": "proof-lem-structural-variance-contraction",
      "title": null,
      "start_line": 1028,
      "end_line": 1156,
      "header_lines": [
        1029
      ],
      "content_start": 1031,
      "content_end": 1155,
      "content": "1031: :label: proof-lem-structural-variance-contraction\n1032: \n1033: The proof uses direct application of the Wasserstein contraction results from the framework, establishing convergence in expectation.\n1034: \n1035: **Step 1: Expected Wasserstein Contraction from Cloning Operator**\n1036: \n1037: From Theorem {prf:ref}`thm-main-contraction-full` in [04_wasserstein_contraction](04_wasserstein_contraction), the cloning operator $\\Psi_{\\text{clone}}$ satisfies:\n1038: \n1039: $$\n1040: \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_1), \\Psi_{\\text{clone}}(\\mu_2))] \\leq (1 - \\kappa_W) W_2^2(\\mu_1, \\mu_2) + C_W\n1041: \n1042: $$\n1043: \n1044: where:\n1045: - $\\kappa_W > 0$ is the N-uniform contraction constant from the cluster-level analysis\n1046: - $C_W = 4d\\delta^2$ is the noise constant from Gaussian cloning perturbations\n1047: - The expectation is taken over the randomness in the cloning operator (Gaussian perturbations and random pairing decisions)\n1048: \n1049: **Note on convergence type:** This establishes convergence of the **expected** Wasserstein distance, which is the appropriate notion for stochastic processes. The inequality bounds how the second moment $\\mathbb{E}[W_2^2]$ evolves, not the distance between individual random realizations.\n1050: \n1051: **Step 2: Wasserstein Contraction from Kinetic Operator**\n1052: \n1053: From Theorem {prf:ref}`thm-foster-lyapunov-main` in [06_convergence](06_convergence), the composed operator's Foster-Lyapunov function includes a Wasserstein component $V_W = W_2^2(\\mu, \\pi_{\\text{QSD}})$ that satisfies:\n1054: \n1055: $$\n1056: \\mathbb{E}[V_W(\\Psi_{\\text{kin}}(\\mu))] \\leq (1 - \\kappa_{\\text{kin}}\\tau) V_W(\\mu) + C_{\\text{kin}}\\tau^2\n1057: \n1058: $$\n1059: \n1060: where:\n1061: - $\\kappa_{\\text{kin}} > 0$ is the hypocoercive contraction rate from the kinetic operator\n1062: - $C_{\\text{kin}}$ is the noise constant from BAOAB discretization\n1063: - $\\tau$ is the time step size\n1064: \n1065: **Note:** The Foster-Lyapunov inequality bounds the **expected** Wasserstein distance after one application of the kinetic operator, averaged over the Langevin noise realizations.\n1066: \n1067: **Step 3: Composition of Both Operators**\n1068: \n1069: Applying both operators sequentially to a realization $\\mu_t$, with the QSD $\\pi_{\\text{QSD}}$ as the comparison measure (noting that $\\Psi_{\\text{total}}(\\pi_{\\text{QSD}}) = \\pi_{\\text{QSD}}$ by stationarity):\n1070: \n1071: $$\n1072: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] = \\mathbb{E}[W_2^2(\\Psi_{\\text{kin}}(\\Psi_{\\text{clone}}(\\mu_t)), \\pi_{\\text{QSD}})]\n1073: \n1074: $$\n1075: \n1076: First apply cloning:\n1077: \n1078: $$\n1079: \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_t), \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_W) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + C_W\n1080: \n1081: $$\n1082: \n1083: Then apply kinetic:\n1084: \n1085: $$\n1086: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{\\text{kin}}\\tau) \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_t), \\pi_{\\text{QSD}})] + C_{\\text{kin}}\\tau^2\n1087: \n1088: $$\n1089: \n1090: Combining:\n1091: \n1092: $$\n1093: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1-\\kappa_W)(1-\\kappa_{\\text{kin}}\\tau) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + (1-\\kappa_{\\text{kin}}\\tau)C_W + C_{\\text{kin}}\\tau^2\n1094: \n1095: $$\n1096: \n1097: For small $\\tau$, the product satisfies:\n1098: \n1099: $$\n1100: (1-\\kappa_W)(1-\\kappa_{\\text{kin}}\\tau) = 1 - \\kappa_W - \\kappa_{\\text{kin}}\\tau + O(\\kappa_W \\kappa_{\\text{kin}} \\tau) \\leq 1 - \\lambda_{\\text{struct}}\\tau\n1101: \n1102: $$\n1103: \n1104: where $\\lambda_{\\text{struct}} := \\min(\\kappa_W/\\tau, \\kappa_{\\text{kin}})$ gives the dominant contraction rate.\n1105: \n1106: Define the noise constant: $C_{\\text{struct}} := C_W + C_{\\text{kin}}\\tau^2$.\n1107: \n1108: **Step 4: From Wasserstein to Structural Variance**\n1109: \n1110: The **variance decomposition** (Villani 2009, Theorem 7.17) states:\n1111: \n1112: $$\n1113: W_2^2(\\mu, \\pi) = W_2^2(\\tilde{\\mu}, \\tilde{\\pi}) + \\|m_\\mu - m_\\pi\\|^2\n1114: \n1115: $$\n1116: \n1117: where $\\tilde{\\mu}, \\tilde{\\pi}$ are centered versions and $m_\\mu, m_\\pi$ are the means.\n1118: \n1119: Therefore, the structural variance (centered Wasserstein) satisfies:\n1120: \n1121: $$\n1122: V_{\\text{struct}}(\\mu, \\pi) := W_2^2(\\tilde{\\mu}, \\tilde{\\pi}) = W_2^2(\\mu, \\pi) - \\|m_\\mu - m_\\pi\\|^2 \\leq W_2^2(\\mu, \\pi)\n1123: \n1124: $$\n1125: \n1126: Applying this to our contraction result:\n1127: \n1128: $$\n1129: \\mathbb{E}[V_{\\text{struct}}(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}}\\tau) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{struct}}\n1130: \n1131: $$\n1132: \n1133: Since $W_2^2(\\mu_t, \\pi_{\\text{QSD}}) = V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}}) + \\|m_{\\mu_t} - m_{\\pi}\\|^2$ and the mean distance contracts as well ({prf:ref}`lem-mass-contraction-revival-death` for mass, standard Langevin contraction for position), we have:\n1134: \n1135: $$\n1136: \\mathbb{E}[V_{\\text{struct}}(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}}\\tau) V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{struct}}\n1137: \n1138: $$\n1139: \n1140: **Step 5: Exponential Convergence**\n1141: \n1142: This is the standard Foster-Lyapunov drift inequality. Iterating and taking expectations:\n1143: \n1144: $$\n1145: \\mathbb{E}[V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}})] \\leq (1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau} \\mathbb{E}[V_{\\text{struct}}(\\mu_0, \\pi_{\\text{QSD}})] + \\frac{C_{\\text{struct}}}{\\lambda_{\\text{struct}}\\tau}(1-(1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau})\n1146: \n1147: $$\n1148: \n1149: Using $(1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau} \\approx e^{-\\lambda_{\\text{struct}} t}$ for small $\\tau$:\n1150: \n1151: $$\n1152: \\mathbb{E}[V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}})] \\leq e^{-\\lambda_{\\text{struct}} t} \\mathbb{E}[V_{\\text{struct}}(\\mu_0, \\pi_{\\text{QSD}})] + \\frac{C_{\\text{struct}}}{\\lambda_{\\text{struct}}}(1 - e^{-\\lambda_{\\text{struct}} t})\n1153: \n1154: $$\n1155: ",
      "metadata": {
        "label": "proof-lem-structural-variance-contraction"
      },
      "section": "## 3. Lemma B: Exponential Contraction of Structural Variance",
      "references": [
        "thm-main-contraction-full",
        "thm-foster-lyapunov-main",
        "lem-mass-contraction-revival-death"
      ],
      "raw_directive": "1028: ### Proof of Lemma B\n1029: \n1030: :::{prf:proof}\n1031: :label: proof-lem-structural-variance-contraction\n1032: \n1033: The proof uses direct application of the Wasserstein contraction results from the framework, establishing convergence in expectation.\n1034: \n1035: **Step 1: Expected Wasserstein Contraction from Cloning Operator**\n1036: \n1037: From Theorem {prf:ref}`thm-main-contraction-full` in [04_wasserstein_contraction](04_wasserstein_contraction), the cloning operator $\\Psi_{\\text{clone}}$ satisfies:\n1038: \n1039: $$\n1040: \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_1), \\Psi_{\\text{clone}}(\\mu_2))] \\leq (1 - \\kappa_W) W_2^2(\\mu_1, \\mu_2) + C_W\n1041: \n1042: $$\n1043: \n1044: where:\n1045: - $\\kappa_W > 0$ is the N-uniform contraction constant from the cluster-level analysis\n1046: - $C_W = 4d\\delta^2$ is the noise constant from Gaussian cloning perturbations\n1047: - The expectation is taken over the randomness in the cloning operator (Gaussian perturbations and random pairing decisions)\n1048: \n1049: **Note on convergence type:** This establishes convergence of the **expected** Wasserstein distance, which is the appropriate notion for stochastic processes. The inequality bounds how the second moment $\\mathbb{E}[W_2^2]$ evolves, not the distance between individual random realizations.\n1050: \n1051: **Step 2: Wasserstein Contraction from Kinetic Operator**\n1052: \n1053: From Theorem {prf:ref}`thm-foster-lyapunov-main` in [06_convergence](06_convergence), the composed operator's Foster-Lyapunov function includes a Wasserstein component $V_W = W_2^2(\\mu, \\pi_{\\text{QSD}})$ that satisfies:\n1054: \n1055: $$\n1056: \\mathbb{E}[V_W(\\Psi_{\\text{kin}}(\\mu))] \\leq (1 - \\kappa_{\\text{kin}}\\tau) V_W(\\mu) + C_{\\text{kin}}\\tau^2\n1057: \n1058: $$\n1059: \n1060: where:\n1061: - $\\kappa_{\\text{kin}} > 0$ is the hypocoercive contraction rate from the kinetic operator\n1062: - $C_{\\text{kin}}$ is the noise constant from BAOAB discretization\n1063: - $\\tau$ is the time step size\n1064: \n1065: **Note:** The Foster-Lyapunov inequality bounds the **expected** Wasserstein distance after one application of the kinetic operator, averaged over the Langevin noise realizations.\n1066: \n1067: **Step 3: Composition of Both Operators**\n1068: \n1069: Applying both operators sequentially to a realization $\\mu_t$, with the QSD $\\pi_{\\text{QSD}}$ as the comparison measure (noting that $\\Psi_{\\text{total}}(\\pi_{\\text{QSD}}) = \\pi_{\\text{QSD}}$ by stationarity):\n1070: \n1071: $$\n1072: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] = \\mathbb{E}[W_2^2(\\Psi_{\\text{kin}}(\\Psi_{\\text{clone}}(\\mu_t)), \\pi_{\\text{QSD}})]\n1073: \n1074: $$\n1075: \n1076: First apply cloning:\n1077: \n1078: $$\n1079: \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_t), \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_W) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + C_W\n1080: \n1081: $$\n1082: \n1083: Then apply kinetic:\n1084: \n1085: $$\n1086: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{\\text{kin}}\\tau) \\mathbb{E}[W_2^2(\\Psi_{\\text{clone}}(\\mu_t), \\pi_{\\text{QSD}})] + C_{\\text{kin}}\\tau^2\n1087: \n1088: $$\n1089: \n1090: Combining:\n1091: \n1092: $$\n1093: \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1-\\kappa_W)(1-\\kappa_{\\text{kin}}\\tau) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + (1-\\kappa_{\\text{kin}}\\tau)C_W + C_{\\text{kin}}\\tau^2\n1094: \n1095: $$\n1096: \n1097: For small $\\tau$, the product satisfies:\n1098: \n1099: $$\n1100: (1-\\kappa_W)(1-\\kappa_{\\text{kin}}\\tau) = 1 - \\kappa_W - \\kappa_{\\text{kin}}\\tau + O(\\kappa_W \\kappa_{\\text{kin}} \\tau) \\leq 1 - \\lambda_{\\text{struct}}\\tau\n1101: \n1102: $$\n1103: \n1104: where $\\lambda_{\\text{struct}} := \\min(\\kappa_W/\\tau, \\kappa_{\\text{kin}})$ gives the dominant contraction rate.\n1105: \n1106: Define the noise constant: $C_{\\text{struct}} := C_W + C_{\\text{kin}}\\tau^2$.\n1107: \n1108: **Step 4: From Wasserstein to Structural Variance**\n1109: \n1110: The **variance decomposition** (Villani 2009, Theorem 7.17) states:\n1111: \n1112: $$\n1113: W_2^2(\\mu, \\pi) = W_2^2(\\tilde{\\mu}, \\tilde{\\pi}) + \\|m_\\mu - m_\\pi\\|^2\n1114: \n1115: $$\n1116: \n1117: where $\\tilde{\\mu}, \\tilde{\\pi}$ are centered versions and $m_\\mu, m_\\pi$ are the means.\n1118: \n1119: Therefore, the structural variance (centered Wasserstein) satisfies:\n1120: \n1121: $$\n1122: V_{\\text{struct}}(\\mu, \\pi) := W_2^2(\\tilde{\\mu}, \\tilde{\\pi}) = W_2^2(\\mu, \\pi) - \\|m_\\mu - m_\\pi\\|^2 \\leq W_2^2(\\mu, \\pi)\n1123: \n1124: $$\n1125: \n1126: Applying this to our contraction result:\n1127: \n1128: $$\n1129: \\mathbb{E}[V_{\\text{struct}}(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq \\mathbb{E}[W_2^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}}\\tau) W_2^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{struct}}\n1130: \n1131: $$\n1132: \n1133: Since $W_2^2(\\mu_t, \\pi_{\\text{QSD}}) = V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}}) + \\|m_{\\mu_t} - m_{\\pi}\\|^2$ and the mean distance contracts as well ({prf:ref}`lem-mass-contraction-revival-death` for mass, standard Langevin contraction for position), we have:\n1134: \n1135: $$\n1136: \\mathbb{E}[V_{\\text{struct}}(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}}\\tau) V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{struct}}\n1137: \n1138: $$\n1139: \n1140: **Step 5: Exponential Convergence**\n1141: \n1142: This is the standard Foster-Lyapunov drift inequality. Iterating and taking expectations:\n1143: \n1144: $$\n1145: \\mathbb{E}[V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}})] \\leq (1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau} \\mathbb{E}[V_{\\text{struct}}(\\mu_0, \\pi_{\\text{QSD}})] + \\frac{C_{\\text{struct}}}{\\lambda_{\\text{struct}}\\tau}(1-(1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau})\n1146: \n1147: $$\n1148: \n1149: Using $(1-\\lambda_{\\text{struct}}\\tau)^{t/\\tau} \\approx e^{-\\lambda_{\\text{struct}} t}$ for small $\\tau$:\n1150: \n1151: $$\n1152: \\mathbb{E}[V_{\\text{struct}}(\\mu_t, \\pi_{\\text{QSD}})] \\leq e^{-\\lambda_{\\text{struct}} t} \\mathbb{E}[V_{\\text{struct}}(\\mu_0, \\pi_{\\text{QSD}})] + \\frac{C_{\\text{struct}}}{\\lambda_{\\text{struct}}}(1 - e^{-\\lambda_{\\text{struct}} t})\n1153: \n1154: $$\n1155: \n1156: This establishes exponential contraction of the structural variance at the realization level.",
      "_registry_context": {
        "stage": "directives",
        "document_id": "11_hk_convergence",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 3. Lemma B: Exponential Contraction of Structural Variance"
      }
    },
    {
      "directive_type": "proof",
      "label": "prop-killing-rate-continuous",
      "title": null,
      "start_line": 1218,
      "end_line": 1329,
      "header_lines": [
        1219,
        1308
      ],
      "content_start": 1221,
      "content_end": 1328,
      "content": "1221: :label: proof-lem-kinetic-hellinger-contraction\n1222: \n1223: The proof proceeds in four steps: (1) decompose Hellinger distance into mass and shape components, (2) prove mass contraction via boundary killing, (3) prove shape contraction via diffusive smoothing using hypocoercivity, and (4) combine with BAOAB discretization error bounds.\n1224: \n1225: **Step 1: Hellinger Decomposition into Mass and Shape**\n1226: \n1227: For unnormalized measures $\\mu_t$ and $\\pi_{\\text{QSD}}$ with masses $k_t = \\|\\mu_t\\|$ and $k_* = \\|\\pi_{\\text{QSD}}\\|$, the Hellinger distance satisfies:\n1228: \n1229: $$\n1230: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = \\int \\left(\\sqrt{f_t} - \\sqrt{f_*}\\right)^2 d\\lambda\n1231: \n1232: $$\n1233: \n1234: where $f_t = d\\mu_t/d\\lambda$ and $f_* = d\\pi_{\\text{QSD}}/d\\lambda$ for some reference measure $\\lambda$.\n1235: \n1236: Writing $f_t = k_t \\tilde{f}_t$ and $f_* = k_* \\tilde{f}_*$ where $\\tilde{f}_t, \\tilde{f}_*$ are probability densities:\n1237: \n1238: $$\n1239: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = \\int \\left(\\sqrt{k_t \\tilde{f}_t} - \\sqrt{k_* \\tilde{f}_*}\\right)^2 d\\lambda\n1240: \n1241: $$\n1242: \n1243: $$\n1244: = \\int \\left(\\sqrt{k_t} \\sqrt{\\tilde{f}_t} - \\sqrt{k_*} \\sqrt{\\tilde{f}_*}\\right)^2 d\\lambda\n1245: \n1246: $$\n1247: \n1248: Expanding the square:\n1249: \n1250: $$\n1251: = k_t \\int \\tilde{f}_t d\\lambda + k_* \\int \\tilde{f}_* d\\lambda - 2\\sqrt{k_t k_*} \\int \\sqrt{\\tilde{f}_t \\tilde{f}_*} d\\lambda\n1252: \n1253: $$\n1254: \n1255: $$\n1256: = k_t + k_* - 2\\sqrt{k_t k_*} \\cdot BC(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n1257: \n1258: $$\n1259: \n1260: where $BC$ is the Bhattacharyya coefficient between the normalized measures.\n1261: \n1262: Using the identity $(a - b)^2 = (a + b)^2 - 4ab$:\n1263: \n1264: $$\n1265: (\\sqrt{k_t} - \\sqrt{k_*})^2 = k_t + k_* - 2\\sqrt{k_t k_*}\n1266: \n1267: $$\n1268: \n1269: Therefore:\n1270: \n1271: $$\n1272: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + 2\\sqrt{k_t k_*}(1 - BC(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}))\n1273: \n1274: $$\n1275: \n1276: Using the relationship $1 - BC(\\tilde{\\mu}, \\tilde{\\pi}) = d_H^2(\\tilde{\\mu}, \\tilde{\\pi})/2$ for normalized measures:\n1277: \n1278: $$\n1279: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + 2\\sqrt{k_t k_*} \\cdot \\frac{d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})}{2}\n1280: \n1281: $$\n1282: \n1283: $$\n1284: = (\\sqrt{k_t} - \\sqrt{k_*})^2 + \\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n1285: \n1286: $$\n1287: \n1288: This is the **exact decomposition** (no approximation). We can bound the geometric mean term:\n1289: \n1290: $$\n1291: k_* \\leq \\sqrt{k_t k_*} \\leq \\frac{k_t + k_*}{2}\n1292: \n1293: $$\n1294: \n1295: For the proof, we will track the $\\sqrt{k_t k_*}$ term exactly and show that deviations from $k_*$ are controlled by {prf:ref}`lem-mass-contraction-revival-death` (mass convergence).\n1296: \n1297: **Key observation:** The kinetic operator affects these two components through different mechanisms:\n1298: - **Mass component:** $(\\sqrt{k_t} - \\sqrt{k_*})^2$ changes via boundary killing\n1299: - **Shape component:** $\\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})$ changes via both mass dynamics and Langevin diffusion\n1300: \n1301: **Step 2: Mass Contraction via Boundary Killing (Connection to Mean-Field Limit)**\n1302: \n1303: The boundary killing mechanism in the discrete algorithm is approximated in continuous time by the killing rate $c(x,v)$ derived in the mean-field analysis. We connect the discrete {prf:ref}`lem-mass-contraction-revival-death` to the continuous kinetic operator using the mean-field limit established in [07_mean_field](07_mean_field) and [08_propagation_chaos](08_propagation_chaos).\n1304: \n1305: **Step 2a: Discrete-to-Continuous Bridge via Mean-Field Theory**\n1306: \n1307: From [07_mean_field](07_mean_field), Section 4.4, the discrete BAOAB integrator with time step $\\tau$ approximates the continuous Langevin SDE with **weak error** $O(\\tau^2)$ (Theorem 4.4.3). Specifically, for the killing rate:\n1308: \n1309: :::{prf:proposition} Continuous-Time Killing Rate from BAOAB\n1310: :label: prop-killing-rate-continuous\n1311: \n1312: The discrete-time exit probability over time step $\\tau$ converges to the continuous-time killing rate in the ballistic limit. For a walker at position $x$ with velocity $v$, let $d(x) := \\text{dist}(x, \\partial\\mathcal{X}_{\\text{valid}})$ be the distance to the boundary. The continuous-time killing rate is:\n1313: \n1314: $$\n1315: c(x,v) = \\frac{v}{d(x)} \\cdot \\mathbb{1}_{\\{v \\cdot \\hat{n}(x) > 0\\}}\n1316: \n1317: $$\n1318: \n1319: where $\\hat{n}(x)$ is the outward normal at the closest boundary point.\n1320: \n1321: The discrete exit probability satisfies:\n1322: \n1323: $$\n1324: p_{\\text{exit}}(x,v;\\tau) = \\tau c(x,v) + O(\\tau^{3/2})\n1325: \n1326: $$\n1327: \n1328: where the $O(\\tau^{3/2})$ error comes from the Gaussian position noise in the BAOAB O-step.",
      "metadata": {
        "label": "prop-killing-rate-continuous"
      },
      "section": "## 4. Lemma C: Kinetic Operator Hellinger Analysis",
      "references": [
        "lem-mass-contraction-revival-death"
      ],
      "raw_directive": "1218: ### Proof of Lemma C\n1219: \n1220: :::{prf:proof}\n1221: :label: proof-lem-kinetic-hellinger-contraction\n1222: \n1223: The proof proceeds in four steps: (1) decompose Hellinger distance into mass and shape components, (2) prove mass contraction via boundary killing, (3) prove shape contraction via diffusive smoothing using hypocoercivity, and (4) combine with BAOAB discretization error bounds.\n1224: \n1225: **Step 1: Hellinger Decomposition into Mass and Shape**\n1226: \n1227: For unnormalized measures $\\mu_t$ and $\\pi_{\\text{QSD}}$ with masses $k_t = \\|\\mu_t\\|$ and $k_* = \\|\\pi_{\\text{QSD}}\\|$, the Hellinger distance satisfies:\n1228: \n1229: $$\n1230: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = \\int \\left(\\sqrt{f_t} - \\sqrt{f_*}\\right)^2 d\\lambda\n1231: \n1232: $$\n1233: \n1234: where $f_t = d\\mu_t/d\\lambda$ and $f_* = d\\pi_{\\text{QSD}}/d\\lambda$ for some reference measure $\\lambda$.\n1235: \n1236: Writing $f_t = k_t \\tilde{f}_t$ and $f_* = k_* \\tilde{f}_*$ where $\\tilde{f}_t, \\tilde{f}_*$ are probability densities:\n1237: \n1238: $$\n1239: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = \\int \\left(\\sqrt{k_t \\tilde{f}_t} - \\sqrt{k_* \\tilde{f}_*}\\right)^2 d\\lambda\n1240: \n1241: $$\n1242: \n1243: $$\n1244: = \\int \\left(\\sqrt{k_t} \\sqrt{\\tilde{f}_t} - \\sqrt{k_*} \\sqrt{\\tilde{f}_*}\\right)^2 d\\lambda\n1245: \n1246: $$\n1247: \n1248: Expanding the square:\n1249: \n1250: $$\n1251: = k_t \\int \\tilde{f}_t d\\lambda + k_* \\int \\tilde{f}_* d\\lambda - 2\\sqrt{k_t k_*} \\int \\sqrt{\\tilde{f}_t \\tilde{f}_*} d\\lambda\n1252: \n1253: $$\n1254: \n1255: $$\n1256: = k_t + k_* - 2\\sqrt{k_t k_*} \\cdot BC(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n1257: \n1258: $$\n1259: \n1260: where $BC$ is the Bhattacharyya coefficient between the normalized measures.\n1261: \n1262: Using the identity $(a - b)^2 = (a + b)^2 - 4ab$:\n1263: \n1264: $$\n1265: (\\sqrt{k_t} - \\sqrt{k_*})^2 = k_t + k_* - 2\\sqrt{k_t k_*}\n1266: \n1267: $$\n1268: \n1269: Therefore:\n1270: \n1271: $$\n1272: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + 2\\sqrt{k_t k_*}(1 - BC(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}))\n1273: \n1274: $$\n1275: \n1276: Using the relationship $1 - BC(\\tilde{\\mu}, \\tilde{\\pi}) = d_H^2(\\tilde{\\mu}, \\tilde{\\pi})/2$ for normalized measures:\n1277: \n1278: $$\n1279: d_H^2(\\mu_t, \\pi_{\\text{QSD}}) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + 2\\sqrt{k_t k_*} \\cdot \\frac{d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})}{2}\n1280: \n1281: $$\n1282: \n1283: $$\n1284: = (\\sqrt{k_t} - \\sqrt{k_*})^2 + \\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n1285: \n1286: $$\n1287: \n1288: This is the **exact decomposition** (no approximation). We can bound the geometric mean term:\n1289: \n1290: $$\n1291: k_* \\leq \\sqrt{k_t k_*} \\leq \\frac{k_t + k_*}{2}\n1292: \n1293: $$\n1294: \n1295: For the proof, we will track the $\\sqrt{k_t k_*}$ term exactly and show that deviations from $k_*$ are controlled by {prf:ref}`lem-mass-contraction-revival-death` (mass convergence).\n1296: \n1297: **Key observation:** The kinetic operator affects these two components through different mechanisms:\n1298: - **Mass component:** $(\\sqrt{k_t} - \\sqrt{k_*})^2$ changes via boundary killing\n1299: - **Shape component:** $\\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})$ changes via both mass dynamics and Langevin diffusion\n1300: \n1301: **Step 2: Mass Contraction via Boundary Killing (Connection to Mean-Field Limit)**\n1302: \n1303: The boundary killing mechanism in the discrete algorithm is approximated in continuous time by the killing rate $c(x,v)$ derived in the mean-field analysis. We connect the discrete {prf:ref}`lem-mass-contraction-revival-death` to the continuous kinetic operator using the mean-field limit established in [07_mean_field](07_mean_field) and [08_propagation_chaos](08_propagation_chaos).\n1304: \n1305: **Step 2a: Discrete-to-Continuous Bridge via Mean-Field Theory**\n1306: \n1307: From [07_mean_field](07_mean_field), Section 4.4, the discrete BAOAB integrator with time step $\\tau$ approximates the continuous Langevin SDE with **weak error** $O(\\tau^2)$ (Theorem 4.4.3). Specifically, for the killing rate:\n1308: \n1309: :::{prf:proposition} Continuous-Time Killing Rate from BAOAB\n1310: :label: prop-killing-rate-continuous\n1311: \n1312: The discrete-time exit probability over time step $\\tau$ converges to the continuous-time killing rate in the ballistic limit. For a walker at position $x$ with velocity $v$, let $d(x) := \\text{dist}(x, \\partial\\mathcal{X}_{\\text{valid}})$ be the distance to the boundary. The continuous-time killing rate is:\n1313: \n1314: $$\n1315: c(x,v) = \\frac{v}{d(x)} \\cdot \\mathbb{1}_{\\{v \\cdot \\hat{n}(x) > 0\\}}\n1316: \n1317: $$\n1318: \n1319: where $\\hat{n}(x)$ is the outward normal at the closest boundary point.\n1320: \n1321: The discrete exit probability satisfies:\n1322: \n1323: $$\n1324: p_{\\text{exit}}(x,v;\\tau) = \\tau c(x,v) + O(\\tau^{3/2})\n1325: \n1326: $$\n1327: \n1328: where the $O(\\tau^{3/2})$ error comes from the Gaussian position noise in the BAOAB O-step.\n1329: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "11_hk_convergence",
        "chapter_index": 4,
        "chapter_file": "chapter_4.json",
        "section_id": "## 4. Lemma C: Kinetic Operator Hellinger Analysis"
      }
    },
    {
      "directive_type": "proof",
      "label": "lem-linearization-qsd",
      "title": null,
      "start_line": 2859,
      "end_line": 3029,
      "header_lines": [
        2860,
        2944
      ],
      "content_start": 2861,
      "content_end": 3028,
      "content": "2861: :::{prf:proof}\n2862: :label: proof-thm-bounded-density-ratio-main\n2863: **Proof of Theorem {prf:ref}`thm-bounded-density-ratio-main`**\n2864: \n2865: We split the proof into two time regimes.\n2866: \n2867: **Regime 1: Early Time** ($t \\in [0, T_0]$)\n2868: \n2869: Fix an equilibration time $T_0 = C / \\kappa_{\\text{QSD}}$ with $C$ large enough for the QSD to be well-established.\n2870: \n2871: **Step 1A: Upper Bound on Numerator**\n2872: \n2873: From Lemma {prf:ref}`lem-linfty-full-operator` (Section 2.4):\n2874: \n2875: $$\n2876: \\sup_{t \\in [0, T_0]} \\|\\rho_t\\|_\\infty \\leq C_{\\text{hypo}}(M_0, T_0, \\gamma, \\sigma_v, \\sigma_x, U, R)\n2877: \n2878: $$\n2879: \n2880: **Step 1B: Lower Bound on Denominator**\n2881: \n2882: From Lemma {prf:ref}`lem-qsd-strict-positivity` (Section 3.3):\n2883: \n2884: $$\n2885: \\inf_{x \\in \\mathcal{X}_{\\text{valid}}} \\pi_{\\text{QSD}}(x) \\geq c_\\pi = c_{\\sigma_x, R} \\cdot m_{\\text{eq}}\n2886: \n2887: $$\n2888: \n2889: **Step 1C: Mass Conservation**\n2890: \n2891: From Lemma {prf:ref}`lem-mass-lower-bound-high-prob` (Section 4.3), for $t \\geq t_{\\text{eq}} \\leq T_0$:\n2892: \n2893: $$\n2894: \\mathbb{P}\\left( \\|\\rho_t\\|_{L^1} \\geq c_{\\text{mass}} \\right) \\geq 1 - e^{-\\delta N}\n2895: \n2896: $$\n2897: \n2898: On this high-probability event, the density ratio satisfies:\n2899: \n2900: $$\n2901: \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} = \\frac{\\rho_t(x) / \\|\\rho_t\\|_{L^1}}{\\pi_{\\text{QSD}}(x) / \\|\\pi_{\\text{QSD}}\\|_{L^1}} = \\frac{\\rho_t(x)}{\\pi_{\\text{QSD}}(x)} \\cdot \\frac{m_{\\text{eq}}}{\\|\\rho_t\\|_{L^1}}\n2902: \n2903: $$\n2904: \n2905: Taking supremum over $x$:\n2906: \n2907: $$\n2908: \\sup_x \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} \\leq \\frac{\\|\\rho_t\\|_\\infty}{\\inf_x \\pi_{\\text{QSD}}(x)} \\cdot \\frac{m_{\\text{eq}}}{\\|\\rho_t\\|_{L^1}}\n2909: \n2910: $$\n2911: \n2912: Substituting the bounds from Steps 1A-1B:\n2913: \n2914: $$\n2915: \\sup_x \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} \\leq \\frac{C_{\\text{hypo}}}{c_{\\sigma_x, R} \\cdot m_{\\text{eq}}} \\cdot \\frac{m_{\\text{eq}}}{c_{\\text{mass}}} = \\frac{C_{\\text{hypo}}}{c_{\\sigma_x, R} \\cdot c_{\\text{mass}}}\n2916: \n2917: $$\n2918: \n2919: Define:\n2920: \n2921: $$\n2922: M_1 := \\frac{C_{\\text{hypo}}(M_0, T_0, \\gamma, \\sigma_v, \\sigma_x, U, R)}{c_{\\sigma_x, R} \\cdot c_{\\text{mass}}}\n2923: \n2924: $$\n2925: \n2926: Then:\n2927: \n2928: $$\n2929: \\sup_{t \\in [0, T_0]} \\sup_{x \\in \\mathcal{X}_{\\text{valid}}} \\frac{d\\tilde{\\mu}_t}{d\\tilde{\\pi}_{\\text{QSD}}}(x) \\leq M_1 < \\infty\n2930: \n2931: $$\n2932: \n2933: **Regime 2: Late Time** ($t > T_0$)\n2934: \n2935: For late times, we use the exponential convergence to QSD combined with local stability analysis to obtain a uniform bound that does not depend on time.\n2936: \n2937: **Strategy Overview**: The key insight is that once the system is close to the QSD in total variation distance (exponentially fast by `06_convergence.md`), we can use *local regularity theory* to upgrade this weak convergence to $L^\\infty$ estimates. The argument proceeds in three steps:\n2938: \n2939: 1. **Linearization**: Show that near the QSD, the nonlinear McKean-Vlasov-Fokker-Planck equation can be analyzed via its linearization\n2940: 2. **L¹-to-L∞ Parabolic Estimate**: Use hypoelliptic regularity to bound the $L^\\infty$ norm of perturbations in terms of their $L^1$ norm\n2941: 3. **Assembly**: Combine with exponential TV convergence to obtain a time-independent bound\n2942: \n2943: **Step 2A: Linearized Operator Around the QSD**\n2944: \n2945: :::{prf:lemma} Linearization Around QSD Fixed Point\n2946: :label: lem-linearization-qsd\n2947: \n2948: Let $\\pi_{\\text{QSD}}$ be the quasi-stationary distribution satisfying:\n2949: \n2950: $$\n2951: \\mathcal{L}_{\\text{full}}^* \\pi_{\\text{QSD}} = 0\n2952: \n2953: $$\n2954: \n2955: where $\\mathcal{L}_{\\text{full}}^* = \\mathcal{L}_{\\text{kin}}^* + \\mathcal{L}_{\\text{clone}}^* - c(z) + r_{\\text{revival}}$ is the full generator.\n2956: \n2957: For $\\rho_t = \\pi_{\\text{QSD}} + \\eta_t$ with $\\|\\eta_t\\|_{L^1} \\ll 1$ small, the perturbation $\\eta_t$ evolves according to:\n2958: \n2959: $$\n2960: \\frac{\\partial \\eta_t}{\\partial t} = \\mathbb{L}^* \\eta_t + \\mathcal{N}[\\eta_t]\n2961: \n2962: $$\n2963: \n2964: where:\n2965: - $\\mathbb{L}^*$ is the **linearized operator** (linear in $\\eta$)\n2966: - $\\mathcal{N}[\\eta]$ is the **nonlinear remainder** with $\\|\\mathcal{N}[\\eta]\\|_{L^1} = O(\\|\\eta\\|_{L^1}^2)$\n2967: \n2968: **Proof**:\n2969: \n2970: The linearization is standard in McKean-Vlasov theory. We expand each term:\n2971: \n2972: **Kinetic Operator**: $\\mathcal{L}_{\\text{kin}}^*$ is linear, so:\n2973: \n2974: $$\n2975: \\mathcal{L}_{\\text{kin}}^*(\\pi_{\\text{QSD}} + \\eta) = \\underbrace{\\mathcal{L}_{\\text{kin}}^* \\pi_{\\text{QSD}}}_{\\text{part of QSD eqn}} + \\mathcal{L}_{\\text{kin}}^* \\eta\n2976: \n2977: $$\n2978: \n2979: **Cloning Operator**: The cloning operator has the form (from `03_cloning.md`):\n2980: \n2981: $$\n2982: \\mathcal{L}_{\\text{clone}}^* f = \\int K_{\\text{clone}}(z, z') V[f](z, z') [f(z') - f(z)] dz'\n2983: \n2984: $$\n2985: \n2986: where $V[f]$ depends nonlinearly on the density. Expanding around $\\pi_{\\text{QSD}}$:\n2987: \n2988: $$\n2989: V[\\pi + \\eta] = V[\\pi] + V'[\\pi] \\cdot \\eta + O(\\eta^2)\n2990: \n2991: $$\n2992: \n2993: The linear part is:\n2994: \n2995: $$\n2996: \\mathbb{L}_{\\text{clone}}^* \\eta := \\int K_{\\text{clone}}(z, z') \\left[ V[\\pi](z, z') \\eta(z') + V'[\\pi](z, z') \\cdot \\eta \\cdot \\pi(z') - \\eta(z) V[\\pi](z, z') \\right] dz'\n2997: \n2998: $$\n2999: \n3000: The quadratic remainder is:\n3001: \n3002: $$\n3003: \\mathcal{N}_{\\text{clone}}[\\eta] = \\int K_{\\text{clone}}(z, z') [V'[\\pi] \\eta \\cdot \\eta + O(\\eta^2)] dz'\n3004: \n3005: $$\n3006: \n3007: **Killing and Revival**: The killing term $-c(z) f$ is linear. The revival term is:\n3008: \n3009: $$\n3010: r_{\\text{revival}} = \\lambda_{\\text{rev}} \\frac{m_d(t)}{m_a(t)} f_{\\text{safe}}\n3011: \n3012: $$\n3013: \n3014: where $m_a(t) = \\int f(t, z) dz$ is the alive mass. For $f = \\pi + \\eta$:\n3015: \n3016: $$\n3017: \\frac{1}{m_a} = \\frac{1}{m_{\\text{eq}} + \\|\\eta\\|_{L^1}} = \\frac{1}{m_{\\text{eq}}} \\left(1 - \\frac{\\|\\eta\\|_{L^1}}{m_{\\text{eq}}} + O(\\|\\eta\\|_{L^1}^2) \\right)\n3018: \n3019: $$\n3020: \n3021: This contributes a linear term and a quadratic remainder.\n3022: \n3023: **Assembly**: Combining all terms, the linearized operator is:\n3024: \n3025: $$\n3026: \\mathbb{L}^* := \\mathcal{L}_{\\text{kin}}^* + \\mathbb{L}_{\\text{clone}}^* - c(z) + \\mathbb{L}_{\\text{revival}}^*\n3027: \n3028: $$",
      "metadata": {
        "label": "lem-linearization-qsd"
      },
      "section": "## 5. Rigorous Proof of Bounded Density Ratio",
      "references": [
        "thm-bounded-density-ratio-main",
        "lem-linfty-full-operator",
        "lem-qsd-strict-positivity",
        "lem-mass-lower-bound-high-prob"
      ],
      "raw_directive": "2859: :::\n2860: \n2861: :::{prf:proof}\n2862: :label: proof-thm-bounded-density-ratio-main\n2863: **Proof of Theorem {prf:ref}`thm-bounded-density-ratio-main`**\n2864: \n2865: We split the proof into two time regimes.\n2866: \n2867: **Regime 1: Early Time** ($t \\in [0, T_0]$)\n2868: \n2869: Fix an equilibration time $T_0 = C / \\kappa_{\\text{QSD}}$ with $C$ large enough for the QSD to be well-established.\n2870: \n2871: **Step 1A: Upper Bound on Numerator**\n2872: \n2873: From Lemma {prf:ref}`lem-linfty-full-operator` (Section 2.4):\n2874: \n2875: $$\n2876: \\sup_{t \\in [0, T_0]} \\|\\rho_t\\|_\\infty \\leq C_{\\text{hypo}}(M_0, T_0, \\gamma, \\sigma_v, \\sigma_x, U, R)\n2877: \n2878: $$\n2879: \n2880: **Step 1B: Lower Bound on Denominator**\n2881: \n2882: From Lemma {prf:ref}`lem-qsd-strict-positivity` (Section 3.3):\n2883: \n2884: $$\n2885: \\inf_{x \\in \\mathcal{X}_{\\text{valid}}} \\pi_{\\text{QSD}}(x) \\geq c_\\pi = c_{\\sigma_x, R} \\cdot m_{\\text{eq}}\n2886: \n2887: $$\n2888: \n2889: **Step 1C: Mass Conservation**\n2890: \n2891: From Lemma {prf:ref}`lem-mass-lower-bound-high-prob` (Section 4.3), for $t \\geq t_{\\text{eq}} \\leq T_0$:\n2892: \n2893: $$\n2894: \\mathbb{P}\\left( \\|\\rho_t\\|_{L^1} \\geq c_{\\text{mass}} \\right) \\geq 1 - e^{-\\delta N}\n2895: \n2896: $$\n2897: \n2898: On this high-probability event, the density ratio satisfies:\n2899: \n2900: $$\n2901: \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} = \\frac{\\rho_t(x) / \\|\\rho_t\\|_{L^1}}{\\pi_{\\text{QSD}}(x) / \\|\\pi_{\\text{QSD}}\\|_{L^1}} = \\frac{\\rho_t(x)}{\\pi_{\\text{QSD}}(x)} \\cdot \\frac{m_{\\text{eq}}}{\\|\\rho_t\\|_{L^1}}\n2902: \n2903: $$\n2904: \n2905: Taking supremum over $x$:\n2906: \n2907: $$\n2908: \\sup_x \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} \\leq \\frac{\\|\\rho_t\\|_\\infty}{\\inf_x \\pi_{\\text{QSD}}(x)} \\cdot \\frac{m_{\\text{eq}}}{\\|\\rho_t\\|_{L^1}}\n2909: \n2910: $$\n2911: \n2912: Substituting the bounds from Steps 1A-1B:\n2913: \n2914: $$\n2915: \\sup_x \\frac{\\tilde{\\rho}_t(x)}{\\tilde{\\pi}_{\\text{QSD}}(x)} \\leq \\frac{C_{\\text{hypo}}}{c_{\\sigma_x, R} \\cdot m_{\\text{eq}}} \\cdot \\frac{m_{\\text{eq}}}{c_{\\text{mass}}} = \\frac{C_{\\text{hypo}}}{c_{\\sigma_x, R} \\cdot c_{\\text{mass}}}\n2916: \n2917: $$\n2918: \n2919: Define:\n2920: \n2921: $$\n2922: M_1 := \\frac{C_{\\text{hypo}}(M_0, T_0, \\gamma, \\sigma_v, \\sigma_x, U, R)}{c_{\\sigma_x, R} \\cdot c_{\\text{mass}}}\n2923: \n2924: $$\n2925: \n2926: Then:\n2927: \n2928: $$\n2929: \\sup_{t \\in [0, T_0]} \\sup_{x \\in \\mathcal{X}_{\\text{valid}}} \\frac{d\\tilde{\\mu}_t}{d\\tilde{\\pi}_{\\text{QSD}}}(x) \\leq M_1 < \\infty\n2930: \n2931: $$\n2932: \n2933: **Regime 2: Late Time** ($t > T_0$)\n2934: \n2935: For late times, we use the exponential convergence to QSD combined with local stability analysis to obtain a uniform bound that does not depend on time.\n2936: \n2937: **Strategy Overview**: The key insight is that once the system is close to the QSD in total variation distance (exponentially fast by `06_convergence.md`), we can use *local regularity theory* to upgrade this weak convergence to $L^\\infty$ estimates. The argument proceeds in three steps:\n2938: \n2939: 1. **Linearization**: Show that near the QSD, the nonlinear McKean-Vlasov-Fokker-Planck equation can be analyzed via its linearization\n2940: 2. **L¹-to-L∞ Parabolic Estimate**: Use hypoelliptic regularity to bound the $L^\\infty$ norm of perturbations in terms of their $L^1$ norm\n2941: 3. **Assembly**: Combine with exponential TV convergence to obtain a time-independent bound\n2942: \n2943: **Step 2A: Linearized Operator Around the QSD**\n2944: \n2945: :::{prf:lemma} Linearization Around QSD Fixed Point\n2946: :label: lem-linearization-qsd\n2947: \n2948: Let $\\pi_{\\text{QSD}}$ be the quasi-stationary distribution satisfying:\n2949: \n2950: $$\n2951: \\mathcal{L}_{\\text{full}}^* \\pi_{\\text{QSD}} = 0\n2952: \n2953: $$\n2954: \n2955: where $\\mathcal{L}_{\\text{full}}^* = \\mathcal{L}_{\\text{kin}}^* + \\mathcal{L}_{\\text{clone}}^* - c(z) + r_{\\text{revival}}$ is the full generator.\n2956: \n2957: For $\\rho_t = \\pi_{\\text{QSD}} + \\eta_t$ with $\\|\\eta_t\\|_{L^1} \\ll 1$ small, the perturbation $\\eta_t$ evolves according to:\n2958: \n2959: $$\n2960: \\frac{\\partial \\eta_t}{\\partial t} = \\mathbb{L}^* \\eta_t + \\mathcal{N}[\\eta_t]\n2961: \n2962: $$\n2963: \n2964: where:\n2965: - $\\mathbb{L}^*$ is the **linearized operator** (linear in $\\eta$)\n2966: - $\\mathcal{N}[\\eta]$ is the **nonlinear remainder** with $\\|\\mathcal{N}[\\eta]\\|_{L^1} = O(\\|\\eta\\|_{L^1}^2)$\n2967: \n2968: **Proof**:\n2969: \n2970: The linearization is standard in McKean-Vlasov theory. We expand each term:\n2971: \n2972: **Kinetic Operator**: $\\mathcal{L}_{\\text{kin}}^*$ is linear, so:\n2973: \n2974: $$\n2975: \\mathcal{L}_{\\text{kin}}^*(\\pi_{\\text{QSD}} + \\eta) = \\underbrace{\\mathcal{L}_{\\text{kin}}^* \\pi_{\\text{QSD}}}_{\\text{part of QSD eqn}} + \\mathcal{L}_{\\text{kin}}^* \\eta\n2976: \n2977: $$\n2978: \n2979: **Cloning Operator**: The cloning operator has the form (from `03_cloning.md`):\n2980: \n2981: $$\n2982: \\mathcal{L}_{\\text{clone}}^* f = \\int K_{\\text{clone}}(z, z') V[f](z, z') [f(z') - f(z)] dz'\n2983: \n2984: $$\n2985: \n2986: where $V[f]$ depends nonlinearly on the density. Expanding around $\\pi_{\\text{QSD}}$:\n2987: \n2988: $$\n2989: V[\\pi + \\eta] = V[\\pi] + V'[\\pi] \\cdot \\eta + O(\\eta^2)\n2990: \n2991: $$\n2992: \n2993: The linear part is:\n2994: \n2995: $$\n2996: \\mathbb{L}_{\\text{clone}}^* \\eta := \\int K_{\\text{clone}}(z, z') \\left[ V[\\pi](z, z') \\eta(z') + V'[\\pi](z, z') \\cdot \\eta \\cdot \\pi(z') - \\eta(z) V[\\pi](z, z') \\right] dz'\n2997: \n2998: $$\n2999: \n3000: The quadratic remainder is:\n3001: \n3002: $$\n3003: \\mathcal{N}_{\\text{clone}}[\\eta] = \\int K_{\\text{clone}}(z, z') [V'[\\pi] \\eta \\cdot \\eta + O(\\eta^2)] dz'\n3004: \n3005: $$\n3006: \n3007: **Killing and Revival**: The killing term $-c(z) f$ is linear. The revival term is:\n3008: \n3009: $$\n3010: r_{\\text{revival}} = \\lambda_{\\text{rev}} \\frac{m_d(t)}{m_a(t)} f_{\\text{safe}}\n3011: \n3012: $$\n3013: \n3014: where $m_a(t) = \\int f(t, z) dz$ is the alive mass. For $f = \\pi + \\eta$:\n3015: \n3016: $$\n3017: \\frac{1}{m_a} = \\frac{1}{m_{\\text{eq}} + \\|\\eta\\|_{L^1}} = \\frac{1}{m_{\\text{eq}}} \\left(1 - \\frac{\\|\\eta\\|_{L^1}}{m_{\\text{eq}}} + O(\\|\\eta\\|_{L^1}^2) \\right)\n3018: \n3019: $$\n3020: \n3021: This contributes a linear term and a quadratic remainder.\n3022: \n3023: **Assembly**: Combining all terms, the linearized operator is:\n3024: \n3025: $$\n3026: \\mathbb{L}^* := \\mathcal{L}_{\\text{kin}}^* + \\mathbb{L}_{\\text{clone}}^* - c(z) + \\mathbb{L}_{\\text{revival}}^*\n3027: \n3028: $$\n3029: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "11_hk_convergence",
        "chapter_index": 5,
        "chapter_file": "chapter_5.json",
        "section_id": "## 5. Rigorous Proof of Bounded Density Ratio"
      }
    },
    {
      "directive_type": "proof",
      "label": "proof-thm-hk-convergence-main-assembly",
      "title": null,
      "start_line": 3850,
      "end_line": 4235,
      "header_lines": [
        3851
      ],
      "content_start": 3853,
      "content_end": 4234,
      "content": "3853: :label: proof-thm-hk-convergence-main-assembly\n3854: \n3855: The proof assembles the three lemmas by carefully tracking how each component of the HK metric evolves under one iteration of $\\Psi_{\\text{total}}$.\n3856: \n3857: **Recall: HK Metric Structure**\n3858: \n3859: For sub-probability measures $\\mu_1, \\mu_2$ on $(\\mathcal{X}, d)$, the Hellinger-Kantorovich metric decomposes as:\n3860: \n3861: $$\n3862: d_{HK}^2(\\mu_1, \\mu_2) = d_H^2(\\mu_1, \\mu_2) + W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)\n3863: \n3864: $$\n3865: \n3866: where:\n3867: - $d_H^2(\\mu_1, \\mu_2)$ is the Hellinger distance (captures both mass and shape differences)\n3868: - $W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ is the Wasserstein-2 distance between normalized measures $\\tilde{\\mu}_i = \\mu_i/\\|\\mu_i\\|$ (captures spatial structure)\n3869: \n3870: **Strategy:** We establish contraction of each component separately, then combine with careful tracking of cross-terms and error accumulation.\n3871: \n3872: ### 6.3. Step 1: Hellinger Component Contraction\n3873: \n3874: From {prf:ref}`lem-kinetic-hellinger-contraction`, the Hellinger distance contracts under the full dynamics via a coupled Lyapunov functional approach:\n3875: \n3876: $$\n3877: \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\kappa_{\\text{kin}} \\tau) d_H^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{kin}} \\tau^2\n3878: \n3879: $$\n3880: \n3881: where:\n3882: - $\\kappa_{\\text{kin}} = \\min(\\lambda_{\\text{mass}}, \\alpha_{\\text{shape}}/2) > 0$ (from coupled Lyapunov analysis in {prf:ref}`lem-kinetic-hellinger-contraction`, Step 5)\n3883: - $\\lambda_{\\text{mass}} = r_* + c_*$ combines revival rate $r_*$ and death rate $c_*$\n3884: - $\\alpha_{\\text{shape}} = 2\\alpha_{\\text{eff}} / (1 + \\log M)$ is the shape contraction rate from direct Hellinger evolution\n3885: - $C_{\\text{kin}} = 4C_m + 4\\sqrt{k_*} K_H$ combines mass variance and BAOAB discretization errors\n3886: \n3887: **Key Insight from {prf:ref}`lem-kinetic-hellinger-contraction`:** The Hellinger component already incorporates mass contraction via the decomposition:\n3888: \n3889: $$\n3890: d_H^2(\\mu, \\pi) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + \\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi})\n3891: \n3892: $$\n3893: \n3894: where the first term measures mass deviation and the second measures normalized shape deviation. Both contract under the kinetic operator, and their coupling is controlled via Cauchy-Schwarz bounds.\n3895: \n3896: **Implication for Assembly:** The Hellinger contraction bound from {prf:ref}`lem-kinetic-hellinger-contraction` is already a **complete bound** for the full Hellinger distance including mass effects. We do not need to separately combine {prf:ref}`lem-mass-contraction-revival-death`'s mass contraction—it is already accounted for in the proof of {prf:ref}`lem-kinetic-hellinger-contraction`.\n3897: \n3898: ### 6.4. Step 2: Wasserstein Component Contraction\n3899: \n3900: From {prf:ref}`lem-structural-variance-contraction`, the structural variance (normalized Wasserstein distance) contracts:\n3901: \n3902: $$\n3903: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})] \\leq e^{-\\lambda_{\\text{struct}} \\tau} W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}}\n3904: \n3905: $$\n3906: \n3907: where:\n3908: - $\\lambda_{\\text{struct}} = \\min(\\kappa_W/\\tau, \\kappa_{\\text{kin}}) > 0$\n3909: - $\\kappa_W > 0$ is the cloning Wasserstein contraction rate from {prf:ref}`thm-main-contraction-full`\n3910: - $\\kappa_{\\text{kin}} > 0$ is the kinetic Foster-Lyapunov rate from {prf:ref}`thm-foster-lyapunov-main`\n3911: - $C_{\\text{struct}} = C_W + C_{\\text{kin}} \\tau^2$ combines noise from both operators\n3912: \n3913: **Realization-Level Nature:** This bound applies to individual realizations (paths) of the particle system, not just to expectations over the law. The Wasserstein distance $W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})$ is a deterministic function of the realization $\\mu_t$, and both operators contract it pathwise.\n3914: \n3915: **Approximation for Small Time Steps:** For $\\tau \\ll 1$, we can approximate $e^{-\\lambda_{\\text{struct}} \\tau} \\approx 1 - \\lambda_{\\text{struct}} \\tau + O(\\tau^2)$:\n3916: \n3917: $$\n3918: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}} \\tau) W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}} + O(\\tau^2)\n3919: \n3920: $$\n3921: \n3922: ### 6.5. Step 3: Combining Both Components\n3923: \n3924: **Full HK Metric Evolution:**\n3925: \n3926: By the definition of the HK metric ({prf:ref}`def-hk-metric-intro`), we have:\n3927: \n3928: $$\n3929: d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) = d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) + W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})\n3930: \n3931: $$\n3932: \n3933: Taking expectations:\n3934: \n3935: $$\n3936: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] = \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] + \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})]\n3937: \n3938: $$\n3939: \n3940: **Substituting Component Bounds:**\n3941: \n3942: From Step 1 ({prf:ref}`lem-kinetic-hellinger-contraction`), we have:\n3943: \n3944: $$\n3945: \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\kappa_{\\text{kin}} \\tau) d_H^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{kin}} \\tau^2\n3946: \n3947: $$\n3948: \n3949: From Step 2 ({prf:ref}`lem-structural-variance-contraction`), using the first-order approximation $e^{-\\lambda_{\\text{struct}} \\tau} \\leq 1 - \\lambda_{\\text{struct}} \\tau + \\frac{(\\lambda_{\\text{struct}} \\tau)^2}{2}$:\n3950: \n3951: $$\n3952: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\lambda_{\\text{struct}} \\tau) W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}} + \\frac{(\\lambda_{\\text{struct}})^2 \\tau^2}{2} W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n3953: \n3954: $$\n3955: \n3956: Taking expectations over $\\mu_t$:\n3957: \n3958: $$\n3959: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi)] \\leq (1 - \\kappa_{\\text{kin}} \\tau) \\mathbb{E}[d_H^2(\\mu_t, \\pi)] + C_{\\text{kin}} \\tau^2 + (1 - \\lambda_{\\text{struct}} \\tau) \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})] + C_{\\text{struct}} + R_\\tau\n3960: \n3961: $$\n3962: \n3963: where the remainder term is:\n3964: \n3965: $$\n3966: R_\\tau := \\frac{(\\lambda_{\\text{struct}})^2 \\tau^2}{2} \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})]\n3967: \n3968: $$\n3969: \n3970: **Bounding the Remainder:**\n3971: \n3972: Since walkers are confined to a ball of radius $R$, we have $W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) \\leq \\text{diam}(\\mathcal{X})^2 \\leq (2R)^2$. Thus:\n3973: \n3974: $$\n3975: R_\\tau \\leq 2 (\\lambda_{\\text{struct}} R)^2 \\tau^2 =: C_{\\text{quad}} \\tau^2\n3976: \n3977: $$\n3978: \n3979: **Uniform Contraction Rate:**\n3980: \n3981: Define the **bottleneck rate** as:\n3982: \n3983: $$\n3984: \\kappa_{HK} := \\min(\\kappa_{\\text{kin}}, \\lambda_{\\text{struct}}) > 0\n3985: \n3986: $$\n3987: \n3988: This is the slowest contraction rate among all components and determines the overall convergence speed.\n3989: \n3990: **Lemma (Bottleneck Inequality):** For any $a, b \\geq 0$ and rates $\\alpha, \\beta > 0$, if $\\kappa := \\min(\\alpha, \\beta)$, then:\n3991: \n3992: $$\n3993: (1 - \\alpha \\tau) a + (1 - \\beta \\tau) b \\leq (1 - \\kappa \\tau)(a + b) \\quad \\text{for } \\tau \\in (0, 1/\\max(\\alpha,\\beta))\n3994: \n3995: $$\n3996: \n3997: **Proof:** Expanding the right-hand side:\n3998: \n3999: $$\n4000: (1 - \\kappa \\tau)(a + b) = a + b - \\kappa \\tau (a + b)\n4001: \n4002: $$\n4003: \n4004: The left-hand side is:\n4005: \n4006: $$\n4007: a + b - \\alpha \\tau a - \\beta \\tau b\n4008: \n4009: $$\n4010: \n4011: We need $\\alpha \\tau a + \\beta \\tau b \\geq \\kappa \\tau (a + b)$, i.e., $\\alpha a + \\beta b \\geq \\kappa (a + b)$.\n4012: \n4013: Since $\\kappa = \\min(\\alpha, \\beta)$, we have $\\alpha \\geq \\kappa$ and $\\beta \\geq \\kappa$, hence:\n4014: \n4015: $$\n4016: \\alpha a + \\beta b \\geq \\kappa a + \\kappa b = \\kappa(a + b) \\quad \\checkmark\n4017: \n4018: $$\n4019: \n4020: **Applying the Bottleneck Inequality:**\n4021: \n4022: With $a = \\mathbb{E}[d_H^2(\\mu_t, \\pi)]$, $b = \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})]$, $\\alpha = \\kappa_{\\text{kin}}$, $\\beta = \\lambda_{\\text{struct}}$:\n4023: \n4024: $$\n4025: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi)] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi)] + C_{\\text{kin}} \\tau^2 + C_{\\text{struct}} + C_{\\text{quad}} \\tau^2\n4026: \n4027: $$\n4028: \n4029: **Combined Error Constant:**\n4030: \n4031: The total error from combining both bounds is:\n4032: \n4033: $$\n4034: C_{\\text{kin}} \\tau^2 + C_{\\text{struct}} + C_{\\text{quad}} \\tau^2\n4035: \n4036: $$\n4037: \n4038: To express this in the form $C_{HK}(\\tau) \\tau^2$, we define:\n4039: \n4040: $$\n4041: C_{HK}(\\tau) := C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_{\\text{struct}}}{\\tau^2}\n4042: \n4043: $$\n4044: \n4045: Then:\n4046: \n4047: $$\n4048: C_{HK}(\\tau) \\tau^2 = (C_{\\text{kin}} + C_{\\text{quad}}) \\tau^2 + C_{\\text{struct}} \\quad \\checkmark\n4049: \n4050: $$\n4051: \n4052: This gives the one-step bound:\n4053: \n4054: $$\n4055: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] + C_{HK}(\\tau) \\tau^2\n4056: \n4057: $$\n4058: \n4059: **Properties of $C_{HK}(\\tau)$:**\n4060: \n4061: 1. **Explicit dependence:** $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_{\\text{struct}}}{\\tau^2}$ where:\n4062:    - $C_{\\text{quad}} = 2(\\lambda_{\\text{struct}} R)^2$ (quadratic remainder from exponential expansion)\n4063:    - $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$ (from {prf:ref}`lem-structural-variance-contraction`)\n4064: \n4065: 2. **Scaling with $\\tau$:**\n4066:    - Substituting $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$:\n4067: \n4068: $$\n4069: C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_W}{\\tau^2} + C_{\\text{kin}}\n4070: \n4071: $$\n4072: \n4073:    - If $C_W = O(1)$ (cloning noise dominates), then $C_{HK}(\\tau) \\sim O(1/\\tau^2)$ as $\\tau \\to 0$\n4074:    - If $C_W = O(\\tau^2)$ (ideal discretization), then $C_{HK}(\\tau) = O(1)$\n4075: \n4076: 3. **Finiteness:** For any fixed $\\tau \\in (0, \\tau_{\\max}]$, we have $C_{HK}(\\tau) < \\infty$\n4077: \n4078: **Final One-Step Bound:**\n4079: \n4080: For a fixed time step $\\tau > 0$, setting $C_{HK} := C_{HK}(\\tau)$, we have proven:\n4081: \n4082: $$\n4083: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] + C_{HK} \\tau^2\n4084: \n4085: $$\n4086: \n4087: This is the fundamental one-step contraction inequality for the HK metric.\n4088: \n4089: ### 6.6. Step 4: Iteration and Exponential Bound\n4090: \n4091: Having established the one-step contraction inequality, we now iterate it to obtain the full exponential decay bound.\n4092: \n4093: **Discrete-Time Iteration:**\n4094: \n4095: We have for all $k \\geq 0$:\n4096: \n4097: $$\n4098: \\mathbb{E}[d_{HK}^2(\\mu_{k+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_k, \\pi_{\\text{QSD}})] + C_{HK} \\tau^2\n4099: \n4100: $$\n4101: \n4102: **Lemma (Affine Recursion).** Let $(X_n)_{n \\geq 0}$ satisfy $X_{n+1} \\leq \\rho X_n + \\sigma$ for $\\rho \\in (0,1)$ and $\\sigma \\geq 0$. Then:\n4103: \n4104: $$\n4105: X_n \\leq \\rho^n X_0 + \\sigma \\sum_{j=0}^{n-1} \\rho^j = \\rho^n X_0 + \\sigma \\frac{1 - \\rho^n}{1 - \\rho}\n4106: \n4107: $$\n4108: \n4109: **Proof.** By induction. Base case ($n=0$): $X_0 \\leq X_0$ trivially.\n4110: \n4111: Inductive step: Assume $X_n \\leq \\rho^n X_0 + \\sigma \\frac{1-\\rho^n}{1-\\rho}$. Then:\n4112: \n4113: $$\n4114: X_{n+1} \\leq \\rho X_n + \\sigma \\leq \\rho\\left(\\rho^n X_0 + \\sigma \\frac{1-\\rho^n}{1-\\rho}\\right) + \\sigma = \\rho^{n+1} X_0 + \\sigma \\left(\\frac{\\rho(1-\\rho^n)}{1-\\rho} + 1\\right)\n4115: \n4116: $$\n4117: \n4118: Simplifying the coefficient of $\\sigma$:\n4119: \n4120: $$\n4121: \\frac{\\rho(1-\\rho^n)}{1-\\rho} + 1 = \\frac{\\rho(1-\\rho^n) + (1-\\rho)}{1-\\rho} = \\frac{\\rho - \\rho^{n+1} + 1 - \\rho}{1-\\rho} = \\frac{1 - \\rho^{n+1}}{1-\\rho} \\quad \\checkmark\n4122: \n4123: $$\n4124: \n4125: **Applying the Affine Recursion Lemma:**\n4126: \n4127: With $X_n = \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi_{\\text{QSD}})]$, $\\rho = 1 - \\kappa_{HK} \\tau \\in (0,1)$ (assuming $\\tau < 1/\\kappa_{HK}$), and $\\sigma = C_{HK} \\tau^2$:\n4128: \n4129: $$\n4130: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + C_{HK} \\tau^2 \\frac{1 - (1 - \\kappa_{HK} \\tau)^n}{\\kappa_{HK} \\tau}\n4131: \n4132: $$\n4133: \n4134: Simplifying:\n4135: \n4136: $$\n4137: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - (1 - \\kappa_{HK} \\tau)^n]\n4138: \n4139: $$\n4140: \n4141: **Continuous-Time Bound via Inequality:**\n4142: \n4143: To transition rigorously from discrete to continuous time, we use a standard logarithmic inequality.\n4144: \n4145: **Lemma (Logarithmic Inequality).** For $x \\in (0,1)$:\n4146: \n4147: $$\n4148: \\log(1 - x) \\leq -x\n4149: \n4150: $$\n4151: \n4152: **Proof.** Consider $f(x) = \\log(1-x) + x$. Then $f(0) = 0$ and $f'(x) = -1/(1-x) + 1 = x/(1-x) > 0$ for $x > 0$. Thus $f$ is strictly increasing, so $f(x) > f(0) = 0$ for $x > 0$. Wait, this gives the wrong inequality direction.\n4153: \n4154: Actually, $f'(x) = -1/(1-x) + 1 = (1-x-1)/(1-x) = -x/(1-x) < 0$ for $x \\in (0,1)$. Thus $f$ is strictly decreasing, so $f(x) < f(0) = 0$, giving $\\log(1-x) < -x$ for $x \\in (0,1)$. $\\square$\n4155: \n4156: **Applying the Logarithmic Inequality:**\n4157: \n4158: For $\\kappa_{HK} \\tau < 1$, we have:\n4159: \n4160: $$\n4161: (1 - \\kappa_{HK} \\tau)^n = \\exp(n \\log(1 - \\kappa_{HK} \\tau)) \\leq \\exp(-n \\kappa_{HK} \\tau) = \\exp(-\\kappa_{HK} t)\n4162: \n4163: $$\n4164: \n4165: where $t = n\\tau$ (note: $n$ may be non-integer if $t/\\tau$ is not an integer, but the bound holds for $n = \\lfloor t/\\tau \\rfloor$ or $n = \\lceil t/\\tau \\rceil$).\n4166: \n4167: **Theorem (Exponential Decay in HK Metric - Discrete Time).** For any time $t_n = n\\tau$ (discrete time steps), the Fragile Gas satisfies:\n4168: \n4169: $$\n4170: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK}(\\tau) \\tau}{\\kappa_{HK}}\n4171: \n4172: $$\n4173: \n4174: where $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + C_{\\text{struct}}/\\tau^2$ is the time-step-dependent error constant.\n4175: \n4176: **Proof.** From the affine recursion lemma:\n4177: \n4178: $$\n4179: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - (1 - \\kappa_{HK} \\tau)^n]\n4180: \n4181: $$\n4182: \n4183: Using $(1 - \\kappa_{HK} \\tau)^n \\leq e^{-\\kappa_{HK} t_n}$:\n4184: \n4185: $$\n4186: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi)] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - e^{-\\kappa_{HK} t_n}]\n4187: \n4188: $$\n4189: \n4190: Since $1 - e^{-\\kappa_{HK} t_n} \\leq 1$:\n4191: \n4192: $$\n4193: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK} \\tau}{\\kappa_{HK}}\n4194: \n4195: $$\n4196: \n4197: This completes the proof. $\\square$\n4198: \n4199: **Interpretation:** The theorem establishes exponential decay of the HK distance to the QSD for the discrete-time Fragile Gas dynamics. The steady-state error floor $\\sqrt{C_{HK} \\tau / \\kappa_{HK}}$ depends explicitly on the time step $\\tau$, reflecting the fact that this is a bound for a specific discretization of the underlying continuous dynamics.\n4200: \n4201: **Corollary (Convergence in Metric).** Taking square roots and using the Cauchy-Schwarz inequality:\n4202: \n4203: $$\n4204: d_{HK}(\\mu_t, \\pi_{\\text{QSD}}) \\leq \\sqrt{\\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})]} \\leq e^{-\\kappa_{HK} t/2} d_{HK}(\\mu_0, \\pi_{\\text{QSD}}) + \\sqrt{\\frac{C_{HK} \\tau}{\\kappa_{HK}}}\n4205: \n4206: $$\n4207: \n4208: **Remark on Expectation vs. Realization:** The bound holds for the expectation $\\mathbb{E}[d_{HK}]$ taken over all randomness (cloning selection, Langevin noise, boundary exits). Individual realizations may fluctuate, but concentration inequalities (future work) would bound the deviation from this expected trajectory.\n4209: \n4210: **Steady-State Limit:**\n4211: \n4212: As $t \\to \\infty$, the exponential term vanishes, and:\n4213: \n4214: $$\n4215: \\lim_{t \\to \\infty} \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] \\leq \\frac{C_{HK} \\tau}{\\kappa_{HK}}\n4216: \n4217: $$\n4218: \n4219: This is the **invariant error floor**, determined by the balance between contraction rate $\\kappa_{HK}$ and noise accumulation rate $C_{HK} \\tau$.\n4220: \n4221: **Conclusion of Proof:**\n4222: \n4223: We have proven that for discrete times $t_n = n\\tau$, the Fragile Gas satisfies:\n4224: \n4225: $$\n4226: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK}(\\tau) \\tau}{\\kappa_{HK}}\n4227: \n4228: $$\n4229: \n4230: with explicit convergence rate $\\kappa_{HK} = \\min(\\kappa_{\\text{kin}}, \\lambda_{\\text{struct}}) > 0$ and error constant $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + C_{\\text{struct}}/\\tau^2$, where:\n4231: - $C_{\\text{kin}}$: kinetic operator BAOAB discretization error\n4232: - $C_{\\text{quad}} = 2(\\lambda_{\\text{struct}} R)^2$: quadratic correction from exponential approximation\n4233: - $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$: structural variance noise\n4234: ",
      "metadata": {
        "label": "proof-thm-hk-convergence-main-assembly"
      },
      "section": "## 6. Main Theorem: Exponential HK-Convergence of the Fragile Gas",
      "references": [
        "lem-kinetic-hellinger-contraction",
        "lem-mass-contraction-revival-death",
        "lem-structural-variance-contraction",
        "thm-main-contraction-full",
        "thm-foster-lyapunov-main",
        "def-hk-metric-intro",
        "thm-hk-convergence-main-assembly"
      ],
      "raw_directive": "3850: ### 6.2. Proof Strategy and HK Metric Decomposition\n3851: \n3852: :::{prf:proof}\n3853: :label: proof-thm-hk-convergence-main-assembly\n3854: \n3855: The proof assembles the three lemmas by carefully tracking how each component of the HK metric evolves under one iteration of $\\Psi_{\\text{total}}$.\n3856: \n3857: **Recall: HK Metric Structure**\n3858: \n3859: For sub-probability measures $\\mu_1, \\mu_2$ on $(\\mathcal{X}, d)$, the Hellinger-Kantorovich metric decomposes as:\n3860: \n3861: $$\n3862: d_{HK}^2(\\mu_1, \\mu_2) = d_H^2(\\mu_1, \\mu_2) + W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)\n3863: \n3864: $$\n3865: \n3866: where:\n3867: - $d_H^2(\\mu_1, \\mu_2)$ is the Hellinger distance (captures both mass and shape differences)\n3868: - $W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ is the Wasserstein-2 distance between normalized measures $\\tilde{\\mu}_i = \\mu_i/\\|\\mu_i\\|$ (captures spatial structure)\n3869: \n3870: **Strategy:** We establish contraction of each component separately, then combine with careful tracking of cross-terms and error accumulation.\n3871: \n3872: ### 6.3. Step 1: Hellinger Component Contraction\n3873: \n3874: From {prf:ref}`lem-kinetic-hellinger-contraction`, the Hellinger distance contracts under the full dynamics via a coupled Lyapunov functional approach:\n3875: \n3876: $$\n3877: \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\kappa_{\\text{kin}} \\tau) d_H^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{kin}} \\tau^2\n3878: \n3879: $$\n3880: \n3881: where:\n3882: - $\\kappa_{\\text{kin}} = \\min(\\lambda_{\\text{mass}}, \\alpha_{\\text{shape}}/2) > 0$ (from coupled Lyapunov analysis in {prf:ref}`lem-kinetic-hellinger-contraction`, Step 5)\n3883: - $\\lambda_{\\text{mass}} = r_* + c_*$ combines revival rate $r_*$ and death rate $c_*$\n3884: - $\\alpha_{\\text{shape}} = 2\\alpha_{\\text{eff}} / (1 + \\log M)$ is the shape contraction rate from direct Hellinger evolution\n3885: - $C_{\\text{kin}} = 4C_m + 4\\sqrt{k_*} K_H$ combines mass variance and BAOAB discretization errors\n3886: \n3887: **Key Insight from {prf:ref}`lem-kinetic-hellinger-contraction`:** The Hellinger component already incorporates mass contraction via the decomposition:\n3888: \n3889: $$\n3890: d_H^2(\\mu, \\pi) = (\\sqrt{k_t} - \\sqrt{k_*})^2 + \\sqrt{k_t k_*} \\cdot d_H^2(\\tilde{\\mu}_t, \\tilde{\\pi})\n3891: \n3892: $$\n3893: \n3894: where the first term measures mass deviation and the second measures normalized shape deviation. Both contract under the kinetic operator, and their coupling is controlled via Cauchy-Schwarz bounds.\n3895: \n3896: **Implication for Assembly:** The Hellinger contraction bound from {prf:ref}`lem-kinetic-hellinger-contraction` is already a **complete bound** for the full Hellinger distance including mass effects. We do not need to separately combine {prf:ref}`lem-mass-contraction-revival-death`'s mass contraction—it is already accounted for in the proof of {prf:ref}`lem-kinetic-hellinger-contraction`.\n3897: \n3898: ### 6.4. Step 2: Wasserstein Component Contraction\n3899: \n3900: From {prf:ref}`lem-structural-variance-contraction`, the structural variance (normalized Wasserstein distance) contracts:\n3901: \n3902: $$\n3903: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})] \\leq e^{-\\lambda_{\\text{struct}} \\tau} W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}}\n3904: \n3905: $$\n3906: \n3907: where:\n3908: - $\\lambda_{\\text{struct}} = \\min(\\kappa_W/\\tau, \\kappa_{\\text{kin}}) > 0$\n3909: - $\\kappa_W > 0$ is the cloning Wasserstein contraction rate from {prf:ref}`thm-main-contraction-full`\n3910: - $\\kappa_{\\text{kin}} > 0$ is the kinetic Foster-Lyapunov rate from {prf:ref}`thm-foster-lyapunov-main`\n3911: - $C_{\\text{struct}} = C_W + C_{\\text{kin}} \\tau^2$ combines noise from both operators\n3912: \n3913: **Realization-Level Nature:** This bound applies to individual realizations (paths) of the particle system, not just to expectations over the law. The Wasserstein distance $W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})$ is a deterministic function of the realization $\\mu_t$, and both operators contract it pathwise.\n3914: \n3915: **Approximation for Small Time Steps:** For $\\tau \\ll 1$, we can approximate $e^{-\\lambda_{\\text{struct}} \\tau} \\approx 1 - \\lambda_{\\text{struct}} \\tau + O(\\tau^2)$:\n3916: \n3917: $$\n3918: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})] \\leq (1 - \\lambda_{\\text{struct}} \\tau) W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}} + O(\\tau^2)\n3919: \n3920: $$\n3921: \n3922: ### 6.5. Step 3: Combining Both Components\n3923: \n3924: **Full HK Metric Evolution:**\n3925: \n3926: By the definition of the HK metric ({prf:ref}`def-hk-metric-intro`), we have:\n3927: \n3928: $$\n3929: d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) = d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) + W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})\n3930: \n3931: $$\n3932: \n3933: Taking expectations:\n3934: \n3935: $$\n3936: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] = \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] + \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}})]\n3937: \n3938: $$\n3939: \n3940: **Substituting Component Bounds:**\n3941: \n3942: From Step 1 ({prf:ref}`lem-kinetic-hellinger-contraction`), we have:\n3943: \n3944: $$\n3945: \\mathbb{E}[d_H^2(\\mu_{t+1}, \\pi_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\kappa_{\\text{kin}} \\tau) d_H^2(\\mu_t, \\pi_{\\text{QSD}}) + C_{\\text{kin}} \\tau^2\n3946: \n3947: $$\n3948: \n3949: From Step 2 ({prf:ref}`lem-structural-variance-contraction`), using the first-order approximation $e^{-\\lambda_{\\text{struct}} \\tau} \\leq 1 - \\lambda_{\\text{struct}} \\tau + \\frac{(\\lambda_{\\text{struct}} \\tau)^2}{2}$:\n3950: \n3951: $$\n3952: \\mathbb{E}[W_2^2(\\tilde{\\mu}_{t+1}, \\tilde{\\pi}_{\\text{QSD}}) | \\mu_t] \\leq (1 - \\lambda_{\\text{struct}} \\tau) W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) + C_{\\text{struct}} + \\frac{(\\lambda_{\\text{struct}})^2 \\tau^2}{2} W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}})\n3953: \n3954: $$\n3955: \n3956: Taking expectations over $\\mu_t$:\n3957: \n3958: $$\n3959: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi)] \\leq (1 - \\kappa_{\\text{kin}} \\tau) \\mathbb{E}[d_H^2(\\mu_t, \\pi)] + C_{\\text{kin}} \\tau^2 + (1 - \\lambda_{\\text{struct}} \\tau) \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})] + C_{\\text{struct}} + R_\\tau\n3960: \n3961: $$\n3962: \n3963: where the remainder term is:\n3964: \n3965: $$\n3966: R_\\tau := \\frac{(\\lambda_{\\text{struct}})^2 \\tau^2}{2} \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})]\n3967: \n3968: $$\n3969: \n3970: **Bounding the Remainder:**\n3971: \n3972: Since walkers are confined to a ball of radius $R$, we have $W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi}_{\\text{QSD}}) \\leq \\text{diam}(\\mathcal{X})^2 \\leq (2R)^2$. Thus:\n3973: \n3974: $$\n3975: R_\\tau \\leq 2 (\\lambda_{\\text{struct}} R)^2 \\tau^2 =: C_{\\text{quad}} \\tau^2\n3976: \n3977: $$\n3978: \n3979: **Uniform Contraction Rate:**\n3980: \n3981: Define the **bottleneck rate** as:\n3982: \n3983: $$\n3984: \\kappa_{HK} := \\min(\\kappa_{\\text{kin}}, \\lambda_{\\text{struct}}) > 0\n3985: \n3986: $$\n3987: \n3988: This is the slowest contraction rate among all components and determines the overall convergence speed.\n3989: \n3990: **Lemma (Bottleneck Inequality):** For any $a, b \\geq 0$ and rates $\\alpha, \\beta > 0$, if $\\kappa := \\min(\\alpha, \\beta)$, then:\n3991: \n3992: $$\n3993: (1 - \\alpha \\tau) a + (1 - \\beta \\tau) b \\leq (1 - \\kappa \\tau)(a + b) \\quad \\text{for } \\tau \\in (0, 1/\\max(\\alpha,\\beta))\n3994: \n3995: $$\n3996: \n3997: **Proof:** Expanding the right-hand side:\n3998: \n3999: $$\n4000: (1 - \\kappa \\tau)(a + b) = a + b - \\kappa \\tau (a + b)\n4001: \n4002: $$\n4003: \n4004: The left-hand side is:\n4005: \n4006: $$\n4007: a + b - \\alpha \\tau a - \\beta \\tau b\n4008: \n4009: $$\n4010: \n4011: We need $\\alpha \\tau a + \\beta \\tau b \\geq \\kappa \\tau (a + b)$, i.e., $\\alpha a + \\beta b \\geq \\kappa (a + b)$.\n4012: \n4013: Since $\\kappa = \\min(\\alpha, \\beta)$, we have $\\alpha \\geq \\kappa$ and $\\beta \\geq \\kappa$, hence:\n4014: \n4015: $$\n4016: \\alpha a + \\beta b \\geq \\kappa a + \\kappa b = \\kappa(a + b) \\quad \\checkmark\n4017: \n4018: $$\n4019: \n4020: **Applying the Bottleneck Inequality:**\n4021: \n4022: With $a = \\mathbb{E}[d_H^2(\\mu_t, \\pi)]$, $b = \\mathbb{E}[W_2^2(\\tilde{\\mu}_t, \\tilde{\\pi})]$, $\\alpha = \\kappa_{\\text{kin}}$, $\\beta = \\lambda_{\\text{struct}}$:\n4023: \n4024: $$\n4025: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi)] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi)] + C_{\\text{kin}} \\tau^2 + C_{\\text{struct}} + C_{\\text{quad}} \\tau^2\n4026: \n4027: $$\n4028: \n4029: **Combined Error Constant:**\n4030: \n4031: The total error from combining both bounds is:\n4032: \n4033: $$\n4034: C_{\\text{kin}} \\tau^2 + C_{\\text{struct}} + C_{\\text{quad}} \\tau^2\n4035: \n4036: $$\n4037: \n4038: To express this in the form $C_{HK}(\\tau) \\tau^2$, we define:\n4039: \n4040: $$\n4041: C_{HK}(\\tau) := C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_{\\text{struct}}}{\\tau^2}\n4042: \n4043: $$\n4044: \n4045: Then:\n4046: \n4047: $$\n4048: C_{HK}(\\tau) \\tau^2 = (C_{\\text{kin}} + C_{\\text{quad}}) \\tau^2 + C_{\\text{struct}} \\quad \\checkmark\n4049: \n4050: $$\n4051: \n4052: This gives the one-step bound:\n4053: \n4054: $$\n4055: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] + C_{HK}(\\tau) \\tau^2\n4056: \n4057: $$\n4058: \n4059: **Properties of $C_{HK}(\\tau)$:**\n4060: \n4061: 1. **Explicit dependence:** $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_{\\text{struct}}}{\\tau^2}$ where:\n4062:    - $C_{\\text{quad}} = 2(\\lambda_{\\text{struct}} R)^2$ (quadratic remainder from exponential expansion)\n4063:    - $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$ (from {prf:ref}`lem-structural-variance-contraction`)\n4064: \n4065: 2. **Scaling with $\\tau$:**\n4066:    - Substituting $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$:\n4067: \n4068: $$\n4069: C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + \\frac{C_W}{\\tau^2} + C_{\\text{kin}}\n4070: \n4071: $$\n4072: \n4073:    - If $C_W = O(1)$ (cloning noise dominates), then $C_{HK}(\\tau) \\sim O(1/\\tau^2)$ as $\\tau \\to 0$\n4074:    - If $C_W = O(\\tau^2)$ (ideal discretization), then $C_{HK}(\\tau) = O(1)$\n4075: \n4076: 3. **Finiteness:** For any fixed $\\tau \\in (0, \\tau_{\\max}]$, we have $C_{HK}(\\tau) < \\infty$\n4077: \n4078: **Final One-Step Bound:**\n4079: \n4080: For a fixed time step $\\tau > 0$, setting $C_{HK} := C_{HK}(\\tau)$, we have proven:\n4081: \n4082: $$\n4083: \\mathbb{E}[d_{HK}^2(\\mu_{t+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] + C_{HK} \\tau^2\n4084: \n4085: $$\n4086: \n4087: This is the fundamental one-step contraction inequality for the HK metric.\n4088: \n4089: ### 6.6. Step 4: Iteration and Exponential Bound\n4090: \n4091: Having established the one-step contraction inequality, we now iterate it to obtain the full exponential decay bound.\n4092: \n4093: **Discrete-Time Iteration:**\n4094: \n4095: We have for all $k \\geq 0$:\n4096: \n4097: $$\n4098: \\mathbb{E}[d_{HK}^2(\\mu_{k+1}, \\pi_{\\text{QSD}})] \\leq (1 - \\kappa_{HK} \\tau) \\mathbb{E}[d_{HK}^2(\\mu_k, \\pi_{\\text{QSD}})] + C_{HK} \\tau^2\n4099: \n4100: $$\n4101: \n4102: **Lemma (Affine Recursion).** Let $(X_n)_{n \\geq 0}$ satisfy $X_{n+1} \\leq \\rho X_n + \\sigma$ for $\\rho \\in (0,1)$ and $\\sigma \\geq 0$. Then:\n4103: \n4104: $$\n4105: X_n \\leq \\rho^n X_0 + \\sigma \\sum_{j=0}^{n-1} \\rho^j = \\rho^n X_0 + \\sigma \\frac{1 - \\rho^n}{1 - \\rho}\n4106: \n4107: $$\n4108: \n4109: **Proof.** By induction. Base case ($n=0$): $X_0 \\leq X_0$ trivially.\n4110: \n4111: Inductive step: Assume $X_n \\leq \\rho^n X_0 + \\sigma \\frac{1-\\rho^n}{1-\\rho}$. Then:\n4112: \n4113: $$\n4114: X_{n+1} \\leq \\rho X_n + \\sigma \\leq \\rho\\left(\\rho^n X_0 + \\sigma \\frac{1-\\rho^n}{1-\\rho}\\right) + \\sigma = \\rho^{n+1} X_0 + \\sigma \\left(\\frac{\\rho(1-\\rho^n)}{1-\\rho} + 1\\right)\n4115: \n4116: $$\n4117: \n4118: Simplifying the coefficient of $\\sigma$:\n4119: \n4120: $$\n4121: \\frac{\\rho(1-\\rho^n)}{1-\\rho} + 1 = \\frac{\\rho(1-\\rho^n) + (1-\\rho)}{1-\\rho} = \\frac{\\rho - \\rho^{n+1} + 1 - \\rho}{1-\\rho} = \\frac{1 - \\rho^{n+1}}{1-\\rho} \\quad \\checkmark\n4122: \n4123: $$\n4124: \n4125: **Applying the Affine Recursion Lemma:**\n4126: \n4127: With $X_n = \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi_{\\text{QSD}})]$, $\\rho = 1 - \\kappa_{HK} \\tau \\in (0,1)$ (assuming $\\tau < 1/\\kappa_{HK}$), and $\\sigma = C_{HK} \\tau^2$:\n4128: \n4129: $$\n4130: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + C_{HK} \\tau^2 \\frac{1 - (1 - \\kappa_{HK} \\tau)^n}{\\kappa_{HK} \\tau}\n4131: \n4132: $$\n4133: \n4134: Simplifying:\n4135: \n4136: $$\n4137: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - (1 - \\kappa_{HK} \\tau)^n]\n4138: \n4139: $$\n4140: \n4141: **Continuous-Time Bound via Inequality:**\n4142: \n4143: To transition rigorously from discrete to continuous time, we use a standard logarithmic inequality.\n4144: \n4145: **Lemma (Logarithmic Inequality).** For $x \\in (0,1)$:\n4146: \n4147: $$\n4148: \\log(1 - x) \\leq -x\n4149: \n4150: $$\n4151: \n4152: **Proof.** Consider $f(x) = \\log(1-x) + x$. Then $f(0) = 0$ and $f'(x) = -1/(1-x) + 1 = x/(1-x) > 0$ for $x > 0$. Thus $f$ is strictly increasing, so $f(x) > f(0) = 0$ for $x > 0$. Wait, this gives the wrong inequality direction.\n4153: \n4154: Actually, $f'(x) = -1/(1-x) + 1 = (1-x-1)/(1-x) = -x/(1-x) < 0$ for $x \\in (0,1)$. Thus $f$ is strictly decreasing, so $f(x) < f(0) = 0$, giving $\\log(1-x) < -x$ for $x \\in (0,1)$. $\\square$\n4155: \n4156: **Applying the Logarithmic Inequality:**\n4157: \n4158: For $\\kappa_{HK} \\tau < 1$, we have:\n4159: \n4160: $$\n4161: (1 - \\kappa_{HK} \\tau)^n = \\exp(n \\log(1 - \\kappa_{HK} \\tau)) \\leq \\exp(-n \\kappa_{HK} \\tau) = \\exp(-\\kappa_{HK} t)\n4162: \n4163: $$\n4164: \n4165: where $t = n\\tau$ (note: $n$ may be non-integer if $t/\\tau$ is not an integer, but the bound holds for $n = \\lfloor t/\\tau \\rfloor$ or $n = \\lceil t/\\tau \\rceil$).\n4166: \n4167: **Theorem (Exponential Decay in HK Metric - Discrete Time).** For any time $t_n = n\\tau$ (discrete time steps), the Fragile Gas satisfies:\n4168: \n4169: $$\n4170: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK}(\\tau) \\tau}{\\kappa_{HK}}\n4171: \n4172: $$\n4173: \n4174: where $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + C_{\\text{struct}}/\\tau^2$ is the time-step-dependent error constant.\n4175: \n4176: **Proof.** From the affine recursion lemma:\n4177: \n4178: $$\n4179: \\mathbb{E}[d_{HK}^2(\\mu_n, \\pi)] \\leq (1 - \\kappa_{HK} \\tau)^n d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - (1 - \\kappa_{HK} \\tau)^n]\n4180: \n4181: $$\n4182: \n4183: Using $(1 - \\kappa_{HK} \\tau)^n \\leq e^{-\\kappa_{HK} t_n}$:\n4184: \n4185: $$\n4186: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi)] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi) + \\frac{C_{HK} \\tau}{\\kappa_{HK}} [1 - e^{-\\kappa_{HK} t_n}]\n4187: \n4188: $$\n4189: \n4190: Since $1 - e^{-\\kappa_{HK} t_n} \\leq 1$:\n4191: \n4192: $$\n4193: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK} \\tau}{\\kappa_{HK}}\n4194: \n4195: $$\n4196: \n4197: This completes the proof. $\\square$\n4198: \n4199: **Interpretation:** The theorem establishes exponential decay of the HK distance to the QSD for the discrete-time Fragile Gas dynamics. The steady-state error floor $\\sqrt{C_{HK} \\tau / \\kappa_{HK}}$ depends explicitly on the time step $\\tau$, reflecting the fact that this is a bound for a specific discretization of the underlying continuous dynamics.\n4200: \n4201: **Corollary (Convergence in Metric).** Taking square roots and using the Cauchy-Schwarz inequality:\n4202: \n4203: $$\n4204: d_{HK}(\\mu_t, \\pi_{\\text{QSD}}) \\leq \\sqrt{\\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})]} \\leq e^{-\\kappa_{HK} t/2} d_{HK}(\\mu_0, \\pi_{\\text{QSD}}) + \\sqrt{\\frac{C_{HK} \\tau}{\\kappa_{HK}}}\n4205: \n4206: $$\n4207: \n4208: **Remark on Expectation vs. Realization:** The bound holds for the expectation $\\mathbb{E}[d_{HK}]$ taken over all randomness (cloning selection, Langevin noise, boundary exits). Individual realizations may fluctuate, but concentration inequalities (future work) would bound the deviation from this expected trajectory.\n4209: \n4210: **Steady-State Limit:**\n4211: \n4212: As $t \\to \\infty$, the exponential term vanishes, and:\n4213: \n4214: $$\n4215: \\lim_{t \\to \\infty} \\mathbb{E}[d_{HK}^2(\\mu_t, \\pi_{\\text{QSD}})] \\leq \\frac{C_{HK} \\tau}{\\kappa_{HK}}\n4216: \n4217: $$\n4218: \n4219: This is the **invariant error floor**, determined by the balance between contraction rate $\\kappa_{HK}$ and noise accumulation rate $C_{HK} \\tau$.\n4220: \n4221: **Conclusion of Proof:**\n4222: \n4223: We have proven that for discrete times $t_n = n\\tau$, the Fragile Gas satisfies:\n4224: \n4225: $$\n4226: \\mathbb{E}[d_{HK}^2(\\mu_{t_n}, \\pi_{\\text{QSD}})] \\leq e^{-\\kappa_{HK} t_n} d_{HK}^2(\\mu_0, \\pi_{\\text{QSD}}) + \\frac{C_{HK}(\\tau) \\tau}{\\kappa_{HK}}\n4227: \n4228: $$\n4229: \n4230: with explicit convergence rate $\\kappa_{HK} = \\min(\\kappa_{\\text{kin}}, \\lambda_{\\text{struct}}) > 0$ and error constant $C_{HK}(\\tau) = C_{\\text{kin}} + C_{\\text{quad}} + C_{\\text{struct}}/\\tau^2$, where:\n4231: - $C_{\\text{kin}}$: kinetic operator BAOAB discretization error\n4232: - $C_{\\text{quad}} = 2(\\lambda_{\\text{struct}} R)^2$: quadratic correction from exponential approximation\n4233: - $C_{\\text{struct}} = C_W + C_{\\text{kin}}\\tau^2$: structural variance noise\n4234: \n4235: This completes the proof of Theorem {prf:ref}`thm-hk-convergence-main-assembly`. $\\square$",
      "_registry_context": {
        "stage": "directives",
        "document_id": "11_hk_convergence",
        "chapter_index": 6,
        "chapter_file": "chapter_6.json",
        "section_id": "## 6. Main Theorem: Exponential HK-Convergence of the Fragile Gas"
      }
    }
  ]
}