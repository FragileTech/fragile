---
title: "Fractal Gas and Fractal Set Theorems (Permit-Adapted)"
---

# Fractal Gas and Fractal Set Theorems (Permit-Adapted)

## TLDR

The Fractal Gas is an algorithmic schema that implements adaptive swarm dynamics through measurement-guided cloning and stochastic perturbation. Walkers explore a state space, select companions via a distance-dependent softmax kernel, and clone toward fitter companions based on a standardized fitness score combining reward and diversity. The framework is deliberately modular: the fitness/companion/cloning kernel is fixed, while the kinetic/mutation operator and reward observable remain abstract, with all regularity assumptions tracked by sieve permits. The Darwinian Ratchet metatheorem establishes that the one-step update decomposes into transport (diffusion/exploration) and reaction (selection/cloning), with the optimal reaction rate driven by value deviations from the mean. Under appropriate scaling limits, the emergent geometry is reconstructed from swarm statistics via the Expansion Adjunction, yielding a metric-measure space that inherits functional inequalities from discrete spectral gaps.

## Introduction

This chapter translates the Fractal Gas algorithmic framework into the language of thin objects and sieve permits, making explicit which hypotheses are built into the algorithmic kernel and which must be verified case-by-case through the diagnostic sieve. The distinction matters: the fitness construction, companion selection rule, and cloning mechanism are fixed algorithmic choices that define what it means to be a Fractal Gas; the kinetic operator, reward function, and boundary interface are left abstract because they vary across instantiations.

The core theorems fall into three categories. The solver dynamics section establishes how the swarm evolves: the Darwinian Ratchet decomposes each step into Wasserstein transport and Fisher-Rao reaction, with mass flowing toward high-value regions; the Coherence Phase Transition describes the competition between viscous synchronization and cloning decorrelation; and the Cheeger Bound (under Doeblin conditions) ensures the information graph remains connected. The reconstruction section develops the discrete-to-continuum bridge: the Expansion Adjunction promotes thin kernel data to a full hypostructure with an emergent metric-measure space, while Gromov-Hausdorff and Gamma convergence theorems characterize when discrete approximations recover continuum geometry and energy functionals. The causal foundations section connects swarm dynamics to spacetime structure, showing that events generated by a quasi-stationary distribution form a faithful causal set of the emergent Lorentzian geometry.

Throughout, every nontrivial statement declares its rigor class and permit dependencies. This forces honesty about what is proven framework-internally, what is imported from classical analysis, and what remains heuristic interpretation. The result is a precise specification of the Fractal Gas as a proof object: a certified algorithm whose behavior is constrained by the permits it can discharge.

(sec-fractal-gas-legend)=

## Legend: Thin Inputs and Permit Mapping

**Thin inputs (default):**
- $\mathcal{X}^{\text{thin}} = (X, d, \mathfrak{m})$
- $\Phi^{\text{thin}} = (\Phi, \nabla, \alpha)$
- $\mathfrak{D}^{\text{thin}} = (\mathfrak{D}, \beta)$
- $G^{\text{thin}} = (G, \rho, \mathcal{S})$
- $\partial^{\text{thin}} = (\mathcal{B}, \mathrm{Tr}, \mathcal{J}, \mathcal{R})$ (open systems only)

Here $(X,d,\mathfrak{m})$ is the **Thin Kernel arena** in the sense of {prf:ref}`def-thin-objects`. We reserve $\mu$ for
*runtime* measures (empirical particle measures, trajectory measures, etc.) as in
`docs/source/2_hypostructure/10_metalearning/01_metalearning.md`.

**Permit legend (node IDs):**
- $D_E$ (Node 1 EnergyCheck)
- $\mathrm{Rec}_N$ (Node 2 ZenoCheck)
- $C_\mu$ (Node 3 CompactCheck)
- $\mathrm{SC}_\lambda$ (Node 4 ScaleCheck)
- $\mathrm{SC}_{\partial c}$ (Node 5 ParamCheck)
- $\mathrm{Cap}_H$ (Node 6 GeomCheck)
- $\mathrm{LS}_\sigma$ (Node 7 StiffnessCheck)
- $\mathrm{TB}_\pi$ (Node 8 TopoCheck)
- $\mathrm{TB}_O$ (Node 9 TameCheck)
- $\mathrm{TB}_\rho$ (Node 10 ErgoCheck)
- $\mathrm{Rep}_K$ (Node 11 ComplexCheck)
- $\mathrm{GC}_\nabla$ (Node 12 OscillateCheck)
- $\mathrm{Bound}_\partial$ (Node 13 BoundaryCheck)
- $\mathrm{Bound}_B$ (Node 14 OverloadCheck)
- $\mathrm{Bound}_\Sigma$ (Node 15 StarveCheck)
- $\mathrm{GC}_T$ (Node 16 AlignCheck)
- $\mathrm{Cat}_{\mathrm{Hom}}$ (Node 17 Lock)

**Axiom to permit translation (used below):**
- Axiom C -> $C_\mu$
- Axiom D -> $D_E$
- Axiom SC -> $\mathrm{SC}_\lambda$ (plus $\mathrm{SC}_{\partial c}$ when parameter stability is needed)
- Axiom Cap -> $\mathrm{Cap}_H$
- Axiom LS -> $\mathrm{LS}_\sigma$
- Axiom TB -> $\mathrm{TB}_\pi,\ \mathrm{TB}_O,\ \mathrm{TB}_\rho$ (topology/tameness/mixing layer)
- Axiom Rep -> $\mathrm{Rep}_K$
- Axiom GC -> $\mathrm{GC}_\nabla$ or $\mathrm{GC}_T$ (context noted)

(sec-fractal-gas-rigor-policy)=

## Status and Rigor Policy (Read This First)

This file is written in the **thin-object + permit language** of the hypostructure framework.

To keep the math honest and usable, every nontrivial block should (in decreasing preference order):
1. Declare a **Rigor Class** ({prf:ref}`def-rigor-classification`) and, when Class L, its **Bridge Verification**
   ({prf:ref}`def-bridge-verification`).
2. Or (legacy) declare a `Status`:
   - **Framework**: follows from Hypopermits machinery (e.g. Expansion Adjunction {prf:ref}`thm-expansion-adjunction`,
     Thin-permit lifting {prf:ref}`thm-lsi-thin-permit`, Lock {prf:ref}`def-node-lock`).
   - **Imported**: direct citation to a proved statement via `{prf:ref}`.
   - **Conditional**: classical analysis/probability/geometry under explicit hypotheses (typically Rigor Class L).
   - **Heuristic**: interpretation/analogy; never used as certificate input.

**Default rule:** if a block does not explicitly declare a `Rigor Class` or a `Status`, treat it as **Heuristic**.
**Proof blocks:** a `:::{prf:proof}` block inherits the Rigor Class / Status of the theorem or definition it proves.

When a statement depends on nontrivial analytic inputs (minorization, Lyapunov drift, reach/sampling density, etc.),
those inputs are recorded as explicit assumptions rather than being silently imported.

**Nomenclature alignment (important):**
- A **permit** is a gate/barrier predicate together with its **certificate type** ({prf:ref}`def-gate-permits`, {prf:ref}`def-barrier-permits`). In this sketch, a block's **Permits** line should be read as its hypothesis list in the "sieve language".
- In the meta-learning framework, the symbol $K_A$ denotes an **axiom defect functional**. In this sketch, the symbol $K$ (when it appears) is used in the *certificate* sense (hypopermits), not as a defect functional.

### Closure: Node 17 (The Lock)

:::{prf:metatheorem} Lock Closure for Fractal Gas
:label: mt:fractal-gas-lock-closure
:class: metatheorem rigor-class-f

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Thin inputs:** all thin objects (plus $\partial^{\text{thin}}$ when treated as an open system).
**Permits:** $\mathrm{Cat}_{\mathrm{Hom}}$ (N17) together with the accumulated context $\Gamma$ from prior nodes.

**Status:** Framework (categorical exclusion closes “unknown unknowns”).

**Statement:** Let $\mathcal{H}$ be the candidate promoted hypostructure produced from thin Fractal Gas data (e.g. via the
Expansion Adjunction {prf:ref}`thm-expansion-adjunction`). If the Lock predicate holds (Definition {prf:ref}`def-node-lock`):

$$
\mathrm{Hom}_{\mathbf{Hypo}}(\mathbb{H}_{\mathrm{bad}}, \mathcal{H})=\varnothing,

$$
then no singularity-forming “bad pattern” can embed in $\mathcal{H}$ and the framework emits a global regularity
certificate.

Moreover, the constructive Lock check may be implemented against a finite Bad Pattern Library $\mathcal{B}$: it is
sound to check $\mathrm{Hom}(B_i,\mathcal{H})=\varnothing$ for all $B_i\in\mathcal{B}$ because $\mathcal{B}$ is dense in
the universal bad object (Metatheorem {prf:ref}`mt-fact-germ-density`). If tactics exhaust without deciding
Hom-emptiness, the Lock explicitly returns an inconclusive certificate trace (Definition {prf:ref}`def-node-lock`), and
Algorithmic Completeness (Tactic E13, Definition {prf:ref}`def-e13`) is available as a systematic last resort.
:::

:::{prf:proof}
This is exactly the Lock specification (Definition {prf:ref}`def-node-lock`). Density of the finite library is
Metatheorem {prf:ref}`mt-fact-germ-density`. The modality-exhaustion fallback is Tactic E13 (Definition
{prf:ref}`def-e13`).
:::

(sec-fractal-gas-core-theorems)=

## Fractal Gas Core Theorems (Solver Dynamics)

### Mathematical Objects

:::{prf:definition} State Space (X)
:label: def:state-space-fg

**Origin:** `hypostructure.md`, Ch 18 (Fractal Gas).

**Thin inputs:** $\mathcal{X}^{\text{thin}} = (X, d, \mathfrak{m})$.

**Status:** Definition.

The **State Space** is a metric-measure space $(X, d_X, \mathfrak{m})$ supporting the swarm dynamics.

- **Walkers:** $w_i \in X$, $i=1,\dots,N$.
- **Algorithmic reading (used by proof objects):** in algorithmic Fractal Gas instantiations (e.g. the latent proof object
  `03_fractal_gas_latent.md`), a walker state is explicitly a pair $w_i=(z_i,v_i)$ where $z_i$ is a representation
  coordinate used for companion selection/fitness and $v_i$ is an auxiliary “velocity-like” coordinate used for companion
  selection/cloning.
- **Kinetic/mutation operator:** deliberately left unspecified at the level of this chapter; all assumptions about it are
  carried by the thin cost object $\mathfrak{D}^{\text{thin}}$ and verified (or blocked) by the sieve permits.
:::

:::{prf:definition} Algorithmic Space (Y)
:label: def:algorithmic-space-fg

**Origin:** `hypostructure.md`, Ch 18 (Fractal Gas).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$.

**Status:** Definition.

The **Algorithmic Space** is a normed vector space $(Y, \|\cdot\|_Y)$ equipped with a **projection/representation map**
$\pi: X \to Y$ (the “map”).

For the Fractal Gas algorithmic kernel used throughout this part, we specialize to the product form

$$
\pi(w) = (z(w), v(w)) \in \mathbb{R}^{d_z}\times \mathbb{R}^{d_v} =: Y,

$$
with a weighted norm

$$
\|(z,v)\|_Y^2 := \|z\|_2^2 + \lambda_{\mathrm{alg}}\|v\|_2^2,\qquad \lambda_{\mathrm{alg}}\ge 0.

$$
The induced **algorithmic distance** is

$$
d_{\mathrm{alg}}(w_i,w_j) := \|\pi(w_i)-\pi(w_j)\|_Y.

$$

**Role:** $d_{\mathrm{alg}}$ is the only distance used for **companion selection** and for the **distance term** inside
fitness (Definition {prf:ref}`def:fractal-gas-fitness-cloning-kernel`).
:::

:::{prf:definition} Spatially-Aware Pairing Operator (Diversity Companion Selection)
:label: def-spatial-pairing-operator-diversity
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$ (via the alive slice and $d_{\mathrm{alg}}$).
**Permits:** none (finite algorithmic sampling rule).

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Status:** Definition (algorithmic kernel).

Let $\mathcal{A}$ be the alive index set on a time slice (Definition depends on the open-system boundary interface
$\partial^{\text{thin}}$). Fix a bandwidth $\epsilon>0$ and define symmetric weights on $\mathcal{A}$:

$$
w_{ij} := \exp\!\left(-\frac{d_{\mathrm{alg}}(w_i,w_j)^2}{2\epsilon^2}\right)\quad (i\neq j),\qquad
w_{ii}:=0.

$$

**Even alive count ($|\mathcal{A}|$ even).**
Sample a perfect matching $M$ of the complete graph on $\mathcal{A}$ with probability proportional to the matching weight

$$
W(M) := \prod_{(i,j)\in M} w_{ij}.

$$
The matching induces a companion map $c:\mathcal{A}\to\mathcal{A}$ by setting $c_i=j$ and $c_j=i$ for each matched pair
$(i,j)\in M$.

**Odd alive count ($|\mathcal{A}|$ odd).**
Select a single index $i_\star\in\mathcal{A}$ to be self-paired (by convention, uniformly at random), set $c_{i_\star} :=
i_\star$, and sample a perfect matching on $\mathcal{A}\setminus\{i_\star\}$ using the even rule above.

This “spatially-aware Gaussian pairing” rule is an analytically convenient **mutual pairing** model (useful when one
wants a symmetric information graph built from a perfect matching). It is **not** the default companion-selection kernel
used by the Fractal Gas schema in this part: proof objects here default to the soft companion selection kernel
(Definition {prf:ref}`def-softmax-companion-selection-fg`), which matches the implementation in
`src/fragile/fractalai/core/companion_selection.py`.
:::

:::{prf:definition} Soft Companion Selection Operator (Distance-Dependent Softmax)
:label: def-softmax-companion-selection-fg
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$ (via the alive slice and $d_{\mathrm{alg}}$).
**Permits:** none (finite algorithmic sampling rule).

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Status:** Definition (algorithmic kernel).

Let $\mathcal{A}$ be the alive index set on a time slice (Definition depends on the open-system boundary interface
$\partial^{\text{thin}}$). Fix a bandwidth $\epsilon>0$ and define weights on $\mathcal{A}$:

$$
w_{ij} := \exp\!\left(-\frac{d_{\mathrm{alg}}(w_i,w_j)^2}{2\epsilon^2}\right)\quad (i\neq j),\qquad
w_{ii}:=0.

$$

For each alive walker $i\in\mathcal{A}$ define a companion distribution on $\mathcal{A}\setminus\{i\}$ by

$$
P_i(j)\ :=\ \frac{w_{ij}}{\sum_{l\in\mathcal{A}\setminus\{i\}} w_{il}}\qquad (j\in\mathcal{A}\setminus\{i\}).

$$

Alive walkers sample $c_i\sim P_i(\cdot)$. Dead walkers sample companions uniformly from $\mathcal{A}$ (recovery). When
$|\mathcal{A}|<2$, the kernel is degenerate; an instantiation must specify a fallback (e.g. cemetery state, uniform
companion-from-alive recovery, or a no-op), and this is treated as part of the open-system boundary interface
$\partial^{\text{thin}}$.

This is the companion-selection kernel used by the latent proof object `docs/source/3_fractal_gas/03_fractal_gas_latent.md`
and corresponds to the implementation `src/fragile/fractalai/core/companion_selection.py` (`select_companions_for_cloning`).
:::

:::{prf:definition} Fractal Gas Fitness/Cloning Kernel (Fixed Operators)
:label: def:fractal-gas-fitness-cloning-kernel
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$ (via the construction below), and (optionally) $\partial^{\text{thin}}$ for alive/dead masking.
**Permits:** none (this is the algorithmic definition; permits enter when certifying boundedness/mixing/regularity).

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Status:** Definition (algorithmic schema).

This chapter treats **Fractal Gas** as an algorithmic schema whose **fixed** components are exactly those used in the
latent proof object `03_fractal_gas_latent.md`:

- the algorithmic distance $d_{\mathrm{alg}}$ (Definition {prf:ref}`def:algorithmic-space-fg`),
- the soft companion selection kernel (distance-dependent softmax; Definition {prf:ref}`def-softmax-companion-selection-fg`),
- the fitness construction from a reward scalar and a companion distance,
- the cloning mechanism (jitter + inelastic collision update).

The only **unspecified** components are:
1. the **reward observable** $r_i$ (a scalar computed from $w_i$, left abstract), and
2. the **kinetic/mutation operator** (the post-cloning update of $(z,v)$, left abstract).

All hypotheses about these two unspecified pieces are carried by the thin permits ($D_E$, $\mathrm{Cap}_H$,
$\mathrm{LS}_\sigma$, $\mathrm{GC}_\nabla$, boundary permits, etc.) and are discharged case-by-case by running the sieve.

**Notation (avoid collisions).**
- $r_i$ in this definition is a *reward observable* used inside $V_{\mathrm{fit},i}$; it is **not** the reaction-rate
  symbol $r$ used in the continuum WFR equation in {prf:ref}`mt:darwinian-ratchet`.
- $v(w)$ in this definition is an auxiliary “velocity-like” coordinate carried by the state; it is **not** the transport
  vector field $v$ that appears in continuum PDE notation.

**Companion selection (distance-dependent softmax).**
On each time slice, define the alive index set $\mathcal{A}$ (from an open-system boundary $\partial^{\text{thin}}$ or any
other “alive mask” rule). On $\mathcal{A}$, companion indices are sampled from the soft companion kernel
({prf:ref}`def-softmax-companion-selection-fg`) with weights

$$
w_{ij} := \exp\!\left(-\frac{d_{\mathrm{alg}}(w_i,w_j)^2}{2\epsilon^2}\right),\qquad \epsilon>0.

$$

In a full step, this companion-selection rule is typically sampled twice: once to obtain companions for the **distance
term** inside fitness and once to obtain companions for **cloning** (these two draws may be independent or shared,
depending on the instantiation). When $|\mathcal{A}|<2$, the kernel is degenerate; an instantiation must specify a
fallback (e.g. cemetery state, uniform companion-from-alive recovery, or a no-op), and this is treated as part of the
open-system boundary interface $\partial^{\text{thin}}$.

**Fitness construction.**
Fix hyperparameters $\alpha_{\mathrm{fit}},\beta_{\mathrm{fit}}\ge 0$ and regularizers $\epsilon_{\mathrm{dist}}>0$,
$A>0$, $\eta>0$. Given a “distance companion” $c_i$, define the regularized companion distance

$$
d_i := \sqrt{d_{\mathrm{alg}}(w_i,w_{c_i})^2 + \epsilon_{\mathrm{dist}}^2}.

$$
Let $r_i$ be a user-specified scalar **reward observable** (left abstract). Standardize rewards and distances using
patched (alive-only) statistics (optionally localized at scale $\rho$, with $\rho=\texttt{None}$ meaning global alive
statistics):

$$
z_r(i) = \frac{r_i - \mu_r}{\sigma_r},\qquad
z_d(i) = \frac{d_i - \mu_d}{\sigma_d}.

$$
Assumption (schema-level): the patching procedure supplies finite $\mu_r,\mu_d$ and strictly positive
$\sigma_r,\sigma_d$ on the alive slice; if not, add an explicit variance floor in the instantiation.
Apply the logistic rescale $g_A(z) = A / (1 + \exp(-z))$ and positivity floor $\eta$:

$$
r_i' = g_A(z_r(i)) + \eta,\qquad d_i' = g_A(z_d(i)) + \eta.

$$
Define per-walker fitness

$$
V_{\mathrm{fit},i} := (d_i')^{\beta_{\mathrm{fit}}}(r_i')^{\alpha_{\mathrm{fit}}}.

$$

**Canonical height functional (thin potential).**
Define the global height as a bounded negative mean fitness (up to an additive constant):

$$
\Phi(w_1,\dots,w_N) := V_{\max} - \frac{1}{N}\sum_{i=1}^N V_{\mathrm{fit},i},

$$
where $V_{\max}:=(A+\eta)^{\alpha_{\mathrm{fit}}+\beta_{\mathrm{fit}}}$ is the deterministic per-walker upper bound.
This is the default $\Phi^{\text{thin}}$ used by Fractal Gas proof objects because it makes EnergyCheck discharge
explicit and purely algebraic.

**Cloning (jitter + inelastic collision update).**
Fix cloning hyperparameters $p_{\max}>0$, $\epsilon_{\mathrm{clone}}>0$, $\sigma_x\ge 0$,
$\alpha_{\mathrm{rest}}\in[0,1]$. Given a “clone companion” $c_i$, define the score and probability

$$
S_i := \frac{V_{\mathrm{fit},c_i} - V_{\mathrm{fit},i}}{V_{\mathrm{fit},i} + \epsilon_{\mathrm{clone}}},\qquad
p_i := \min(1,\max(0,S_i/p_{\max})).

$$
Cloning decisions are Bernoulli draws with parameter $p_i$ (dead walkers clone deterministically). If $i$ clones, update
positions via Gaussian jitter

$$
z_i' = z_{c_i} + \sigma_x\zeta_i,\qquad \zeta_i\sim\mathcal{N}(0,I),

$$
and update the auxiliary “velocity-like” coordinates via a momentum-preserving inelastic collision map. For each
collision group $G$ (a companion together with all cloners to it), let

$$
V_{\mathrm{COM}} = |G|^{-1}\sum_{k\in G} v_k,\qquad u_k = v_k - V_{\mathrm{COM}},

$$
and set

$$
v_k' = V_{\mathrm{COM}} + \alpha_{\mathrm{rest}}u_k,\qquad k\in G.

$$
This conserves $\sum_{k\in G} v_k$ for each group update.

**Kinetic/mutation step (unspecified).**
After cloning, apply a user-specified kinetic/mutation operator (Definition {prf:ref}`def:fractal-gas-kinetic-operator`)
to evolve $(z,v)$; all regularity/mixing assumptions needed by later theorems are recorded as sieve permits.
:::

:::{prf:definition} Emergent Manifold (M)
:label: def:emergent-manifold-fg
:class: rigor-class-f

**Origin:** `hypostructure.md`, Ch 18 (Fractal Gas).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Status:** Definition (canonical expansion of thin geometry).

The **Emergent Manifold** is the (possibly non-smooth) continuum geometry canonically induced by the thin inputs via
the **Expansion Adjunction** (Theorem {prf:ref}`thm-expansion-adjunction`).

Concretely, apply the expansion functor $\mathcal{F}:\mathbf{Thin}_T\to\mathbf{Hypo}_T$ to the thin kernel inputs and
read off the resulting metric-measure substrate:

$$
\mathcal{F}(\mathcal{X}^{\text{thin}},\Phi^{\text{thin}},\mathfrak{D}^{\text{thin}})
\leadsto (M, g_{\text{eff}}, \mathfrak{m}_{\text{eff}}).

$$
When the expanded object admits a smooth atlas and $g_{\text{eff}}$ is nondegenerate, we may regard $(M,g_{\text{eff}})$
as an ordinary Riemannian manifold; otherwise it should be read as a metric-measure space in the sense of the
Hypopermits metric-measure upgrade.

**Capacity-constrained reading (agent map, not territory).**
In the agent-centric geometry, the effective metric is constrained by the **capacity-constrained metric law**
(Theorem {prf:ref}`thm-capacity-constrained-metric-law`) and the **Causal Information Bound**
(Theorem {prf:ref}`thm-causal-information-bound`): near saturation, $g_{\text{eff}}$ must deform so that bulk information
remains boundary-grounded.

**Diffusive proxy (special case).**
In a purely diffusive (balanced) limit where a local diffusion tensor $D$ is well-defined and elliptic, one often has
the local identification $g_{\text{eff}}\approx D^{-1}$. This is a model-specific proxy, not the definition.

**Remark:** The metric $g_{\text{eff}}$ emerges from swarm dynamics and is not imposed a priori. It reflects how the swarm "perceives" distances through its collective exploration behavior.
:::

:::{prf:definition} Anisotropic Diffusion (Stiffness-Adapted)
:label: def:anisotropic-diffusion-fg
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7).

**Status:** Definition (canonical stiffness-adapted noise).

**Statement:**
When the kinetic operator injects Gaussian noise, a canonical **stiffness-adapted** choice is to precondition that noise
by the local curvature of the fitness landscape. Concretely, define the diffusion preconditioner from the Hessian of the
fitness potential $V_{\mathrm{fit}}$ (Definition {prf:ref}`def:fractal-gas-fitness-cloning-kernel`):

$$
\Sigma_{\mathrm{reg}}(x) = \bigl(\nabla_x^2 V_{\mathrm{fit}}(x)+\epsilon_{\Sigma} I\bigr)^{-1/2},

$$
where $\epsilon_{\Sigma} > 0$ is a regularization constant. This tensor scales the driving noise
$\xi \sim \mathcal{N}(0, I)$ in any kinetic/mutation update that injects Gaussian noise (see Definition
{prf:ref}`def:fractal-gas-kinetic-operator` for a Langevin/BAOAB example).
:::

:::{prf:definition} Kinetic / Mutation Operator (Abstract)
:label: def:fractal-gas-kinetic-operator
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7).

**Status:** Definition (interface placeholder for the “transport” part of Fractal Gas).

**Statement:**
The Fractal Gas schema intentionally leaves the **kinetic/mutation operator** unspecified: it is any (possibly
state-dependent) Markov kernel on the swarm state that is composed after cloning (Definition
{prf:ref}`def:fractal-gas-fitness-cloning-kernel`).

All assumptions about this operator (regularity, noise injection/ellipticity, drift/dissipation, boundary behavior,
mixing, etc.) are not hard-coded here; they are tracked by the thin objects and discharged (or blocked) by the sieve via
the permits listed in theorems.

**Example (Langevin/BAOAB instantiation).**
One common choice is an underdamped Langevin diffusion on a smooth representation manifold, which (in flat coordinates)
takes the schematic form

$$
dx = v \, dt, \quad dv = -\gamma v \, dt - \nabla \Phi \, dt + \Sigma_{\mathrm{reg}}(x) \, dW_t

$$
where $\gamma$ is friction, $\Phi$ is the fitness potential (often disabled in viscous-only variants), and $\Sigma_{\mathrm{reg}}(x)$ is the **anisotropic diffusion tensor** (Definition {prf:ref}`def:anisotropic-diffusion-fg`) which preconditions the Wiener process $dW_t$ to align noise with the local stiffness of the landscape.
:::

### Solver Metatheorems

:::{prf:theorem} Geometric Adaptation (Metric Distortion Under Representation)
:label: thm:geometric-adaptation

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $G^{\text{thin}}$, embedding $\pi: X \to Y$.
**Permits:** $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (linear-algebraic; no solver assumptions).

**Assumptions:**
1. The algorithmic distance is computed from an embedding $\pi: X\to \mathbb{R}^n$ by

   $$
   d_{\mathrm{alg}}(x,y)=\|\pi(x)-\pi(y)\|_2

   $$
   (or any fixed Euclidean norm on the representation space).
2. Two embeddings are related by a linear map $T:\mathbb{R}^n\to\mathbb{R}^n$ via $\pi_2=T\circ \pi_1$.

**Statement:** For all $x,y\in X$,

$$
\sigma_{\min}(T)\, d_{\mathrm{alg}}^{(1)}(x,y)\ \le\ d_{\mathrm{alg}}^{(2)}(x,y)\ \le\ \|T\|\, d_{\mathrm{alg}}^{(1)}(x,y),

$$
where $\|T\|$ is the operator norm and $\sigma_{\min}(T)$ is the smallest singular value. In particular, if $T$ is invertible then $\pi_1$ and $\pi_2$ are bi-Lipschitz equivalent, and any Information Graph built from a monotone kernel of $d_{\mathrm{alg}}$ (e.g. Gaussian weights) changes only by a controlled rescaling/anisotropy of its effective neighborhood geometry.

**Remark (What “tunneling” can and cannot mean):** Changing representation can change **graph geodesics** and therefore the solver’s navigation *metric*, but it does not create new topological paths in the intrinsic space $X$; it changes the geometry used to move through $X$.
:::

:::{prf:proof}
Let $\Delta:=\pi_1(x)-\pi_1(y)\in\mathbb{R}^n$. Then $\pi_2(x)-\pi_2(y)=T\Delta$.
By definition of the operator norm and smallest singular value,

$$
\sigma_{\min}(T)\,\|\Delta\|_2\ \le\ \|T\Delta\|_2\ \le\ \|T\|\,\|\Delta\|_2.

$$
Substituting $\|\Delta\|_2=d_{\mathrm{alg}}^{(1)}(x,y)$ and $\|T\Delta\|_2=d_{\mathrm{alg}}^{(2)}(x,y)$ yields the claim.
:::

:::{prf:metatheorem} The Darwinian Ratchet (WFR Transport + Reaction)
:label: mt:darwinian-ratchet

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Imported (agent geometry; WFR dynamics and stationarity).

**Statement (algorithmic split; always).**
For any Fractal Gas instantiation using the fixed fitness/companion/cloning kernel (Definition
{prf:ref}`def:fractal-gas-fitness-cloning-kernel`), the one-step update decomposes *by construction* into:
- a **reaction/resampling** operator (selection + cloning), and
- a **transport/mutation** operator (the user-specified kinetic/mutation step).
This is the discrete-time version of “transport + reaction” and does not require any scaling limit nor a particular
choice of kinetic operator.

**Statement (WFR dynamics).**
In the WFR instantiation of Fractal Gas, the (unnormalized) particle/belief density $\rho(s,z)$ evolves in computation
time $s$ by the unbalanced continuity equation (Definition {prf:ref}`def-the-wfr-action`):

$$
\partial_s \rho + \nabla\cdot(\rho v) = \rho r,

$$
where:
- **Transport** ($v$) captures mutation/diffusion/exploration as a Wasserstein flow on the continuous coordinates, and
- **Reaction** ($r$) captures selection/cloning as Fisher–Rao mass creation/destruction.

**Statement (Value creates mass; the “ratchet”).**
The optimal reaction rate is value-driven (Theorem {prf:ref}`thm-wfr-consistency-value-creates-mass`):

$$
r(z)=\frac{1}{s_r}\bigl(V(z)-\bar V\bigr),

$$
so mass increases in regions with $V(z)>\bar V$ and decreases where $V(z)<\bar V$. This is the rigorous content of the
Darwinian “ratchet”: probability mass is forced to accumulate in high-value regions under reaction.

**Statement (stationarity).**
In the conservative case (curl-free value field) the stationary distribution is Boltzmann-type
({prf:ref}`cor-equilibrium-distribution`); in the non-conservative case there exists a non-equilibrium steady state
with persistent current (Theorem {prf:ref}`thm-ness-existence`).

**Remark (classical reversible/QSD specializations).**
If $r\equiv 0$ and the transport operator is an overdamped Langevin diffusion, this reduces to the standard reversible
Gibbs invariant measure picture. If selection/cloning is implemented via killing/respawn rather than explicit reaction,
the long-time normalized law is described by quasi-stationary distributions (see `mt:quasi-stationary-distribution-sampling`).
:::

:::{prf:proof}
The algorithmic transport+reaction split is definitional for the kernel in {prf:ref}`def:fractal-gas-fitness-cloning-kernel`.
The continuum WFR equation and the value-determined reaction rate are imported statements (Definition
{prf:ref}`def-the-wfr-action`, Theorem {prf:ref}`thm-wfr-consistency-value-creates-mass`), which apply when a chosen
instantiation admits the corresponding continuum/scaling interpretation.
:::

:::{prf:principle} Coherence Phase Transition
:label: prin:coherence-transition

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1), $\mathrm{SC}_\lambda$ (N4).

**Status:** Heuristic-to-conditional (requires a specified continuum scaling; not a sieve-level metatheorem).

**Assumptions (for a conditional reading):**
1. A viscous mixing length $l_\nu$ is well-defined for the chosen kinetic/viscous operator over one macroscopic step, and scales as $l_\nu\sim \sqrt{\nu\,\Delta t}$ in the regime of interest.
2. A cloning/jitter correlation length $l_{\mathrm{clone}}$ is well-defined and scales as $l_{\mathrm{clone}}\sim \sigma_x$ (clone position jitter).
3. The coherence observable below is self-averaging as $N\to\infty$ (law of large numbers regime).

**Statement:** The internal coherence of the swarm is controlled by the ratio of the viscous mixing scale to the cloning correlation scale. A convenient (dimensionless) coherence observable is

$$
\bar v := \frac{1}{N}\sum_{i=1}^N v_i,\qquad
\Psi_{\mathrm{coh}} := \frac{\|\bar v\|^2}{\frac{1}{N}\sum_{i=1}^N \|v_i\|^2}\ \in[0,1],

$$
where $v_i$ are the particle velocities (or generalized “update directions” if no explicit velocities exist). Heuristically:
- **Gas:** $l_\nu \ll l_{\mathrm{clone}}$ (weak viscous synchronization) $\Rightarrow$ $\Psi_{\mathrm{coh}}\approx 0$.
- **Solid:** $l_\nu \gg l_{\mathrm{clone}}$ (strong viscous synchronization) $\Rightarrow$ $\Psi_{\mathrm{coh}}\approx 1$.
- **Liquid:** intermediate regime with partial coherence.

A phase transition (or crossover) is expected when $l_\nu$ and $l_{\mathrm{clone}}$ are comparable.
:::

:::{prf:proof}
**Step 1 (Order Parameter).**
Define $\Psi_{\mathrm{coh}}$ as the ratio “mean velocity energy / mean kinetic energy”. By Cauchy–Schwarz,
$\|\bar v\|^2 \le \frac{1}{N}\sum_i \|v_i\|^2$, hence $\Psi_{\mathrm{coh}}\in[0,1]$.
If the velocities are i.i.d. with mean $0$ (incoherent), $\|\bar v\|^2$ is small and $\Psi_{\mathrm{coh}}\approx 0$.
If the velocities are nearly identical (coherent motion), $\Psi_{\mathrm{coh}}\approx 1$.

**Step 2 (Competition of Scales).**
The dynamics are governed by two length scales:
- **Viscous Length $l_\nu$:** The distance over which momentum diffuses in time $\Delta t$. $l_\nu \sim \sqrt{\nu \Delta t}$.
- **Cloning Length $l_{\mathrm{clone}}$:** The mean separation between a parent and its clone (determined by position jitter). $l_{\mathrm{clone}} \sim \sigma_x$.

**Step 3 (Criticality).**
When $l_\nu \gg l_{\mathrm{clone}}$, viscous mixing synchronizes the swarm faster than cloning decorrelates it, leading to coherent motion.
When $l_\nu \ll l_{\mathrm{clone}}$, cloning decorrelates the swarm faster than viscosity can synchronize it, leading to incoherent motion.
A crossover is expected when $l_\nu/l_{\mathrm{clone}}$ is $O(1)$; extracting a sharp critical exponent requires a specific scaling limit and is not asserted here.
:::

:::{prf:theorem} Topological Regularization (Cheeger Bound, Conditional)
:label: thm:cheeger-bound

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6), $\mathrm{TB}_\pi$ (N8).

**Status:** Conditional (graph/Markov-chain mixing; not implied by viscosity alone).

**Assumption (uniform minorization / Doeblin condition):** The Information Graph induces a reversible Markov kernel $P_t$
on vertices with stationary law $\pi_t$, and there exist $\delta\in(0,1]$ and a probability measure $\nu_t$ such that for
all times $t$ and all vertices $i$,

$$
P_t(i,\cdot)\ \ge\ \delta\,\nu_t(\cdot).

$$

**Statement:** Under this assumption, the chain has a uniform spectral gap $\lambda_1(P_t)\ge \delta$ and the Cheeger (conductance) constant is uniformly bounded below:

$$
h(G_t)\ \ge\ \frac{\lambda_1(P_t)}{2}\ \ge\ \frac{\delta}{2}\ >\ 0.

$$
In particular the graph stays connected and does not “pinch off”.

**FG-kernel discharge (default companion selection).**
For the soft companion selection kernel used by the Fractal Gas kernel (Definition {prf:ref}`def:fractal-gas-fitness-cloning-kernel`),
a Doeblin floor is explicit on any alive core with bounded algorithmic diameter $D_{\mathrm{alg}}$: with

$$
m_\epsilon := \exp\!\left(-\frac{D_{\mathrm{alg}}^2}{2\epsilon^2}\right),

$$
the induced one-step companion kernel has an explicit **off-diagonal** floor on the $|\mathcal{A}|\ge 2$ slice:

$$
P(c_i=j)\ \ge\ \frac{m_\epsilon}{|\mathcal{A}|-1}\qquad (j\neq i).

$$
Because the softmax kernel excludes self-pairs for alive walkers, the strict one-step Doeblin form
$P(i,\cdot)\ge \delta\,\nu(\cdot)$ may fail as stated (it would force $P(i,i)>0$ whenever $\nu(i)>0$). In such cases one
applies the theorem to a **lazified** kernel or to a fixed power $P^m$ (typically $m=2$), which inherits an explicit
Doeblin minorization from the off-diagonal floor above. In particular, Fractal Gas proof objects typically discharge the
mixing/minorization hypothesis directly from bounded diameter, independent of any kinetic details.
:::

:::{prf:proof}
Under the Doeblin condition, $P_t$ is a strict contraction in total variation with coefficient at most $1-\delta$ (Dobrushin’s argument), implying geometric ergodicity and a spectral gap bounded below by $\delta$.
For reversible chains, the (reverse) Cheeger inequality gives $h\ge \lambda_1/2$. Combining yields $h\ge \delta/2$.
:::

:::{prf:principle} Induced Local Geometry (Quadratic Form from Landscape + Graph Energy)
:label: thm:induced-riemannian-structure

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (becomes rigorous under uniform positive-definiteness).

**Statement:** On a compact “alive” slice where $\Phi$ and $\mathfrak{D}$ are $C^2$, the Fractal/Information-Graph constructions canonically define a **positive semidefinite quadratic form** on perturbations $\delta z$ of the swarm state that combines:
- local curvature of the landscape (via Hessians of $\Phi$ and $\mathfrak{D}$), and
- discrete Dirichlet energy from the Information Graph (via its Laplacian).

When this quadratic form is uniformly positive definite on the tangent space (e.g. near nondegenerate minima or under uniform ellipticity hypotheses), it defines a genuine Riemannian metric; otherwise it defines a sub-Riemannian/degenerate geometry.

**Do not read this as a literal tensor identity** “$g=\nabla^2\Phi+\nu L$”: Hessians and graph Laplacians live on different objects and only combine meaningfully after a concrete discretization choice (finite-dimensional tangent space, chosen coordinates, and a graph energy functional).
:::

:::{prf:proof}
This block is a design principle: a Taylor expansion of a smooth energy landscape produces Hessian quadratic forms, while graph-based "kinetic" regularization produces Dirichlet energies of the form $\sum_{i,j} w_{ij}\|\delta z_i-\delta z_j\|^2$, whose Euler–Lagrange operator is a graph Laplacian. Under uniform positive-definiteness, such quadratic forms define an inner product and therefore a Riemannian metric.
:::

(sec-fractal-set-reconstruction)=

## Fractal Set, CST/IG Reconstruction, and Convergence

:::{prf:principle} Geometric Reconstruction
:label: prin:geometric-reconstruction
:class: rigor-class-f

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{SC}_\lambda$ (N4), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6), $\mathrm{Rep}_K$ (N11).

**Rigor Class:** F (Framework-Original) — see {prf:ref}`def-rigor-classification`

**Status:** Framework (canonical continuum via Expansion Adjunction) + optional classical identification.

**Statement (framework reading; no graph-limit assumption).**
Given a thin Fractal/IG presentation at a fixed scale (a weighted graph inside $\mathcal{X}^{\text{thin}}$ with its
fitness/dissipation data), the **Expansion Adjunction** (Theorem {prf:ref}`thm-expansion-adjunction`) provides a
canonical promoted continuum object

$$
\mathcal{F}(\text{thin data}) \leadsto (M, g_{\text{eff}}, \mathfrak{m}_{\text{eff}})

$$
together with its intrinsic Dirichlet-form / heat-flow structure (Cheeger energy on the promoted metric-measure space).
In this reading, “the continuum limit” is not a separate convergence hypothesis: it is the universal continuum object
generated by the thin data.

**Statement (classical identification; Bridge Verification).**
To read the promoted object in an ordinary set-based foundation, apply the ZFC bridge
(Metatheorem {prf:ref}`mt-krnl-zfc-bridge`). If the thin graphs satisfy a stiffness certificate that lifts (e.g. LSI via
the thin spectral gap protocol, Theorem {prf:ref}`thm-lsi-thin-permit`), then a standard Bridge Verification can embed
the promoted object into classical metric-measure classes (e.g. RCD$(K,N)$ spaces as used in
{prf:ref}`thm-lsi-thin-permit`). Under additional manifold-learning hypotheses (reach, sampling density, kernel scaling),
one recovers the familiar manifold-learning conclusions: IG shortest-path distances approximate geodesic distances and
the rescaled graph Laplacian approximates the Laplace–Beltrami operator.
:::

:::{prf:proof}
*Step 1 (Canonical promotion).* Apply Theorem {prf:ref}`thm-expansion-adjunction` to promote the thin kernel data to a
Hypostructure, whose metric-measure substrate defines the continuum object $(M,g_{\text{eff}},\mathfrak{m}_{\text{eff}})$.

*Step 2 (Bridge to set-based semantics).* Apply Metatheorem {prf:ref}`mt-krnl-zfc-bridge` to interpret the promoted
object as a classical metric-measure space when desired.

*Step 3 (Stiffness lifting; a typical bridge input).* Under the stiffness permit $\mathrm{LS}_\sigma$, apply the thin
spectral-gap-to-LSI lifting protocol (Theorem {prf:ref}`thm-lsi-thin-permit`) to obtain a functional-inequality
certificate on the promoted continuum object (via the Bridge Verification recorded in that theorem).

*Step 4 (Optional identification with smooth manifolds).* If, in addition, the promoted object is known (by separate
regularity inputs) to lie in a smooth manifold regime, then standard manifold-learning/Dirichlet-form convergence
results identify the promoted Dirichlet form with the Laplace–Beltrami operator and yield the usual diffusion-maps /
heat-kernel reconstructions.

*Step 5 (Curvature proxies).* Discrete curvature notions remain diagnostic: their stability and interpretation depend on
the specific bridge/limit notion chosen (GH/RCD/Mosco) and on the sampling regime.
:::

:::{prf:theorem} Causal Horizon Lock (Causal Information Bound + Stasis)
:label: thm:causal-horizon-lock

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1), $\mathrm{SC}_\lambda$ (N4), $\mathrm{Cap}_H$ (N6), $\mathrm{TB}_\pi$ (N8).

**Status:** Imported (agent geometry; rigorous area law + freezing criterion).

**Statement (area law).**
For the promoted latent geometry $(M,g_{\mathrm{eff}})$, the maximum grounded bulk information is bounded by boundary
area in Levin-length units (Theorem {prf:ref}`thm-causal-information-bound`), with the Poincaré-disk normalization
recovering the familiar $1/4$ coefficient (Theorem {prf:ref}`thm-a-complete-derivation-area-law`):

$$
I_{\max}\;=\;\nu_D\cdot\frac{\mathrm{Area}(\partial M)}{\ell_L^{D-1}}
\qquad\text{(and for $D=2$: }I_{\max}=\mathrm{Area}(\partial M)/(4\ell_L^2)\text{).}

$$

**Statement (horizon lock / stasis).**
As $I_{\mathrm{bulk}}\to I_{\max}$, the effective metric develops a “horizon” (a diverging radial component) and the
internal update velocity vanishes: $\|v\|_{g_{\mathrm{eff}}}\to 0$ (Theorem {prf:ref}`thm-causal-stasis`). This is the
rigorous content of the “horizon lock”: once capacity saturates, dynamics must freeze unless the agent performs a
structural intervention (reduce $I_{\mathrm{bulk}}$ or increase boundary capacity).

**Discrete proxy (optional).**
For an IG implemented as a per-edge bounded channel, cut-capacity bounds are a discrete proxy for boundary area
($\sum_{e\in\partial\Sigma}C_e$), but they are not the fundamental statement; the fundamental statement is the
metric-law-derived causal bound above.
:::

:::{prf:proof}
The area law is Theorem {prf:ref}`thm-causal-information-bound`, with the explicit $D=2$ normalization derived in
Theorem {prf:ref}`thm-a-complete-derivation-area-law`. Causal freezing at saturation is Theorem {prf:ref}`thm-causal-stasis`.
:::

:::{prf:principle} Scutoid Selection Principle (Heuristic Geometry)
:label: thm:scutoid-selection

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1), $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic.

**Statement:** In 3D swarm dynamics with local neighbor exchange (cloning + companion reassignment), the induced Voronoi/Delaunay adjacency can undergo T1-like transitions. In some geometries this produces scutoid-like cell shapes. This provides a geometric analogy for “topological regularization,” but it is not asserted here as a variational minimization theorem (e.g. no claim is made that a Regge action is minimized by the algorithm).
:::

:::{prf:proof}
This block is intentionally non-rigorous: it records a geometric interpretation (neighbor exchanges can induce scutoid-like adjacency changes) without claiming a precise variational principle.
:::

:::{prf:theorem} Archive Invariance (Gromov–Hausdorff Stability, Conditional)
:label: thm:archive-invariance

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6).

**Status:** Conditional (metric-space convergence; “quasi-isometry” is not the right notion on compact spaces).

**Assumption (common compact limit):** There exists a compact metric space $(M,d)$ and scales $\varepsilon_k\downarrow 0$ such that

$$
d_{\mathrm{GH}}(\mathcal{F}_1,M)\le \varepsilon_1,\qquad d_{\mathrm{GH}}(\mathcal{F}_2,M)\le \varepsilon_2.

$$

**Statement:** Then

$$
d_{\mathrm{GH}}(\mathcal{F}_1,\mathcal{F}_2)\ \le\ \varepsilon_1+\varepsilon_2,

$$
and there exists an $(\varepsilon_1+\varepsilon_2)$-approximation map between the two archives (an $\varepsilon$-isometry in the standard GH sense). Consequently, any **stable** geometric invariant (e.g. persistent homology at scales $\gg \varepsilon_1+\varepsilon_2$) agrees between the two runs.
:::

:::{prf:proof}
The GH triangle inequality yields the bound on $d_{\mathrm{GH}}(\mathcal{F}_1,\mathcal{F}_2)$. The existence of an $\varepsilon$-approximation map is part of the definition of GH distance.
:::

### Fractal Set Foundations (Discrete-to-Continuum)

:::{prf:definition} Fractal Set ($\mathcal{F}$)
:label: def:fractal-set

**Origin:** `hypostructure.md`, Ch 19 (Fractal Set Foundations).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $G^{\text{thin}}$.

**Status:** Definition.

A **Fractal Set** is a tuple $\mathcal{F} = (V, \text{CST}, \text{IG}, \Phi_V, w, \mathcal{L})$:
- **$V$:** Vertex set (swarm snapshots/events)
- **CST:** Causal Spacetime Tree (Temporal Precedence $\prec$)
- **IG:** Information Graph (Spatial Adjacency)
- **Fitness:** $\Phi_V: V \to \mathbb{R}_{\geq 0}$
- **Weights:** $w: E \to \mathbb{R}_{>0}$ (edge weights)
- **Labels:** $\mathcal{L}$ (Topological types, Gauge labels)

**Remark:** The CST encodes the genealogy (which states came from which), while the IG encodes spatial/informational proximity at each time slice. Together they form a discrete spacetime structure.
:::

:::{prf:definition} Minimizing Movement Scheme
:label: def:minimizing-movement

**Origin:** `hypostructure.md`, Ch 19 (Fractal Set Foundations).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $C_\mu$ (N3).

**Status:** Definition.

The **Minimizing Movement** scheme approximates gradient flow via recursive variational optimization:

$$ x_{n+1}^\tau \in \arg\min_{x} \left\{ \Phi(x) + \frac{d(x, x_n^\tau)^2}{2\tau} \right\} $$
This provides a variational interpretation of the discrete time-stepping.

**Remark:** The scheme balances two objectives: minimizing the potential $\Phi$ and staying close to the previous iterate. The parameter $\tau$ controls the trade-off between exploitation (following $\nabla\Phi$) and stability (small steps).
:::

:::{prf:metatheorem} Fractal Representation
:label: mt:fractal-representation

**Thin inputs:** all thin objects.
**Permits:** $C_\mu$, $D_E$, $\mathrm{SC}_\lambda$, $\mathrm{Cap}_H$, $\mathrm{Rep}_K$, $\mathrm{TB}_\pi$.

**Status:** Conditional (inverse-limit construction with an explicit Cauchy-thread embedding).

**Assumptions (one concrete setting):**
1. (**Projective system**) A compatible projective system of vertex sets $(V_n,\phi_{nm})$ is specified, where
   $V_n:=V(G_n)$ is a finite discrete set (hence compact Hausdorff) and the bonding maps satisfy
   $\phi_{nn}=\mathrm{id}$ and $\phi_{n\ell}=\phi_{nm}\circ\phi_{m\ell}$ for $n\le m\le \ell$.
2. (**Embedding control**) $(X,d)$ is complete and there exist maps $\iota_n:V_n\to X$ and a scale error sequence
   $\varepsilon_n\downarrow 0$ such that for all $m\ge n$ and all $x_m\in V_m$,

   $$
   d\bigl(\iota_n(\phi_{nm}(x_m)),\ \iota_m(x_m)\bigr)\ \le\ \varepsilon_n.

   $$

**Statement:** Define the Fractal Set as the inverse limit

$$
\mathcal{F}\ :=\ \varprojlim (V_n,\phi_{nm})
\;=\;
\left\{(x_n)_{n\ge 1}\in \prod_{n\ge 1} V_n:\ \phi_{nm}(x_m)=x_n\ \forall m\ge n\right\}.

$$
Then $\mathcal{F}$ is compact (and totally disconnected when each $V_n$ is discrete), and the representation map

$$
\Pi:\mathcal{F}\to X,\qquad \Pi((x_n)):=\lim_{n\to\infty}\iota_n(x_n)

$$
is well-defined. Any further claims about mapping discrete time dynamics (CST shift operators, solver updates) into
trajectories in $X$ require an additional hypothesis: a compatible family of evolution maps on the projective system.
:::

:::{prf:proof}
*Step 1 (Existence and compactness).* Each $V_n$ is compact Hausdorff and $\prod_n V_n$ is compact by Tychonoff. The
inverse limit $\mathcal{F}$ is the closed subset cut out by the compatibility equalities $\phi_{nm}(x_m)=x_n$, hence
compact. If each $V_n$ is discrete, $\mathcal{F}$ is totally disconnected.

*Step 2 (Cauchy-thread limit).* Let $(x_n)\in\mathcal{F}$ and fix $m\ge n$. Since $\phi_{nm}(x_m)=x_n$, the embedding
control assumption gives

$$
d\bigl(\iota_n(x_n),\iota_m(x_m)\bigr)
\;=\;
d\bigl(\iota_n(\phi_{nm}(x_m)),\iota_m(x_m)\bigr)
\;\le\;
\varepsilon_n.

$$
As $\varepsilon_n\downarrow 0$, $(\iota_n(x_n))$ is Cauchy and converges in the complete space $X$, defining
$\Pi((x_n))$.

*Step 3 (Optional dynamics).* If a compatible family of time-evolution maps $S_t^{(n)}:V_n\to V_n$ exists with
$\phi_{nm}\circ S_t^{(m)} = S_t^{(n)}\circ \phi_{nm}$, then the induced map $S_t:\mathcal{F}\to\mathcal{F}$ is defined
componentwise and can be pushed forward by $\Pi$; this is not asserted without that extra hypothesis.
:::

:::{prf:theorem} Fitness Convergence via Gamma-Convergence
:label: thm:fitness-convergence

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Conditional (standard $\Gamma$-convergence; requires an identification of discrete states with continuum states).

**Assumptions (one typical setting):**
1. There is an identification/embedding map $\iota_\varepsilon:\mathcal{F}_\varepsilon\to X$ so that sequences $(x_\varepsilon\in\mathcal{F}_\varepsilon)$ can be compared via $\iota_\varepsilon(x_\varepsilon)\to x$ in $X$.
2. The family $\{\Phi_\varepsilon\}$ is **equicoercive** with respect to this identification (sublevel sets are precompact).
3. The $\Gamma$-liminf and $\Gamma$-limsup inequalities hold with respect to $\iota_\varepsilon$.

**Statement:** Under these assumptions, the discrete functionals $\Phi_\varepsilon$ $\Gamma$-converge to $\Phi$ (in the sense above). Consequently, almost-minimizers of $\Phi_\varepsilon$ have accumulation points that minimize $\Phi$ (and minimizing values converge).
:::

:::{prf:proof}
This is the standard $\Gamma$-convergence implication:
- the liminf and limsup inequalities are the definition of $\Gamma$-convergence (relative to $\iota_\varepsilon$), and
- equicoercivity upgrades $\Gamma$-convergence to convergence of (almost-)minimizers.

The nontrivial content in applications is to verify (i) the approximation map $\iota_\varepsilon$ and (ii) the liminf/limsup bounds from the concrete discrete energy definition.
:::

:::{prf:theorem} Gromov-Hausdorff Convergence
:label: thm:gromov-hausdorff-convergence

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (standard geometric-graph convergence results; requires sampling and scaling hypotheses).

**Assumptions (one typical setting):**
1. $(M,d_g)$ is a compact Riemannian manifold.
2. The vertex set $V_\varepsilon\subset M$ is an $\varepsilon$-net (Hausdorff distance $\le \varepsilon$).
3. The graph edges/weights are constructed from a kernel or neighborhood radius $r_\varepsilon\to 0$ in a regime that makes shortest-path distances approximate $d_g$ (e.g. dense enough to avoid “short-circuiting” and connected enough to avoid fragmentation).

**Statement:** Under such hypotheses, the metric spaces $(V_\varepsilon,d_{\mathrm{IG}}^\varepsilon)$ converge to $(M,d_g)$ in the Gromov–Hausdorff sense:

$$
(V_\varepsilon, d_{\mathrm{IG}}^\varepsilon)\xrightarrow{\mathrm{GH}} (M, d_g).

$$
:::

:::{prf:proof}
Given an $\varepsilon$-net, the natural correspondence is $(v,x)$ with $x=v\in M$. The net property controls the Hausdorff part of GH distance. The nontrivial part is to bound the distortion of shortest-path distances by comparing graph paths to manifold geodesics and vice versa; this is where the edge radius/kernel scaling hypotheses enter.
:::

:::{prf:metatheorem} Convergence of Minimizing Movements
:label: mt:convergence-minimizing-movements

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7).

**Status:** Conditional (standard minimizing-movements theory).

**Assumptions:** $(X,d)$ is a complete metric space and $\Phi:X\to(-\infty,\infty]$ is proper, lower semicontinuous, and (geodesically) $\lambda$-convex for some $\lambda\in\mathbb{R}$ (or satisfies an alternative slope-compactness condition ensuring well-posed gradient flows).

**Statement:** The discrete “minimizing movement” scheme

$$x_{k+1} \in \mathrm{argmin}_y \left( \Phi(y) + \frac{1}{2\tau} d^2(x_k, y) \right)$$
converges (as $\tau\to 0$) to the unique curve of maximal slope (metric gradient flow) for $\Phi$. Under the standard hypotheses above, the limit satisfies the Energy–Dissipation Inequality, and under additional regularity it satisfies the Energy–Dissipation Equality.
:::

:::{prf:proof}
**Step 1 (Discrete Variational Problem).**
The update rule is implicit Euler discretization of gradient descent. It balances minimizing potential $\Phi$ with minimizing transport cost $d^2$.

**Step 2 (De Giorgi Interpolation).**
Construct a continuous trajectory $\tilde{x}_\tau(t)$ by interpolating the discrete points.
We check if the limit satisfies the weak formulation of the gradient flow.

This is a classical result of Ambrosio–Gigli–Savaré: under the stated hypotheses, the interpolated discrete solutions are precompact and any limit is the gradient flow of $\Phi$.
:::

:::{prf:metatheorem} Symplectic Shadowing
:label: mt:symplectic-shadowing

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{GC}_\nabla$ (N12), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (backward error analysis for symplectic integrators).

**Statement:** For sufficiently smooth (often analytic) Hamiltonians and sufficiently small step size $h$, a symplectic splitting scheme is the exact time-$h$ map of a **modified Hamiltonian**

$$
\tilde H = H + h H_1 + h^2 H_2 + \cdots

$$
up to a truncation error. As a consequence, the numerical energy error typically remains bounded and oscillatory over long times; in analytic settings one can obtain exponentially long stability times in $1/h$.
:::

:::{prf:proof}
**Step 1 (Baker-Campbell-Hausdorff).**
The splitting method (Lie-Trotter) approximates $e^{h(A+B)}$ by $e^{hA} e^{hB}$. The BCH formula gives $e^{hA} e^{hB} = e^{Z(h)}$ where $Z(h) = h(A+B) + \frac{h^2}{2}[A,B] + \dots$.
Identifying $A$ and $B$ with Liouville operators for kinetic and potential parts, the flow generated by $Z(h)$ is the exact flow of a perturbed Hamiltonian.

**Step 2 (Modified Hamiltonian).**
We explicitly construct the formal power series for $\tilde{H}$. Since the integrator is symplectic, such a Hamiltonian exists (locally).

**Step 3 (Energy Bound).**
Backward error analysis controls the difference between the numerical map and the modified Hamiltonian flow; bounded long-time energy error follows from conservation of $\tilde H$ for the modified flow and the smallness of $H-\tilde H$ at the chosen truncation order.
:::

:::{prf:metatheorem} Homological Reconstruction
:label: mt:homological-reconstruction

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (computational topology; requires reach + sampling hypotheses).

**Statement (standard recovery pattern):** Let $M\subset \mathbb{R}^D$ be a compact $C^2$ submanifold with reach $\tau>0$, and let $P\subset M$ be an $\varepsilon$-sample (Hausdorff distance $\le\varepsilon$) with $\varepsilon<\tau/2$.
Then:
1. The union of balls $U_\varepsilon=\bigcup_{p\in P} B_\varepsilon(p)$ deformation retracts to $M$.
2. The Čech complex $\check C_\varepsilon(P)$ is homotopy equivalent to $U_\varepsilon$ (Nerve Lemma), hence $\check C_\varepsilon(P)\simeq M$.
3. The Vietoris–Rips and Čech filtrations are interleaved (up to a scale factor), so persistent homology of $\mathrm{VR}_r(P)$ recovers $H_\ast(M)$ at appropriate scales.

This is the rigorous content behind using IG samples to infer topological invariants: topology recovery requires **geometric sampling conditions**, not just an algorithmic run.
:::

:::{prf:proof}
Items (1)–(2) follow from the Niyogi–Smale–Weinberger theorem and the Nerve Lemma. Item (3) is the standard Čech–Vietoris–Rips interleaving: $\check C_r(P)\subseteq \mathrm{VR}_{2r}(P)\subseteq \check C_{2r}(P)$ (in Euclidean ambient space), which yields homology recovery in the persistent sense.
:::

:::{prf:metatheorem} Symmetry Completion
:label: mt:symmetry-completion

**Thin inputs:** $G^{\text{thin}}$.
**Permits:** $\mathrm{GC}_\nabla$ (N12), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (bundle/Noether inputs are standard under explicit hypotheses; “full hypostructure determination” is interpretive).

**Statement:** Given a specified symmetry group $G$ acting on local internal states and a compatible family of transition functions satisfying the cocycle condition on overlaps, the local gauge data determine (up to isomorphism) a principal $G$-bundle with a connection. If, in addition, the (continuum-limit) dynamics admit a $G$-invariant Lagrangian/Hamiltonian, Noether’s theorem yields conserved quantities/constraints. These constrain admissible hypostructure instantiations but do not by themselves uniquely determine all thin/thick objects.
:::

:::{prf:proof}
**Step 1 (Local Gauge).**
At each node $i$, the "internal state" transforms under a group $G$. Interactions are invariant under global rotation $g \in G$.

**Step 2 (Holonomy).**
Parallel transport around loops defines the holonomy group. If the curvature vanishes (flat connection), global symmetry is preserved. If not, we have a Gauge Theory.

**Step 3 (Reconstruction).**
Given transition functions satisfying the cocycle condition, they define a principal $G$-bundle; a choice of connection encodes parallel transport. If the dynamics are required to be globally gauge-covariant, observables/equations must be compatible with this bundle data. This constrains admissible global models, but does not by itself determine a unique “physics”.
:::

:::{prf:metatheorem} Gauge-Geometry Correspondence
:label: mt:gauge-geometry-correspondence

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{GC}_\nabla$ (N12), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (lattice-gauge correspondence is conditional once a gauge field is specified; “spacetime geometry emerges” is interpretive).

**Statement:** If the Information Graph is endowed with group-valued edge variables $U_{ij}\in G$ interpreted as parallel transports, then holonomies around loops encode a discrete curvature (Wilson loops / plaquette holonomy) and in suitable continuum limits recover the field-strength tensor.

$$ F_{\mu\nu} \leftrightarrow \text{Hol}(\text{plaquette}) $$
Interpreting the same data as a unified “geometry + forces” object is heuristic beyond this lattice-gauge correspondence.
:::

:::{prf:proof}
**Step 1 (Lattice Gauge Theory).**
Interpret the graph as a lattice. Link variables $U_{ij}$ are parallel transport operators.
The Wilson loop around a face (plaquette) $P_{ijkl} = U_{ij}U_{jk}U_{kl}U_{li}$ measures the flux through the face.

**Step 2 (Continuum Limit).**
For smooth fields $A_\mu$, $U_{ij} \approx e^{i \int A \cdot dx}$. The Wilson loop is $e^{i \oint A \cdot dx} \approx e^{i F_{\mu\nu} \Delta x \Delta y}$.
Thus, the discrete loop product corresponds to the field strength tensor $F_{\mu\nu}$.

**Step 3 (Unified Geometry).**
Kaluza–Klein identifies gauge fields with metric components in an enlarged spacetime. No such identification is implied
by the lattice-gauge correspondence above: a graph can carry both metric weights and group-valued parallel transports
without there being a canonical “geometry + forces” unification. Any Kaluza–Klein-style unification requires specifying
an explicit higher-dimensional geometric model and a reduction ansatz; this sketch does not assert that step.
:::

:::{prf:metatheorem} Emergent Continuum
:label: mt:emergent-continuum

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{Cap}_H$ (N6), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (Dirichlet-form / graph-Laplacian convergence under explicit sampling/weighting hypotheses).

**Assumptions (typical manifold setting):**
1. The graphs are built from $\varepsilon_N$-samples of a compact $C^2$ Riemannian manifold $(M,g)$ with $\varepsilon_N\downarrow 0$, using a kernel-based weight scheme with bandwidth shrinking at an admissible rate.
2. The associated graph Dirichlet forms Mosco-converge to the Dirichlet form of Brownian motion on $(M,g)$.
3. (Optional stiffness input) If a functional-inequality conclusion is desired (Poincaré/LSI), the corresponding
   discrete constants are uniformly bounded in $N$ and the property is stable under the chosen convergence notion (as
   in the thin stiffness lifting protocol {prf:ref}`thm-lsi-thin-permit`).

**Statement:** With spectral gap and Laplacian convergence on the Information Graph, the rescaled graph Laplacian converges to the Laplace-Beltrami operator $\Delta_g$ on the emergent manifold. The random walk converges to Brownian motion on $(M, g)$.
:::

:::{prf:proof}
**Step 1 (Mosco Convergence).**
We prove Mosco convergence of the energy forms $\mathcal{E}_N \xrightarrow{M} \mathcal{E}$.
This requires two conditions:
1.  **Limsup:** For every $u \in H^1(M)$, there exists a sequence $u_N$ in the graph such that $\mathcal{E}_N(u_N) \to \mathcal{E}(u)$.
2.  **Liminf:** For every sequence $u_N$ converging to $u$, $\liminf \mathcal{E}_N(u_N) \geq \mathcal{E}(u)$.

**Step 2 (Semigroup Convergence).**
Mosco convergence implies strong convergence of the generated semigroups $P_t^N \to P_t$.
$P_t^N = e^{t L_N}$ is the random walk diffusion.
$P_t = e^{t \Delta_g}$ is heat diffusion on the manifold.

**Step 3 (Structure Preservation).**
Mosco convergence yields convergence of the associated resolvents/semigroups and (under standard compactness
hypotheses) spectral convergence of eigenvalues. Inheritance of functional inequalities such as Poincaré/LSI is **not**
automatic from Mosco convergence alone; it requires uniform inequality constants and stability in the relevant
category. When stiffness is tracked via permits, this is handled separately (e.g. Theorem {prf:ref}`thm-lsi-thin-permit`).
:::

:::{prf:metatheorem} Dimension Selection
:label: mt:dimension-selection

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (dimension notions are standard; any “selection” claim is interpretive without a specified sampling/update model).

**Statement:** When the IG sequence admits a scaling limit with well-defined Hausdorff and walk dimensions $(d_H,d_w)$, the spectral dimension $d_s=2d_H/d_w$ controls long-time diffusion scaling. The “dimension selection” interpretation refers to solver dynamics/sampling biasing the observed scaling exponents toward regimes where these dimensions appear stable across scales; it is not asserted as a universal theorem that the algorithm forces a particular dimension in all problems.
:::

:::{prf:proof}
**Step 1 (Definitions).**
$d_H$ (Hausdorff dimension), $d_w$ (walk dimension), and $d_s$ (spectral dimension) are standard scaling exponents for
metric-measure diffusion processes when the relevant limits exist.

**Step 2 (Einstein relation; conditional).**
In many self-similar/fractal diffusion settings with sub-Gaussian heat-kernel bounds (or resistance-form structure), one
has the relation $d_s = 2d_H/d_w$. This is not an identity that holds for arbitrary graphs; it is a regime statement
conditional on the chosen class of spaces and the existence of the scaling limits.

**Step 3 (Selection interpretation; heuristic).**
The additional claim that the solver “selects” dimensions (i.e. biases the observed exponents toward stable
universality regimes) is an interpretation about sampling/update bias. Making it rigorous requires specifying the
algorithmic update rule and proving a law of large numbers/limit theorem for the induced IG sequence.
:::

:::{prf:metatheorem} Discrete Curvature-Stiffness Transfer
:label: mt:curvature-stiffness-transfer

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (discrete curvature ⇒ functional inequalities is conditional; transfer to the continuum requires stability under the chosen convergence notion).

**Statement:** In graph settings, uniform lower bounds on an appropriate discrete curvature notion (e.g. Bakry–Émery curvature-dimension, or Ollivier-Ricci under additional regularity) imply functional inequalities such as a Poincaré inequality / spectral gap for the graph Laplacian. If, additionally, the graph sequence converges to a metric-measure limit and the curvature/Dirichlet-form bounds are stable under this convergence, the limiting space inherits the corresponding inequality (and in RCD-type settings can be interpreted as a lower Ricci-curvature bound).
:::

:::{prf:proof}
**Step 1 (Ollivier-Ricci Curvature).**
Defined by transport distance contraction:

$$ \kappa(x,y) = 1 - \frac{W_1(m_x, m_y)}{d(x,y)} $$
where $m_x, m_y$ are local neighborhoods (measures). Positive $\kappa$ means balls are closer "on average" than their centers (convergence).

**Step 2 (Bakry-Emery Condition).**
For $\Gamma$-calculus/Bakry–Émery curvature on graphs, $CD(K,\infty)$ is a checkable hypothesis implying Poincaré/log-Sobolev inequalities. For Ollivier-Ricci curvature, positive lower bounds imply certain Wasserstein contraction properties and can yield spectral-gap bounds under additional assumptions; in this sketch we treat the implication “curvature $\Rightarrow$ stiffness” as conditional on the chosen curvature notion and regularity regime. Stability under convergence is likewise conditional (e.g. Mosco convergence of Dirichlet forms and stability of the curvature-dimension condition in the relevant category, such as RCD limits).

**Step 3 (Stiffness).**
By the Lichnerowicz theorem (extended to metric measure spaces), $CD(K, \infty)$ with $K > 0$ implies a spectral gap $\lambda_1 \geq K$. This is exactly the **Stiffness** (Axiom LS) property required for exponential convergence.
:::

:::{prf:metatheorem} Dobrushin-Shlosman Interference Barrier
:label: mt:dobrushin-shlosman

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{TB}_\rho$ (N10).

**Status:** Conditional (standard decay-of-correlations under a uniqueness regime; permits treated as hypotheses).

**Assumptions:** The induced Gibbs/Markov specification lies in a Dobrushin uniqueness (or high-temperature / strong-convexity) regime so that influence coefficients are summable and correlation length is finite.

**Statement:** Local mixing (`Stiffness`) and spectral gap prevent long-range interference. Stochastic dependencies decay exponentially with distance.

$$ \mathrm{Cov}(f(x), g(y)) \leq C e^{-d(x,y)/\xi} $$
This blocks oscillatory failures ("Goldstone modes") and ensures stability.
:::

:::{prf:proof}
**Step 1 (Dobrushin Uniqueness Condition).**
In a spin system (or particle gas), if the interaction between a site and its neighbors is weak enough (high temperature or strong external field/stiffness), the Gibbs measure is unique.

**Step 2 (Decay of Correlations).**
Under the uniqueness condition, influence propagates only locally. The correlation length $\xi$ is finite.
This is proven via coupling arguments or cluster expansion.

**Step 3 (Stability).**
Finite correlation length implies that perturbations at boundary do not affect the bulk state (no "butterfly effect" for static properties). This guarantees that the system is robust to noise and boundary conditions.
:::

:::{prf:metatheorem} Parametric Stiffness Map
:label: mt:parametric-stiffness-map

**Thin inputs:** $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $D_E$ (N1).

**Status:** Heuristic-to-conditional (Bakry–Émery/Lichnerowicz in log-concave settings; requires global convexity on the region of interest).

**Statement:** The local stiffness (spectral gap) of the Fractal Gas is determined by the Hessian of the potential $\Phi$:

$$\lambda_1(x) \geq \inf \text{eig}(\nabla^2 \Phi(x))$$
Regions of high curvature in the optimization landscape correspond to "stiff" regions in the Information Graph where diffusion is suppressed and selection is strong.
:::

:::{prf:proof}
**Step 1 (Bakry-Emery Criterion).**
For a potential $V$, the generator is $L = \Delta - \nabla V \cdot \nabla$.
The Bakry-Emery curvature is bounded below by $\nabla^2 V$.

**Step 2 (Local Spectral Gap).**
By the Lichnerowicz theorem extension, if $\nabla^2 V \succeq K I$, then the local spectral gap $\lambda_1 \ge K$.
In the Fractal Gas, $V = \beta \Phi + \text{entropic terms}$.

**Step 3 (Stiffness interpretation).**
High positive curvature of $\Phi$ implies a deep local minimum. Fluctuations are suppressed by the restoring force $\nabla \Phi$. This corresponds to a "stiff" mode in the mechanical sense, or a large mass term in field theory.
:::

:::{prf:metatheorem} Micro-Macro Consistency
:label: mt:micro-macro-consistency

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (hydrodynamic/renormalization limits; requires a specified coarse-graining scheme).

**Statement:** The emergent dynamics are consistent across scales. Coarse-graining the microscopic random walk yields the same effective theory as simulating the macroscopic diffusion directly (Commutativity of the diagram).

$$ \mathbb{E}[\pi(\mathcal{S}_{\text{micro}}(x))] = \mathcal{S}_{\text{macro}}(\pi(x)) $$
:::

:::{prf:proof}
**Step 1 (Renormalization Group).**
Let $R_\tau$ be the coarse-graining operator (e.g., block spin or spectral truncation).
We require that the generator $L$ flows to a "renormalized" generator $L'$ such that dynamics are preserved.

**Step 2 (Hydrodynamic Limit).**
The scaling limit of the random walk converges to the diffusion equation.
The coarse-grained variables (e.g., local density) obey a hydrodynamic equation (Euler or Navier-Stokes equivalent for the graph).

**Step 3 (Commutativity).**
If the coarse-graining operator $R_\tau$ is compatible with the generator family (e.g. $R_\tau L \approx L'R_\tau$ in an appropriate topology) and the coarse-grained equation closes in the same family (e.g. near an RG fixed point), then micro-evolve-then-average and macro-evolve approximate each other. Verifying such a closure/fixed-point property is additional to the sieve and is not asserted here.
:::

:::{prf:metatheorem} Observer Universality
:label: mt:observer-universality

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_O$ (N9), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (invariance intuition; the precise “observer group” must be specified).

**Statement:** The Information Graph is intrinsic; it does not depend on the coordinate system or labeling of external states, up to isometry.

$$ \text{IG}(\pi(X)) \cong \text{IG}(X) $$
:::

:::{prf:proof}
**Step 1 (Isometry Invariance).**
The distances in the IG are defined by transition probabilities or mutual information, which are coordinate-independent quantities. $P(j|i)$ depends only on the graph topology and weights.

**Step 2 (Spectral Invariance).**
The spectrum of the Laplacian (Heat Kernel Signature) is an isometry invariant of the manifold. Two observers seeing the same graph will measure the same diffusion times and eigenvalues.

**Step 3 (Reconstruction).**
Since the geometry is reconstructed from spectral properties (see Geometric Reconstruction), any two isometric representations yield the same emergent geometry.
:::

:::{prf:metatheorem} Law Universality
:label: mt:universality-of-laws

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{TB}_O$ (N9).

**Status:** Heuristic-to-conditional (RG/universality is standard in restricted settings; not an automatic consequence of the sieve).

**Statement:** In settings where an effective field-theory/RG description applies (locality, scale separation, and existence of a scaling limit), the large-scale form of the effective equations is controlled by symmetry and dimension: microscopic details primarily renormalize coupling constants, while irrelevant operators are suppressed at long scales. This is a conditional universality claim, not a generic sieve consequence.
:::

:::{prf:proof}
**Step 1 (Universality of Random Walks).**
Under standard invariance-principle hypotheses (finite second moment, appropriate mixing, and diffusive rescaling), many random walks and Markov chains converge in law to Brownian motion (or a diffusion with effective covariance) on the limiting space. The precise conditions and limiting generator depend on the model.

**Step 2 (Local Operators).**
The effective action must be constructed from local geometric invariants (scalars constructed from curvature, gradient, etc.).
$$ S_{\text{eff}} \sim \int (c_1 |\nabla \phi|^2 + c_2 R \phi^2 + \dots) \sqrt{g} dx $$

**Step 3 (Relevance).**
Under RG flow, irrelevant operators (higher derivatives) suppressed by the scale cut-off vanish. Only relevant and marginal operators remain in the continuum limit. This dictates the form of the macroscopic laws (e.g., standard kinetic terms).
:::

:::{prf:metatheorem} Closure-Curvature Duality
:label: mt:closure-curvature-duality

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic (analogy between compactness and geometric regularity; no equivalence theorem is claimed).

**Statement:** The "closure" of the agent's memory or state space (boundedness) invites a curvature/compactness analogy in information geometry. Finite capacity can be modeled as a compactness/finite-volume constraint (UV/IR cutoffs) on the agent’s internal map, but no literal equivalence theorem is claimed.
:::

:::{prf:proof}
**Step 1 (Compactness).**
If the state space $X$ is compact (finite volume), the spectrum of the Laplacian is discrete.
On an infinite flat space, the spectrum is continuous.

**Step 2 (Curvature bound).**
By Bonnet-Myers theorem, if Ricci curvature is bounded below by a positive constant, the manifold is compact.
Conversely, restricting a random walk to a finite domain induces an effective positive curvature (confinement).

**Step 3 (Information Capacity).**
Finite channel capacity limits the resolution of the state space. This acts as a UV cutoff (discretization) and an IR cutoff (compactness/bounded domain). The geometry of the codebook is necessarily curved (like packing spheres on a surface).
:::

:::{prf:metatheorem} Well-Foundedness Barrier
:label: mt:well-foundedness-barrier

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\rho$ (N10).

**Status:** Conditional (a design-time invariant once the multiscale construction is indexed by a well-founded set).

**Statement:** If the Fractal Gas / Fractal Set construction is indexed by a well-founded parameter (e.g. resolution level $n\in\mathbb{N}$ with coarse-graining maps $\phi_{nm}$ only for $n\le m$) and each definition depends only on strictly “finer” or strictly “coarser” levels, then there is no infinite regress: every dependency chain terminates at a base level (atomic inputs or the minimum/maximum resolution used).
:::

:::{prf:proof}
**Step 1 (Well-founded index).**
Let the multiscale construction be indexed by a well-founded set $(I,\prec)$ (e.g. $(\mathbb{N},>)$ for “strictly finer” or “strictly coarser” indices, depending on convention).

**Step 2 (Termination of dependency chains).**
Each definitional dependency step moves strictly along $\prec$ (by hypothesis). Therefore any dependency chain induces a strictly descending $\prec$-chain in $I$. Since $I$ is well-founded, no infinite descending chain exists, so every dependency chain terminates at a base level.

**Step 3 (DAG view).**
Equivalently, the dependency graph is acyclic because any directed edge strictly decreases the well-founded rank.
:::

:::{prf:metatheorem} Continuum Injection
:label: mt:continuum-injection

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (conditional on a specified manifold-learning embedding and a coupling/limit theorem; “canonical” is generally too strong).

**Statement:** Under standard manifold-learning hypotheses (sampling density, reach/regularity, appropriate kernel bandwidth), there exist embeddings/injections $\iota:V(G)\hookrightarrow M$ (e.g. diffusion maps / heat-kernel embeddings) whose distortion vanishes as resolution increases, so that discrete random-walk paths on $G$ can be coupled to diffusion/geodesic processes on $(M,g)$ in the continuum limit.
$$ \iota: V(G) \hookrightarrow M $$
:::

:::{prf:proof}
**Step 1 (Embedding).**
Use the Heat Kernel embedding or Eigenmaps:
$\iota(x) = (\lambda_1 \phi_1(x), \dots, \lambda_k \phi_k(x))$.
This minimizes distortion of the diffusion metric.

**Step 2 (Shadowing).**
Under standard graph-to-manifold invariance principles for random walks (under the same sampling/bandwidth/scaling hypotheses as in manifold learning), the interpolated walk pushed through $\iota$ can converge in law to Brownian motion (or the corresponding diffusion) on $(M,g)$ under an appropriate time rescaling. A *pathwise* strong coupling estimate is additional structure and is not asserted here.

**Step 3 (Injectivity).**
Injectivity of $\iota$ is not automatic: it must be verified from the specific embedding theorem used (e.g. that the chosen coordinates separate points in the limit, and that finite-sample collisions are excluded by sampling density/separation). In many constructions one obtains an approximately bi-Lipschitz embedding on a scale range, but this is model-dependent.
:::

(sec-fractal-gas-causal-foundations)=

## Causal Foundations

:::{prf:definition} Faithful Causal Set
:label: def:faithful-causal-set

**Origin:** `hypostructure.md`, Ch 14 (Causal Foundations).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Definition.

A causal set $\mathcal{C}$ is **faithful** to a Lorentzian manifold $(M, g)$ if there exists an embedding $\phi: \mathcal{C} \hookrightarrow M$ that:
1. **Preserves causal order:** $x \prec y$ in $\mathcal{C}$ iff $\phi(x)$ causally precedes $\phi(y)$ in $M$
2. **Is statistically uniform:** The embedded points follow a Poisson distribution with density $\rho = \sqrt{-g}$

**Remark:** Faithfulness connects the discrete causal structure to continuum Lorentzian geometry. The Poisson sprinkling ensures that the number of elements in a region is proportional to its spacetime volume.
:::

:::{prf:metatheorem} Bombelli-Sorkin Theorem
:label: mt:bombelli-sorkin

**Origin:** `hypostructure.md`, Ch 14 (Causal Foundations).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1), $\mathrm{TB}_\pi$ (N8).

**Status:** Conditional (requires QSD existence and appropriate scaling limits).

**Statement.** The set of events generated by a stochastic process settling to a Quasi-Stationary Distribution forms a
Faithful Causal Set of the emergent geometry $(M,g_{\mathrm{eff}})$ (Definition {prf:ref}`def:emergent-manifold-fg`)
under the usual causal-set faithfulness hypotheses (appropriate sprinkling/statistical uniformity and a specified
Lorentzian continuation when required).

**Interpretation:** This theorem connects the Fractal Gas dynamics to causal set theory: when the swarm reaches a QSD, its event history discretizes an emergent Lorentzian spacetime in a statistically uniform way.
:::

:::{prf:proof}
**Step 1 (QSD as Stationary Measure).**
The quasi-stationary distribution $\nu$ represents the long-time conditioned behavior of the killed/resampling process. Events generated from $\nu$ sample the "surviving" regions uniformly with respect to the QSD.

**Step 2 (Causal Structure from CST).**
The Causal Spacetime Tree records the parent-child relationships (cloning/descent). This defines a partial order $\prec$ on events that respects the temporal sequence of the dynamics.

**Step 3 (Density Matching).**
Under the QSD, the density of events $\rho(x)$ is controlled by the survival kernel. If the dynamics induce an
effective metric $g_{\mathrm{eff}}$ on the promoted continuum object, then the QSD density scales with the associated
volume density (schematically $\sqrt{\det g_{\mathrm{eff}}}$ in local coordinates), matching the continuum
volume-element condition required for faithfulness. In purely diffusive limits one often has the proxy
$g_{\mathrm{eff}}\approx D^{-1}$, but the faithfulness claim is stated in terms of $g_{\mathrm{eff}}$.

**Step 4 (Convergence to Faithfulness).**
In appropriate scaling limits (large $N$, long times, small $\tau$), the discrete causal set statistics converge to those of a Poisson sprinkling on the emergent geometry $(M, g_{\mathrm{eff}})$.
:::

(sec-algorithmic-calculus-fractal-sets)=

## Algorithmic Calculus on Fractal Sets

:::{prf:metatheorem} Discrete Stokes' Theorem
:label: mt:discrete-stokes

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (combinatorial topology; holds for oriented simplicial complexes by definition of boundary/coboundary).

**Statement:** For any discrete $k$-form $\omega$ on a simplicial complex $K$ representing the Information Graph state:
$$\langle d\omega, K \rangle = \langle \omega, \partial K \rangle$$
Flux is invariant under local remeshing (scutoid transitions) provided the cohomology class is preserved.
:::

:::{prf:proof}
**Step 1 (Chain Complex).**
Define $k$-cochains as functions on $k$-simplices. The coboundary operator $d$ is the adjoint of the boundary operator $\partial$.
$$\langle d\omega, c \rangle = \langle \omega, \partial c \rangle$$
This is the definition of the discrete exterior derivative.

**Step 2 (Local Conservation).**
The sum of fluxes out of a volume element equals the creation of "local charge" inside.
$\sum_{F \in \partial V} \text{Flux}(F) = \text{Source}(V)$.

**Step 3 (Topological Invariance).**
Pachner moves (bistellar flips) change the triangulation but preserve the manifold topology. Since $\int_M d\omega = \int_{\partial M} \omega$, and $\partial M$ is unchanged by internal remeshing, the total integral is invariant.
:::

:::{prf:metatheorem} Frostman Sampling Principle
:label: mt:frostman-sampling

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $C_\mu$ (N3).

**Status:** Heuristic-to-conditional (becomes conditional once the limiting/invariant measure is known to be $s$-Frostman; this is not automatic).

**Statement:** If the empirical measures $\mu_N=\frac1N\sum_i\delta_{x_i}$ converge (along a subsequence) to a limit/invariant measure $\mu$ supported on an attractor $A$, and if $\mu$ is $s$-Frostman (upper $s$-regular),
$$ \mu(B_r(x)) \leq C r^s $$
then $s\le \dim_H(A)$ and $\mu$ controls integrals on $A$ via standard potential-theoretic estimates. The “Frostman sampling” interpretation is that, in regimes where the solver concentrates on a fractal attractor with a regular limiting law, such Frostman-type bounds can hold and justify continuum integration on $A$.
:::

:::{prf:proof}
Assume $\mu$ is supported on $A$ and satisfies the $s$-Frostman bound $\mu(B_r(x))\le Cr^s$ for all $x$ and all $r>0$.

**Step 1 (Hausdorff dimension lower bound).**
Let $\{B_{r_i}(x_i)\}$ be any countable cover of $A$ by balls. Then

$$
1=\mu(A)\ \le\ \sum_i \mu(B_{r_i}(x_i))\ \le\ C\sum_i r_i^s.

$$
Taking the infimum over covers shows $\mathcal{H}^s(A)\ge 1/C>0$, hence $\dim_H(A)\ge s$.

**Step 2 (Finite energy below $s$).**
For any $t<s$, one can write (layer-cake)

$$
\int |x-y|^{-t}\,d\mu(y)\ =\ t\int_0^\infty r^{-t-1}\,\mu(B_r(x))\,dr.

$$
Splitting the integral at $r=1$ and using $\mu(B_r(x))\le Cr^s$ on $(0,1)$ gives finiteness since
$\int_0^1 r^{s-t-1}\,dr<\infty$ when $t<s$. Integrating in $x$ yields $I_t(\mu)<\infty$.

**Step 3 (What remains to certify).**
The nontrivial step for an algorithmic instantiation is to verify existence of a subsequential limit/invariant measure $\mu$ and the Frostman bound itself; this is model-dependent and not implied by the sieve without extra hypotheses.
:::

:::{prf:metatheorem} Genealogical Feynman-Kac
:label: mt:genealogical-feynman-kac

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (Feynman–Kac + branching particle representation under a specified birth/death rule).

**Assumptions (one standard setting):**
1. $(X_t)_{t\ge 0}$ is a Markov process with generator $K$ (diffusion/transport part).
2. $r:X\to\mathbb{R}$ is a bounded measurable “net growth” rate, decomposed as $r=r^+-r^-$ with $r^\pm\ge 0$.
3. A branching Markov process is defined where each particle moves as $X_t$, branches at rate $r^+$ and is killed at rate $r^-$.

**Statement:** The Feynman–Kac semigroup with rate $r$,

$$
u(t,x)\ :=\ \mathbb{E}_x\!\left[f(X_t)\exp\Bigl(\int_0^t r(X_s)\,ds\Bigr)\right],

$$
admits a branching representation:

$$
u(t,x)\ =\ \mathbb{E}_{\text{genealogy},x}\!\left[\sum_{i=1}^{N_t} f(x_i^t)\right].

$$
(Setting $r=-\Phi$ recovers the pure killing potential case $\partial_t u=Ku-\Phi u$.)
:::

:::{prf:proof}
**Step 1 (Feynman-Kac Formula).**
The function $u(t,x)=\mathbb{E}_x[f(X_t)\exp(\int_0^t r(X_s)\,ds)]$ solves the linear PDE $\partial_t u = Ku + r\,u$ under standard regularity assumptions on $K,r$ (classical Feynman–Kac).

**Step 2 (Particle Interpretation).**
For the branching Markov process specified in the assumptions (motion $K$, birth $r^+$, death $r^-$), the expected “mass”
$m(t,x):=\mathbb{E}_{\text{genealogy},x}[\sum_{i=1}^{N_t} f(x_i^t)]$ satisfies the same linear PDE $\partial_t m = Km + r\,m$ by conditioning on the first event time and using the Markov property.

**Step 3 (Mean Field Limit).**
Particle approximations of Feynman–Kac semigroups (sequential Monte Carlo / Fleming–Viot type systems) admit law-of-large-numbers limits under standard mixing/tightness hypotheses. Any additional claim identifying *most probable paths* or action minimizers requires a separate large-deviations/Laplace-principle argument and is not used here.
:::

:::{prf:metatheorem} Cheeger Gradient Isomorphism
:label: mt:cheeger-gradient

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (metric-measure / Γ-convergence statement under doubling + Poincaré + graph-limit hypotheses).

**Statement:** The discrete graph gradient $\nabla_G f$ converges to the Cheeger derivation $D f$ on the metric measure space limit.
$$ \| \nabla_G f \|_{L^2} \to \| D f \|_{L^2} $$
This justifies using graph neural networks to compute continuum derivatives.
:::

:::{prf:proof}
**Step 1 (Discrete Gradient).**
$\nabla_{ij} f = \sqrt{w_{ij}} (f(j) - f(i))$.
The Dirichlet energy is $\mathcal{E}(f) = \sum w_{ij} (f(j)-f(i))^2$.

**Step 2 (Relaxed Gradient).**
On a metric measure space $(X, d, \mathfrak{m})$, the modulus of the gradient $|\nabla f|$ is the minimal weak upper gradient.
Cheeger proved that for doubling spaces with Poincaré inequality, a differentiable structure exists.

**Step 3 (Gamma Convergence).**
The sequence of graph energies $\Gamma$-converges to the Cheeger energy on the limit space. Thus, minimizers (harmonic functions) converge.
:::

:::{prf:metatheorem} Anomalous Diffusion Principle
:label: mt:anomalous-diffusion

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $D_E$ (N1).

**Status:** Heuristic-to-conditional (conditional for classes of self-similar fractals / spaces with sub-Gaussian heat-kernel bounds).

**Statement:** On fractal supports with walk dimension $d_w>2$ and sub-Gaussian heat-kernel bounds, diffusion is anomalous: the mean squared displacement scales as
$$ \langle r^2(t) \rangle \sim t^{2/d_w} $$
where $d_w > 2$ is the walk dimension. The heat kernel obeys sub-Gaussian bounds.
:::

:::{prf:proof}
**Step 1 (Spectral Dimension).**
The density of states regularizes as $\rho(\lambda) \sim \lambda^{d_s/2 - 1}$.
The return probability decays as $p_t(x,x) \sim t^{-d_s/2}$.

**Step 2 (Resistance Metric).**
The effective resistance between points at distance $r$ scales as $R(r) \sim r^{d_w - d_H}$.
Time to exit a ball $B_r$ is $T_r \sim r^{d_w}$.

**Step 3 (Sub-Gaussian Kernel).**
The heat kernel bounds are:
$$ p_t(x,y) \asymp \frac{1}{t^{d_s/2}} \exp\left( - \left(\frac{d(x,y)^{d_w}}{t}\right)^{\frac{1}{d_w-1}} \right) $$
This slower-than-Gaussian scaling reflects the "traps" and "mazes" in the fractal geometry.
:::

:::{prf:metatheorem} Spectral Decimation Principle
:label: mt:spectral-decimation

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Rep}_K$ (N11).

**Status:** Conditional (standard for finitely ramified self-similar graphs; requires a specified decimation scheme).

**Statement:** On self-similar graphs (like Sierpinski gaskets), the Laplacian eigenvalues satisfy a recursive relation $\lambda_{k-1} = R(\lambda_k)$.
The eigenfunctions are fractals themselves. This allows exact computation of the spectrum.
:::

:::{prf:proof}
**Step 1 (Schur Complement).**
Decompose graph nodes into "boundary" and "interior" for a cell.
Project the Laplacian onto boundary nodes: $L_{eff} = L_{bb} - L_{bi} L_{ii}^{-1} L_{ib}$.

**Step 2 (Renormalization Map).**
For self-similar graphs, $L_{eff}(\lambda) \propto L_{original}(R(\lambda))$.
The function $R(\lambda)$ is a rational map governing the spectral flow.

**Step 3 (Eigenvalues).**
In spectral decimation, eigenvalues on level $k$ are obtained by iterating inverse branches of $R$ starting from a finite “seed” set (and excluding singular values where the Schur complement is ill-defined). The accumulation set of these iterates is often related to the Julia set of $R$ (e.g. for the Sierpiński gasket), but the precise identification depends on the fractal and the decimation scheme.
:::

:::{prf:metatheorem} Discrete Uniformization Principle
:label: mt:discrete-uniformization

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $C_\mu$ (N3).

**Status:** Conditional (circle packings / discrete conformal geometry under planar triangulation hypotheses).

**Statement:** Any planar triangulation admits a "circle packing" metric that is discretely conformally equivalent to a constant curvature surface (Spherical, Euclidean, or Hyperbolic).
This provides a canonical coordinate system for the Information Graph.
:::

:::{prf:proof}
**Step 1 (Circle Packing).**
Associate a radius $r_i$ to each vertex. Edge lengths are $l_{ij} \approx r_i + r_j$ (tangency).
The discrete conformal factor is $u_i = \log r_i$.

**Step 2 (Discrete Ricci Flow).**
Deform radii to equalize curvatures at vertices (defect angle summing to $2\pi$ or 0).
$\frac{du_i}{dt} = -K_i$.
This flow converges to a unique constant curvature metric (Chow-Luo).

**Step 3 (Approximation).**
The convergence of circle packing maps to the Riemann mapping (He-Schramm theorem) ensures that the discrete coordinates approximate the true conformal structure of the underlying manifold.
:::

:::{prf:metatheorem} Persistence Isomorphism
:label: mt:persistence-isomorphism

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{SC}_\lambda$ (N4).

**Status:** Conditional (standard persistent-homology stability for tame filtrations).

**Statement:** The persistent homology of the density sublevel sets calculates the robust topological features of the underlying manifold. The persistence diagram is stable under perturbations (Bottleneck Stability).
:::

:::{prf:proof}
**Step 1 (Filtration).**
Consider the sublevel sets $X_c = \{x : \rho(x) > c\}$.
As $c$ decreases, we get a nested sequence of spaces (filtration).

**Step 2 (Homology).**
Compute homology groups $H_k(X_c)$ across all $c$. Track birth and death of features (connected components, loops).

**Step 3 (Stability).**
The Cohen-Steiner Stability Theorem states that small changes in the function $\rho$ (in $L^\infty$ norm) lead to small changes in the persistence diagram (in bottleneck distance). Thus, the estimated topology is robust to sampling noise.
:::

:::{prf:metatheorem} Swarm Monodromy Principle
:label: mt:swarm-monodromy

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (requires a precise model of labeled-particle braiding/transport; not a generic topology-recovery theorem).

**Statement:** Heuristically, topology (holes/handles) can be probed by transporting a labeled swarm around loops and recording the induced permutations/braid data of particle clusters.
$\pi_1(M) \to S_N$.
:::

:::{prf:proof}
**Step 1 (Covering Space).**
Consider the configuration space of $N$ distinct points $C_N(M)$.
Paths in $C_N(M)$ correspond to braids.

**Step 2 (Loop Traversal).**
If one specifies a rule for moving a labeled configuration along a loop (or family of loops) in $M$, the induced path in configuration space $C_N(M)$ determines an element of the braid group $\pi_1(C_N(M))$ (and hence a permutation in $S_N$ after forgetting pure braiding). The construction depends on the chosen transport rule and is not a canonical homomorphism from $\pi_1(M)$ without additional structure.

**Step 3 (Reconstruction).**
Such braid/permutation statistics can provide evidence about the presence of nontrivial loops/holes and can be used as topology-sensitive features, but reconstructing $\pi_1(M)$ in general is not claimed here.
:::

:::{prf:metatheorem} Particle-Field Duality
:label: mt:particle-field-duality

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Heuristic-to-conditional (empirical-measure weak convergence is standard; PDE/SPDE limits require propagation-of-chaos or mean-field hypotheses).

**Statement:** The discrete particle configuration (Lagrangian) and the continuous probability density (Eulerian) are dual representations.
Weak convergence ensures $\int f\,d\mu_N \to \int f\,d\mu$ for test functions $f$; when the limit $\mu$ is absolutely continuous, $\mu=\rho\,dx$ and $\int f\,d\mu=\int f\rho\,dx$.
:::

:::{prf:proof}
**Step 1 (Empirical Measure).**
Define mapping $\mathcal{P}: \mathbb{R}^{Nd} \to \mathcal{M}(X)$ by $X \mapsto \frac{1}{N} \sum \delta_{x_i}$.

**Step 2 (SPDE Limit).**
Under propagation-of-chaos / mean-field hypotheses for the interacting particle system, the empirical measures $\mu_N$ converge (in probability, in a weak topology) to a deterministic limit $\mu_t$ whose density (when it exists) solves the corresponding Fokker–Planck or McKean–Vlasov equation. Fluctuations around the limit are typically of order $N^{-1/2}$ and can be described in a CLT/SPDE scaling; they do not “vanish” pointwise, but they are negligible at the law-of-large-numbers level.

**Step 3 (Radon-Nikodym).**
If the limit $\mu_t$ is absolutely continuous with respect to the chosen reference measure (e.g. volume), write $\mu_t=\rho_t\,dx$ and interpret $\rho_t$ as the Eulerian density field. If not, one must work with $\mu_t$ directly as a measure (no density).
:::

:::{prf:metatheorem} Cloning Transport Principle
:label: mt:cloning-transport

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11), $D_E$ (N1).

**Status:** Heuristic-to-conditional (becomes conditional for classical multiplicative Feynman–Kac weights).

**Statement:** Reweighting/cloning of particles along a path acts as parallel transport of the normalization factor. This defines a connection on the line bundle of densities.
:::

:::{prf:proof}
**Step 1 (Multiplicative Cocycles).**
Let $W(x, y) = e^{-\beta (\Phi(y) - \Phi(x))}$ be the weight change.
Along a path $\gamma$, the cumulative weight is $W(\gamma) = \prod W(x_i, x_{i+1}) = e^{-\beta \Delta \Phi}$.

**Step 2 (Connection).**
This has the form of a parallel transport with connection 1-form $A = \beta d\Phi$.
If the potential is not single-valued (e.g., in non-conservative fields or with magnetic terms), the curvature $F = dA$ is non-zero, leading to holonomy.

**Step 3 (Bundle Section).**
The particle density is a section of a line bundle. The cloning process "transports" the density value from one tangent space to another, adjusting for local potential changes.
:::

(sec-fractal-gas-computation-engine)=

## Fractal Gas as Computation, Quantum, and Information Engine

:::{prf:metatheorem} Projective Feynman-Kac Isomorphism
:label: mt:projective-feynman-kac

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\rho$ (N10), $\mathrm{LS}_\sigma$ (N7).

**Status:** Conditional (classical Feynman–Kac normalization; the implemented pairwise selection is an approximation to this envelope).

**Assumptions (one standard setting):**
1. The linear equation is positivity preserving: $v_0\ge 0$ implies $v_t\ge 0$ for $t>0$.
2. The linear semigroup is strongly positive/irreducible on an appropriate cone (e.g. a Doeblin/minorization condition for a Markov kernel, or a Krein–Rutman/Perron–Frobenius regime ensuring a unique leading eigenfunction up to scale).

**Statement:** The normalized (nonlinear) evolution of a density $u_t$ obtained by projectivizing an unnormalized Feynman–Kac evolution $v_t$ can be written as a projection of a linear flow onto the unit simplex: $u_t=v_t/\|v_t\|_1$. This is an exact algebraic identity at the PDE/semigroup level under the assumptions above.
:::

:::{prf:proof}
**Step 1 (Linear Evolution).**
Let $v_t$ boundedly solve $\partial_t v = \mathcal{L} v - \beta \Phi v$ (linear sink/source term).

**Step 2 (Projection).**
Let $u_t = \frac{v_t}{\|v_t\|_1}$.
Differentiation gives the nonlinear equation:
$\partial_t u = \mathcal{L} u - \beta \Phi u + (\beta \int \Phi u) u$.
The last term is the mean field feedback maintaining normalization.

**Step 3 (Metric Contraction).**
Under the strong-positivity/irreducibility assumptions, the normalized flow contracts in the Hilbert projective metric (Birkhoff-type contraction), yielding convergence of $u_t$ to the unique (normalized) positive ground state/eigenfunction (Perron–Frobenius / Krein–Rutman). Without those positivity hypotheses, no uniqueness/convergence claim is made here.
:::

:::{prf:principle} Fisher Information Ratchet
:label: prin:fisher-information-ratchet

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1).

**Status:** Imported (WFR geometry; value-driven mass creation).

**Statement:** In the WFR formulation (Definition {prf:ref}`def-the-wfr-action`), mutation/diffusion is the transport
term and selection/cloning is the reaction term. The reaction rate is value-determined (Theorem
{prf:ref}`thm-wfr-consistency-value-creates-mass`), so belief mass must grow in regions where $V>\bar V$ and decay where
$V<\bar V$. This is the rigorous “ratchet” content: mass is created where value is above average.

In regimes where the density sharpens (e.g. low-temperature conservative limits), this typically increases Fisher
information by concentrating $\rho$. However, no global monotonicity law for Fisher information is asserted here
without additional convexity/regularity hypotheses on the generator (e.g. log-concavity / Bakry–Émery conditions).
:::

:::{prf:proof}
The ratchet mechanism is Theorem {prf:ref}`thm-wfr-consistency-value-creates-mass`: the WFR reaction term increases mass
exactly where $V>\bar V$. The relationship between diffusion, entropy production, and Fisher information in the pure
transport case is classical (de Bruijn identity). Combining them into a sign-definite Fisher-information law requires
additional assumptions (e.g. convexity/LSI), so this block records only the rigorous mass-creation direction and the
standard diffusion identities.
:::

:::{prf:principle} Complexity Tunneling
:label: prin:complexity-tunneling

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{SC}_\lambda$ (N4), $\mathrm{LS}_\sigma$ (N7).

**Status:** Imported (WFR reaction provides a literal tunneling mechanism).

**Statement:** In WFR dynamics (Definition {prf:ref}`def-the-wfr-action`), the reaction term enables tunneling by **mass
creation on the far side of barriers** (Proposition {prf:ref}`prop-wfr-reaction-tunneling`): belief mass can be
destroyed in the current basin and created in a distant basin without traversing intermediate states. The balance
between transport (barrier traversal) and reaction (teleportation) is controlled by the teleportation length $\lambda$
in WFR (Definition {prf:ref}`def-the-wfr-action`).

This is a geometric mechanism statement, not a worst-case complexity theorem: converting it into barrier-crossing time
bounds requires specifying how the agent estimates high-value regions beyond the barrier (what triggers $r>0$ there)
and how the reaction budget scales with problem size.
:::

:::{prf:proof}
Proposition {prf:ref}`prop-wfr-reaction-tunneling` is the rigorous tunneling claim: reaction creates mass beyond a
barrier and annihilates mass on this side, with the reaction-vs-transport regime controlled by $\lambda$. The standard
large-deviation scaling for barrier traversal under pure diffusion motivates why such a reaction term can be
algorithmically valuable, but no uniform polynomial-in-$\Delta E$ conclusion is asserted without a concrete model.
:::

:::{prf:metatheorem} Landauer Optimality
:label: mt:landauer-optimality

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Cap}_H$ (N6), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (Landauer is a physical bound; applying it to an abstract solver requires an explicit physical implementation model).

**Statement:** If a physical implementation of the Fractal Gas at temperature $T$ performs an information-erasing operation reducing entropy by $\Delta I$ bits, then the minimal dissipated work satisfies $W\ge k_B T\ln 2\cdot \Delta I$. Interpreting $\Delta I$ as a mutual-information gain between an initial state and an identified optimum yields the schematic bound
$$E_{\text{search}} \geq k_B T \ln 2 \cdot I(x_{\text{start}}; x_{\text{opt}})$$
Saturation requires quasi-static reversible driving and is not asserted for generic algorithmic runs.
:::

:::{prf:proof}
**Step 1 (Information Erasure).**
Selecting the optimal state $x_{\text{opt}}$ from a prior distribution reduces entropy by $\Delta S = H_{\text{prior}} - H_{\text{final}}$.
Landauer's principle requires heat dissipation $Q \geq T \Delta S$.

**Step 2 (Free Energy).**
The Fractal Gas minimizes free energy $F = U - TS$. The work done by the selection mechanism equals the change in free energy.
Efficiency is measured by proximity to this bound.

**Step 3 (Reversibility).**
If the definition of fitness changes slowly (quasi-static), the cloning/killing is reversible (detailed balance holds), and the system saturates the Landauer bound.
:::

:::{prf:metatheorem} Levin Search Isomorphism
:label: mt:levin-search

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Conditional (exact for an explicit dovetailing kinetic operator; the “Fractal Gas” reading is an implementation schema).

**Setup (search in program space).**
Fix a universal prefix machine $U$ with a prefix-free program set $\mathcal{P}\subseteq\{0,1\}^\star$. Let $R(x,y)$ be a
decidable predicate defining a search/inversion problem: given an instance $x$, find any output $y$ such that
$R(x,y)=1$.

Define the **time-bounded interpreter** $U_t(p,x)$ as “run $U(p,x)$ for at most $t$ steps” (returning a distinguished
symbol $\bot$ if it has not halted by time $t$). Consider the countable computation space

$$
\mathcal{C}\;:=\;\{(p,t): p\in\mathcal{P},\ t\in\mathbb{N}_{\ge 1}\}.

$$
Define the **Levin potential**

$$
\Phi(p,t)\ :=\ (\ln 2)\,|p|+\ln t
\qquad\text{(equivalently, }e^{-\Phi(p,t)}=2^{-|p|}/t\text{).}

$$

**Statement (isomorphism).**
The classical Levin/universal dovetailing schedule is equivalent (up to a constant factor) to expanding computations in
increasing $\Phi(p,t)$ and running each $(p,t)$ for exactly $t$ steps. Concretely, for each stage $s\in\mathbb{N}$ run,
for every program $p$ with $|p|\le s$, the bounded run $U_{2^{s-|p|}}(p,x)$. If any run produces $y$ with $R(x,y)=1$,
stop.

If there exists a program $p_\star\in\mathcal{P}$ such that $U(p_\star,x)$ halts within $t_\star$ steps and outputs a
valid $y$ (i.e. $R(x,U(p_\star,x))=1$), then the total number of simulated machine steps before success is

$$
O\!\left(2^{|p_\star|}\,t_\star\right),

$$
which is the standard Levin-search envelope (up to a constant factor).
:::

:::{prf:proof}
**Step 1 (Dovetailing as a $\Phi$-cutoff).**
At stage $s$, the schedule runs each $p$ for $2^{s-|p|}$ steps. Writing $t:=2^{s-|p|}$ gives

$$
|p|+\log_2 t = s \quad\Longleftrightarrow\quad \Phi(p,t)=s\ln 2,

$$
so stage-$s$ dovetailing enumerates computations with $\Phi(p,t)\le s\ln 2$ and runs them with the matching time budget
at that cutoff.

**Step 2 (Total work per stage).**
The total work at stage $s$ is

$$
\sum_{p:\,|p|\le s} 2^{s-|p|} = 2^s\sum_{p:\,|p|\le s} 2^{-|p|} \le 2^s,

$$
by Kraft’s inequality for the prefix-free set $\mathcal{P}$.

**Step 3 (Levin envelope).**
Let $p_\star$ halt with a valid output within $t_\star$ steps. Choose $s_\star:=|p_\star|+\lceil\log_2 t_\star\rceil$.
Then stage $s_\star$ runs $p_\star$ for at least $t_\star$ steps, so the schedule will discover the solution by the end
of stage $s_\star$. The total work up to that point is

$$
\sum_{s=0}^{s_\star} 2^s \le 2^{s_\star+1} = O\!\left(2^{|p_\star|}\,t_\star\right).

$$
This is the standard universal-search guarantee. The “Fractal Gas” phrasing is the observation that $\Phi(p,t)$ is a
single scalar “energy” whose cutoff induces Levin’s resource allocation.
:::

:::{prf:remark} Complexity Envelope (Framework Classes)
The complexity-class refinement (Propagator-regime linear-in-depth wavefront bound; singular-regime Levin fallback) is
stated in the Algorithmic Classification chapter as Definition {prf:ref}`def-propagator-tube-witness` and Theorem
{prf:ref}`mt:geodesic-tunneling-fractal-trees`.
:::

:::{prf:principle} Algorithmic Tunneling
:label: prin:algorithmic-tunneling

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (Kolmogorov complexity is uncomputable; any practical proxy is model-dependent).

**Statement:** The (uncomputable) algorithmic information distance $d_K(x,y)=K(x|y)+K(y|x)$ defines a geometry where “close” means “easily computable from one another”. A Fractal-Gas-like solver can be interpreted as diffusing in *approximations* of this geometry (program-edit graphs, compression-based distances), enabling “tunneling” between conceptually related but structurally distinct solutions when Euclidean parameter distances are misleading.
:::

:::{prf:proof}
**Step 1 (Algorithmic Geometry).**
Programs are nodes in a graph; edges are simple edits. The graph distance approximates $d_K$.

**Step 2 (Mutation).**
Random mutations in program space correspond to diffusion.
Regions connected by short programs (common subroutines) are close.

**Step 3 (Shortcuts).**
What appears as a high energetic barrier in the parameter space of a neural network (Euclidean distance) might be a short hop in program space (e.g., changing one hyperparameter or rule). The Fractal Gas explores these "wormholes."
:::

:::{prf:metatheorem} Cloning-Lindblad Equivalence
:label: mt:cloning-lindblad

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Heuristic (quantum open-system language; at best an analogy to master equations for classical interacting particle systems).

**Statement:** Heuristically, cloning/death can be viewed as coupling the system to an “environment” that implements dissipation/selection. One can write master-equation evolutions for ensembles and draw analogies to GKSL/Lindblad structure in quantum mechanics, but this sketch does not assert that Fractal Gas dynamics literally define a Lindblad evolution on a quantum density matrix.
$$ \frac{d\rho}{dt} = -i[H, \rho] + \sum (2 L_k \rho L_k^\dagger - \{L_k^\dagger L_k, \rho\}) $$
:::

:::{prf:proof}
**Step 1 (Jump Operators).**
Identify the cloning events as quantum jumps. The "jump operator" $L$ creates a copy.
The rate of jumping depends on the potential $\Phi$.

**Step 2 (Master Equation).**
Write the (classical) master equation for the ensemble law of a Markov jump process describing birth/death/resampling on particle configurations. In operator notation, such generators contain “jump” and “loss” terms that can resemble the algebraic shape of GKSL/Lindblad operators, but the objects here are classical probability measures (or densities), not quantum density matrices.

**Step 3 (Dissipation).**
This analogy is only organizational: the rigorous framework formulation of selection is via WFR reaction (Definition {prf:ref}`def-the-wfr-action`). Any mapping to GKSL language is an optional embedding and is not used as a certificate in this document.
:::

:::{prf:principle} Zeno Effect
:label: prin:zeno-effect

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3).

**Status:** Heuristic (quantum analogy; the cloning operator is not literally a projective measurement).

**Statement:** Frequent cloning (measurement) confines the system to a subspace (the ground state). If the cloning rate $\gamma$ is large compared to the diffusion rate, the system is "frozen" in the optimal state.
:::

:::{prf:proof}
**Step 1 (Measurement Projection).**
Each cloning event acts as a weak measurement of position (soft projection).
High cloning rate $\to$ Continuous surveillance.

**Step 2 (Survival Probability).**
The probability of transitioning out of the ground state decays as $1 - (\Delta E)^2 t^2$.
With frequent checks at interval $\tau$, the survival prob at time $T$ is $(1 - (\tau \Delta E)^2)^{T/\tau} \approx e^{-T \tau (\Delta E)^2}$.
As $\tau \to 0$, decay is suppressed.

**Step 3 (Optimization).**
This "Quantum Zeno Effect" prevents the optimizer from drifting away from a sharp minimum once found, provided the "observation" (gradient/fitness check) is frequent enough.
:::

:::{prf:principle} Importance Sampling Isomorphism
:label: prin:importance-sampling

**Thin inputs:** $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (standard importance sampling statement for *known* integrands; cloning provides an adaptive approximation).

**Statement:** For estimating an integral $\int f(x)\,dx$ with $f$ known, the zero-variance proposal is $q(x)\propto |f(x)|$. In Fractal-Gas-like interacting particle systems, resampling/cloning adaptively concentrates particles in regions with high estimated contribution to observables, which can be interpreted as learning an approximate importance distribution (e.g. Gibbs-like densities $e^{-\beta\Phi}$ in equilibrium regimes). This is an interpretation of the *variance-reduction role* of cloning, not a claim that the stationary law is exactly optimal for all observables.
:::

:::{prf:proof}
**Step 1 (Zero Variance Condition).**
The optimal proposal distribution $q(x)$ for estimating $\int f(x) dx$ is $q(x) \propto |f(x)|$.
Here we want to estimate the "ground state energy" or normalization $Z$.

**Step 2 (Resampling as weight control).**
In sequential Monte Carlo / Feynman–Kac particle systems, resampling replaces a weighted particle cloud by an approximately unweighted cloud targeting (approximately) the same distribution. This controls weight degeneracy (effective sample size) and can reduce estimator variance for many observables, but the effect is model- and observable-dependent.

**Step 3 (No zero-variance guarantee).**
Zero-variance estimators require sampling exactly from the ideal proposal $q\propto |f|$ (or from the exact target distribution for the normalized Feynman–Kac semigroup). Adaptive cloning/resampling can only approximate such proposals from finite data; it does not in general produce exact proportionality $N(x)\propto |f(x)|$ nor zero variance.
:::

:::{prf:metatheorem} Epistemic Flow
:label: mt:epistemic-flow

**Thin inputs:** $\Phi^{\text{thin}} = -\mathcal{U} (Uncertainty)$.
**Permits:** $D_E$ (N1), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (becomes conditional once “uncertainty” is a specified smooth functional and the induced dynamics are identified).

**Statement:** If the potential is chosen as $\Phi(x)=-\mathcal{U}(x)$ for a specified epistemic-uncertainty functional $\mathcal{U}$, then (in idealized continuum limits where the drift is $-\nabla\Phi$) the swarm drifts toward regions of high uncertainty and can be interpreted as maximizing an information-gain proxy. The “knowledge boundary” language is interpretive and depends on the statistical model used to define $\mathcal{U}$.
:::

:::{prf:proof}
**Step 1 (Information Gain).**
The expected information gain from sampling $x$ is related to the epistemic uncertainty (entropy of the posterior predictive).
$IG(x) \approx H(y|x, \mathcal{D})$.

**Step 2 (Gradient Flow).**
Dynamics $\dot{x} = -\nabla \Phi = \nabla IG$ drive agents towards high uncertainty.
Diffusion ensures exploration of multiple uncertainty modes.

**Step 3 (Space Filling).**
As regions are sampled, uncertainty decreases (potential rises). The swarm flows like a liquid filling a vessel, leveling out the uncertainty landscape (flattening the posterior).
:::

:::{prf:principle} Curriculum Generation
:label: prin:curriculum-generation

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{SC}_\lambda$ (N4).

**Status:** Heuristic (learning/optimization design principle).

**Statement:** The sequence of datasets $\{\mathcal{D}_t\}$ generated by the Fractal Gas constitutes an optimal curriculum. The effective temperature $T(t)$ acts as a spectral filter, admitting low-frequency (easy) patterns first and high-frequency (detail) patterns later.
:::

:::{prf:proof}
**Step 1 (Spectral Bias).**
Neural networks learn low-frequency functions faster.
The Fractal Gas at high temperature samples broadly (low frequencies).

**Step 2 (Annealing).**
As parameters converge (cooling), the "resolution" of the sampler increases (Dimension Selection).
The swarm focuses on finer details of the landscape (high frequencies).

**Step 3 (Matched Filtering).**
The distribution of training examples $P_t(x)$ evolves such that the "difficulty" of samples matches the current capacity of the learner, maximizing learning progress (the flow of gradients).
:::

:::{prf:metatheorem} Manifold Sampling Isomorphism
:label: mt:manifold-sampling

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11), $\mathrm{SC}_\lambda$ (N4).

**Status:** Heuristic-to-conditional (conditional on a manifold hypothesis + a separation of normal/tangent scales).

**Statement:** If the solution set lies on a low-dimensional manifold $\mathcal{M} \subset \mathbb{R}^D$, the Fractal Gas naturally concentrates on $\mathcal{M}$, reducing the effective search dimension from $D$ to $d_{\text{intrinsic}}$.
:::

:::{prf:proof}
**Step 1 (Dimensional Collapse).**
High-energy regions are exponentially suppressed. If the potential wells are aligned with $\mathcal{M}$, the transverse fluctuations are Gaussian bounded.

**Step 2 (Tangent Space Dynamics).**
The random walk effectively occurs on the tangent bundle $T\mathcal{M}$.
The diffusion coefficient in the normal direction scales to zero (or is confined).

**Step 3 (Complexity Reduction).**
The sample complexity depends on the covering number of $\mathcal{M}$, not the volume of the ambient space. $N \sim (1/\epsilon)^d \ll (1/\epsilon)^D$.
:::

(sec-physics-emergence-theorems)=

## Physics Emergence Theorems

This section is **agent-centric**: it records rigorous field-equation constraints on the agent’s *internal map*
(the promoted latent geometry and its belief-update fields), not claims about the external territory.

- When a block cites an explicit theorem (via `{prf:ref}`), the claim is about the latent manifold/metric/fields that a
  boundary-grounded, capacity-limited agent must implement.
- Any remaining “physics” analogies are explicitly labeled **Heuristic** and should not be used as certificate inputs.

### Quantum Foundations

:::{prf:metatheorem} Hessian-Metric Isomorphism
:label: mt:hessian-metric

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (Fisher-information identities are standard; interpreting them as “gravitational metrics” is heuristic).

**Statement:** For a Gibbs family $\rho_\theta(x)=Z(\theta)^{-1}e^{-\Phi(x;\theta)}$ satisfying standard regularity conditions (differentiate under the integral sign; finite moments), the Fisher information metric on parameter space satisfies

$$
g_{\mu\nu}(\theta)=\mathbb{E}_{\rho_\theta}\!\left[\partial_\mu \log\rho_\theta\,\partial_\nu \log\rho_\theta\right]
=\mathrm{Cov}_{\rho_\theta}\!\left(\partial_\mu \Phi,\partial_\nu \Phi\right)
=\partial_\mu\partial_\nu\log Z(\theta).

$$
In Laplace/quadratic regimes (sharp concentration), this metric is controlled by second-order curvature data of $\Phi$ near dominant modes. Any identification of $g_{\mu\nu}$ with a spacetime/gravity metric is an analogy, not a generic theorem of the framework.
:::

:::{prf:proof}
**Step 1 (Equilibrium Distribution).**
$\rho_\theta(x) = \frac{1}{Z} e^{-\Phi(x; \theta)}$.

**Step 2 (Fisher Metric).**
$\log\rho_\theta(x)=-\Phi(x;\theta)-\log Z(\theta)$, so

$$
\partial_\mu \log\rho_\theta(x)= -\partial_\mu \Phi(x;\theta)+\mathbb{E}_{\rho_\theta}[\partial_\mu \Phi(\cdot;\theta)].

$$
Hence

$$
g_{\mu\nu}=\mathbb{E}_{\rho_\theta}\!\left[(\partial_\mu \log\rho_\theta)(\partial_\nu \log\rho_\theta)\right]
=\mathrm{Cov}_{\rho_\theta}\!\left(\partial_\mu \Phi,\partial_\nu \Phi\right).

$$

**Step 3 (Equivalence).**
Under the same regularity assumptions one also has $g_{\mu\nu}=\partial_\mu\partial_\nu\log Z(\theta)$. In Laplace/quadratic approximations, $\log Z$ is controlled by local second derivatives of $\Phi$ around dominant modes, which motivates the heuristic “Hessian” language in sharply concentrated regimes.
:::

:::{prf:metatheorem} Symmetry-Gauge Correspondence
:label: mt:symmetry-gauge

**Thin inputs:** $G^{\text{thin}}$.
**Permits:** $\mathrm{GC}_\nabla$ (N12), $\mathrm{Rep}_K$ (N11).

**Status:** Imported (agent gauge theory; Yang–Mills dynamics on the internal map).

**Statement:** If the agent’s internal update rule is required to be covariant under a local symmetry group on its
internal representations, then “differences” must be replaced by **covariant differences** with an explicit connection
field (parallel transporters on graph edges / covariant derivatives in the continuum). In the agent’s internal field
theory, this yields the Yang–Mills field equations for the connection dynamics (Theorem {prf:ref}`thm-yang-mills-equations`).
This is a statement about the agent’s internal map/fields, not about the external territory.
:::

:::{prf:proof}
This is the standard gauge-covariance construction, instantiated in the framework by Theorem
{prf:ref}`thm-yang-mills-equations`.
:::

:::{prf:metatheorem} Three-Tier Gauge Hierarchy
:label: mt:three-tier-gauge

**Thin inputs:** $G^{\text{thin}}$.
**Permits:** $\mathrm{GC}_\nabla$ (N12), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (the gauge principle is rigorous; the specific group identification is not).

**Statement:** Heuristically, different layers of symmetry in the solver (normalization/phase-like invariances,
orientation-like symmetries, and clustering/permutation structure) invite analogies to $U(1)$/$SU(2)$/$SU(3)$-type
organization. The rigorous part is the *existence of gauge-field dynamics on the internal map* under local covariance
requirements (Theorem {prf:ref}`thm-yang-mills-equations`); identifying the resulting gauge group with the Standard
Model is not claimed here.
:::

:::{prf:proof}
**Step 1 (Phase).**
The wavefunction $\psi$ is complex; phase rotation $e^{i\theta}$ is a $U(1)$ symmetry.

**Step 2 (Orientation).**
On a Riemannian manifold, the tangent bundle $O(d)$ reduces to spin structure $Spin(d)$. For 3D/4D effective spacetime, this yields weak isospin-like $SU(2)$ symmetry.

**Step 3 (Clustering).**
Local permutations of indistinguishable nodes in a cluster (the "quarks" of the graph) generate $S_3$ or embedded $SU(3)$ symmetries in the strong coupling limit.
:::

:::{prf:metatheorem} Antisymmetry-Fermion Theorem
:label: mt:antisymmetry-fermion

**Thin inputs:** $G^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11), $\mathrm{TB}_\pi$ (N8).

**Status:** Heuristic (antisymmetric structures suggest symplectic/fermionic formalisms in some representations; no “must be fermionic” implication is claimed).

**Statement:** Antisymmetric couplings ($w_{ij}=-w_{ji}$) naturally encode oriented flows/currents and can be represented using symplectic or Pfaffian/Grassmann formalisms in some path-integral constructions. This sketch uses the “fermion” analogy as an organizing intuition for antisymmetric interaction structure; it is not a theorem that antisymmetric graph weights force a fermionic QFT.
:::

:::{prf:proof}
**Step 1 (Path Integral).**
Bosonic integrals require positive definite quadratic forms ($\int e^{-xAx}$).
Antisymmetric forms vanish or are ill-defined for commuting variables.

**Step 2 (Grassmann Variables).**
For anticommuting variables $\theta$, $\int e^{-\theta^T A \theta} = \text{Pf}(A) = \sqrt{\det A}$.
This is non-zero for antisymmetric $A$.

**Step 3 (Exclusion Principle).**
Grassmann anticommutation implies $\psi(x)^2 = 0$ in the formalism, which matches the combinatorics of exclusion in fermionic models. This motivates using fermionic/Pfaffian language to represent antisymmetric couplings, but any identification with physical fermions or a literal Pauli principle for IG currents is interpretive.
:::

:::{prf:metatheorem} Scalar-Reward Duality (Higgs Mechanism)
:label: mt:scalar-reward-duality

**Thin inputs:** $\Phi^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{SC}_{\partial c}$ (N5).

**Status:** Heuristic (analogy to symmetry-breaking patterns; not a derived field-theory statement).

**Statement:** The potential field $\Phi$ can be viewed as a scalar “order parameter” whose minima structure induces symmetry-breaking patterns; in this analogy, “mass generation” corresponds to increased stiffness/spectral gap in certain directions once a symmetry is broken. This is a correspondence, not a claim that a Higgs mechanism is literally implemented.
:::

:::{prf:proof}
**Step 1 (Mexican Hat).**
If the potential $\Phi(\phi) = \lambda(|\phi|^2 - v^2)^2$ has a non-zero minimum $v$.
The ground state is $\phi_0 = v$.

**Step 2 (Expansion).**
Expanding around the vacuum $\phi = v + h$, the covariant derivative term $|D_\mu \phi|^2$ generates mass terms $\frac{1}{2} (gv)^2 A_\mu^2$ for the gauge field $A$.

**Step 3 (Optimization Stiffness).**
Physically, this means the solver becomes "stiff" or "massive" in certain directions—deviations cost high energy. This constrains the search to a sub-manifold.
:::

:::{prf:metatheorem} IG-Quantum Isomorphism
:label: mt:ig-quantum-isomorphism

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (OS reconstruction is conditional on reflection positivity and Euclidean invariance; these are not guaranteed by generic IG dynamics).

**Statement:** If an IG-based continuum limit defines Euclidean correlation functions satisfying the Osterwalder–Schrader axioms (notably reflection positivity and Euclidean invariance), then the OS reconstruction theorem yields a corresponding Lorentzian QFT. This sketch does not assert that generic Fractal Gas dynamics satisfy OS axioms; it records the conditional bridge if such axioms can be verified in a specific instantiation.
:::

:::{prf:proof}
**Step 1 (Reflection Positivity).**
Assume the Euclidean correlation functions (Schwinger functions) of the IG-based continuum limit satisfy the Osterwalder–Schrader axioms, including reflection positivity. (This is a nontrivial verification step and is not implied by generic Markov-chain reversibility.)

**Step 2 (Euclidean Invariance).**
Assume the Schwinger functions are Euclidean covariant/invariant in the sense required by the OS axioms (e.g. invariance under Euclidean group actions in the limit).

**Step 3 (Wick Rotation).**
Then the OS reconstruction theorem constructs a Hilbert space, a vacuum state, and quantum fields whose Wightman functions are obtained by analytic continuation (Wick rotation) of the Schwinger functions. This provides a **conditional bridge**: verifying OS axioms for a specific IG limit is sufficient to obtain a corresponding Lorentzian QFT; no claim is made that generic Fractal Gas dynamics satisfy those axioms.
:::

:::{prf:metatheorem} Spectral Action Principle
:label: mt:spectral-action-principle

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (noncommutative-geometry correspondence; requires a fully specified spectral triple and scaling regime).

**Statement:** In noncommutative-geometry settings with a specified spectral triple $(\mathcal{A},\mathcal{H},D)$, one can define a spectral action $\mathrm{Tr}(f(D/\Lambda))$ whose heat-kernel expansion produces curvature invariants. The “reproduces Einstein–Hilbert + Standard Model” claim is specific to particular spectral triples and is not derived here for generic Information Graph constructions.
:::

:::{prf:proof}
**Step 1 (Dirac Operator).**
Construct the Dirac operator $D$ from the graph Laplacian and spin connection. $D^2 \approx \Delta$.

**Step 2 (Heat Kernel Expansion).**
$\mathrm{Tr}(e^{-t D^2}) \sim \frac{1}{t^{d/2}} \sum a_n t^n$.
The coefficients $a_n$ are geometric invariants: Volume, Scalar Curvature $R$, $R^2$, etc.

**Step 3 (Physical Lagrangian).**
For a cutoff function $f$, $\mathrm{Tr}(f(D/\Lambda)) \approx \Lambda^4 \text{Vol} + \Lambda^2 \int R + \dots$
The dominant terms are Cosmological Constant and Gravity. Lower terms govern gauge couplings.
:::

:::{prf:metatheorem} Geometric Diffusion Isomorphism
:label: mt:geometric-diffusion-isomorphism

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $\mathrm{Cap}_H$ (N6), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Framework (operator transport via Expansion Adjunction) + conditional classical asymptotics.

**Statement (framework).**
The discrete diffusion operator defined by the IG Dirichlet form (graph Laplacian) is transported to the continuum via
the **Expansion Adjunction** (Theorem {prf:ref}`thm-expansion-adjunction`): the promoted metric-measure substrate
$(M,g_{\mathrm{eff}},\mathfrak{m}_{\mathrm{eff}})$ carries a canonical Dirichlet form (Cheeger energy) whose generator is
the continuum Laplacian/heat flow on $M$. Under a stiffness certificate (e.g. LSI lifting via
Theorem {prf:ref}`thm-lsi-thin-permit`), this diffusion has the standard functional-inequality control expected of a
geometric heat semigroup.

**Statement (smooth regime; classical identification).**
If the promoted object lies in a smooth compact Riemannian-manifold regime and the IG is built in a standard
manifold-learning scaling, then the rescaled graph Laplacian $\Delta_G$ converges (in Dirichlet-form/Mosco sense) to
the Laplace–Beltrami operator $\Delta_M$, and the short-time heat-trace expansion recovers geometric invariants:

$$
\mathrm{Tr}(e^{-t\Delta})
\sim
\frac{\mathrm{Vol}(M)}{(4\pi t)^{d/2}}
\left(1 + \frac{t}{6} S_R + O(t^2)\right).

$$
:::

:::{prf:proof}
The framework statement is the categorical transport of the discrete Dirichlet form to the promoted continuum object
via Theorem {prf:ref}`thm-expansion-adjunction`, with stiffness control supplied by the thin LSI lifting protocol
{prf:ref}`thm-lsi-thin-permit`.

The smooth-regime identification (Mosco/Dirichlet-form convergence and heat-kernel asymptotics) is classical once a
specific manifold-learning scaling and a smooth limit object are specified.
:::

:::{prf:metatheorem} Spectral Distance Isomorphism
:label: mt:spectral-distance-isomorphism

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (true for commutative spectral triples under standard hypotheses; depends on how $D$ is constructed from the IG).

**Statement:** For commutative spectral triples associated to a smooth compact Riemannian manifold, the Connes spectral distance recovers the geodesic distance. Whether an IG-constructed Dirac operator achieves this in a given discretization is conditional on the spectral-triple construction and convergence regime.
$$ d_D(x,y) = \sup_{f: \|[D,f]\| \le 1} |f(x) - f(y)| = d_{\text{geo}}(x,y) $$
:::

:::{prf:proof}
**Step 1 (Gradient Constraint).**
The condition $\|[D,f]\| \le 1$ is equivalent to $|\nabla f| \le 1$ almost everywhere.

**Step 2 (Monge-Kantorovich).**
In the commutative smooth case, the Connes distance reduces to the supremum of $|f(x)-f(y)|$ over 1-Lipschitz $f$. By the Kantorovich–Rubinstein duality, this equals $W_1(\delta_x,\delta_y)$, which is $d_{\mathrm{geo}}(x,y)$ on a geodesic metric space.

**Step 3 (Recovery).**
Thus, given the full commutative spectral triple $(\mathcal{A},\mathcal{H},D)$ satisfying the standard hypotheses, the geodesic distance is recovered from operator data. (The spectrum alone is not sufficient; the operator and algebra structure matter.)
:::

:::{prf:metatheorem} Dimension Spectrum
:label: mt:dimension-spectrum

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{SC}_\lambda$ (N4), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (dimension spectrum is a noncommutative-geometry notion; relation to Hausdorff dimension is model-dependent for fractals).

**Statement:** In noncommutative geometry one defines a dimension spectrum via poles of $\zeta_D(s)=\mathrm{Tr}(|D|^{-s})$ for an appropriate Dirac-type operator. In commutative smooth settings the leading pole recovers the manifold dimension; for fractal/singular spaces the relation to Hausdorff dimension is conditional on the chosen spectral triple and regularity assumptions.
:::

:::{prf:proof}
**Step 1 (Zeta Function).**
Define $\zeta(s) = \sum \lambda_k^{-s/2}$.
For a manifold of dimension $d$, $\lambda_k \sim k^{2/d}$.
Thus the sum diverges when $s/2 \cdot 2/d = 1 \implies s=d$.

**Step 2 (Complex Poles).**
For certain self-similar/fractal operators, $\zeta_D(s)$ admits a meromorphic continuation with additional (sometimes complex) poles (“complex dimensions” in the sense of Lapidus and collaborators). When present, these poles encode oscillatory scaling corrections (lacunarity/log-periodic effects), but their existence and location are model-dependent.

**Step 3 (Universality).**
The dimension spectrum is invariant under unitary equivalence of the chosen spectral triple, hence coordinate-free **within that model**. However, changing the spectral triple on the same underlying space can change the spectrum; it should be treated as a descriptor of the chosen noncommutative-geometry model, not an automatic invariant of the raw set.
:::

### Spacetime and Gravity

:::{prf:metatheorem} Scutoidal Interpolation
:label: mt:scutoidal-interpolation

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (Pachner-move connectivity is conditional; the “causal foliation” interpretation requires extra structure).

**Statement:** Conditional on working with triangulations of a fixed manifold class, any two triangulations are related by a finite sequence of bistellar (Pachner) moves. Interpreting these local remeshings as “scutoid” transitions provides a discrete interpolation picture; ensuring a well-defined **causal** foliation requires additional input beyond pure topology (time-slicing, admissible moves, and compatibility with the update rule).
:::

:::{prf:proof}
**Step 1 (Pachner Moves).**
Any two triangulations of the same manifold are related by a finite sequence of Pachner moves (e.g., 2-3 flip, 1-4 flip).

**Step 2 (Spacetime Prism).**
The transition corresponds to filling the prism $M \times [0,1]$ with simplices.
A Pachner move is the cross-section of a higher-dimensional simplex (4-simplex in 3+1D).

**Step 3 (Scutoid Geometry).**
One can *visualize* intermediate cross-sections of such a prism as scutoid-like prisms that change adjacency while preserving basic topological invariants, but this is an optional geometric metaphor; the rigorous content is Pachner-move connectivity in Step 1.
:::

:::{prf:metatheorem} Regge-Scutoid Dynamics
:label: mt:regge-scutoid

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{TB}_\pi$ (N8).

**Status:** Heuristic (Regge-calculus analogy; no variational principle for the implemented solver is asserted).

**Statement:** Heuristically, certain rewiring/remeshing dynamics can be compared to Regge-calculus moves that redistribute curvature concentration in a simplicial complex. This sketch does not assert that the Information Graph optimizer literally minimizes a Regge action; it records the analogy that local topology changes can relieve geometric “defects” in a discrete curvature proxy.
$$ S_{\text{Regge}} = \sum_h L_h \epsilon_h \to \min $$
:::

:::{prf:proof}
**Step 1 (Regge Action).**
For a simplicial complex, the curvature is concentrated at hinges (bones). $\epsilon_h = 2\pi - \sum \theta_i$.
The action is proportional to the integral of scalar curvature.

**Step 2 (Flip Energy).**
A bistellar flip changes the edge lengths and connectivity.
If a region has high defect (curvature), a flip can reduce the action in Regge-calculus settings.
Example: Flipping a diagonal in a non-convex quadrilateral relaxes tension.

**Step 3 (Relaxation).**
Regge calculus admits Monte Carlo / Metropolis–Hastings schemes that propose local flips and accept/reject based on a discrete action. A Fractal Gas rewiring rule can be *compared* to this if (and only if) it is explicitly defined as an accept/reject move driven by a Regge-like defect energy; this is not asserted for generic implementations.
:::

:::{prf:metatheorem} Bio-Geometric Isomorphism
:label: mt:bio-geometric-isomorphism

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic (analogy between tissue vertex models and graph rewiring; no biological claim is proved).

**Statement:** Heuristically, certain local operations in vertex-model tissue simulations (T1 neighbor exchanges, cell division) resemble local graph rewiring operations (edge flips, vertex splits) that appear in Fractal Gas implementations. This is an analogy for “surgery-like” updates of a discrete adjacency structure; it is not a claim of a canonical isomorphism nor a biological law for the solver.
:::

:::{prf:proof}
**Step 1 (Tissue mechanics).**
Epithelial tissues minimize surface energy. Cell shape changes (T1 transitions) are driven by stress relaxation.

**Step 2 (Information Geometry).**
In the Fractal Gas, "cells" are clusters of particles (Voronoi regions).
High local error (stress) triggers cloning (cell division).

**Step 3 (Analogy only).**
Some local graph operations used in optimization/sampling (edge flips, vertex splits) are similar in *combinatorial shape* to moves used in vertex-model simulations. The correspondence is not canonical and depends on how “cells” and energies are defined; no claim is made that swarm dynamics obey the same geometric laws as biological tissues.
:::

:::{prf:metatheorem} Antichain-Surface Correspondence
:label: mt:antichain-surface

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{TB}_\pi$ (N8), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (becomes conditional under faithful-embedding/sprinkling hypotheses from causal set theory).

**Statement:** In causal set theory, under hypotheses of faithful embedding (e.g. Poisson sprinkling into a globally hyperbolic spacetime and appropriate scaling limits), maximal antichains can correspond to discrete analogues of spacelike hypersurfaces, and their cardinality can approximate spatial volume/area proxies. This sketch records that conditional correspondence, not a general theorem for arbitrary IG dynamics.
:::

:::{prf:proof}
**Step 1 (Antichains).**
An antichain is a set of elements where no two are causally related (no path exists). This represents "space" at an instant of time.

**Step 2 (Continuum Limit).**
Under faithful embedding hypotheses (e.g. Poisson sprinkling at fixed density into a globally hyperbolic spacetime), the cardinality of suitably chosen antichains concentrates around a deterministic quantity proportional to the spacelike hypersurface volume/area proxy (with proportionality depending on sprinkling density and dimension). The precise scaling law and error bounds are part of causal-set limit theorems and are not asserted here without those hypotheses.

**Step 3 (Foliation).**
A consistent sequence of antichains can be used as a discrete “slicing” in faithful-embedding regimes, but recovering continuum ADM structure requires additional inputs (choice of time function, compatibility conditions, and limit theorems). This block records only the conditional correspondence.
:::

:::{prf:principle} Holographic Bound (Causal Information Bound)
:label: mt:holographic-bound

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{Cap}_H$ (N6), $\mathrm{Rep}_K$ (N11), $C_\mu$ (N3).

**Status:** Imported (agent geometry; holographic area law).

**Statement:** The maximum grounded information that can be stored in the promoted bulk is bounded by boundary area in
Levin-length units (Theorem {prf:ref}`thm-causal-information-bound`). In particular, bulk capacity scales as
$\mathrm{Area}(\partial M)$ rather than $\mathrm{Vol}(M)$. The discrete cut-capacity picture is a proxy for this bound;
the rigorous statement is the metric-law-derived area law.
:::

:::{prf:proof}
Immediate from Theorem {prf:ref}`thm-causal-information-bound` (and the discussion/proof of the discrete proxy in
`thm:causal-horizon-lock`).
:::

:::{prf:metatheorem} Quasi-Stationary Distribution Sampling (Killed Kernels and Fleming–Viot)
:label: mt:quasi-stationary-distribution-sampling

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Conditional (standard QSD / Fleming–Viot theory).

**Setup (killing):** Let $(X_k)_{k\ge 0}$ be a Markov chain on a state space $E$ with a cemetery state $\partial$ and killing time $\tau_\partial=\inf\{k\ge 0: X_k=\partial\}$. Let $Q$ be the corresponding **sub-Markov kernel** on $E$:

$$
Q(x,A):=\mathbb{P}_x(X_1\in A,\ X_1\neq \partial),\qquad A\subseteq E.

$$

**Definition (QSD):** A probability measure $\nu$ on $E$ is a quasi-stationary distribution if there exists $\alpha\in(0,1)$ such that

$$
\nu Q=\alpha\,\nu.

$$
Equivalently, if $X_0\sim \nu$ then for all $k\ge 0$,

$$
\mathcal{L}(X_k\mid k<\tau_\partial)=\nu,\qquad \mathbb{P}(k<\tau_\partial)=\alpha^k.

$$

**Statement (existence/uniqueness and convergence):** Under standard hypotheses ensuring tightness and mixing—e.g. a Foster–Lyapunov drift condition and a small-set/Doeblin minorization on a compact set (precisely the kind of inputs tracked by $D_E$ and $C_\mu$)—a QSD exists, is unique, and the conditioned law converges to it at an exponential rate (in total variation / Wasserstein, depending on the model).

**Statement (particle approximation):** The constant-$N$ Fleming–Viot particle system (kill-at-$\partial$ + instantaneous resampling from survivors) provides an empirical-measure approximation of the QSD: as $N\to\infty$, the empirical measure converges to the nonlinear normalized semigroup, and its stationary point is the QSD $\nu$.

**Remark (what is and is not “canonical”):** QSD sampling is canonical **for the killed dynamics** $(Q,\partial)$ (up to measurable isomorphism). It does not imply a unique “diffeomorphism-invariant discretization” beyond that standard invariance.
:::

:::{prf:proof}
This is a standard theorem family in QSD theory. One route to the result is spectral: under compactness/regularity assumptions, the sub-Markov operator $Q$ has a principal eigenvalue/eigenmeasure pair $(\alpha,\nu)$, and a spectral gap gives exponential convergence of the conditioned semigroup. Another route uses Harris-type drift/minorization to prove existence/uniqueness and quantitative convergence. Fleming–Viot convergence follows from propagation-of-chaos arguments for interacting particle systems approximating the normalized semigroup.
:::

:::{prf:metatheorem} Modular-Thermal Isomorphism
:label: mt:modular-thermal

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (operator-algebraic QFT correspondence; requires a specified observable algebra and state).

**Statement:** The modular flow $\sigma_t^\phi$ of the local algebra of observables generates the time evolution. The state satisfies the KMS condition with respect to this flow, implying an intrinsic temperature (Unruh effect).
:::

:::{prf:proof}
**Step 1 (Tomita-Takesaki Theory).**
For a von Neumann algebra $\mathcal{A}$ and state $\Omega$, there exists a modular automorphism group $\sigma_t$.
$\Delta^{it} A \Delta^{-it}$.

**Step 2 (KMS Condition).**
The state $\Omega$ behaves like a thermal state $e^{-\beta H}$ with respect to the modular Hamiltonian $H = -\log \Delta$.

**Step 3 (Geometry).**
In curved spacetime (Rindler wedge), the modular flow corresponds to the boost generator. The geometric horizon induces an effective temperature proportional to surface gravity.
:::

:::{prf:metatheorem} Thermodynamic Gravity Principle
:label: mt:thermodynamic-gravity

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Cap}_H$ (N6), $\mathrm{Rep}_K$ (N11).

**Status:** Imported (agent geometry; cognitive field equation for the internal metric).

**Statement:** For the agent’s internal latent geometry, stationarity of a capacity-constrained curvature functional under
boundary grounding implies an Einstein-like field equation for the internal metric (Theorem
{prf:ref}`thm-capacity-constrained-metric-law`):

$$
R_{ij} - \frac{1}{2}R\,G_{ij} + \Lambda G_{ij} = \kappa\,T_{ij},

$$
where $T_{ij}$ is the (internal) risk tensor induced by the reward/value field. This is a statement about the agent’s
optimal internal map under interface capacity constraints, not a claim about the external territory obeying general
relativity.
:::

:::{prf:proof}
This is Theorem {prf:ref}`thm-capacity-constrained-metric-law`.
:::

:::{prf:metatheorem} Inevitability of General Relativity
:label: mt:inevitability-gr

**Thin inputs:** all thin objects.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Rep}_K$ (N11).

**Status:** Imported (agent geometry; GR-like equations are a constraint on the internal map).

**Statement:** We do not claim the external territory is governed by general relativity. The rigorous claim is
agent-internal: if an agent maintains a boundary-grounded representation while operating near the causal information
limit, then its optimal internal metric must satisfy the capacity-constrained metric law (Theorem
{prf:ref}`thm-capacity-constrained-metric-law`), i.e. an Einstein-like equation relating curvature to a source term. In
this precise sense, “GR” is **cognitively necessary** as an efficient internal map under information-theoretic
constraints.
:::

:::{prf:proof}
Immediate from Theorem {prf:ref}`thm-capacity-constrained-metric-law` (as a stationarity condition of the internal
capacity-constrained variational problem).
:::

:::{prf:metatheorem} Virial-Cosmological Transition
:label: mt:virial-cosmological

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic (cosmology analogy; no physical phase transition is derived from the solver).

**Statement:** Heuristically, one can compare “bound” regimes (strong confinement/low effective temperature) to virialized equilibria and “unbound” regimes (high diffusion/weak confinement) to expansion. This is an analogy for solver behavior across energy/temperature scales, not a claim of a literal cosmological phase transition.
:::

:::{prf:proof}
**Step 1 (Virial Theorem).**
For bound systems: $2K + U = 0$. $\rho$ is stationary.
This corresponds to $\Lambda_{eff} \approx 0$ or attractive gravity.

**Step 2 (Dark Energy).**
If diffusion dominates (high entropy production), the system expands.
The acceleration $\ddot{a} > 0$ corresponds to a positive cosmological constant $\Lambda > 0$.

**Step 3 (Transition).**
A crossover analogy can be drawn when a “boundary entropy” proxy is comparable to a “bulk entropy” proxy. Any claim that the solver tunes a cosmological constant is interpretive; no tuning mechanism is derived here.
:::

:::{prf:metatheorem} Flow with Surgery
:label: mt:flow-with-surgery

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Cap}_H$ (N6), $\mathrm{TB}_\pi$ (N8).

**Status:** Heuristic-to-conditional (Ricci flow with surgery is conditional on geometric hypotheses; the resampling correspondence is interpretive).

**Statement:** Conditional on being in a regime where an effective Ricci-flow description is meaningful, Ricci flow can be continued through singularities via surgery (Perelman’s theory). The analogy to Fractal Gas is that killing/resampling can remove “high-curvature/high-energy” regions and allow continued evolution; the correspondence is interpretive rather than a proved equivalence.
:::

:::{prf:proof}
**Step 1 (Singularity Formation).**
Finite time singularities occur where curvature blows up (neck pinching).
In the graph, this is a collapsing cluster or disconnected component.

**Step 2 (Surgery).**
Remove the high-curvature region and cap the holes.
In Fractal Gas: kill unstably high-energy particles and renormalization.

**Step 3 (Continuation).**
Perelman’s theory gives a well-posed continuation for Ricci flow with surgery once surgery parameters/schedules are fixed. Any correspondence to a concrete Fractal Gas implementation requires explicitly identifying (i) a curvature proxy, (ii) an update rule that removes/rewires “high-curvature” regions, and (iii) a scale schedule; this is not automatic and is not asserted here.
:::

:::{prf:metatheorem} Agency-Geometry Unification
:label: mt:agency-geometry

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{GC}_T$ (N16), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic-to-conditional (control–geometry dualities exist in specified settings; “dual” is interpretive without a concrete model).

**Statement:** In certain control problems, cost minimization can be reformulated as geodesic motion for an appropriate metric (e.g. Jacobi/Maupertuis metrics in conservative settings or information-geometric metrics in statistical control). This block records the conditional pattern; a specific equivalence requires an explicit dynamics/cost model and the corresponding geometric structure.
$$ \min_{\pi} J(\pi) \iff \delta \int ds = 0 $$
:::

:::{prf:proof}
**Step 1 (Control Hamiltonian).**
Optimal control defines a Hamiltonian $H(x, p)$.
Trajectories satisfy Hamilton's equations.

**Step 2 (Maupertuis Principle).**
For conservative systems (or fixed energy), the trajectories are geodesics of the Jacobi metric $g_{ij} = 2(E-V) M_{ij}$.

**Step 3 (Curvature as Constraint).**
High cost regions act as "hills" (positive curvature) that deflects the agent. The agent "perceives" the problem difficulty as geometric curvature. Constructing a solver is measuring the geometry.
:::

### Thermodynamics and Statistical Mechanics

:::{prf:definition} Logarithmic Sobolev Inequality (LSI)
:label: def:lsi

**Origin:** `hypostructure.md`, Ch 6 (General Theory).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7).

**Status:** Definition.

A measure $\mu$ on a metric space $(X, d)$ satisfies the **Logarithmic Sobolev Inequality (LSI)** with constant $\kappa > 0$ if for all smooth $f$:
$$ \text{Ent}_\mu(f^2) \leq \frac{2}{\kappa} \int |\nabla f|^2 d\mu $$
where $\text{Ent}_\mu(f^2) = \int f^2 \log f^2 \, d\mu - \left(\int f^2 d\mu\right) \log\left(\int f^2 d\mu\right)$ is the entropy functional.

**Significance:**
- LSI controls the rate of convergence to equilibrium (exponential in time)
- It implies a spectral gap: $\lambda_1 \geq \kappa$
- It suppresses "bad" topological sectors by concentrating measure
- LSI is stronger than Poincaré inequality and implies Gaussian concentration
:::

:::{prf:metatheorem} The Spectral Generator
:label: mt:spectral-generator

**Origin:** `hypostructure.md`, Ch 6 (General Theory).

**Thin inputs:** $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6).

**Status:** Conditional (Bakry–Émery criterion; requires $C^2$ regularity and uniform convexity).

**Assumptions:**
1. The dissipation potential $\mathfrak{D}$ is $C^2$ on the region of interest.
2. There exists $\kappa > 0$ such that $\nabla^2 \mathfrak{D} \succeq \kappa I$ uniformly.

**Statement.** Positive Hessian of dissipation $\nabla^2 \mathfrak{D} \succ 0$ enforces a spectral gap and LSI. Specifically:
1. The spectral gap is bounded below: $\lambda_1 \geq \inf_x \lambda_{\min}(\nabla^2 \mathfrak{D}(x))$
2. LSI holds with constant $\kappa = \inf_x \lambda_{\min}(\nabla^2 \mathfrak{D}(x))$
3. This guarantees exponential convergence to the safe manifold
4. It prevents stiffness breakdown (Mode S.D) by maintaining uniform mixing
:::

:::{prf:proof}
**Step 1 (Bakry–Émery Curvature).**
The Bakry–Émery $\Gamma_2$ operator measures the "curvature" of the diffusion. For a generator $\mathcal{L} = \Delta - \nabla V \cdot \nabla$, the curvature-dimension condition $CD(K, \infty)$ holds if $\Gamma_2(f, f) \geq K \Gamma(f, f)$ for all $f$, where $\Gamma(f, f) = |\nabla f|^2$.

**Step 2 (Hessian Bound Implies Curvature).**
When $\nabla^2 V \succeq K I$ (uniform convexity), the $CD(K, \infty)$ condition holds with the same constant. This is the standard Bakry–Émery criterion for log-concave measures.

**Step 3 (LSI from Curvature).**
The Bakry–Émery theorem states that $CD(K, \infty)$ with $K > 0$ implies LSI with constant $\kappa = K$. This follows from the $\Gamma$-calculus and semigroup interpolation.

**Step 4 (Spectral Gap from LSI).**
LSI implies Poincaré inequality with the same constant, hence spectral gap $\lambda_1 \geq \kappa$.
:::

:::{prf:metatheorem} LSI for Particle Systems
:label: mt:lsi-particle-systems

**Origin:** `hypostructure.md`, Ch 6 (General Theory).

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $C_\mu$ (N3).

**Status:** Conditional (requires explicit convexity/repulsion hypotheses).

**Assumptions:**
1. The confining potential $\Phi_{\text{conf}}(x_i)$ is strictly convex: $\nabla^2 \Phi_{\text{conf}} \succeq c_0 I$ for some $c_0 > 0$.
2. OR: The pairwise interactions are repulsive: $\nabla^2 \Phi_{\text{pair}}(|x_i - x_j|) \succeq 0$.

**Statement.** For interacting particle systems, strict convexity of the confining potential (or repulsive pairwise interactions) implies LSI. By the **Otto-Villani theorem**, LSI implies Transport-Entropy inequalities (Talagrand $T_2$), guaranteeing concentration of measure.

**Consequences:**
1. **Exponential Ergodicity:** The particle system converges exponentially fast to equilibrium.
2. **Concentration:** Empirical observables concentrate around their means with Gaussian tails.
3. **Propagation of Chaos:** In the mean-field limit, particles become asymptotically independent.
:::

:::{prf:proof}
**Step 1 (Confining Case).**
For a single particle with potential $V(x)$ satisfying $\nabla^2 V \succeq c_0 I$, the Gibbs measure $\mu \propto e^{-V}$ satisfies LSI with constant $c_0$ (direct Bakry–Émery).

**Step 2 (Many-Body Extension).**
For $N$ non-interacting particles in a convex potential, LSI tensorizes: the product measure satisfies LSI with the same constant. For weakly interacting particles, perturbation arguments (Holley–Stroock) preserve LSI with a modified constant.

**Step 3 (Repulsive Interactions).**
Repulsive interactions (log-concave pair potentials like Riesz gases) preserve or strengthen log-concavity. The total Hamiltonian $H = \sum_i \Phi_{\text{conf}}(x_i) + \sum_{i<j} \Phi_{\text{pair}}(|x_i - x_j|)$ remains convex.

**Step 4 (Otto–Villani Transport-Entropy).**
LSI with constant $\kappa$ implies the Talagrand $T_2$ inequality:
$$W_2^2(\nu, \mu) \leq \frac{2}{\kappa} H(\nu | \mu)$$
This bounds the Wasserstein distance to equilibrium by the relative entropy, giving Gaussian concentration for Lipschitz functions.
:::

:::{prf:metatheorem} Fisher-Hessian Isomorphism (Thermodynamics)
:label: mt:fisher-hessian-thermo

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{LS}_\sigma$ (N7).

**Status:** Heuristic-to-conditional (Ruppeiner metric is standard in equilibrium thermodynamics; relating it directly to $\nabla^2\Phi$ depends on the ensemble/coordinates and Gaussian approximations).

**Statement:** In equilibrium thermodynamics, the Ruppeiner metric is defined (in entropy representation) by the Hessian

$$
g_{ij}=-\frac{\partial^2 S}{\partial E_i\,\partial E_j}.

$$
In Gaussian/Laplace regimes for Gibbs families, this metric is related to fluctuation covariances and to Hessians of appropriate thermodynamic potentials (free energies) in the chosen coordinates. The schematic identification $g_{ij}\propto \nabla^2\Phi$ should be read as an approximation valid when $\Phi$ plays the role of a quadratic effective potential in the coordinates used.
:::

:::{prf:proof}
**Step 1 (Einstein Fluctuation Formula).**
The probability of a fluctuation from equilibrium is $P(\delta x) \propto \exp(\delta S / k_B) \approx \exp(-\frac{1}{2} g_{ij} \delta x^i \delta x^j)$.

**Step 2 (Hessian).**
Expanding the potential $\Phi$ around the minimum: $\Phi \approx \Phi_0 + \frac{1}{2} \nabla^2 \Phi (\delta x)^2$.
Thus $g_{ij} \propto \nabla^2 \Phi$.

**Step 3 (Stability).**
Positive definiteness of the metric (Stiffness permit) ensures thermodynamic stability (convexity of free energy).
:::

:::{prf:metatheorem} Scalar Curvature Barrier
:label: mt:scalar-curvature-barrier

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (Ruppeiner-curvature interpretations are conditional; relating curvature bounds to solver stability is interpretive).

**Statement:** In thermodynamic geometry, scalar curvature is often interpreted as a proxy for interaction strength/correlation volume in certain model classes; near critical points it can diverge. If one is in a regime where such interpretations apply and curvature remains bounded, Gaussian/mean-field approximations are more plausible. This is a conditional diagnostic, not a universal barrier theorem for all Fractal Gas instantiations.
:::

:::{prf:proof}
**Step 1 (Interaction Length).**
Ruppeiner curvature $R$ is related to the correlation volume $\xi^d$.
$R \sim \xi^d$.

**Step 2 (Critical Point).**
At a critical point, correlation length diverges $\xi \to \infty$, so $R \to \infty$.
The breakdown of the Law of Large Numbers occurs here.

**Step 3 (Gap Condition).**
The spectral gap condition (Stiffness) bounds the correlation length $\xi < 1/\sqrt{\lambda_1}$. This implies finiteness of $R$, guaranteeing the system remains in the "gas" phase (or stable "solid" phase) away from critical boundaries.
:::

:::{prf:metatheorem} GTD Equivalence Principle
:label: mt:gtd-equivalence

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $D_E$ (N1), $\mathrm{Rep}_K$ (N11).

**Status:** Heuristic (geometrothermodynamics is a specific formalism; Legendre invariance does not automatically imply representation-independence of a solver).

**Statement:** GTD proposes Legendre-invariant geometric structures on the space of equilibrium states. This block records the analogy that some thermodynamic predictions should be representation/ensemble-invariant; applying that idea to a concrete Fractal Gas requires specifying the ensemble, potential, and observables being compared.
:::

:::{prf:proof}
**Step 1 (Legendre Invariance).**
Construct a contact manifold with coordinates $(\Phi, x, \nabla \Phi)$.
A Legendre transform is a change of coordinates preserving the contact structure.

**Step 2 (Quevedo Metric).**
Define a metric $G$ on the space of equilibrium states that transforms as a tensor under Legendre maps.
$G = (\Phi - x \nabla \Phi) \nabla^2 \Phi$.

**Step 3 (Physical Meaning).**
The curvature of this metric encodes interaction independent of the control parameters used to probe it. This ensures "Observer Universality" extends to thermodynamic observation.
:::

:::{prf:metatheorem} Tikhonov Regularization
:label: mt:tikhonov-regularization

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{SC}_{\partial c}$ (N5), $\mathrm{Cap}_H$ (N6).

**Status:** Heuristic-to-conditional (regularization improves conditioning; geometric curvature claims are model-dependent).

**Statement:** Adding a Tikhonov regularizer (weight decay) $\Phi_{reg} = \Phi + \lambda \|x\|^2$ smooths the thermodynamic geometry, preventing curvature divergence and ensuring compact level sets (Cap_H).
:::

:::{prf:proof}
**Step 1 (Hessian Modification).**
$\nabla^2 \Phi_{reg} = \nabla^2 \Phi + 2\lambda I$.
This shifts the spectrum $\text{spec}(\nabla^2 \Phi) \to \text{spec}(\nabla^2 \Phi) + 2\lambda$.

**Step 2 (Conditioning).**
Even if $\nabla^2 \Phi$ has zero eigenvalues (flat directions/Goldstone modes), the regularized Hessian is strictly positive definite. Condition number improves.

**Step 3 (Curvature Bound).**
Since the metric determinant is bounded away from zero, the scalar curvature (involving inverse metric) remains bounded. Singularities are resolved.
:::

:::{prf:metatheorem} Convex Hull Resolution
:label: mt:convex-hull-resolution

**Thin inputs:** $\Phi^{\text{thin}}$.
**Permits:** $\mathrm{Cap}_H$ (N6), $\mathrm{TB}_O$ (N9).

**Status:** Conditional (convex-envelope/Maxwell constructions in equilibrium statistical mechanics; requires an equilibrium/large-system regime).

**Statement:** Thermodynamic equilibrium is determined by the convex hull of the potential (Maxwell construction). Non-convexities in $\Phi$ (instabilities) are bridged by phase coexistence, effectively flattening the geometry to its convex envelope $\Phi^{**}$.
:::

:::{prf:proof}
**Step 1 (Legendre-Fenchel).**
The Free Energy $F(\beta)$ is the Legendre transform of $\Phi(E)$. $F$ is always concave.
Transforming back yields $\Phi^{**}$, the convex envelope.

**Step 2 (Phase Separation).**
In regions where $\Phi > \Phi^{**}$, the system separates into a mixture of pure phases (tangent points).
The effective potential sensed by macroscopic observers is $\Phi^{**}$.

**Step 3 (Stability).**
Global stability is restoring; microscopic instabilities correspond to interface formation (domain walls) which cost energy, driving the system to the convex hull solution.
:::

### Additional Physics Bounds

:::{prf:metatheorem} Holographic Power Bound
:label: mt:holographic-power-bound

**Thin inputs:** $\mathcal{X}^{\text{thin}}$.
**Permits:** $\mathrm{Cap}_H$ (N6), $\mathrm{LS}_\sigma$ (N7).

**Status:** Heuristic (physics-bound analogy; not a proved counting theorem for generic kinetic power sets).

**Statement:** The number of physical states in the Kinetic Power Set $\mathcal{P}(X)$ scales as entropy $e^S$, not as the full power set $2^{e^S}$.
Most subsets of states are physically inaccessible (energy forbidden).
:::

:::{prf:proof}
**Step 1 (Typical Set).**
By the Asymptotic Equipartition Property, the typical set $A_\epsilon^{(n)}$ has size $2^{nH}$.
The full configuration space size is $|\mathcal{X}|^n$.
If $H < \log |\mathcal{X}|$, the fraction of occupied states vanishes.

**Step 2 (Energy constraint).**
Constraint $\langle \Phi \rangle < E_{max}$ restricts the system to a thin shell in phase space.
The volume of this shell grows as $E^{dim}$, whereas the volume of the hypercube grows exponentially in dimension.

**Step 3 (Holography).**
Combining with the Holographic bound, $S \propto \text{Area}$. The accessible state space dimension is effectively lower than the bulk dimension. The "Power Set" is an illusion of non-physical kinematics.
:::

:::{prf:theorem} Trotter-Suzuki Product Formula
:label: thm:trotter-suzuki

**Thin inputs:** $\Phi^{\text{thin}}$, $\mathfrak{D}^{\text{thin}}$.
**Permits:** $\mathrm{Rep}_K$ (N11), $\mathrm{SC}_\lambda$ (N4).

**Status:** Conditional (Trotter–Kato product formula under generator/domain conditions).

**Statement:** Under standard semigroup hypotheses for generators $K$ (diffusion) and $V$ (multiplication/killing potential), the propagator for the combined operator $H = K + V$ is the limit of alternating steps:
$$e^{-t(K+V)} = \lim_{n\to\infty} (e^{-\frac{t}{n}K} e^{-\frac{t}{n}V})^n$$
This provides a mathematical justification for split-step schemes at the level of the limiting semigroup; a specific solver’s convergence still depends on how its discrete mutation/selection steps approximate $e^{-tK}$ and $e^{-tV}$.
:::

:::{prf:proof}
**Step 1 (Operator Norm).**
For bounded operators, the error is $O(t^2/n)$.
$\| e^{t(A+B)} - (e^{tA/n} e^{tB/n})^n \| \le \frac{t^2}{2n} \|[A,B]\| e^{t(\|A\|+\|B\|)}$.

**Step 2 (Unbounded Operators).**
For Laplacian $K$ and potentials $V$ bounded below, the formula holds on a core of the domain (Kato-Trotter theorem).

**Step 3 (Simulation).**
This proves the limiting semigroup identity under the stated generator/domain conditions. Convergence of a particular split-step *algorithm* requires verifying that its mutation/selection steps approximate $e^{-tK}$ and $e^{-tV}$ in the appropriate topology and that the discretization matches the continuous-time model.
:::

:::{prf:theorem} Global Convergence (Darwinian Ratchet)
:label: thm:global-convergence

**Thin inputs:** $\mathcal{X}^{\text{thin}}$, $\Phi^{\text{thin}}$.
**Permits:** $C_\mu$ (N3), $D_E$ (N1).

**Status:** Conditional (Laplace principle / simulated annealing under ergodicity + schedule hypotheses).

**Statement:** If the potential $\Phi$ has a unique global minimum $x^*$ and sublevel sets are compact, the Fractal Gas measure converges weakly to the delta measure $\delta_{x^*}$ as $\beta \to \infty$ (annealing limit).
$$ \lim_{\beta \to \infty} \rho_\beta = \delta_{x^*} $$
:::

:::{prf:proof}
**Step 1 (Large Deviation).**
The equilibrium density is $\rho_\beta(x) \propto e^{-\beta \Phi(x)}$.
The probability of being outside a neighborhood $U$ of $x^*$ is bounded by $e^{-\beta (\min_{X \setminus U} \Phi - \Phi(x^*))}$.

**Step 2 (Gap).**
Since $\Phi(x) > \Phi(x^*)$ for all $x \notin U$, the exponent is negative.
As $\beta \to \infty$, the probability vanishes exponentially.

**Step 3 (Weak convergence).**
Since $\rho_\beta(U^c)\to 0$ for every neighborhood $U$ of $x^*$, we have $\rho_\beta\Rightarrow \delta_{x^*}$ as $\beta\to\infty$ (e.g. by the Portmanteau theorem / standard Laplace principle arguments). Time-inhomogeneous simulated annealing schedules (e.g. Geman–Geman) are a separate statement about a specific dynamics and are not needed for the equilibrium $\beta\to\infty$ limit above.
:::

:::{prf:theorem} Spontaneous Symmetry Breaking
:label: thm:ssb

**Thin inputs:** $\Phi^{\text{thin}}$, $G^{\text{thin}}$.
**Permits:** $\mathrm{LS}_\sigma$ (N7), $\mathrm{SC}_{\partial c}$ (N5).

**Status:** Heuristic-to-conditional (SSB is sharp in thermodynamic/infinite-volume limits; finite-$N$ systems do not literally break symmetry).

**Statement:** In infinite-volume/thermodynamic limits of symmetric systems, one can have multiple extremal equilibrium states selecting a particular “vacuum” and breaking a symmetry of the Hamiltonian/potential; in that setting Goldstone modes correspond to low-cost fluctuations along the orbit of minimizers. For finite-$N$ Fractal Gas instances, symmetry breaking should be interpreted as long-lived metastable localization near one symmetry-related basin rather than literal non-invariant stationary laws.
:::

:::{prf:proof}
**Step 1 (Degeneracy).**
Symmetry implies $\Phi(g x^*) = \Phi(x^*)$. The set of minima is the manifold $M_0 \cong G/H$.

**Step 2 (Instability).**
Any perturbation breaks the symmetry explicitly. The "center of mass" of the swarm cannot remain at the unstable symmetric point (maximum of free energy in the order parameter space).

**Step 3 (Goldstone Bosons).**
The Hessian has null eigenvectors tangent to $M_0$. These are massless modes (diffusive with no drift). Transverse modes are massive (restoring force).
:::
