{
  "document_id": "16_convergence_mean_field",
  "stage": "directives",
  "directive_type": "conjecture",
  "generated_at": "2025-11-08T17:07:43.258422+00:00",
  "count": 1,
  "items": [
    {
      "directive_type": "conjecture",
      "label": "conj-ldp-mean-field",
      "title": "Large Deviations Principle for Mean-Field Limit (Unproven)",
      "start_line": 213,
      "end_line": 231,
      "header_lines": [
        214
      ],
      "content_start": 216,
      "content_end": 230,
      "content": "216: :label: conj-ldp-mean-field\n217: \n218: As $N \\to \\infty$, the empirical measure $\\mu_N = \\frac{1}{N} \\sum_{i=1}^N \\delta_{(x_i, v_i)}$ is conjectured to satisfy a large deviations principle with rate function:\n219: \n220: $$\n221: I(\\rho) = \\begin{cases}\n222: D_{\\text{KL}}(\\rho \\| \\rho_\\infty) & \\text{if } \\rho \\ll \\rho_\\infty \\\\\n223: +\\infty & \\text{otherwise}\n224: \\end{cases}\n225: \n226: $$\n227: \n228: This means deviations from the mean-field limit $\\rho_\\infty$ would be exponentially suppressed with probability $\\sim e^{-N \\cdot D_{\\text{KL}}}$.\n229: \n230: **Status**: This LDP has **not been proven** for systems with state-dependent killing and proportional revival. Standard LDP results (Dawson-Gärtner, Dupuis-Ellis) apply to conservative systems or systems with fixed jump rates, not QSD-conditioned dynamics.",
      "metadata": {
        "label": "conj-ldp-mean-field"
      },
      "section": "## 1. Why Mean-Field KL-Convergence is Valuable",
      "raw_directive": "213: For McKean-Vlasov systems, KL-divergence is the **fundamental** metric:\n214: \n215: :::{prf:conjecture} Large Deviations Principle for Mean-Field Limit (Unproven)\n216: :label: conj-ldp-mean-field\n217: \n218: As $N \\to \\infty$, the empirical measure $\\mu_N = \\frac{1}{N} \\sum_{i=1}^N \\delta_{(x_i, v_i)}$ is conjectured to satisfy a large deviations principle with rate function:\n219: \n220: $$\n221: I(\\rho) = \\begin{cases}\n222: D_{\\text{KL}}(\\rho \\| \\rho_\\infty) & \\text{if } \\rho \\ll \\rho_\\infty \\\\\n223: +\\infty & \\text{otherwise}\n224: \\end{cases}\n225: \n226: $$\n227: \n228: This means deviations from the mean-field limit $\\rho_\\infty$ would be exponentially suppressed with probability $\\sim e^{-N \\cdot D_{\\text{KL}}}$.\n229: \n230: **Status**: This LDP has **not been proven** for systems with state-dependent killing and proportional revival. Standard LDP results (Dawson-Gärtner, Dupuis-Ellis) apply to conservative systems or systems with fixed jump rates, not QSD-conditioned dynamics.\n231: ",
      "_registry_context": {
        "stage": "directives",
        "document_id": "16_convergence_mean_field",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 1. Why Mean-Field KL-Convergence is Valuable"
      }
    }
  ]
}