{
  "chapter_index": 7,
  "section_id": "## 2. Analysis of the Finite-N to Mean-Field Transition",
  "directive_count": 3,
  "hints": [
    {
      "directive_type": "theorem",
      "label": "thm-finite-n-lsi-preservation",
      "title": "Finite-N LSI Preservation (Proven)",
      "start_line": 515,
      "end_line": 535,
      "header_lines": [
        516
      ],
      "content_start": 518,
      "content_end": 534,
      "content": "518: :label: thm-finite-n-lsi-preservation\n519: \n520: The N-particle cloning operator $\\Psi_{\\text{clone}}: \\Sigma_N \\to \\Sigma_N$ **preserves the LSI** with controlled constant degradation. Specifically, if a distribution $\\mu$ on $\\Sigma_N$ satisfies:\n521: \n522: $$\n523: D_{\\text{KL}}(\\mu \\| \\pi) \\le C_{\\text{LSI}} \\cdot I(\\mu \\| \\pi)\n524: $$\n525: \n526: then the push-forward $\\Psi_{\\text{clone}}^* \\mu$ satisfies:\n527: \n528: $$\n529: D_{\\text{KL}}(\\Psi_{\\text{clone}}^* \\mu \\| \\Psi_{\\text{clone}}^* \\pi) \\le C'_{\\text{LSI}} \\cdot I(\\Psi_{\\text{clone}}^* \\mu \\| \\Psi_{\\text{clone}}^* \\pi)\n530: $$\n531: \n532: where $C'_{\\text{LSI}} = C_{\\text{LSI}} \\cdot (1 + O(\\delta^2))$ for cloning noise variance $\\delta^2$.\n533: \n534: **Key mechanism**: The cloning operator introduces small Gaussian noise ($\\delta \\xi$) when copying walkers, which regularizes the Fisher information and prevents LSI constant blow-up.",
      "metadata": {
        "label": "thm-finite-n-lsi-preservation"
      },
      "section": "## 2. Analysis of the Finite-N to Mean-Field Transition",
      "raw_directive": "515: From [09_kl_convergence.md](../1_euclidean_gas/09_kl_convergence.md), the finite-N cloning operator $\\Psi_{\\text{clone}}$ satisfies:\n516: \n517: :::{prf:theorem} Finite-N LSI Preservation (Proven)\n518: :label: thm-finite-n-lsi-preservation\n519: \n520: The N-particle cloning operator $\\Psi_{\\text{clone}}: \\Sigma_N \\to \\Sigma_N$ **preserves the LSI** with controlled constant degradation. Specifically, if a distribution $\\mu$ on $\\Sigma_N$ satisfies:\n521: \n522: $$\n523: D_{\\text{KL}}(\\mu \\| \\pi) \\le C_{\\text{LSI}} \\cdot I(\\mu \\| \\pi)\n524: $$\n525: \n526: then the push-forward $\\Psi_{\\text{clone}}^* \\mu$ satisfies:\n527: \n528: $$\n529: D_{\\text{KL}}(\\Psi_{\\text{clone}}^* \\mu \\| \\Psi_{\\text{clone}}^* \\pi) \\le C'_{\\text{LSI}} \\cdot I(\\Psi_{\\text{clone}}^* \\mu \\| \\Psi_{\\text{clone}}^* \\pi)\n530: $$\n531: \n532: where $C'_{\\text{LSI}} = C_{\\text{LSI}} \\cdot (1 + O(\\delta^2))$ for cloning noise variance $\\delta^2$.\n533: \n534: **Key mechanism**: The cloning operator introduces small Gaussian noise ($\\delta \\xi$) when copying walkers, which regularizes the Fisher information and prevents LSI constant blow-up.\n535: "
    },
    {
      "directive_type": "problem",
      "label": "prob-finite-n-vs-mean-field",
      "title": "Critical Differences Between Finite-N and Mean-Field",
      "start_line": 549,
      "end_line": 561,
      "header_lines": [
        550
      ],
      "content_start": 552,
      "content_end": 560,
      "content": "552: :label: prob-finite-n-vs-mean-field\n553: \n554: | Aspect | Finite-N Cloning | Mean-Field Revival | Implication |\n555: |:-------|:-----------------|:-------------------|:------------|\n556: | **Dimensionality** | Finite $(Nd)$ | Infinite (function space) | Compactness arguments may fail |\n557: | **Noise** | Explicit $\\delta \\xi$ noise | No explicit noise in $\\mathcal{R}$ | Fisher information regularization unclear |\n558: | **Nonlinearity** | Linear in empirical measure | Nonlinear (division by $\\\\|\\rho\\\\|_{L^1}$) | May create singularities |\n559: | **Discreteness** | Discrete selection among N walkers | Continuous sampling from $\\rho$ | Combinatorial structure lost |\n560: | **Companion selection** | Finite sample ($j \\in \\mathcal{A}$) | Integral over $\\rho$ | Correlations differ |",
      "metadata": {
        "label": "prob-finite-n-vs-mean-field"
      },
      "section": "## 2. Analysis of the Finite-N to Mean-Field Transition",
      "raw_directive": "549: **Potential issues**:\n550: \n551: :::{prf:problem} Critical Differences Between Finite-N and Mean-Field\n552: :label: prob-finite-n-vs-mean-field\n553: \n554: | Aspect | Finite-N Cloning | Mean-Field Revival | Implication |\n555: |:-------|:-----------------|:-------------------|:------------|\n556: | **Dimensionality** | Finite $(Nd)$ | Infinite (function space) | Compactness arguments may fail |\n557: | **Noise** | Explicit $\\delta \\xi$ noise | No explicit noise in $\\mathcal{R}$ | Fisher information regularization unclear |\n558: | **Nonlinearity** | Linear in empirical measure | Nonlinear (division by $\\\\|\\rho\\\\|_{L^1}$) | May create singularities |\n559: | **Discreteness** | Discrete selection among N walkers | Continuous sampling from $\\rho$ | Combinatorial structure lost |\n560: | **Companion selection** | Finite sample ($j \\in \\mathcal{A}$) | Integral over $\\rho$ | Correlations differ |\n561: "
    },
    {
      "directive_type": "theorem",
      "label": "thm-data-processing",
      "title": "Data Processing Inequality (Standard Result)",
      "start_line": 575,
      "end_line": 587,
      "header_lines": [
        576
      ],
      "content_start": 578,
      "content_end": 586,
      "content": "578: :label: thm-data-processing\n579: \n580: For any Markov kernel $K: \\mathcal{X} \\to \\mathcal{P}(\\mathcal{Y})$:\n581: \n582: $$\n583: D_{\\text{KL}}(K \\rho \\| K \\sigma) \\le D_{\\text{KL}}(\\rho \\| \\sigma)\n584: $$\n585: \n586: where $K\\rho(y) = \\int K(x \\to y) \\rho(x) dx$ is the push-forward.",
      "metadata": {
        "label": "thm-data-processing"
      },
      "section": "## 2. Analysis of the Finite-N to Mean-Field Transition",
      "raw_directive": "575: This is analogous to updating a prior $\\rho$ by conditioning on the event \"walker survives.\" Bayesian updates are known to be KL-contractive:\n576: \n577: :::{prf:theorem} Data Processing Inequality (Standard Result)\n578: :label: thm-data-processing\n579: \n580: For any Markov kernel $K: \\mathcal{X} \\to \\mathcal{P}(\\mathcal{Y})$:\n581: \n582: $$\n583: D_{\\text{KL}}(K \\rho \\| K \\sigma) \\le D_{\\text{KL}}(\\rho \\| \\sigma)\n584: $$\n585: \n586: where $K\\rho(y) = \\int K(x \\to y) \\rho(x) dx$ is the push-forward.\n587: "
    }
  ],
  "validation": {
    "ok": true,
    "errors": []
  }
}