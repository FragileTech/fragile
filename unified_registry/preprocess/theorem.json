[
  {
    "label": "thm-geometry-guarantees-variance",
    "title": "Geometric Structure Guarantees Measurement Variance",
    "type": "theorem",
    "nl_statement": "There exists a positional variance threshold \\(R^2_{\\mathrm{var}} > 0\\) and a positive \\(\\varepsilon\\)-dependent constant \\(\\kappa_{\\text{meas}}(\\epsilon) > 0\\) such that for any swarm with \\(k \\geq 2\\) alive walkers, if the internal positional variance satisfies \\(\\mathrm{Var}(x) \\ge R^2_{\\mathrm{var}}\\), then the expected empirical variance of the raw distance-to-companion measurements is \\(\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\kappa_{\\text{meas}}(\\epsilon) > 0\\).",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\kappa_{\\text{meas}}(\\epsilon) > 0"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": "The expected empirical variance of the raw distance-to-companion measurements is uniformly bounded below.",
      "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\kappa_{\\text{meas}}(\\epsilon) > 0"
    },
    "variables": [
      {
        "symbol": "k",
        "name": "number of alive walkers",
        "description": "Number of alive walkers in the swarm",
        "constraints": [
          ">= 2"
        ],
        "tags": [
          "swarm",
          "count"
        ]
      },
      {
        "symbol": "\\epsilon",
        "name": "epsilon",
        "description": "Parameter influencing the constant kappa",
        "constraints": [],
        "tags": [
          "parameter",
          "dependence"
        ]
      },
      {
        "symbol": "R^2_{\\mathrm{var}}",
        "name": "positional variance threshold",
        "description": "Threshold for internal positional variance",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "threshold",
          "variance"
        ]
      },
      {
        "symbol": "\\kappa_{\\text{meas}}(\\epsilon)",
        "name": "measurement constant",
        "description": "Positive constant depending on epsilon",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "constant",
          "bound"
        ]
      },
      {
        "symbol": "x",
        "name": "positions",
        "description": "Internal positions of the swarm",
        "constraints": [],
        "tags": [
          "position",
          "swarm"
        ]
      },
      {
        "symbol": "d",
        "name": "distance-to-companion",
        "description": "Raw distance-to-companion measurements",
        "constraints": [],
        "tags": [
          "distance",
          "measurement"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Swarm positions are in a Euclidean or metric space allowing variance computation.",
        "confidence": 0.9
      },
      {
        "text": "The pairing operator produces valid companion pairings for distance measurements.",
        "confidence": 0.8
      }
    ],
    "local_refs": [
      "def-greedy-pairing-algorithm"
    ],
    "proof": {
      "label": "proof-thm-geometry-guarantees-variance",
      "title": null,
      "type": "proof",
      "proves": "thm-geometry-guarantees-variance",
      "proof_type": "construction",
      "proof_status": "complete",
      "content_markdown": ":label: proof-thm-geometry-guarantees-variance\n\n**Proof.**\n\nThe proof is constructive and proceeds in three stages. First, we invoke the proven geometric consequences for a high-variance swarm, which guarantee a separation in the *expected* distance measurements between the high-error and low-error subpopulations. Second, we prove that this separation between subpopulation means necessitates a non-zero variance in the set of all individual expected distances. Finally, we use the Law of Total Variance to show that this provides a direct lower bound for the total expected measurement variance.\n\n**1. Invoking Proven Guarantees on Expected Distances in the `d_alg` Metric.**\n\nThe premise of the theorem is that $Var_x \\geq R^{2}_var$. From the results established in Chapter 6, this premise has two direct consequences:\n\n*   **Geometric Structure ({prf:ref}`cor-vvarx-to-high-error-fraction` & {prf:ref}`lem-geometric-separation-of-partition`):** The swarm's alive set `A_k` is guaranteed to contain a **unified high-error set** `H_k` and a **low-error set** `L_k = A_k \\ H_k`. The fractional sizes of these sets, `f_H = |H_k|/k` and `f_L = |L_k|/k`, are bounded below by positive, N-uniform constants. Furthermore, these sets possess distinct geometric separation properties in the **algorithmic phase-space metric (`d_alg`)**, as quantified by the constants $D_H(\\varepsilon)$ and $R_L(\\varepsilon)$.\n\n*   **Algorithmic Perception ({prf:ref}`lem-greedy-preserves-signal`):** The `Sequential Stochastic Greedy Pairing Operator`, when applied to this guaranteed geometric structure in `d_alg`, produces a statistical separation in the expected raw distance measurements for these two populations. Let $\\mu_d(H_k) = \\text{E}[d_i | i \\in H_k]$ be the mean expected distance for a high-error walker and $\\mu_d(L_k) = \\text{E}[d_j | j \\in L_k]$ be the mean for a low-error walker.\n\n    From {prf:ref}`lem-greedy-preserves-signal`, we have the bounds $\\mu_d(H_k) \\geq D_H(\\varepsilon)$ and $\\mu_d(L_k) \\leq R_L(\\varepsilon) + C_tail(\\varepsilon)$, where $C_tail(\\varepsilon)$ is a small, exponentially decaying error term accounting for boundary effects. As the separation $D_H(\\varepsilon) > R_L(\\varepsilon)$ is a required condition for a well-posed system (guaranteed by the Unified Condition from Section 6.5.4), we can choose parameters such that $D_H(\\varepsilon) - R_L(\\varepsilon)$ is large enough to dominate $C_tail(\\varepsilon)$.\n\n    We therefore define the guaranteed positive gap:\n\n\n$$\n\\kappa'_{\\text{gap}}(\\epsilon) := D_H(\\epsilon) - R_L(\\epsilon) - C_{\\text{tail}}(\\epsilon) > 0\n$$\n\n    This ensures:\n\n\n$$\n\\mu_d(H_k) - \\mu_d(L_k) \\ge \\kappa'_{\\text{gap}}(\\epsilon) > 0\n$$\n\n**2. From Subpopulation Mean Gap to Variance of Expectations.**\n\nLet `E_d` be the set of individual expected distances for all `k` alive walkers: `E_d = {E[d₁], E[d₂], ..., E[d_k]}`. We now prove that the gap between the subpopulation means, established above, forces the variance of this entire set, `Var(E_d)`, to be non-zero.\n\nThe variance of a set partitioned into two subsets (`H_k`, `L_k`) is bounded below by the squared difference of their means, weighted by their population fractions. This follows from the Law of Total Variance, which states that for any partition:\n\n$$\n\\operatorname{Var}(X) = \\operatorname{Var}_{\\text{within}}(X) + \\operatorname{Var}_{\\text{between}}(X)\n$$\n\nwhere the within-group variance `Var_within(X)` is always non-negative. Therefore, the total variance is bounded below by the between-group variance:\n\n$$\n\\operatorname{Var}(E_d) \\ge \\operatorname{Var}_{\\text{between}}(E_d) = f_H f_L (\\mu_d(H_k) - \\mu_d(L_k))^2\n$$\n\nSubstituting the guaranteed bounds from Step 1, we get a uniform lower bound on the variance of the *expected* raw distances:\n\n$$\n\\operatorname{Var}(E_d) \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2 > 0\n$$\n\n**3. From Variance of Expectations to Expected Variance (The Key Inequality).**\n\nThe final step is to prove the key inequality connecting the variance of the *expectations* to the expectation of the *variance*: $\\text{E}[\\text{Var}(d)] \\geq \\text{Var}(E_d)$.\n\nLet `d_i` denote the random distance measurement for walker `i`, and let $\\mu_i = \\text{E}[d_i]$ be its expectation. The empirical variance of the measurements is:\n\n$$\n\\operatorname{Var}(d) = \\frac{1}{k}\\sum_{i=1}^k (d_i - \\bar{d})^2\n$$\n\nwhere $bar{d} = (1/k) \\Sigma d_i$ is the sample mean.\n\nTaking expectations and using the fact that $\\text{E}[d_i] = \\mu_i$ and $\\text{E}[bar{d}] = bar{\\mu}$ where $bar{\\mu} = (1/k) \\Sigma \\mu_i$:\n\n$$\n\\mathbb{E}[\\operatorname{Var}(d)] = \\mathbb{E}\\left[\\frac{1}{k}\\sum_{i=1}^k (d_i - \\bar{d})^2\\right]\n$$\n\nWe decompose each squared deviation using the standard technique. For each walker $i$, we write:\n\n$$\n(d_i - \\bar{d})^2 = [(d_i - \\mu_i) + (\\mu_i - \\bar{d})]^2\n$$\n\nExpanding and taking expectations term by term:\n\n$$\n\\mathbb{E}[(d_i - \\bar{d})^2] = \\mathbb{E}[(d_i - \\mu_i)^2] + \\mathbb{E}[(\\mu_i - \\bar{d})^2] + 2\\mathbb{E}[(d_i - \\mu_i)(\\mu_i - \\bar{d})]\n$$\n\nThe **cross-term vanishes**: Since $\\mu_i$ is a constant (the expectation of $d_i$), we have:\n\n$$\n\\mathbb{E}[(d_i - \\mu_i)(\\mu_i - \\bar{d})] = (\\mu_i - \\mathbb{E}[\\bar{d}]) \\mathbb{E}[d_i - \\mu_i] = (\\mu_i - \\bar{\\mu}) \\cdot 0 = 0\n$$\n\nThe **first term** is simply the variance of $d_i$:\n\n$$\n\\mathbb{E}[(d_i - \\mu_i)^2] = \\operatorname{Var}(d_i)\n$$\n\nThe **second term** requires care because $\\mu_i$ is constant but $\\bar{d}$ is random. Using the standard variance decomposition for $(X - c)^2$ where $c$ is constant:\n\n$$\n\\mathbb{E}[(\\mu_i - \\bar{d})^2] = (\\mu_i - \\mathbb{E}[\\bar{d}])^2 + \\operatorname{Var}(\\bar{d}) = (\\mu_i - \\bar{\\mu})^2 + \\operatorname{Var}(\\bar{d})\n$$\n\nCombining these results:\n\n$$\n\\mathbb{E}[(d_i - \\bar{d})^2] = \\operatorname{Var}(d_i) + (\\mu_i - \\bar{\\mu})^2 + \\operatorname{Var}(\\bar{d})\n$$\n\nSumming over all $k$ walkers and dividing by $k$ gives the expected empirical variance:\n\n$$\n\\mathbb{E}[\\operatorname{Var}(d)] = \\frac{1}{k}\\sum_{i=1}^k \\mathbb{E}[(d_i - \\bar{d})^2] = \\underbrace{\\frac{1}{k}\\sum_{i=1}^k \\operatorname{Var}(d_i)}_{\\text{within-walker variance}} + \\underbrace{\\frac{1}{k}\\sum_{i=1}^k (\\mu_i - \\bar{\\mu})^2}_{\\text{= Var}(E_d)} + \\underbrace{\\operatorname{Var}(\\bar{d})}_{\\text{sample mean variance}}\n$$\n\nSince all three terms are non-negative, we immediately obtain the key inequality:\n\n$$\n\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d) = \\frac{1}{k}\\sum_{i=1}^k (\\mu_i - \\bar{\\mu})^2\n$$\n\nThis establishes the key inequality rigorously.\n\n**4. Final Assembly.**\n\nCombining the results from Steps 2 and 3:\n\n$$\n\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d) \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2\n$$\n\nWe define the final constant $\\kappa_meas(\\varepsilon) := f_H f_L (\\kappa'_{gap}(\\varepsilon))^{2}$. Since `f_H`, `f_L`, and $\\kappa'_gap(\\varepsilon)$ are all positive, N-uniform, $\\varepsilon$-dependent constants derived from the geometric analysis in Chapter 6, their product $\\kappa_meas(\\varepsilon)$ is also a positive, N-uniform, $\\varepsilon$-dependent constant.\n\nThis completes the proof. We have rigorously shown that a large internal positional variance is sufficient to guarantee a non-zero expected variance in the raw distance measurements.",
      "raw_directive": "3339: \n3340: :::\n3341: :::{prf:proof}\n3342: :label: proof-thm-geometry-guarantees-variance\n3343: \n3344: **Proof.**\n3345: \n3346: The proof is constructive and proceeds in three stages. First, we invoke the proven geometric consequences for a high-variance swarm, which guarantee a separation in the *expected* distance measurements between the high-error and low-error subpopulations. Second, we prove that this separation between subpopulation means necessitates a non-zero variance in the set of all individual expected distances. Finally, we use the Law of Total Variance to show that this provides a direct lower bound for the total expected measurement variance.\n3347: \n3348: **1. Invoking Proven Guarantees on Expected Distances in the `d_alg` Metric.**\n3349: \n3350: The premise of the theorem is that $Var_x \\geq R^{2}_var$. From the results established in Chapter 6, this premise has two direct consequences:\n3351: \n3352: *   **Geometric Structure ({prf:ref}`cor-vvarx-to-high-error-fraction` & {prf:ref}`lem-geometric-separation-of-partition`):** The swarm's alive set `A_k` is guaranteed to contain a **unified high-error set** `H_k` and a **low-error set** `L_k = A_k \\ H_k`. The fractional sizes of these sets, `f_H = |H_k|/k` and `f_L = |L_k|/k`, are bounded below by positive, N-uniform constants. Furthermore, these sets possess distinct geometric separation properties in the **algorithmic phase-space metric (`d_alg`)**, as quantified by the constants $D_H(\\varepsilon)$ and $R_L(\\varepsilon)$.\n3353: \n3354: *   **Algorithmic Perception ({prf:ref}`lem-greedy-preserves-signal`):** The `Sequential Stochastic Greedy Pairing Operator`, when applied to this guaranteed geometric structure in `d_alg`, produces a statistical separation in the expected raw distance measurements for these two populations. Let $\\mu_d(H_k) = \\text{E}[d_i | i \\in H_k]$ be the mean expected distance for a high-error walker and $\\mu_d(L_k) = \\text{E}[d_j | j \\in L_k]$ be the mean for a low-error walker.\n3355: \n3356:     From {prf:ref}`lem-greedy-preserves-signal`, we have the bounds $\\mu_d(H_k) \\geq D_H(\\varepsilon)$ and $\\mu_d(L_k) \\leq R_L(\\varepsilon) + C_tail(\\varepsilon)$, where $C_tail(\\varepsilon)$ is a small, exponentially decaying error term accounting for boundary effects. As the separation $D_H(\\varepsilon) > R_L(\\varepsilon)$ is a required condition for a well-posed system (guaranteed by the Unified Condition from Section 6.5.4), we can choose parameters such that $D_H(\\varepsilon) - R_L(\\varepsilon)$ is large enough to dominate $C_tail(\\varepsilon)$.\n3357: \n3358:     We therefore define the guaranteed positive gap:\n3359: \n3360: \n3361: $$\n3362: \\kappa'_{\\text{gap}}(\\epsilon) := D_H(\\epsilon) - R_L(\\epsilon) - C_{\\text{tail}}(\\epsilon) > 0\n3363: $$\n3364: \n3365:     This ensures:\n3366: \n3367: \n3368: $$\n3369: \\mu_d(H_k) - \\mu_d(L_k) \\ge \\kappa'_{\\text{gap}}(\\epsilon) > 0\n3370: $$\n3371: \n3372: **2. From Subpopulation Mean Gap to Variance of Expectations.**\n3373: \n3374: Let `E_d` be the set of individual expected distances for all `k` alive walkers: `E_d = {E[d₁], E[d₂], ..., E[d_k]}`. We now prove that the gap between the subpopulation means, established above, forces the variance of this entire set, `Var(E_d)`, to be non-zero.\n3375: \n3376: The variance of a set partitioned into two subsets (`H_k`, `L_k`) is bounded below by the squared difference of their means, weighted by their population fractions. This follows from the Law of Total Variance, which states that for any partition:\n3377: \n3378: $$\n3379: \\operatorname{Var}(X) = \\operatorname{Var}_{\\text{within}}(X) + \\operatorname{Var}_{\\text{between}}(X)\n3380: $$\n3381: \n3382: where the within-group variance `Var_within(X)` is always non-negative. Therefore, the total variance is bounded below by the between-group variance:\n3383: \n3384: $$\n3385: \\operatorname{Var}(E_d) \\ge \\operatorname{Var}_{\\text{between}}(E_d) = f_H f_L (\\mu_d(H_k) - \\mu_d(L_k))^2\n3386: $$\n3387: \n3388: Substituting the guaranteed bounds from Step 1, we get a uniform lower bound on the variance of the *expected* raw distances:\n3389: \n3390: $$\n3391: \\operatorname{Var}(E_d) \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2 > 0\n3392: $$\n3393: \n3394: **3. From Variance of Expectations to Expected Variance (The Key Inequality).**\n3395: \n3396: The final step is to prove the key inequality connecting the variance of the *expectations* to the expectation of the *variance*: $\\text{E}[\\text{Var}(d)] \\geq \\text{Var}(E_d)$.\n3397: \n3398: Let `d_i` denote the random distance measurement for walker `i`, and let $\\mu_i = \\text{E}[d_i]$ be its expectation. The empirical variance of the measurements is:\n3399: \n3400: $$\n3401: \\operatorname{Var}(d) = \\frac{1}{k}\\sum_{i=1}^k (d_i - \\bar{d})^2\n3402: $$\n3403: \n3404: where $bar{d} = (1/k) \\Sigma d_i$ is the sample mean.\n3405: \n3406: Taking expectations and using the fact that $\\text{E}[d_i] = \\mu_i$ and $\\text{E}[bar{d}] = bar{\\mu}$ where $bar{\\mu} = (1/k) \\Sigma \\mu_i$:\n3407: \n3408: $$\n3409: \\mathbb{E}[\\operatorname{Var}(d)] = \\mathbb{E}\\left[\\frac{1}{k}\\sum_{i=1}^k (d_i - \\bar{d})^2\\right]\n3410: $$\n3411: \n3412: We decompose each squared deviation using the standard technique. For each walker $i$, we write:\n3413: \n3414: $$\n3415: (d_i - \\bar{d})^2 = [(d_i - \\mu_i) + (\\mu_i - \\bar{d})]^2\n3416: $$\n3417: \n3418: Expanding and taking expectations term by term:\n3419: \n3420: $$\n3421: \\mathbb{E}[(d_i - \\bar{d})^2] = \\mathbb{E}[(d_i - \\mu_i)^2] + \\mathbb{E}[(\\mu_i - \\bar{d})^2] + 2\\mathbb{E}[(d_i - \\mu_i)(\\mu_i - \\bar{d})]\n3422: $$\n3423: \n3424: The **cross-term vanishes**: Since $\\mu_i$ is a constant (the expectation of $d_i$), we have:\n3425: \n3426: $$\n3427: \\mathbb{E}[(d_i - \\mu_i)(\\mu_i - \\bar{d})] = (\\mu_i - \\mathbb{E}[\\bar{d}]) \\mathbb{E}[d_i - \\mu_i] = (\\mu_i - \\bar{\\mu}) \\cdot 0 = 0\n3428: $$\n3429: \n3430: The **first term** is simply the variance of $d_i$:\n3431: \n3432: $$\n3433: \\mathbb{E}[(d_i - \\mu_i)^2] = \\operatorname{Var}(d_i)\n3434: $$\n3435: \n3436: The **second term** requires care because $\\mu_i$ is constant but $\\bar{d}$ is random. Using the standard variance decomposition for $(X - c)^2$ where $c$ is constant:\n3437: \n3438: $$\n3439: \\mathbb{E}[(\\mu_i - \\bar{d})^2] = (\\mu_i - \\mathbb{E}[\\bar{d}])^2 + \\operatorname{Var}(\\bar{d}) = (\\mu_i - \\bar{\\mu})^2 + \\operatorname{Var}(\\bar{d})\n3440: $$\n3441: \n3442: Combining these results:\n3443: \n3444: $$\n3445: \\mathbb{E}[(d_i - \\bar{d})^2] = \\operatorname{Var}(d_i) + (\\mu_i - \\bar{\\mu})^2 + \\operatorname{Var}(\\bar{d})\n3446: $$\n3447: \n3448: Summing over all $k$ walkers and dividing by $k$ gives the expected empirical variance:\n3449: \n3450: $$\n3451: \\mathbb{E}[\\operatorname{Var}(d)] = \\frac{1}{k}\\sum_{i=1}^k \\mathbb{E}[(d_i - \\bar{d})^2] = \\underbrace{\\frac{1}{k}\\sum_{i=1}^k \\operatorname{Var}(d_i)}_{\\text{within-walker variance}} + \\underbrace{\\frac{1}{k}\\sum_{i=1}^k (\\mu_i - \\bar{\\mu})^2}_{\\text{= Var}(E_d)} + \\underbrace{\\operatorname{Var}(\\bar{d})}_{\\text{sample mean variance}}\n3452: $$\n3453: \n3454: Since all three terms are non-negative, we immediately obtain the key inequality:\n3455: \n3456: $$\n3457: \\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d) = \\frac{1}{k}\\sum_{i=1}^k (\\mu_i - \\bar{\\mu})^2\n3458: $$\n3459: \n3460: This establishes the key inequality rigorously.\n3461: \n3462: **4. Final Assembly.**\n3463: \n3464: Combining the results from Steps 2 and 3:\n3465: \n3466: $$\n3467: \\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d) \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2\n3468: $$\n3469: \n3470: We define the final constant $\\kappa_meas(\\varepsilon) := f_H f_L (\\kappa'_{gap}(\\varepsilon))^{2}$. Since `f_H`, `f_L`, and $\\kappa'_gap(\\varepsilon)$ are all positive, N-uniform, $\\varepsilon$-dependent constants derived from the geometric analysis in Chapter 6, their product $\\kappa_meas(\\varepsilon)$ is also a positive, N-uniform, $\\varepsilon$-dependent constant.\n3471: \n3472: This completes the proof. We have rigorously shown that a large internal positional variance is sufficient to guarantee a non-zero expected variance in the raw distance measurements.\n3473: ",
      "strategy_summary": "The proof constructs a lower bound on the expected variance of distance measurements by first invoking geometric guarantees to establish a positive gap in expected distances between high- and low-error subpopulations, then using the law of total variance to bound the variance of these expectations from below, and finally deriving a key inequality that relates the expected empirical variance to this variance of expectations.",
      "conclusion": {
        "text": "A large internal positional variance (Var_x >= R_var^2) is sufficient to guarantee a non-zero expected variance in the raw distance measurements, bounded below by the positive constant kappa_meas(epsilon).",
        "latex": null
      },
      "assumptions": [
        {
          "text": "Var_x >= R_var^2 (high positional variance premise)",
          "latex": "Var_x \\geq R_{var}^2"
        },
        {
          "text": "Geometric separation in the d_alg metric with D_H(epsilon) > R_L(epsilon) guaranteed by the Unified Condition (Section 6.5.4)",
          "latex": "D_H(\\epsilon) > R_L(\\epsilon)"
        },
        {
          "text": "Positive fractional sizes f_H and f_L bounded below by N-uniform constants",
          "latex": null
        },
        {
          "text": "Application of Sequential Stochastic Greedy Pairing Operator preserves signal separation",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "invocation",
          "text": "Invoke geometric guarantees from Chapter 6 to establish unified high-error set H_k and low-error set L_k with positive fractions f_H and f_L, and distinct properties in d_alg metric quantified by D_H(epsilon) and R_L(epsilon). Use lem-greedy-preserves-signal to obtain separation in expected distances: mu_d(H_k) >= D_H(epsilon) and mu_d(L_k) <= R_L(epsilon) + C_tail(epsilon), yielding mu_d(H_k) - mu_d(L_k) >= kappa'_gap(epsilon) > 0.",
          "latex": null,
          "references": [
            "cor-vvarx-to-high-error-fraction",
            "lem-geometric-separation-of-partition",
            "lem-greedy-preserves-signal"
          ],
          "derived_statement": "mu_d(H_k) - mu_d(L_k) >= kappa'_gap(epsilon) > 0"
        },
        {
          "order": 2.0,
          "kind": "derivation",
          "text": "Apply the law of total variance to the set of expected distances E_d partitioned into H_k and L_k, yielding Var(E_d) >= f_H f_L (mu_d(H_k) - mu_d(L_k))^2 >= f_H f_L (kappa'_gap(epsilon))^2 > 0.",
          "latex": null,
          "references": [],
          "derived_statement": "Var(E_d) >= f_H f_L (kappa'_gap(epsilon))^2 > 0"
        },
        {
          "order": 3.0,
          "kind": "derivation",
          "text": "Decompose E[Var(d)] by expanding (d_i - bar d)^2 for each i, showing the cross-term vanishes, and obtaining E[Var(d)] = average Var(d_i) + Var(E_d) + Var(bar d), all terms non-negative, hence E[Var(d)] >= Var(E_d).",
          "latex": null,
          "references": [],
          "derived_statement": "E[Var(d)] >= Var(E_d)"
        },
        {
          "order": 4.0,
          "kind": "assembly",
          "text": "Combine steps: E[Var(d)] >= Var(E_d) >= f_H f_L (kappa'_gap(epsilon))^2, defining kappa_meas(epsilon) := f_H f_L (kappa'_gap(epsilon))^2 > 0 as the uniform lower bound.",
          "latex": null,
          "references": [],
          "derived_statement": "E[Var(d)] >= kappa_meas(epsilon) > 0"
        }
      ],
      "key_equations": [
        {
          "label": "eq-kappa-gap",
          "latex": "\\kappa'_{\\text{gap}}(\\epsilon) := D_H(\\epsilon) - R_L(\\epsilon) - C_{\\text{tail}}(\\epsilon) > 0",
          "role": "Guaranteed positive gap in subpopulation mean expected distances"
        },
        {
          "label": "eq-var-between",
          "latex": "\\operatorname{Var}(E_d) \\ge f_H f_L (\\mu_d(H_k) - \\mu_d(L_k))^2",
          "role": "Between-group variance lower bound from law of total variance"
        },
        {
          "label": "eq-key-inequality",
          "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d)",
          "role": "Key inequality linking expected variance to variance of expectations"
        },
        {
          "label": "eq-final-bound",
          "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2 = \\kappa_{\\text{meas}}(\\varepsilon)",
          "role": "Final lower bound on expected measurement variance"
        }
      ],
      "references": [
        "cor-vvarx-to-high-error-fraction",
        "lem-geometric-separation-of-partition",
        "lem-greedy-preserves-signal"
      ],
      "math_tools": [
        {
          "toolName": "Law of Total Variance",
          "field": "Probability and Statistics",
          "description": "Decomposes the total variance of a random variable into within-group and between-group components for a partitioned sample.",
          "roleInProof": "Applied to bound the variance of expected distances by the positive between-group variance due to subpopulation separation.",
          "levelOfAbstraction": "Theorem/Lemma",
          "relatedTools": []
        },
        {
          "toolName": "Decomposition of Expected Sample Variance",
          "field": "Probability and Statistics",
          "description": "Expands the expected value of the empirical variance into within-walker variances, variance of expectations, and variance of the sample mean.",
          "roleInProof": "Used to derive the inequality E[Var(d)] >= Var(E_d) by showing non-negative terms in the expansion.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Law of Total Variance"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "All constants (f_H, f_L, kappa'_gap) are positive, N-uniform, and epsilon-dependent, ensuring uniformity in the guarantees."
        }
      ],
      "gaps": [],
      "tags": [
        "variance-decomposition",
        "geometric-separation",
        "subpopulations",
        "expected-distances",
        "law-of-total-variance",
        "greedy-pairing",
        "constructive-proof"
      ],
      "document_id": "03_cloning",
      "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
      "span": {
        "start_line": 3339,
        "end_line": 3473,
        "content_start": 3342,
        "content_end": 3472,
        "header_lines": [
          3340
        ]
      },
      "metadata": {
        "label": "proof-thm-geometry-guarantees-variance"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 7,
        "chapter_file": "chapter_7.json",
        "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "geometry",
      "variance",
      "measurement",
      "greedy-pairing",
      "swarm",
      "stochastic",
      "expected-value"
    ],
    "content_markdown": ":label: thm-geometry-guarantees-variance\n\nLet the `Sequential Stochastic Greedy Pairing Operator` be defined as in {prf:ref}`def-greedy-pairing-algorithm`. There exists a positional variance threshold $R^2_{\\mathrm{var}} > 0$ and a positive, $\\varepsilon$-dependent constant $\\kappa_{\\text{meas}}(\\epsilon) > 0$ such that for any swarm with $k \\geq 2$ alive walkers:\n\nIf the internal positional variance of the swarm is large, $\\mathrm{Var}(x) \\ge R^2_{\\mathrm{var}}$, then the expected empirical variance of the raw distance-to-companion measurements is uniformly bounded below:\n\n$$\n\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\kappa_{\\text{meas}}(\\epsilon) > 0",
    "raw_directive": "3327: \n3328: #### 7.2.1 Guaranteed Measurement Variance from Geometric Structure\n3329: :::{prf:theorem} Geometric Structure Guarantees Measurement Variance\n3330: :label: thm-geometry-guarantees-variance\n3331: \n3332: Let the `Sequential Stochastic Greedy Pairing Operator` be defined as in {prf:ref}`def-greedy-pairing-algorithm`. There exists a positional variance threshold $R^2_{\\mathrm{var}} > 0$ and a positive, $\\varepsilon$-dependent constant $\\kappa_{\\text{meas}}(\\epsilon) > 0$ such that for any swarm with $k \\geq 2$ alive walkers:\n3333: \n3334: If the internal positional variance of the swarm is large, $\\mathrm{Var}(x) \\ge R^2_{\\mathrm{var}}$, then the expected empirical variance of the raw distance-to-companion measurements is uniformly bounded below:\n3335: \n3336: $$\n3337: \\mathbb{E}[\\operatorname{Var}(d)] \\ge \\kappa_{\\text{meas}}(\\epsilon) > 0\n3338: $$",
    "document_id": "03_cloning",
    "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
    "span": {
      "start_line": 3327,
      "end_line": 3338,
      "content_start": 3330,
      "content_end": 3337,
      "header_lines": [
        3328
      ]
    },
    "references": [
      "def-greedy-pairing-algorithm",
      "cor-vvarx-to-high-error-fraction",
      "lem-geometric-separation-of-partition",
      "lem-greedy-preserves-signal"
    ],
    "metadata": {
      "label": "thm-geometry-guarantees-variance"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 7,
      "chapter_file": "chapter_7.json",
      "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-derivation-of-stability-condition",
    "title": "Derivation of the Stability Condition for Intelligent Adaptation",
    "type": "theorem",
    "nl_statement": "Under the foundational axioms including non-deceptive landscapes and sufficient swarm positional variance, the algorithm's targeting mechanism is intelligent—meaning high-error walkers have systematically lower expected fitness than low-error walkers—if and only if the parameters satisfy the stability condition β ln(1 + κ_{mean,d'}(ε)/(g_{A,max} + η)) > α ln(1 + κ_{mean,r'}/η).",
    "equations": [
      {
        "label": "stability-condition",
        "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)"
      }
    ],
    "hypotheses": [
      {
        "text": "The system satisfies the foundational axioms, including the Axiom of Non-Deceptive Landscapes (EG-7).",
        "latex": null
      },
      {
        "text": "Swarm k has sufficiently large internal positional variance.",
        "latex": "\\mathrm{Var}_x(S_k) > R^2_{\\mathrm{var}}"
      }
    ],
    "conclusion": {
      "text": "The algorithm's targeting mechanism is intelligent (expected fitness of high-error walker systematically lower than low-error walker) if and only if the parameters (α, β, ε, etc.) satisfy the Stability Condition.",
      "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)"
    },
    "variables": [
      {
        "symbol": "\\alpha",
        "name": "alpha",
        "description": "Dynamics parameter influencing low-error targeting.",
        "constraints": [],
        "tags": [
          "parameter",
          "dynamics"
        ]
      },
      {
        "symbol": "\\beta",
        "name": "beta",
        "description": "Dynamics parameter influencing high-error targeting.",
        "constraints": [],
        "tags": [
          "parameter",
          "dynamics"
        ]
      },
      {
        "symbol": "\\varepsilon",
        "name": "epsilon",
        "description": "Error threshold parameter in the stability condition.",
        "constraints": [],
        "tags": [
          "parameter",
          "error"
        ]
      },
      {
        "symbol": "\\kappa_{\\text{mean},d'}(\\epsilon)",
        "name": "kappa_mean_d_prime",
        "description": "Mean curvature or density factor for deviated positions depending on epsilon.",
        "constraints": [],
        "tags": [
          "curvature",
          "density"
        ]
      },
      {
        "symbol": "g_{A,max}",
        "name": "g_A_max",
        "description": "Maximum gradient of the attraction function.",
        "constraints": [],
        "tags": [
          "gradient",
          "maximum"
        ]
      },
      {
        "symbol": "\\eta",
        "name": "eta",
        "description": "Noise or regularization parameter.",
        "constraints": [],
        "tags": [
          "noise",
          "regularization"
        ]
      },
      {
        "symbol": "\\kappa_{\\text{mean},r'}",
        "name": "kappa_mean_r_prime",
        "description": "Mean curvature or density factor for reference positions.",
        "constraints": [],
        "tags": [
          "curvature",
          "density"
        ]
      },
      {
        "symbol": "S_k",
        "name": "S_k",
        "description": "Swarm k positions.",
        "constraints": [],
        "tags": [
          "swarm",
          "positions"
        ]
      },
      {
        "symbol": "R^2_{\\mathrm{var}}",
        "name": "R_var_squared",
        "description": "Variance threshold radius squared.",
        "constraints": [],
        "tags": [
          "variance",
          "threshold"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The system is a well-posed Fragile Gas system with statistical analysis applicable to population fitness.",
        "confidence": 0.9
      },
      {
        "text": "Parameters α, β, ε are positive real numbers ensuring logarithmic terms are defined.",
        "confidence": 0.8
      }
    ],
    "local_refs": [
      "EG-7"
    ],
    "proof": {
      "label": "proof-thm-derivation-of-stability-condition",
      "title": null,
      "type": "proof",
      "proves": "thm-derivation-of-stability-condition",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":label: proof-thm-derivation-of-stability-condition\n\n**Proof.**\n\nThe proof proceeds in four stages. First, we formalize the condition for intelligent targeting in terms of the expected log-fitness of the high-error and low-error populations. Second, we decompose this condition to isolate the trade-off between the diversity and reward signals. Third, we derive rigorous, uniform bounds for these signal gaps under worst-case adversarial conditions. Finally, we assemble these bounds to derive the necessary and sufficient inequality.\n\n**1. The Formal Condition for Intelligent Targeting**\n\nFor the algorithm's targeting mechanism to be corrective, the high-error population `H_k` must, on average, be less fit than the low-error population `L_k = A_k \\setminus H_k`. Due to the multiplicative form of the fitness potential, $V_{\\text{fit}} = (d')^\\beta (r')^\\alpha$, the most robust way to analyze this condition is by comparing the expected logarithms of the fitness. The condition for intelligent targeting is therefore:\n\n$$\n\\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]\n$$\n\n**2. Decomposing the Condition into a Signal Trade-off**\n\nUsing the definition $ln(V_fit) = \\beta ln(d') + \\alpha ln(r')$ and the linearity of expectation, the condition from Step 1 becomes:\n\n$$\n\\beta \\mathbb{E}[\\ln(d')|H_k] + \\alpha \\mathbb{E}[\\ln(r')|H_k] < \\beta \\mathbb{E}[\\ln(d')|L_k] + \\alpha \\mathbb{E}[\\ln(r')|L_k]\n$$\n\nRearranging the terms to separate the contribution from the diversity signal and the reward signal yields the core trade-off inequality that must be satisfied:\n\n$$\n\\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right) \\quad (*)\n$$\n\nThis inequality states that the fitness advantage from the reliable diversity signal (LHS, with β > 0 from {prf:ref}`axiom-active-diversity`) must be strong enough to overcome the potential fitness advantage from a deceptive reward signal (RHS).\n\n**3. Deriving Uniform Bounds on the Signal Gaps**\n\nWe now find uniform bounds for the two parenthesized terms in inequality `(*)`. This is the critical step where we correctly apply {prf:ref}`lem-variance-to-gap` to establish rigorous bounds. These bounds must hold for any swarm configuration, including the most adversarial ones.\n\n*   **LHS: The Minimum Guaranteed Diversity Signal.**\n\n    The term `E[ln(d')|H_k] - E[ln(d')|L_k]` represents the guaranteed advantage in the diversity signal for the high-error population. We establish this through the following causal chain:\n\n    1. **From Geometry to Raw Measurement Variance:** A high-error state guarantees a raw measurement variance $\\text{E}[\\text{Var}(d)] \\geq \\kappa_meas(\\varepsilon) > 0$ (from [](#thm-geometry-guarantees-variance)).\n\n    2. **From Raw Variance to Rescaled Variance:** This raw variance propagates through the pipeline, guaranteeing a variance in the rescaled values $\\text{Var}(d') \\geq \\kappa_var(d') > 0$. The constant $\\kappa_var(d')$ is defined in terms of $\\kappa_meas(\\varepsilon)$ and the pipeline parameters via the gap propagation lemmas from Section 7.3.\n\n    3. **Signal-to-Noise Condition:** The Signal-to-Noise Condition $\\kappa_var(d') > Var_max(d')$ is satisfied by the choice of the gain parameter $\\gamma$ (from {prf:ref}`prop-satisfiability-of-snr-gamma`).\n\n    4. **Applying [](#lem-variance-to-mean-separation):** We now apply [](#lem-variance-to-mean-separation) to the set of rescaled diversity values `d'`. Let:\n        - `V = d'` (the total set of rescaled diversity values)\n        - `H = H_k` and `L = L_k` (the partition)\n        - The premise $\\text{Var}(V) \\geq \\kappa_var$ is met with $\\kappa_var = \\kappa_var(d')$\n        - The premise $\\kappa_var > Var_max$ is met by the Signal-to-Noise Condition\n\n    5. **Result from [](#lem-variance-to-mean-separation):** This yields a guaranteed lower bound on the separation between the subset means:\n\n\n$$\n|\\mathbb{E}[d'|H_k] - \\mathbb{E}[d'|L_k]| \\ge \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')}\n$$\n\n    6. **Define the Mean Gap Constant:** We define this entire N-uniform lower bound as:\n\n\n$$\n\\kappa_{\\text{mean},d'}(\\epsilon) := \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')} > 0\n$$\n\n    7. **From Mean Separation to Logarithmic Separation:** The smallest possible logarithmic gap corresponding to this minimal mean separation occurs when the values are compressed at the top of their allowed range, $[\\eta, g_A,max + \\eta]$. This provides a uniform lower bound on the reliable signal:\n\n\n$$\n\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right)\n$$\n\n*   **RHS: The Maximum Adversarial Reward Signal.**\n\n    Symmetrically, we apply the same logic to find an upper bound on the term `E[ln(r')|L_k] - E[ln(r')|H_k]`, which represents the maximum potential advantage from a deceptive reward signal. A potential adversarial raw gap $\\kappa_r'$ leads, through the application of [](#lem-variance-to-mean-separation) to the reward channel, to a maximum possible rescaled mean gap of $\\kappa_{\\text{mean},r'}$. The largest possible logarithmic gap corresponding to this reward separation occurs when the values are compressed at the bottom of their range. This gives a uniform upper bound on the adversarial signal:\n\n\n$$\n\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\n$$\n\n**4. Assembling the Final Stability Condition**\n\nFor the intelligent targeting inequality `(*)` to hold robustly for *any* high-variance swarm, the guaranteed *minimum* of the LHS must be strictly greater than the allowed *maximum* of the RHS. The assembly of the final condition is now rigorous because it compares provably non-vanishing bounds on the *means of the populations*, not on unrepresentative individual values. Substituting the bounds derived in Stage 3 gives the necessary and sufficient condition.",
      "raw_directive": "3928: where $\\kappa_mean,d'(\\varepsilon)$ and $\\kappa_mean,r'$ are the guaranteed N-uniform separations between the *mean* rescaled values of the high-error and low-error populations, derived from the system's guaranteed signal variance and landscape regularity, respectively.\n3929: :::\n3930: :::{prf:proof}\n3931: :label: proof-thm-derivation-of-stability-condition\n3932: \n3933: **Proof.**\n3934: \n3935: The proof proceeds in four stages. First, we formalize the condition for intelligent targeting in terms of the expected log-fitness of the high-error and low-error populations. Second, we decompose this condition to isolate the trade-off between the diversity and reward signals. Third, we derive rigorous, uniform bounds for these signal gaps under worst-case adversarial conditions. Finally, we assemble these bounds to derive the necessary and sufficient inequality.\n3936: \n3937: **1. The Formal Condition for Intelligent Targeting**\n3938: \n3939: For the algorithm's targeting mechanism to be corrective, the high-error population `H_k` must, on average, be less fit than the low-error population `L_k = A_k \\setminus H_k`. Due to the multiplicative form of the fitness potential, $V_{\\text{fit}} = (d')^\\beta (r')^\\alpha$, the most robust way to analyze this condition is by comparing the expected logarithms of the fitness. The condition for intelligent targeting is therefore:\n3940: \n3941: $$\n3942: \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]\n3943: $$\n3944: \n3945: **2. Decomposing the Condition into a Signal Trade-off**\n3946: \n3947: Using the definition $ln(V_fit) = \\beta ln(d') + \\alpha ln(r')$ and the linearity of expectation, the condition from Step 1 becomes:\n3948: \n3949: $$\n3950: \\beta \\mathbb{E}[\\ln(d')|H_k] + \\alpha \\mathbb{E}[\\ln(r')|H_k] < \\beta \\mathbb{E}[\\ln(d')|L_k] + \\alpha \\mathbb{E}[\\ln(r')|L_k]\n3951: $$\n3952: \n3953: Rearranging the terms to separate the contribution from the diversity signal and the reward signal yields the core trade-off inequality that must be satisfied:\n3954: \n3955: $$\n3956: \\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right) \\quad (*)\n3957: $$\n3958: \n3959: This inequality states that the fitness advantage from the reliable diversity signal (LHS, with β > 0 from {prf:ref}`axiom-active-diversity`) must be strong enough to overcome the potential fitness advantage from a deceptive reward signal (RHS).\n3960: \n3961: **3. Deriving Uniform Bounds on the Signal Gaps**\n3962: \n3963: We now find uniform bounds for the two parenthesized terms in inequality `(*)`. This is the critical step where we correctly apply {prf:ref}`lem-variance-to-gap` to establish rigorous bounds. These bounds must hold for any swarm configuration, including the most adversarial ones.\n3964: \n3965: *   **LHS: The Minimum Guaranteed Diversity Signal.**\n3966: \n3967:     The term `E[ln(d')|H_k] - E[ln(d')|L_k]` represents the guaranteed advantage in the diversity signal for the high-error population. We establish this through the following causal chain:\n3968: \n3969:     1. **From Geometry to Raw Measurement Variance:** A high-error state guarantees a raw measurement variance $\\text{E}[\\text{Var}(d)] \\geq \\kappa_meas(\\varepsilon) > 0$ (from [](#thm-geometry-guarantees-variance)).\n3970: \n3971:     2. **From Raw Variance to Rescaled Variance:** This raw variance propagates through the pipeline, guaranteeing a variance in the rescaled values $\\text{Var}(d') \\geq \\kappa_var(d') > 0$. The constant $\\kappa_var(d')$ is defined in terms of $\\kappa_meas(\\varepsilon)$ and the pipeline parameters via the gap propagation lemmas from Section 7.3.\n3972: \n3973:     3. **Signal-to-Noise Condition:** The Signal-to-Noise Condition $\\kappa_var(d') > Var_max(d')$ is satisfied by the choice of the gain parameter $\\gamma$ (from {prf:ref}`prop-satisfiability-of-snr-gamma`).\n3974: \n3975:     4. **Applying [](#lem-variance-to-mean-separation):** We now apply [](#lem-variance-to-mean-separation) to the set of rescaled diversity values `d'`. Let:\n3976:         - `V = d'` (the total set of rescaled diversity values)\n3977:         - `H = H_k` and `L = L_k` (the partition)\n3978:         - The premise $\\text{Var}(V) \\geq \\kappa_var$ is met with $\\kappa_var = \\kappa_var(d')$\n3979:         - The premise $\\kappa_var > Var_max$ is met by the Signal-to-Noise Condition\n3980: \n3981:     5. **Result from [](#lem-variance-to-mean-separation):** This yields a guaranteed lower bound on the separation between the subset means:\n3982: \n3983: \n3984: $$\n3985: |\\mathbb{E}[d'|H_k] - \\mathbb{E}[d'|L_k]| \\ge \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')}\n3986: $$\n3987: \n3988:     6. **Define the Mean Gap Constant:** We define this entire N-uniform lower bound as:\n3989: \n3990: \n3991: $$\n3992: \\kappa_{\\text{mean},d'}(\\epsilon) := \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')} > 0\n3993: $$\n3994: \n3995:     7. **From Mean Separation to Logarithmic Separation:** The smallest possible logarithmic gap corresponding to this minimal mean separation occurs when the values are compressed at the top of their allowed range, $[\\eta, g_A,max + \\eta]$. This provides a uniform lower bound on the reliable signal:\n3996: \n3997: \n3998: $$\n3999: \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right)\n4000: $$\n4001: \n4002: *   **RHS: The Maximum Adversarial Reward Signal.**\n4003: \n4004:     Symmetrically, we apply the same logic to find an upper bound on the term `E[ln(r')|L_k] - E[ln(r')|H_k]`, which represents the maximum potential advantage from a deceptive reward signal. A potential adversarial raw gap $\\kappa_r'$ leads, through the application of [](#lem-variance-to-mean-separation) to the reward channel, to a maximum possible rescaled mean gap of $\\kappa_{\\text{mean},r'}$. The largest possible logarithmic gap corresponding to this reward separation occurs when the values are compressed at the bottom of their range. This gives a uniform upper bound on the adversarial signal:\n4005: \n4006: \n4007: $$\n4008: \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\n4009: $$\n4010: \n4011: **4. Assembling the Final Stability Condition**\n4012: \n4013: For the intelligent targeting inequality `(*)` to hold robustly for *any* high-variance swarm, the guaranteed *minimum* of the LHS must be strictly greater than the allowed *maximum* of the RHS. The assembly of the final condition is now rigorous because it compares provably non-vanishing bounds on the *means of the populations*, not on unrepresentative individual values. Substituting the bounds derived in Stage 3 gives the necessary and sufficient condition.\n4014: ",
      "strategy_summary": "The proof formalizes the intelligent targeting condition via expected log-fitness, decomposes it into a trade-off between diversity and reward signals using linearity of expectation, derives uniform bounds on signal gaps via variance-to-mean-separation lemmas under adversarial conditions, and assembles these bounds to obtain the necessary and sufficient stability inequality.",
      "conclusion": {
        "text": "The necessary and sufficient condition for intelligent targeting and stability is that the guaranteed minimum logarithmic diversity signal gap exceeds the maximum adversarial logarithmic reward signal gap: \\(\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max} + \\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\\).",
        "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max} + \\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)"
      },
      "assumptions": [
        {
          "text": "High-error states guarantee raw measurement variance \\(\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon) > 0\\).",
          "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon) > 0"
        },
        {
          "text": "Signal-to-Noise Condition: \\(\\kappa_{\\text{var}}(d') > \\operatorname{Var}_{\\max}(d')\\), satisfied by gain parameter \\(\\gamma\\).",
          "latex": "\\kappa_{\\text{var}}(d') > \\operatorname{Var}_{\\max}(d')"
        },
        {
          "text": "Rescaled values lie in bounded ranges: diversity \\([\\eta, g_{A,\\max} + \\eta]\\), reward near \\([\\eta, \\cdot]\\).",
          "latex": "[\\eta, g_{A,\\max} + \\eta]"
        },
        {
          "text": "Fitness potential is multiplicative: \\(V_{\\text{fit}} = (d')^\\beta (r')^\\alpha\\).",
          "latex": "V_{\\text{fit}} = (d')^\\beta (r')^\\alpha"
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "formalization",
          "text": "Formalize the condition for intelligent targeting: the expected log-fitness of the high-error population H_k is less than that of the low-error population L_k.",
          "latex": "\\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]",
          "references": [],
          "derived_statement": "Targeting condition in terms of expected log-fitness."
        },
        {
          "order": 2.0,
          "kind": "decomposition",
          "text": "Decompose using linearity of expectation and log definition to isolate signal trade-off.",
          "latex": "\\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right)",
          "references": [],
          "derived_statement": "Core trade-off inequality (*)."
        },
        {
          "order": 3.0,
          "kind": "bounding",
          "text": "Derive lower bound for LHS diversity signal gap via causal chain: geometry to variance, rescaling, SNR condition, and apply lem-variance-to-mean-separation.",
          "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max}+\\eta}\\right)",
          "references": [
            "thm-geometry-guarantees-variance",
            "lem-variance-to-mean-separation",
            "prop-satisfiability-of-snr-gamma"
          ],
          "derived_statement": "Guaranteed minimum diversity logarithmic gap."
        },
        {
          "order": 4.0,
          "kind": "bounding",
          "text": "Derive upper bound for RHS reward signal gap symmetrically, applying lem-variance-to-mean-separation to adversarial case.",
          "latex": "\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)",
          "references": [
            "lem-variance-to-mean-separation"
          ],
          "derived_statement": "Maximum adversarial reward logarithmic gap."
        },
        {
          "order": 5.0,
          "kind": "assembly",
          "text": "Substitute bounds into (*) to obtain the necessary and sufficient stability condition, ensuring it holds uniformly for any swarm.",
          "latex": null,
          "references": [],
          "derived_statement": "Final stability inequality."
        }
      ],
      "key_equations": [
        {
          "label": "eq-targeting-condition",
          "latex": "\\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]",
          "role": "Formal condition for intelligent targeting"
        },
        {
          "label": "eq-trade-off",
          "latex": "\\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right)",
          "role": "Decomposed signal trade-off inequality"
        },
        {
          "label": "eq-mean-separation",
          "latex": "|\\mathbb{E}[d'|H_k] - \\mathbb{E}[d'|L_k]| \\ge \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')}",
          "role": "Uniform bound from variance-to-mean-separation"
        },
        {
          "label": "eq-diversity-gap",
          "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,\\max}+\\eta}\\right)",
          "role": "Lower bound on diversity log-gap"
        },
        {
          "label": "eq-reward-gap",
          "latex": "\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)",
          "role": "Upper bound on reward log-gap"
        }
      ],
      "references": [
        "axiom-active-diversity",
        "lem-variance-to-gap",
        "prop-satisfiability-of-snr-gamma",
        "thm-geometry-guarantees-variance",
        "lem-variance-to-mean-separation"
      ],
      "math_tools": [
        {
          "toolName": "Linearity of Expectation",
          "field": "Probability Theory",
          "description": "The expected value of a linear combination is the linear combination of expected values.",
          "roleInProof": "Decomposes the expected log-fitness into separate contributions from diversity and reward signals.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Expectation"
          ]
        },
        {
          "toolName": "Variance-to-Mean-Separation Lemma",
          "field": "Statistics",
          "description": "Provides a lower bound on the absolute difference between conditional means of subsets given the total variance and maximum subset variance.",
          "roleInProof": "Establishes uniform separations between mean rescaled values of high-error and low-error populations for both diversity and reward signals.",
          "levelOfAbstraction": "Theorem/Lemma",
          "relatedTools": [
            "Chebyshev's Inequality"
          ]
        },
        {
          "toolName": "Logarithmic Bounding",
          "field": "Analysis",
          "description": "Bounds the difference in logarithms based on range compression and mean separations.",
          "roleInProof": "Converts mean separations in rescaled values to logarithmic gaps for fitness comparison.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Concavity of Logarithm"
          ]
        },
        {
          "toolName": "Signal-to-Noise Condition",
          "field": "Signal Processing",
          "description": "Ensures that the variance of the signal exceeds the maximum noise variance via gain parameter choice.",
          "roleInProof": "Guarantees the applicability of variance-to-mean-separation by satisfying premise conditions.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Variance Analysis"
          ]
        }
      ],
      "cases": [
        {
          "name": "Diversity Signal (LHS)",
          "condition": "High-error guarantees variance \\(\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon)\\)",
          "summary": "Derives minimum guaranteed logarithmic gap using geometry, rescaling, SNR, and mean-separation lemma."
        },
        {
          "name": "Reward Signal (RHS)",
          "condition": "Adversarial raw gap \\(\\kappa_r'\\)",
          "summary": "Derives maximum possible logarithmic gap using symmetric application of mean-separation lemma under compression at range bottom."
        }
      ],
      "remarks": [
        {
          "type": "clarity",
          "text": "The bounds are N-uniform and hold for worst-case adversarial swarms, ensuring robustness."
        },
        {
          "type": "rigor",
          "text": "The final condition compares means of populations, avoiding reliance on individual values."
        }
      ],
      "gaps": [],
      "tags": [
        "intelligent targeting",
        "stability condition",
        "signal trade-off",
        "uniform bounds",
        "diversity signal",
        "reward signal",
        "variance separation",
        "logarithmic gap"
      ],
      "document_id": "03_cloning",
      "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
      "span": {
        "start_line": 3928,
        "end_line": 4014,
        "content_start": 3931,
        "content_end": 4013,
        "header_lines": [
          3929
        ]
      },
      "metadata": {
        "label": "proof-thm-derivation-of-stability-condition"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 7,
        "chapter_file": "chapter_7.json",
        "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "stability-condition",
      "intelligent-adaptation",
      "swarm-dynamics",
      "fitness",
      "error-walkers",
      "algorithm-parameters",
      "variance"
    ],
    "content_markdown": ":label: thm-derivation-of-stability-condition\n\nLet the system satisfy the foundational axioms, including the **Axiom of Non-Deceptive Landscapes (EG-7)**. Let a swarm `k` have a sufficiently large internal positional variance, $\\mathrm{Var}_x(S_k) > R^2_{\\mathrm{var}}$.\n\nThe algorithm's targeting mechanism is \"intelligent\" (i.e., the expected fitness of a high-error walker is systematically lower than that of a low-error walker) if and only if the system parameters ($\\alpha$, $\\beta$, $\\varepsilon$, etc.) satisfy the following **Stability Condition**:\n\n$$\n\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\n$$",
    "raw_directive": "3915: This property is not unconditional. We will rigorously derive a **Stability Condition** on the algorithm's dynamics parameters ($\\alpha$, $\\beta$, $\\varepsilon$) from first principles. The proof will be statistical in nature, analyzing the expected fitness of the entire \"high-error\" population versus the \"low-error\" population. We will demonstrate that satisfying this Stability Condition is the necessary and sufficient condition to guarantee that the high-error walkers are, on average, less fit. This derivation provides the formal justification for elevating this condition to the status of a foundational axiom for any well-posed Fragile Gas system.\n3916: \n3917: :::{prf:theorem} Derivation of the Stability Condition for Intelligent Adaptation\n3918: :label: thm-derivation-of-stability-condition\n3919: \n3920: Let the system satisfy the foundational axioms, including the **Axiom of Non-Deceptive Landscapes (EG-7)**. Let a swarm `k` have a sufficiently large internal positional variance, $\\mathrm{Var}_x(S_k) > R^2_{\\mathrm{var}}$.\n3921: \n3922: The algorithm's targeting mechanism is \"intelligent\" (i.e., the expected fitness of a high-error walker is systematically lower than that of a low-error walker) if and only if the system parameters ($\\alpha$, $\\beta$, $\\varepsilon$, etc.) satisfy the following **Stability Condition**:\n3923: \n3924: $$\n3925: \\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\n3926: $$\n3927: ",
    "document_id": "03_cloning",
    "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
    "span": {
      "start_line": 3915,
      "end_line": 3927,
      "content_start": 3918,
      "content_end": 3926,
      "header_lines": [
        3916
      ]
    },
    "references": [
      "axiom-active-diversity",
      "lem-variance-to-gap",
      "prop-satisfiability-of-snr-gamma",
      "thm-geometry-guarantees-variance",
      "lem-variance-to-mean-separation"
    ],
    "metadata": {
      "label": "thm-derivation-of-stability-condition"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 7,
      "chapter_file": "chapter_7.json",
      "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-stability-condition-final-corrected",
    "title": "The Corrected Stability Condition for Intelligent Adaptation",
    "type": "theorem",
    "nl_statement": "For a swarm k in a high-error state, the algorithm's targeting mechanism is intelligent (i.e., \\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k]) if and only if the system parameters satisfy \\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right).",
    "equations": [
      {
        "label": null,
        "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right)"
      }
    ],
    "hypotheses": [
      {
        "text": "A swarm k is in a high-error state.",
        "latex": null
      },
      {
        "text": "The algorithm's targeting mechanism is intelligent, i.e., \\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k].",
        "latex": "\\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k]"
      }
    ],
    "conclusion": {
      "text": "The system parameters satisfy the Corrected Stability Condition: \\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right).",
      "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right)"
    },
    "variables": [
      {
        "symbol": "k",
        "name": "swarm",
        "description": "Identifier for the swarm.",
        "constraints": [],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "\\beta",
        "name": "beta",
        "description": "System parameter in the stability inequality.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "parameter"
        ]
      },
      {
        "symbol": "\\alpha",
        "name": "alpha",
        "description": "System parameter in the stability inequality.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "parameter"
        ]
      },
      {
        "symbol": "\\kappa_{d', \\text{mean}}",
        "name": "kappa_d_prime_mean",
        "description": "Mean value of kappa for d prime.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "kappa",
          "mean"
        ]
      },
      {
        "symbol": "g_{A,\\max}",
        "name": "g_A_max",
        "description": "Maximum value of g_A.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "max"
        ]
      },
      {
        "symbol": "\\eta",
        "name": "eta",
        "description": "Regularization or noise parameter.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "eta"
        ]
      },
      {
        "symbol": "\\kappa_{\\mathrm{rescaled}}",
        "name": "kappa_rescaled",
        "description": "Rescaled kappa function.",
        "constraints": [],
        "tags": [
          "kappa",
          "rescaled"
        ]
      },
      {
        "symbol": "L_R",
        "name": "L_R",
        "description": "Loss or length related to R.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "loss"
        ]
      },
      {
        "symbol": "D_{\\mathrm{valid}}",
        "name": "D_valid",
        "description": "Valid dimension or distance.",
        "constraints": [
          "positive"
        ],
        "tags": [
          "dimension"
        ]
      },
      {
        "symbol": "V_{\\text{fit}}",
        "name": "V_fit",
        "description": "Fitness value.",
        "constraints": [],
        "tags": [
          "fitness"
        ]
      },
      {
        "symbol": "H_k",
        "name": "H_k",
        "description": "High-error state for swarm k.",
        "constraints": [],
        "tags": [
          "high-error"
        ]
      },
      {
        "symbol": "L_k",
        "name": "L_k",
        "description": "Low-error state for swarm k.",
        "constraints": [],
        "tags": [
          "low-error"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "All parameters (\\alpha, \\beta, \\eta, \\kappa values, etc.) are positive real numbers.",
        "confidence": 0.9
      },
      {
        "text": "The expectations \\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] and \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k] are well-defined.",
        "confidence": 0.8
      },
      {
        "text": "The swarm k exists in a defined state space with high-error condition.",
        "confidence": 0.7
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-stability-condition-final-corrected",
      "title": null,
      "type": "proof",
      "proves": "thm-stability-condition-final-corrected",
      "proof_type": "reference",
      "proof_status": "complete",
      "content_markdown": ":label: proof-thm-stability-condition-final-corrected\n\n**Proof.**\n\nThe proof is a direct assembly of the bounds derived in the preceding propositions. The condition for intelligence, as established in the core trade-off inequality of the main stability proof, is that the guaranteed *minimum* of the corrective signal must be strictly greater than the allowed *maximum* of the adversarial signal.\n\n*   **LHS (Corrective Signal):** The lower bound is given by **{prf:ref}`prop-corrective-signal-bound`**.\n*   **RHS (Adversarial Signal):** The upper bound is now given by **{prf:ref}`prop-log-reward-gap-axiom-bound`** (the axiom-based bound).\n\nSubstituting the lower bound for the corrective signal (from {prf:ref}`prop-corrective-signal-bound`) and the upper bound for the adversarial signal (from {prf:ref}`prop-log-reward-gap-axiom-bound`) into the inequality $\\beta \\times (\\text{Corrective Gap}) > \\alpha \\times (\\text{Adversarial Gap})$ yields the final, corrected stability condition.",
      "raw_directive": "4521: where $\\kappa_{d', \\text{mean}}$ is the guaranteed N-uniform separation between the mean rescaled diversity values of the high-error and low-error populations, as derived in **{prf:ref}`prop-corrective-signal-bound`**.\n4522: :::\n4523: :::{prf:proof}\n4524: :label: proof-thm-stability-condition-final-corrected\n4525: \n4526: **Proof.**\n4527: \n4528: The proof is a direct assembly of the bounds derived in the preceding propositions. The condition for intelligence, as established in the core trade-off inequality of the main stability proof, is that the guaranteed *minimum* of the corrective signal must be strictly greater than the allowed *maximum* of the adversarial signal.\n4529: \n4530: *   **LHS (Corrective Signal):** The lower bound is given by **{prf:ref}`prop-corrective-signal-bound`**.\n4531: *   **RHS (Adversarial Signal):** The upper bound is now given by **{prf:ref}`prop-log-reward-gap-axiom-bound`** (the axiom-based bound).\n4532: \n4533: Substituting the lower bound for the corrective signal (from {prf:ref}`prop-corrective-signal-bound`) and the upper bound for the adversarial signal (from {prf:ref}`prop-log-reward-gap-axiom-bound`) into the inequality $\\beta \\times (\\text{Corrective Gap}) > \\alpha \\times (\\text{Adversarial Gap})$ yields the final, corrected stability condition.\n4534: ",
      "strategy_summary": "The proof directly assembles the lower bound on the corrective signal from the referenced proposition prop-corrective-signal-bound and the upper bound on the adversarial signal from prop-log-reward-gap-axiom-bound, substituting them into the core trade-off inequality β × (Corrective Gap) > α × (Adversarial Gap) to establish the final stability condition for intelligence.",
      "conclusion": {
        "text": "The inequality β × (Corrective Gap) > α × (Adversarial Gap), with Corrective Gap lower bounded by the result from prop-corrective-signal-bound and Adversarial Gap upper bounded by the result from prop-log-reward-gap-axiom-bound, yields the final corrected stability condition.",
        "latex": null
      },
      "assumptions": [],
      "steps": [
        {
          "order": 1.0,
          "kind": "explanation",
          "text": "The condition for intelligence requires the guaranteed minimum of the corrective signal to exceed the allowed maximum of the adversarial signal, as per the core trade-off inequality.",
          "latex": null,
          "references": [],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "reference",
          "text": "Lower bound for the LHS (Corrective Signal): Given by prop-corrective-signal-bound.",
          "latex": null,
          "references": [
            "prop-corrective-signal-bound"
          ],
          "derived_statement": null
        },
        {
          "order": 3.0,
          "kind": "reference",
          "text": "Upper bound for the RHS (Adversarial Signal): Given by prop-log-reward-gap-axiom-bound (axiom-based bound).",
          "latex": null,
          "references": [
            "prop-log-reward-gap-axiom-bound"
          ],
          "derived_statement": null
        },
        {
          "order": 4.0,
          "kind": "substitution",
          "text": "Substitute the lower bound for the corrective signal and the upper bound for the adversarial signal into the inequality β × (Corrective Gap) > α × (Adversarial Gap).",
          "latex": null,
          "references": [
            "prop-corrective-signal-bound",
            "prop-log-reward-gap-axiom-bound"
          ],
          "derived_statement": "Final corrected stability condition."
        }
      ],
      "key_equations": [
        {
          "label": "eq-stability-tradeoff",
          "latex": "\\beta \\times (\\text{Corrective Gap}) > \\alpha \\times (\\text{Adversarial Gap})",
          "role": "Core trade-off inequality into which bounds are substituted."
        }
      ],
      "references": [
        "prop-corrective-signal-bound",
        "prop-log-reward-gap-axiom-bound"
      ],
      "math_tools": [],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "This proof provides the final, corrected version of the stability condition by assembling preceding bounds."
        }
      ],
      "gaps": [],
      "tags": [
        "stability-condition",
        "corrective-signal",
        "adversarial-signal",
        "bounds-assembly",
        "trade-off-inequality",
        "intelligence-condition"
      ],
      "document_id": "03_cloning",
      "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
      "span": {
        "start_line": 4521,
        "end_line": 4534,
        "content_start": 4524,
        "content_end": 4533,
        "header_lines": [
          4522
        ]
      },
      "metadata": {
        "label": "proof-thm-stability-condition-final-corrected"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 7,
        "chapter_file": "chapter_7.json",
        "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "stability-condition",
      "intelligent-adaptation",
      "swarm-algorithm",
      "targeting-mechanism",
      "adversarial-reward",
      "corrected-inequality"
    ],
    "content_markdown": ":label: thm-stability-condition-final-corrected\n\nLet a swarm `k$ be in a high-error state. The algorithm's targeting mechanism is intelligent (i.e., $\\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k]$) if and only if the system parameters satisfy the following **Corrected Stability Condition**:\n$$\n\\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right)",
    "raw_directive": "4512: With a rigorous, axiom-based bound on the adversarial reward signal now established (based on {prf:ref}`axiom-non-deceptive-landscape`), we can state the corrected and final stability condition (derived in {prf:ref}`thm-derivation-of-stability-condition`).\n4513: \n4514: :::{prf:theorem} **(The Corrected Stability Condition for Intelligent Adaptation)**\n4515: :label: thm-stability-condition-final-corrected\n4516: \n4517: Let a swarm `k$ be in a high-error state. The algorithm's targeting mechanism is intelligent (i.e., $\\mathbb{E}[\\ln(V_{\\text{fit}})|H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}})|L_k]$) if and only if the system parameters satisfy the following **Corrected Stability Condition**:\n4518: $$\n4519: \\beta \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_{R} \\cdot D_{\\mathrm{valid}})}{\\eta}\\right)\n4520: $$",
    "document_id": "03_cloning",
    "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
    "span": {
      "start_line": 4512,
      "end_line": 4520,
      "content_start": 4515,
      "content_end": 4519,
      "header_lines": [
        4513
      ]
    },
    "references": [
      "prop-corrective-signal-bound",
      "prop-log-reward-gap-axiom-bound"
    ],
    "metadata": {
      "label": "thm-stability-condition-final-corrected"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 7,
      "chapter_file": "chapter_7.json",
      "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-unfit-high-error-overlap-fraction",
    "title": "N-Uniform Lower Bound on the Unfit-High-Error Overlap Fraction",
    "type": "theorem",
    "nl_statement": "For a swarm state satisfying \\(V_{\\mathrm{struct}} > R^2_{\\mathrm{spread}}\\), with \\(U_k\\) the unfit set and \\(H_k(\\epsilon)\\) the high-error set, if the Stability Condition holds, then the fraction of alive walkers in their intersection \\(I_{UH} = U_k \\cap H_k(\\epsilon)\\) is bounded below by a positive N-uniform constant: \\(\\frac{|I_{UH}|}{k} \\ge f_{UH}(\\epsilon) > 0\\).",
    "equations": [
      {
        "label": null,
        "latex": "\\frac{|I_{UH}|}{k} \\ge f_{UH}(\\epsilon) > 0"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": null,
      "latex": null
    },
    "variables": [
      {
        "symbol": "V_{\\mathrm{struct}}",
        "name": "structural variance",
        "description": "Variance measure for swarm structure.",
        "constraints": [
          "> R^2_{\\mathrm{spread}}"
        ],
        "tags": [
          "swarm state"
        ]
      },
      {
        "symbol": "R_{\\mathrm{spread}}",
        "name": "spread radius",
        "description": "Radius parameter for swarm spread.",
        "constraints": [],
        "tags": [
          "swarm geometry"
        ]
      },
      {
        "symbol": "U_k",
        "name": "unfit set",
        "description": "Set of unfit walkers in swarm k.",
        "constraints": [],
        "tags": [
          "unfit walkers"
        ]
      },
      {
        "symbol": "H_k(\\epsilon)",
        "name": "high-error set",
        "description": "Unified high-error set for swarm k with threshold \\epsilon.",
        "constraints": [],
        "tags": [
          "error walkers"
        ]
      },
      {
        "symbol": "I_{UH}",
        "name": "intersection set",
        "description": "Intersection of unfit and high-error sets: U_k \\cap H_k(\\epsilon).",
        "constraints": [],
        "tags": [
          "overlap"
        ]
      },
      {
        "symbol": "k",
        "name": "swarm index",
        "description": "Index of the swarm.",
        "constraints": [],
        "tags": [
          "swarm size"
        ]
      },
      {
        "symbol": "f_{UH}(\\epsilon)",
        "name": "overlap fraction lower bound",
        "description": "Positive constant bounding the overlap fraction.",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "uniform bound"
        ]
      },
      {
        "symbol": "\\epsilon",
        "name": "error threshold",
        "description": "Threshold parameter for high-error definition.",
        "constraints": [],
        "tags": [
          "error level"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Walkers are alive and countable in the sets.",
        "confidence": 0.9
      },
      {
        "text": "N refers to a fixed dimension or system size independent of k.",
        "confidence": 0.8
      },
      {
        "text": "The swarm algorithm targets unfit walkers for corrective cloning.",
        "confidence": 1.0
      }
    ],
    "local_refs": [
      "thm-stability-condition-final-corrected"
    ],
    "proof": {
      "label": "proof-thm-unfit-high-error-overlap-fraction",
      "title": null,
      "type": "proof",
      "proves": "thm-unfit-high-error-overlap-fraction",
      "proof_type": "contradiction",
      "proof_status": "complete",
      "content_markdown": ":label: proof-thm-unfit-high-error-overlap-fraction\n\n**Proof (by contradiction).**\n\nThe proof follows directly from the consequences of the **Stability Condition** ([](#thm-stability-condition-final-corrected)). This condition guarantees that the high-error population is systematically less fit, a statistical property that makes a vanishing overlap with the unfit set impossible.\n\n**1. Setup for Contradiction.**\nAssume the premises hold: the swarm `k` has a large structural error, and the **Stability Condition** is satisfied. Now, assume for the sake of contradiction that the overlap between the unfit and high-error sets is vanishingly small. Formally, this means the fraction of their intersection approaches zero:\n\n$$\nf_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0\n$$\n\n**2. Consequence 1: High-Error Walkers Must Be \"Fit\".**\nIf the overlap is nearly zero, then the high-error set `H_k` must consist almost entirely of walkers that are *not* in the unfit set. This means they must belong to the complementary \"fit\" set, $F_k = \\mathcal{A}_k \\setminus U_k$. Formally, $H_k \\approx H_k \\cap F_k$.\n\nBy the definition of the fit set, any walker $j \\in F_k$ has a fitness greater than the swarm's mean fitness, $V_{k,j} > \\mu_{V,k}$. Therefore, the expected fitness of the high-error set, which is composed almost entirely of fit walkers, must also be greater than the mean:\n\n$$\n\\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] > \\mu_{V,k} \\quad (*)\n$$\n\n**3. Consequence 2: The Axiom's Guarantee.**\nThe **Stability Condition** is precisely the condition required to ensure that the algorithm's targeting is intelligent. As proven in [](#thm-stability-condition-final-corrected), satisfying this condition guarantees that the expected fitness of the high-error population is *strictly less than* the expected fitness of the low-error population:\n\n$$\n\\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] < \\mathbb{E}[V_{\\text{fit}} \\mid i \\in L_k]\n$$\n\nThe mean fitness of the entire swarm, $\\mu_{V,k}$, is the weighted average of the means of these two disjoint populations: $\\mu_{V,k} = f_H \\mathbb{E}[V_{\\text{fit}}|H_k] + f_L \\mathbb{E}[V_{\\text{fit}}|L_k]$. A weighted average must lie strictly between its two components **as long as both components have non-zero weight**. From Chapter 6, we are guaranteed that both the high-error ($H_k$) and low-error ($L_k$) sets are non-empty and constitute non-vanishing fractions of the population, so $f_H > 0$ and $f_L > 0$. Therefore, it must be that:\n\n$$\n\\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] < \\mu_{V,k} \\quad (**)\n$$\n\n**4. The Contradiction.**\nThe conclusion from Step 2, $\\text{E}[V_fit | H_k] > \\mu_V$, directly contradicts the conclusion from Step 3, $\\text{E}[V_fit | H_k] < \\mu_V$. Both conclusions follow from our premises, so the initial assumption of a vanishing overlap must be false.\n\n**5. Conclusion.**\nThe assumption of a vanishing overlap leads to a contradiction. Therefore, the overlap fraction must be bounded below by a strictly positive constant. A more detailed analysis of the underlying distributions shows that this lower bound, $f_UH(\\varepsilon)$, is an N-uniform constant that is a monotonic function of the fitness gap between the high-error and low-error populations guaranteed by the axiom. This completes the proof.",
      "raw_directive": "4647: where `k` is the number of alive walkers in swarm `k`.\n4648: :::\n4649: :::{prf:proof}\n4650: :label: proof-thm-unfit-high-error-overlap-fraction\n4651: \n4652: **Proof (by contradiction).**\n4653: \n4654: The proof follows directly from the consequences of the **Stability Condition** ([](#thm-stability-condition-final-corrected)). This condition guarantees that the high-error population is systematically less fit, a statistical property that makes a vanishing overlap with the unfit set impossible.\n4655: \n4656: **1. Setup for Contradiction.**\n4657: Assume the premises hold: the swarm `k` has a large structural error, and the **Stability Condition** is satisfied. Now, assume for the sake of contradiction that the overlap between the unfit and high-error sets is vanishingly small. Formally, this means the fraction of their intersection approaches zero:\n4658: \n4659: $$\n4660: f_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0\n4661: $$\n4662: \n4663: **2. Consequence 1: High-Error Walkers Must Be \"Fit\".**\n4664: If the overlap is nearly zero, then the high-error set `H_k` must consist almost entirely of walkers that are *not* in the unfit set. This means they must belong to the complementary \"fit\" set, $F_k = \\mathcal{A}_k \\setminus U_k$. Formally, $H_k \\approx H_k \\cap F_k$.\n4665: \n4666: By the definition of the fit set, any walker $j \\in F_k$ has a fitness greater than the swarm's mean fitness, $V_{k,j} > \\mu_{V,k}$. Therefore, the expected fitness of the high-error set, which is composed almost entirely of fit walkers, must also be greater than the mean:\n4667: \n4668: $$\n4669: \\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] > \\mu_{V,k} \\quad (*)\n4670: $$\n4671: \n4672: **3. Consequence 2: The Axiom's Guarantee.**\n4673: The **Stability Condition** is precisely the condition required to ensure that the algorithm's targeting is intelligent. As proven in [](#thm-stability-condition-final-corrected), satisfying this condition guarantees that the expected fitness of the high-error population is *strictly less than* the expected fitness of the low-error population:\n4674: \n4675: $$\n4676: \\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] < \\mathbb{E}[V_{\\text{fit}} \\mid i \\in L_k]\n4677: $$\n4678: \n4679: The mean fitness of the entire swarm, $\\mu_{V,k}$, is the weighted average of the means of these two disjoint populations: $\\mu_{V,k} = f_H \\mathbb{E}[V_{\\text{fit}}|H_k] + f_L \\mathbb{E}[V_{\\text{fit}}|L_k]$. A weighted average must lie strictly between its two components **as long as both components have non-zero weight**. From Chapter 6, we are guaranteed that both the high-error ($H_k$) and low-error ($L_k$) sets are non-empty and constitute non-vanishing fractions of the population, so $f_H > 0$ and $f_L > 0$. Therefore, it must be that:\n4680: \n4681: $$\n4682: \\mathbb{E}[V_{\\text{fit}} \\mid i \\in H_k] < \\mu_{V,k} \\quad (**)\n4683: $$\n4684: \n4685: **4. The Contradiction.**\n4686: The conclusion from Step 2, $\\text{E}[V_fit | H_k] > \\mu_V$, directly contradicts the conclusion from Step 3, $\\text{E}[V_fit | H_k] < \\mu_V$. Both conclusions follow from our premises, so the initial assumption of a vanishing overlap must be false.\n4687: \n4688: **5. Conclusion.**\n4689: The assumption of a vanishing overlap leads to a contradiction. Therefore, the overlap fraction must be bounded below by a strictly positive constant. A more detailed analysis of the underlying distributions shows that this lower bound, $f_UH(\\varepsilon)$, is an N-uniform constant that is a monotonic function of the fitness gap between the high-error and low-error populations guaranteed by the axiom. This completes the proof.\n4690: ",
      "strategy_summary": "Assume vanishing overlap between unfit and high-error sets, implying high-error walkers are mostly fit with above-average fitness, which contradicts the Stability Condition guaranteeing that high-error walkers have below-average fitness as a weighted average effect.",
      "conclusion": {
        "text": "The overlap fraction must be bounded below by a strictly positive constant, specifically an N-uniform constant monotonic in the fitness gap from the Stability Condition.",
        "latex": "$f_{UH} \\geq f_{UH}(\\varepsilon) > 0$, where $f_{UH}(\\varepsilon)$ is monotonic in the fitness gap."
      },
      "assumptions": [
        {
          "text": "The swarm k has a large structural error.",
          "latex": null
        },
        {
          "text": "The Stability Condition is satisfied.",
          "latex": null
        },
        {
          "text": "Both high-error (H_k) and low-error (L_k) sets are non-empty with non-vanishing fractions (f_H > 0, f_L > 0).",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "setup",
          "text": "Assume premises hold: large structural error in swarm k and Stability Condition satisfied. For contradiction, assume vanishing overlap: f_UH = |U_k ∩ H_k|/k ≈ 0.",
          "latex": "$f_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0$",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "consequence",
          "text": "If overlap ≈0, then H_k ≈ H_k ∩ F_k, where F_k is the fit set with V_{k,j} > μ_{V,k} for j in F_k. Thus, expected fitness in H_k > mean: E[V | i ∈ H_k] > μ_{V,k}.",
          "latex": "$\\mathbb{E}[V \\mid i \\in H_k] > \\mu_{V,k}$",
          "references": [],
          "derived_statement": "E[V_fit | H_k] > μ_{V,k} (*)"
        },
        {
          "order": 3.0,
          "kind": "application",
          "text": "By Stability Condition, E[V | i ∈ H_k] < E[V | i ∈ L_k]. Swarm mean μ_{V,k} = f_H E[V|H_k] + f_L E[V|L_k], and since f_H >0, f_L>0, the mean lies strictly between, so E[V | i ∈ H_k] < μ_{V,k}.",
          "latex": "$\\mathbb{E}[V \\mid i \\in H_k] < \\mathbb{E}[V \\mid i \\in L_k]$ and $\\mu_{V,k} = f_H \\mathbb{E}[V|H_k] + f_L \\mathbb{E}[V|L_k]$",
          "references": [
            "thm-stability-condition-final-corrected"
          ],
          "derived_statement": "E[V_fit | H_k] < μ_{V,k} (**)"
        },
        {
          "order": 4.0,
          "kind": "contradiction",
          "text": "(*) implies E[V | H_k] > μ_{V,k}, while (**) implies E[V | H_k] < μ_{V,k}, a direct contradiction.",
          "latex": null,
          "references": [],
          "derived_statement": "Contradiction in fitness expectation."
        },
        {
          "order": 5.0,
          "kind": "conclusion",
          "text": "Assumption of vanishing overlap is false; thus, overlap fraction bounded below by positive constant from detailed distribution analysis.",
          "latex": null,
          "references": [],
          "derived_statement": null
        }
      ],
      "key_equations": [
        {
          "label": "eq-fuh",
          "latex": "$f_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0$",
          "role": "Definition of vanishing overlap assumption."
        },
        {
          "label": "eq-fit-high",
          "latex": "$\\mathbb{E}[V \\mid i \\in H_k] > \\mu_{V,k}$",
          "role": "Consequence of high-error set being mostly fit."
        },
        {
          "label": "eq-stability",
          "latex": "$\\mathbb{E}[V \\mid i \\in H_k] < \\mathbb{E}[V \\mid i \\in L_k]$",
          "role": "Guarantee from Stability Condition."
        },
        {
          "label": "eq-weighted-mean",
          "latex": "$\\mu_{V,k} = f_H \\mathbb{E}[V|H_k] + f_L \\mathbb{E}[V|L_k]$",
          "role": "Swarm mean as weighted average, implying strict inequality."
        }
      ],
      "references": [
        "thm-stability-condition-final-corrected"
      ],
      "math_tools": [
        {
          "toolName": "Proof by Contradiction",
          "field": "Mathematical Logic",
          "description": "A proof technique that assumes the negation of the statement to be proven and derives a logical contradiction.",
          "roleInProof": "Structures the entire argument by assuming zero overlap and showing inconsistency with the Stability Condition.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Expectation"
          ]
        },
        {
          "toolName": "Conditional Expectation",
          "field": "Probability Theory",
          "description": "The expected value of a random variable given that it belongs to a specific subset or event.",
          "roleInProof": "Used to compare fitness expectations in high-error and low-error populations against the swarm mean.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Weighted Average"
          ]
        },
        {
          "toolName": "Weighted Average",
          "field": "Statistics",
          "description": "A mean computed as a sum of values weighted by their proportions.",
          "roleInProof": "Establishes that the swarm mean fitness lies strictly between high-error and low-error expectations when both fractions are positive.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Conditional Expectation"
          ]
        },
        {
          "toolName": "Set Intersection and Cardinality",
          "field": "Set Theory",
          "description": "Measures the size of overlap between sets using intersection and division by total size for fractions.",
          "roleInProof": "Defines the overlap fraction f_UH and assumes it approaches zero to derive consequences.",
          "levelOfAbstraction": "Notation",
          "relatedTools": []
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "Detailed analysis of underlying distributions provides the explicit lower bound f_UH(ε) as an N-uniform constant monotonic in the fitness gap."
        }
      ],
      "gaps": [],
      "tags": [
        "contradiction",
        "stability-condition",
        "fitness-expectation",
        "set-overlap",
        "high-error",
        "unfit-population",
        "swarm-walkers"
      ],
      "document_id": "03_cloning",
      "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
      "span": {
        "start_line": 4647,
        "end_line": 4690,
        "content_start": 4650,
        "content_end": 4689,
        "header_lines": [
          4648
        ]
      },
      "metadata": {
        "label": "proof-thm-unfit-high-error-overlap-fraction"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 7,
        "chapter_file": "chapter_7.json",
        "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "swarm dynamics",
      "unfit set",
      "high-error set",
      "overlap fraction",
      "stability condition",
      "uniform lower bound"
    ],
    "content_markdown": ":label: thm-unfit-high-error-overlap-fraction\n\nLet a swarm state satisfy $V_{\\mathrm{struct}} > R^2_{\\mathrm{spread}}$. Let $U_k$ be the unfit set for swarm `k` and let $H_k(\\epsilon)$ be its corresponding unified high-error set.\n\nIf the **Stability Condition** ([](#thm-stability-condition-final-corrected)) holds for the chosen system parameters, then the fraction of alive walkers in the intersection set $I_{UH} = U_k \\cap H_k(\\epsilon)$ is bounded below by a positive, N-uniform constant:\n\n$$\n\\frac{|I_{UH}|}{k} \\ge f_{UH}(\\epsilon) > 0\n$$",
    "raw_directive": "4634: This theorem proves that the set of walkers targeted by the algorithm for corrective cloning has a substantial and non-vanishing overlap with the set of walkers that are the primary source of the system's geometric error. This is the ultimate proof of the Keystone Principle's corrective feedback loop.\n4635: \n4636: :::{prf:theorem} N-Uniform Lower Bound on the Unfit-High-Error Overlap Fraction\n4637: :label: thm-unfit-high-error-overlap-fraction\n4638: \n4639: Let a swarm state satisfy $V_{\\mathrm{struct}} > R^2_{\\mathrm{spread}}$. Let $U_k$ be the unfit set for swarm `k` and let $H_k(\\epsilon)$ be its corresponding unified high-error set.\n4640: \n4641: If the **Stability Condition** ([](#thm-stability-condition-final-corrected)) holds for the chosen system parameters, then the fraction of alive walkers in the intersection set $I_{UH} = U_k \\cap H_k(\\epsilon)$ is bounded below by a positive, N-uniform constant:\n4642: \n4643: $$\n4644: \\frac{|I_{UH}|}{k} \\ge f_{UH}(\\epsilon) > 0\n4645: $$\n4646: ",
    "document_id": "03_cloning",
    "section": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation",
    "span": {
      "start_line": 4634,
      "end_line": 4646,
      "content_start": 4637,
      "content_end": 4645,
      "header_lines": [
        4635
      ]
    },
    "references": [
      "thm-stability-condition-final-corrected"
    ],
    "metadata": {
      "label": "thm-unfit-high-error-overlap-fraction"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 7,
      "chapter_file": "chapter_7.json",
      "section_id": "## 7. The Corrective Nature of Fitness: From Signal Generation to Intelligent Adaptation"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-cloning-operator-composition",
    "title": "Compositional Structure of $\\Psi_{\\text{clone}}$",
    "type": "theorem",
    "nl_statement": "The cloning operator $\\Psi_{\\text{clone}}$ admits a compositional integral representation involving measurement, fitness, decision, and update components, forming a proper Markov kernel on the state space $\\Sigma_N$.",
    "equations": [],
    "hypotheses": [],
    "conclusion": {
      "text": null,
      "latex": null
    },
    "variables": [
      {
        "symbol": "S",
        "name": "current state",
        "description": "Current population state.",
        "constraints": [
          "$S \\in \\Sigma_N$"
        ],
        "tags": [
          "state",
          "population"
        ]
      },
      {
        "symbol": "\\mathbf{d}",
        "name": "distance vector",
        "description": "Raw distance vector from measurements.",
        "constraints": [],
        "tags": [
          "distance",
          "vector"
        ]
      },
      {
        "symbol": "\\mathbf{c}",
        "name": "companion assignments",
        "description": "Assignments of companions in the cloning process.",
        "constraints": [],
        "tags": [
          "companion",
          "assignment"
        ]
      },
      {
        "symbol": "\\mathbf{a}",
        "name": "actions",
        "description": "Actions taken in the decision process.",
        "constraints": [],
        "tags": [
          "action",
          "decision"
        ]
      },
      {
        "symbol": "\\mathbf{V}_{\\text{fit}}",
        "name": "fitness vector",
        "description": "Deterministic fitness values derived from distances.",
        "constraints": [],
        "tags": [
          "fitness",
          "vector"
        ]
      },
      {
        "symbol": "A",
        "name": "measurable set",
        "description": "Subset of the state space $\\Sigma_N$.",
        "constraints": [
          "measurable"
        ],
        "tags": [
          "set",
          "measurable"
        ]
      },
      {
        "symbol": "S'",
        "name": "next state",
        "description": "Resulting state after cloning transition.",
        "constraints": [
          "$S' \\in \\Sigma_N$"
        ],
        "tags": [
          "state",
          "next"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "All involved distributions $P_{\\text{measure}}$ and $P_{\\text{decision}}$ are probability measures ensuring the integral is well-defined.",
        "confidence": 1.0
      },
      {
        "text": "The state space $\\Sigma_N$ is equipped with a sigma-algebra making subsets measurable.",
        "confidence": 1.0
      },
      {
        "text": "$\\Psi_{\\text{update}}$ is a stochastic kernel outputting valid distributions on $\\Sigma_N$.",
        "confidence": 0.9
      },
      {
        "text": "Fitness evaluation $\\mathbf{V}_{\\text{fit}}$ is deterministic and measurable.",
        "confidence": 1.0
      }
    ],
    "local_refs": [],
    "proof": null,
    "tags": [
      "cloning",
      "operator",
      "composition",
      "Markov kernel",
      "integral representation",
      "stochastic process"
    ],
    "content_markdown": ":label: thm-cloning-operator-composition\n\nThe cloning operator admits the following compositional representation:\n\n$$\n\\Psi_{\\text{clone}}(S, \\cdot) = \\int_{\\mathbf{d}} \\int_{\\mathbf{c}, \\mathbf{a}} \\Psi_{\\text{update}}(S, \\mathbf{c}, \\mathbf{a}, \\cdot) \\, dP_{\\text{decision}}(S, \\mathbf{V}_{\\text{fit}}(\\mathbf{d}), \\mathbf{c}, \\mathbf{a}) \\, dP_{\\text{measure}}(S, \\mathbf{d})\n$$\n\nwhere:\n- $P_{\\text{measure}}(S, \\cdot)$ is the distribution of raw distance vectors from $\\Psi_{\\text{measure}}$\n- $\\mathbf{V}_{\\text{fit}}(\\mathbf{d})$ is the deterministic fitness vector from $\\Psi_{\\text{fitness}}$ given $S$ and $\\mathbf{d}$\n- $P_{\\text{decision}}(S, \\mathbf{V}_{\\text{fit}}, \\cdot)$ is the joint distribution of companion assignments and actions\n- $\\Psi_{\\text{update}}(S, \\mathbf{c}, \\mathbf{a}, \\cdot)$ is the (possibly stochastic) output distribution given the actions\n\nThis composition is a proper Markov kernel: for any measurable set $A \\subseteq \\Sigma_N$,\n\n$$\n\\Psi_{\\text{clone}}(S, A) = P(S' \\in A \\mid S)\n$$",
    "raw_directive": "6178: We now assemble the complete operator from its components.\n6179: \n6180: :::{prf:theorem} Compositional Structure of $\\Psi_{\\text{clone}}$\n6181: :label: thm-cloning-operator-composition\n6182: \n6183: The cloning operator admits the following compositional representation:\n6184: \n6185: $$\n6186: \\Psi_{\\text{clone}}(S, \\cdot) = \\int_{\\mathbf{d}} \\int_{\\mathbf{c}, \\mathbf{a}} \\Psi_{\\text{update}}(S, \\mathbf{c}, \\mathbf{a}, \\cdot) \\, dP_{\\text{decision}}(S, \\mathbf{V}_{\\text{fit}}(\\mathbf{d}), \\mathbf{c}, \\mathbf{a}) \\, dP_{\\text{measure}}(S, \\mathbf{d})\n6187: $$\n6188: \n6189: where:\n6190: - $P_{\\text{measure}}(S, \\cdot)$ is the distribution of raw distance vectors from $\\Psi_{\\text{measure}}$\n6191: - $\\mathbf{V}_{\\text{fit}}(\\mathbf{d})$ is the deterministic fitness vector from $\\Psi_{\\text{fitness}}$ given $S$ and $\\mathbf{d}$\n6192: - $P_{\\text{decision}}(S, \\mathbf{V}_{\\text{fit}}, \\cdot)$ is the joint distribution of companion assignments and actions\n6193: - $\\Psi_{\\text{update}}(S, \\mathbf{c}, \\mathbf{a}, \\cdot)$ is the (possibly stochastic) output distribution given the actions\n6194: \n6195: This composition is a proper Markov kernel: for any measurable set $A \\subseteq \\Sigma_N$,\n6196: \n6197: $$\n6198: \\Psi_{\\text{clone}}(S, A) = P(S' \\in A \\mid S)\n6199: $$\n6200: ",
    "document_id": "03_cloning",
    "section": "## 9.4. Complete Operator Specification",
    "span": {
      "start_line": 6178,
      "end_line": 6200,
      "content_start": 6181,
      "content_end": 6199,
      "header_lines": [
        6179
      ]
    },
    "references": [],
    "metadata": {
      "label": "thm-cloning-operator-composition"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 12,
      "chapter_file": "chapter_12.json",
      "section_id": "## 9.4. Complete Operator Specification"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-positional-variance-contraction",
    "title": "Positional Variance Contraction Under Cloning",
    "type": "theorem",
    "nl_statement": "Under the foundational axioms of Chapter 4, there exist constants κ_x > 0, C_x < ∞, and structural error threshold R²_spread > 0, all independent of N, such that for any pair of swarms (S_1, S_2), the expected positional variance after cloning contracts: E_clone[V_Var,x(S'_1, S'_2) | S_1, S_2] ≤ (1 - κ_x) V_Var,x(S_1, S_2) + C_x. Moreover, if V_Var,x(S_1, S_2) > \\tilde{C}_x for sufficiently large \\tilde{C}_x, then E_clone[Δ V_Var,x] < 0, where Δ V_Var,x = V_Var,x(S'_1, S'_2) - V_Var,x(S_1, S_2).",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S_1, S_2) + C_x"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] := \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) - V_{\\text{Var},x}(S_1, S_2)] < 0"
      }
    ],
    "hypotheses": [
      {
        "text": "Under the foundational axioms (Chapter 4)",
        "latex": null
      },
      {
        "text": "There exist constants κ_x > 0, C_x < ∞, and R²_spread > 0, all independent of N",
        "latex": null
      },
      {
        "text": "For any pair of swarms (S_1, S_2)",
        "latex": null
      },
      {
        "text": "When V_Var,x(S_1, S_2) > \tilde{C}_x for sufficiently large \tilde{C}_x",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "The expected positional variance after cloning satisfies the contraction inequality, and becomes strictly negative when above the threshold",
      "latex": null
    },
    "variables": [
      {
        "symbol": "\\kappa_x",
        "name": "kappa_x",
        "description": "positive contraction constant",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "C_x",
        "name": "C_x",
        "description": "finite additive error constant",
        "constraints": [
          "< \\infty"
        ],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "R^2_{\\text{spread}}",
        "name": "R_spread_squared",
        "description": "structural error threshold",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "threshold"
        ]
      },
      {
        "symbol": "V_{\\text{Var},x}",
        "name": "V_Var_x",
        "description": "positional variance function",
        "constraints": [],
        "tags": [
          "variance",
          "function"
        ]
      },
      {
        "symbol": "S_1",
        "name": "S_1",
        "description": "first swarm",
        "constraints": [],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "S_2",
        "name": "S_2",
        "description": "second swarm",
        "constraints": [],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "S'_1",
        "name": "S_prime_1",
        "description": "cloned first swarm",
        "constraints": [],
        "tags": [
          "swarm",
          "cloned"
        ]
      },
      {
        "symbol": "S'_2",
        "name": "S_prime_2",
        "description": "cloned second swarm",
        "constraints": [],
        "tags": [
          "swarm",
          "cloned"
        ]
      },
      {
        "symbol": "\\tilde{C}_x",
        "name": "C_tilde_x",
        "description": "sufficiently large variance threshold",
        "constraints": [],
        "tags": [
          "threshold"
        ]
      },
      {
        "symbol": "N",
        "name": "N",
        "description": "swarm size parameter",
        "constraints": [],
        "tags": [
          "size"
        ]
      },
      {
        "symbol": "\\text{clone}",
        "name": "clone",
        "description": "cloning process",
        "constraints": [],
        "tags": [
          "process"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Constants are independent of swarm size N",
        "confidence": 1.0
      },
      {
        "text": "Cloning process is stochastic, allowing for expectation",
        "confidence": 0.9
      },
      {
        "text": "Swarms S_1 and S_2 are valid under foundational axioms",
        "confidence": 1.0
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-lem-velocity-noise-propagation",
      "title": null,
      "type": "proof",
      "proves": "thm-positional-variance-contraction",
      "proof_type": "direct",
      "proof_status": "sketch",
      "content_markdown": ":::{prf:proof}\n:label: proof-lem-velocity-noise-propagation\n**Proof of {prf:ref}`thm-positional-variance-contraction`.**\n\nCombining Lemmas 10.3.4 and 10.3.5:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] &= \\sum_{k=1,2} \\mathbb{E}[\\Delta V_{\\text{Var},x}^{(k,\\text{alive})} + \\Delta V_{\\text{Var},x}^{(k,\\text{status})}] \\\\\n&\\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|\n\\end{aligned}\n$$\n\n**Step 1: Relate $V_{\\text{struct}}$ to $V_{\\text{Var},x}$**\n\nFrom {prf:ref}`lem-sx-implies-variance`, if the structural error satisfies $V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}$ (which holds when both swarms have similar numbers of alive walkers), then:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}\n$$\n\nwhere $C_{\\text{total}}$ absorbs all bounded terms.\n\n**Step 2: Express as geometric contraction**\n\nDefine:\n\n$$\n\\kappa_x := \\frac{\\chi(\\epsilon)}{4N} \\cdot \\frac{1}{\\text{(typical variance)}}\n$$\n\nAfter rescaling and using the fact that $V_{\\text{Var},x}$ is $N$-normalized:\n\n$$\n\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x\n$$\n\nThe constant $\\kappa_x > 0$ is independent of $N$ due to the N-uniformity of the Keystone Lemma.",
      "raw_directive": "6703: ### 10.3.6. Proof of Main Theorem\n6704: \n6705: :::{prf:proof}\n6706: :label: proof-lem-velocity-noise-propagation\n6707: **Proof of {prf:ref}`thm-positional-variance-contraction`.**\n6708: \n6709: Combining Lemmas 10.3.4 and 10.3.5:\n6710: \n6711: $$\n6712: \\begin{aligned}\n6713: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] &= \\sum_{k=1,2} \\mathbb{E}[\\Delta V_{\\text{Var},x}^{(k,\\text{alive})} + \\Delta V_{\\text{Var},x}^{(k,\\text{status})}] \\\\\n6714: &\\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|\n6715: \\end{aligned}\n6716: $$\n6717: \n6718: **Step 1: Relate $V_{\\text{struct}}$ to $V_{\\text{Var},x}$**\n6719: \n6720: From {prf:ref}`lem-sx-implies-variance`, if the structural error satisfies $V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}$ (which holds when both swarms have similar numbers of alive walkers), then:\n6721: \n6722: $$\n6723: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}\n6724: $$\n6725: \n6726: where $C_{\\text{total}}$ absorbs all bounded terms.\n6727: \n6728: **Step 2: Express as geometric contraction**\n6729: \n6730: Define:\n6731: \n6732: $$\n6733: \\kappa_x := \\frac{\\chi(\\epsilon)}{4N} \\cdot \\frac{1}{\\text{(typical variance)}}\n6734: $$\n6735: \n6736: After rescaling and using the fact that $V_{\\text{Var},x}$ is $N$-normalized:\n6737: \n6738: $$\n6739: \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x\n6740: $$\n6741: \n6742: The constant $\\kappa_x > 0$ is independent of $N$ due to the N-uniformity of the Keystone Lemma.\n6743: ",
      "strategy_summary": "The proof combines bounds from Lemmas 10.3.4 and 10.3.5 to obtain an inequality for the expected change in positional variance, relates the structural variance term back to the total variance using Lemma 10.3.6, and rescales to demonstrate a geometric contraction in the variance functional independent of the swarm size N.",
      "conclusion": {
        "text": "The expected positional variance contracts geometrically: \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x, where \\kappa_x > 0 is independent of N.",
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x"
      },
      "assumptions": [
        {
          "text": "The structural error satisfies V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}, which holds when both swarms have similar numbers of alive walkers.",
          "latex": "V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}"
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "combination",
          "text": "Combine Lemmas 10.3.4 and 10.3.5 to bound the expected change in variance.",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] = \\sum_{k=1,2} \\mathbb{E}[\\Delta V_{\\text{Var},x}^{(k,\\text{alive})} + \\Delta V_{\\text{Var},x}^{(k,\\text{status})}] \\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|",
          "references": [
            "lem-10.3.4",
            "lem-10.3.5"
          ],
          "derived_statement": "Initial bound on \\Delta V_{\\text{Var},x}"
        },
        {
          "order": 2.0,
          "kind": "relation",
          "text": "Use Lemma 10.3.6 to relate V_{\\text{struct}} to V_{\\text{Var},x} under the assumption, absorbing bounded terms into C_{\\text{total}}.",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}",
          "references": [
            "lem-sx-implies-variance"
          ],
          "derived_statement": "Simplified bound with contraction in V_{\\text{Var},x}"
        },
        {
          "order": 3.0,
          "kind": "rescaling",
          "text": "Define \\kappa_x and rescale using N-normalization to obtain the geometric contraction form.",
          "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x",
          "references": [],
          "derived_statement": "Final contraction inequality"
        }
      ],
      "key_equations": [
        {
          "label": "eq-combined-bound",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|",
          "role": "Initial combined inequality from lemmas"
        },
        {
          "label": "eq-related-variance",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}",
          "role": "Bound after relating structural to total variance"
        },
        {
          "label": "eq-geometric-contraction",
          "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x",
          "role": "Final contraction result"
        }
      ],
      "references": [
        "thm-positional-variance-contraction",
        "lem-sx-implies-variance"
      ],
      "math_tools": [
        {
          "toolName": "Lyapunov Function",
          "field": "Dynamical Systems",
          "description": "A function used to prove stability or convergence by showing its decrease along system trajectories.",
          "roleInProof": "V_var,x serves as a Lyapunov functional whose expected decrease implies contraction in positional variance.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Contraction Mapping"
          ]
        },
        {
          "toolName": "Expectation Operator",
          "field": "Probability Theory",
          "description": "The integral average over a probability measure, used to analyze average behavior in stochastic settings.",
          "roleInProof": "Applied to compute the expected change in variance under cloning and updates.",
          "levelOfAbstraction": "Notation",
          "relatedTools": [
            "Variance"
          ]
        },
        {
          "toolName": "Geometric Contraction",
          "field": "Analysis",
          "description": "A form of inequality showing that a quantity decreases by a fixed factor less than 1 plus a constant term.",
          "roleInProof": "Derives the final form E[V'(S)] <= (1 - kappa) V(S) + C to establish convergence.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Lyapunov Function",
            "Gronwall Inequality"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "The contraction constant \\kappa_x > 0 is independent of N due to the N-uniformity of the Keystone Lemma."
        }
      ],
      "gaps": [
        {
          "description": "Detailed derivation of the combination of Lemmas 10.3.4 and 10.3.5 is omitted; assumes direct summation of their bounds.",
          "severity": "minor",
          "location_hint": "Initial inequality"
        },
        {
          "description": "Precise definition of 'typical variance' and rescaling details for \\kappa_x are not fully expanded.",
          "severity": "moderate",
          "location_hint": "Step 2"
        }
      ],
      "tags": [
        "variance-contraction",
        "expected-change",
        "geometric-decay",
        "stochastic-process",
        "swarm-dynamics",
        "lyapunov-function",
        "n-uniformity"
      ],
      "document_id": "03_cloning",
      "section": "## 10.3. Positional Variance Contraction",
      "span": {
        "start_line": 6703,
        "end_line": 6743,
        "content_start": 6705,
        "content_end": 6742,
        "header_lines": [
          6704
        ]
      },
      "metadata": {
        "label": "proof-lem-velocity-noise-propagation"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 17,
        "chapter_file": "chapter_17.json",
        "section_id": "## 10.3. Positional Variance Contraction"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "variance",
      "contraction",
      "cloning",
      "swarms",
      "positional",
      "expected value",
      "axioms"
    ],
    "content_markdown": ":label: thm-positional-variance-contraction\n\nUnder the foundational axioms (Chapter 4), there exist constants $\\kappa_x > 0$, $C_x < \\infty$, and a structural error threshold $R^2_{\\text{spread}} > 0$, all independent of $N$, such that for any pair of swarms $(S_1, S_2)$:\n\n$$\n\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S_1, S_2) + C_x\n$$\n\nFurthermore, when $V_{\\text{Var},x}(S_1, S_2) > \\tilde{C}_x$ for a sufficiently large threshold $\\tilde{C}_x$, the contraction becomes strict:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] := \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) - V_{\\text{Var},x}(S_1, S_2)] < 0",
    "raw_directive": "6363: ### 10.3.1. Main Theorem\n6364: \n6365: :::{prf:theorem} Positional Variance Contraction Under Cloning\n6366: :label: thm-positional-variance-contraction\n6367: \n6368: Under the foundational axioms (Chapter 4), there exist constants $\\kappa_x > 0$, $C_x < \\infty$, and a structural error threshold $R^2_{\\text{spread}} > 0$, all independent of $N$, such that for any pair of swarms $(S_1, S_2)$:\n6369: \n6370: $$\n6371: \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S_1, S_2) + C_x\n6372: $$\n6373: \n6374: Furthermore, when $V_{\\text{Var},x}(S_1, S_2) > \\tilde{C}_x$ for a sufficiently large threshold $\\tilde{C}_x$, the contraction becomes strict:\n6375: \n6376: $$\n6377: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] := \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S'_1, S'_2) - V_{\\text{Var},x}(S_1, S_2)] < 0\n6378: $$",
    "document_id": "03_cloning",
    "section": "## 10.3. Positional Variance Contraction",
    "span": {
      "start_line": 6363,
      "end_line": 6378,
      "content_start": 6366,
      "content_end": 6377,
      "header_lines": [
        6364
      ]
    },
    "references": [
      "thm-positional-variance-contraction",
      "lem-sx-implies-variance"
    ],
    "metadata": {
      "label": "thm-positional-variance-contraction"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 17,
      "chapter_file": "chapter_17.json",
      "section_id": "## 10.3. Positional Variance Contraction"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-velocity-variance-bounded-expansion",
    "title": "Bounded Velocity Variance Expansion from Cloning",
    "type": "theorem",
    "nl_statement": "There exists a state-independent constant \\(C_v < \\infty\\) such that for any swarm \\(S\\), the expected velocity variance after cloning is at most the current velocity variance plus \\(C_v\\), equivalently the expected one-step drift is at most \\(C_v\\).",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},v}(S')] \\leq V_{\\text{Var},v}(S) + C_v"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": null,
      "latex": null
    },
    "variables": [
      {
        "symbol": "C_v",
        "name": "constant",
        "description": "State-independent upper bound for variance expansion",
        "constraints": [
          "< \\infty"
        ],
        "tags": [
          "bound",
          "constant"
        ]
      },
      {
        "symbol": "S",
        "name": "swarm",
        "description": "Current state of the swarm",
        "constraints": [],
        "tags": [
          "swarm",
          "state"
        ]
      },
      {
        "symbol": "S'",
        "name": "cloned swarm",
        "description": "Swarm state after cloning",
        "constraints": [],
        "tags": [
          "swarm",
          "state"
        ]
      },
      {
        "symbol": "V_{\\text{Var},v}",
        "name": "velocity variance",
        "description": "Variance of velocities in the swarm",
        "constraints": [],
        "tags": [
          "variance",
          "velocity"
        ]
      }
    ],
    "implicit_assumptions": [],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-velocity-variance-bounded-expansion",
      "title": null,
      "type": "proof",
      "proves": "thm-velocity-variance-bounded-expansion",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-velocity-variance-bounded-expansion\n**Proof.**\n\nThe proof analyzes how the inelastic collision model affects velocity variance.\n\n**Step 1: Velocity domain boundedness**\n\nBy Axiom EG-4 (velocity regularization), all walker velocities in viable swarms satisfy:\n\n$$\n\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}\n$$\n\nThis bound is state-independent, depending only on physical parameters.\n\n**Step 2: Per-walker velocity change**\n\nWhen walker $i$ participates in an $(M+1)$-particle inelastic collision, its velocity changes from $v_i$ to:\n\n$$\nv'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)\n$$\n\nwhere $u_i = v_i - V_{\\text{COM}}$ and $R_i$ is a random rotation.\n\nThe squared velocity change is bounded:\n\n$$\n\\|v'_i - v_i\\|^2 = \\|\\alpha_{\\text{restitution}} \\cdot R_i(u_i) - u_i\\|^2 \\leq (\\alpha_{\\text{restitution}} + 1)^2 \\|u_i\\|^2\n$$\n\nSince $\\|u_i\\| \\leq 2V_{\\max}$ (difference of two bounded velocities):\n\n$$\n\\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2\n$$\n\n**Step 3: Variance change decomposition**\n\nThe velocity variance changes due to:\n\n1. **Direct velocity resets** for cloned walkers (bounded by Step 2)\n2. **Barycenter shift** affecting centered velocities (bounded by total momentum conservation)\n3. **Random rotations** redistributing kinetic energy (bounded by elastic limit)\n\nEach contribution is bounded by constants depending only on $V_{\\max}$, $\\alpha_{\\text{restitution}}$, and $N$.\n\n**Step 4: Total bounded expansion**\n\nSumming over all walkers and using $N$-normalization:\n\n$$\n\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq \\frac{1}{N} \\sum_{i=1}^N p_i \\cdot 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}}\n$$\n\nSince $p_i \\in [0,1]$ and $\\sum_i p_i \\leq N$ (at most all walkers clone):\n\n$$\n\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}} =: C_v\n$$\n\nThis constant is **state-independent** and **$N$-independent** (the $N$ cancels in the normalization).",
      "raw_directive": "6768: ### 10.4.1. Proof\n6769: \n6770: :::{prf:proof}\n6771: :label: proof-thm-velocity-variance-bounded-expansion\n6772: **Proof.**\n6773: \n6774: The proof analyzes how the inelastic collision model affects velocity variance.\n6775: \n6776: **Step 1: Velocity domain boundedness**\n6777: \n6778: By Axiom EG-4 (velocity regularization), all walker velocities in viable swarms satisfy:\n6779: \n6780: $$\n6781: \\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}\n6782: $$\n6783: \n6784: This bound is state-independent, depending only on physical parameters.\n6785: \n6786: **Step 2: Per-walker velocity change**\n6787: \n6788: When walker $i$ participates in an $(M+1)$-particle inelastic collision, its velocity changes from $v_i$ to:\n6789: \n6790: $$\n6791: v'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)\n6792: $$\n6793: \n6794: where $u_i = v_i - V_{\\text{COM}}$ and $R_i$ is a random rotation.\n6795: \n6796: The squared velocity change is bounded:\n6797: \n6798: $$\n6799: \\|v'_i - v_i\\|^2 = \\|\\alpha_{\\text{restitution}} \\cdot R_i(u_i) - u_i\\|^2 \\leq (\\alpha_{\\text{restitution}} + 1)^2 \\|u_i\\|^2\n6800: $$\n6801: \n6802: Since $\\|u_i\\| \\leq 2V_{\\max}$ (difference of two bounded velocities):\n6803: \n6804: $$\n6805: \\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2\n6806: $$\n6807: \n6808: **Step 3: Variance change decomposition**\n6809: \n6810: The velocity variance changes due to:\n6811: \n6812: 1. **Direct velocity resets** for cloned walkers (bounded by Step 2)\n6813: 2. **Barycenter shift** affecting centered velocities (bounded by total momentum conservation)\n6814: 3. **Random rotations** redistributing kinetic energy (bounded by elastic limit)\n6815: \n6816: Each contribution is bounded by constants depending only on $V_{\\max}$, $\\alpha_{\\text{restitution}}$, and $N$.\n6817: \n6818: **Step 4: Total bounded expansion**\n6819: \n6820: Summing over all walkers and using $N$-normalization:\n6821: \n6822: $$\n6823: \\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq \\frac{1}{N} \\sum_{i=1}^N p_i \\cdot 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}}\n6824: $$\n6825: \n6826: Since $p_i \\in [0,1]$ and $\\sum_i p_i \\leq N$ (at most all walkers clone):\n6827: \n6828: $$\n6829: \\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}} =: C_v\n6830: $$\n6831: \n6832: This constant is **state-independent** and **$N$-independent** (the $N$ cancels in the normalization).\n6833: ",
      "strategy_summary": "The proof establishes a state- and N-independent bound on the expected change in velocity variance by first bounding individual velocities, then the velocity changes in collisions, decomposing the variance change into direct resets, barycenter shifts, and random rotations, and finally summing the bounded contributions.",
      "conclusion": {
        "text": "The expected change in velocity variance is bounded by a constant C_v independent of state and N.",
        "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq C_v"
      },
      "assumptions": [
        {
          "text": "Axiom EG-4: Velocity regularization bounds all velocities by V_max based on physical parameters.",
          "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}"
        },
        {
          "text": "Inelastic collision with restitution coefficient alpha_restitution and random rotations.",
          "latex": "v'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)"
        },
        {
          "text": "Momentum conservation in collisions.",
          "latex": null
        },
        {
          "text": "Normalization by N and probabilities p_i summing appropriately.",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "bound",
          "text": "Establish boundedness of velocity domain using Axiom EG-4.",
          "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}",
          "references": [
            "axiom-eg-4"
          ],
          "derived_statement": "All velocities are uniformly bounded by state-independent constant."
        },
        {
          "order": 2.0,
          "kind": "bound",
          "text": "Bound the squared velocity change for a walker in collision.",
          "latex": "\\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2",
          "references": [],
          "derived_statement": "Individual velocity updates are bounded."
        },
        {
          "order": 3.0,
          "kind": "decomposition",
          "text": "Decompose variance change into direct resets, barycenter shift, and random rotations, each bounded.",
          "latex": null,
          "references": [],
          "derived_statement": "Each component's contribution to variance change is controlled by constants."
        },
        {
          "order": 4.0,
          "kind": "summing",
          "text": "Sum bounds over walkers with N-normalization to get total expected variance change bound.",
          "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}} =: C_v",
          "references": [],
          "derived_statement": "Overall bound is state- and N-independent."
        }
      ],
      "key_equations": [
        {
          "label": "eq-vmax",
          "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}",
          "role": "Velocity bound from axiom."
        },
        {
          "label": "eq-velocity-update",
          "latex": "v'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)",
          "role": "Post-collision velocity formula."
        },
        {
          "label": "eq-change-bound",
          "latex": "\\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2",
          "role": "Bound on squared velocity change."
        },
        {
          "label": "eq-variance-change",
          "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq \\frac{1}{N} \\sum_{i=1}^N p_i \\cdot 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}}",
          "role": "Decomposed expected variance change."
        },
        {
          "label": "eq-final-bound",
          "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq C_v",
          "role": "Final constant bound."
        }
      ],
      "references": [],
      "math_tools": [
        {
          "toolName": "Vector norms",
          "field": "Linear Algebra",
          "description": "Measures the magnitude of velocity vectors to bound changes.",
          "roleInProof": "Used to bound velocity magnitudes and squared differences in collision updates.",
          "levelOfAbstraction": "Notation",
          "relatedTools": [
            "Euclidean norm"
          ]
        },
        {
          "toolName": "Expectation",
          "field": "Probability",
          "description": "Computes the average change in variance under random collision outcomes.",
          "roleInProof": "Bounds the expected variance change by linearity over walker contributions.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Variance"
          ]
        },
        {
          "toolName": "Inelastic collision model",
          "field": "Physics",
          "description": "Models velocity updates in multi-particle collisions with restitution coefficient.",
          "roleInProof": "Defines the velocity post-collision formula involving center-of-mass and rotations.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Center of mass",
            "Restitution coefficient"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "The bound is state-independent, relying only on physical parameters like V_max and alpha_restitution."
        },
        {
          "type": "note",
          "text": "N-independence arises from normalization canceling the sum over N walkers."
        }
      ],
      "gaps": [],
      "tags": [
        "velocity variance",
        "inelastic collision",
        "bounded expansion",
        "swarm model",
        "velocity regularization",
        "momentum conservation",
        "random rotation"
      ],
      "document_id": "03_cloning",
      "section": "## 10.4. Velocity Variance Bounded Expansion",
      "span": {
        "start_line": 6768,
        "end_line": 6833,
        "content_start": 6770,
        "content_end": 6832,
        "header_lines": [
          6769
        ]
      },
      "metadata": {
        "label": "proof-thm-velocity-variance-bounded-expansion"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 18,
        "chapter_file": "chapter_18.json",
        "section_id": "## 10.4. Velocity Variance Bounded Expansion"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "velocity",
      "variance",
      "cloning",
      "bounded",
      "expansion",
      "swarm",
      "drift",
      "expectation"
    ],
    "content_markdown": ":label: thm-velocity-variance-bounded-expansion\n\nThere exists a state-independent constant $C_v < \\infty$ such that for any swarm $S$:\n\n$$\n\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},v}(S')] \\leq V_{\\text{Var},v}(S) + C_v\n$$\n\nEquivalently, the one-step drift satisfies:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v",
    "raw_directive": "6749: We now prove that the velocity variance expansion from cloning is uniformly bounded.\n6750: \n6751: :::{prf:theorem} Bounded Velocity Variance Expansion from Cloning\n6752: :label: thm-velocity-variance-bounded-expansion\n6753: \n6754: There exists a state-independent constant $C_v < \\infty$ such that for any swarm $S$:\n6755: \n6756: $$\n6757: \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},v}(S')] \\leq V_{\\text{Var},v}(S) + C_v\n6758: $$\n6759: \n6760: Equivalently, the one-step drift satisfies:\n6761: \n6762: $$\n6763: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v\n6764: $$",
    "document_id": "03_cloning",
    "section": "## 10.4. Velocity Variance Bounded Expansion",
    "span": {
      "start_line": 6749,
      "end_line": 6764,
      "content_start": 6752,
      "content_end": 6763,
      "header_lines": [
        6750
      ]
    },
    "references": [],
    "metadata": {
      "label": "thm-velocity-variance-bounded-expansion"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 18,
      "chapter_file": "chapter_18.json",
      "section_id": "## 10.4. Velocity Variance Bounded Expansion"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-complete-variance-drift",
    "title": "Complete Variance Drift Characterization for Cloning",
    "type": "theorem",
    "nl_statement": "The cloning operator Ψ_clone induces a strong contraction on positional variance, bounded expansion on velocity variance, and a net contraction on total internal variance of the Lyapunov function.",
    "equations": [
      {
        "label": "positional-variance",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x"
      },
      {
        "label": "velocity-variance",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v"
      },
      {
        "label": "total-variance",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": "The cloning operator Ψ_clone induces the specified drifts on variance components: strong contraction for positional variance with N-independent κ_x > 0, bounded expansion for velocity variance, and net bound for total internal variance.",
      "latex": null
    },
    "variables": [
      {
        "symbol": "\\Psi_{\\text{clone}}",
        "name": "cloning operator",
        "description": "Operator inducing variance drifts on Lyapunov function components.",
        "constraints": [
          "linear"
        ],
        "tags": [
          "operator",
          "cloning"
        ]
      },
      {
        "symbol": "V_{\\text{Var},x}",
        "name": "positional variance",
        "description": "Variance component for positions in Lyapunov function.",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "variance",
          "position"
        ]
      },
      {
        "symbol": "V_{\\text{Var},v}",
        "name": "velocity variance",
        "description": "Variance component for velocities in Lyapunov function.",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "variance",
          "velocity"
        ]
      },
      {
        "symbol": "V_{\\text{Var}}",
        "name": "total internal variance",
        "description": "Sum of positional and velocity variance components.",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "variance",
          "total"
        ]
      },
      {
        "symbol": "\\kappa_x",
        "name": "contraction rate",
        "description": "Positive constant for positional variance contraction, N-independent.",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "rate",
          "contraction"
        ]
      },
      {
        "symbol": "C_x",
        "name": "positional constant",
        "description": "Constant in positional variance drift bound.",
        "constraints": [],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "C_v",
        "name": "velocity constant",
        "description": "Finite state-independent constant in velocity variance bound.",
        "constraints": [
          "< \\infty"
        ],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "\\Delta",
        "name": "change operator",
        "description": "Drift or change in variance components.",
        "constraints": [],
        "tags": [
          "drift"
        ]
      },
      {
        "symbol": "\\mathbb{E}_{\\text{clone}}",
        "name": "cloning expectation",
        "description": "Expectation under cloning operator.",
        "constraints": [],
        "tags": [
          "expectation"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The Lyapunov function is composed of variance components for positions and velocities.",
        "confidence": 1.0
      },
      {
        "text": "The system involves N particles or clones, with κ_x independent of N.",
        "confidence": 0.9
      },
      {
        "text": "Constants C_x and C_v are finite and state-independent where applicable.",
        "confidence": 1.0
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-complete-variance-drift",
      "title": null,
      "type": "proof",
      "proves": "thm-complete-variance-drift",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-complete-variance-drift\n**Proof.**\n\nThis result follows immediately by combining the two component drift inequalities established earlier in this chapter.\n\nFrom {prf:ref}`thm-positional-variance-contraction` ({prf:ref}`thm-positional-variance-contraction`), we have:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x\n$$\n\nFrom {prf:ref}`thm-bounded-velocity-expansion-cloning` ({prf:ref}`thm-velocity-variance-bounded-expansion`), we have:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v\n$$\n\nBy linearity of expectation, the total internal variance drift is:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] &= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x} + \\Delta V_{\\text{Var},v}] \\\\\n&= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\\\\n&\\leq (-\\kappa_x V_{\\text{Var},x} + C_x) + C_v \\\\\n&= -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)\n\\end{aligned}\n$$\n\nThis establishes the claimed drift inequality for the total variance.",
      "raw_directive": "6924: :::\n6925: \n6926: :::{prf:proof}\n6927: :label: proof-thm-complete-variance-drift\n6928: **Proof.**\n6929: \n6930: This result follows immediately by combining the two component drift inequalities established earlier in this chapter.\n6931: \n6932: From {prf:ref}`thm-positional-variance-contraction` ({prf:ref}`thm-positional-variance-contraction`), we have:\n6933: \n6934: $$\n6935: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x\n6936: $$\n6937: \n6938: From {prf:ref}`thm-bounded-velocity-expansion-cloning` ({prf:ref}`thm-velocity-variance-bounded-expansion`), we have:\n6939: \n6940: $$\n6941: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v\n6942: $$\n6943: \n6944: By linearity of expectation, the total internal variance drift is:\n6945: \n6946: $$\n6947: \\begin{aligned}\n6948: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] &= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x} + \\Delta V_{\\text{Var},v}] \\\\\n6949: &= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\\\\n6950: &\\leq (-\\kappa_x V_{\\text{Var},x} + C_x) + C_v \\\\\n6951: &= -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)\n6952: \\end{aligned}\n6953: $$\n6954: \n6955: This establishes the claimed drift inequality for the total variance.\n6956: ",
      "strategy_summary": "The proof directly combines the established drift inequalities for positional and velocity variances using linearity of expectation to derive the total internal variance drift inequality.",
      "conclusion": {
        "text": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)"
      },
      "assumptions": [],
      "steps": [
        {
          "order": 1.0,
          "kind": "reference",
          "text": "Recall the positional variance contraction inequality.",
          "latex": null,
          "references": [
            "thm-positional-variance-contraction"
          ],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x"
        },
        {
          "order": 2.0,
          "kind": "reference",
          "text": "Recall the bounded velocity variance expansion inequality.",
          "latex": null,
          "references": [
            "thm-bounded-velocity-expansion-cloning",
            "thm-velocity-variance-bounded-expansion"
          ],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v"
        },
        {
          "order": 3.0,
          "kind": "application",
          "text": "Apply linearity of expectation to the total variance change.",
          "latex": null,
          "references": [],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x} + \\Delta V_{\\text{Var},v}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]"
        },
        {
          "order": 4.0,
          "kind": "inequality",
          "text": "Combine the inequalities to obtain the total drift bound.",
          "latex": null,
          "references": [],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq (-\\kappa_x V_{\\text{Var},x} + C_x) + C_v = -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)"
        }
      ],
      "key_equations": [
        {
          "label": "eq-positional-drift",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x",
          "role": "Component inequality for positional variance"
        },
        {
          "label": "eq-velocity-drift",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v",
          "role": "Component inequality for velocity variance"
        },
        {
          "label": "eq-total-drift",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)",
          "role": "Final total variance drift inequality"
        }
      ],
      "references": [
        "thm-positional-variance-contraction",
        "thm-bounded-velocity-expansion-cloning",
        "thm-velocity-variance-bounded-expansion"
      ],
      "math_tools": [
        {
          "toolName": "Linearity of Expectation",
          "field": "Probability Theory",
          "description": "The expectation of the sum of random variables equals the sum of their individual expectations, regardless of dependence.",
          "roleInProof": "Applied to separate the expected change in total variance into positional and velocity components.",
          "levelOfAbstraction": "Theorem/Lemma",
          "relatedTools": []
        }
      ],
      "cases": [],
      "remarks": [],
      "gaps": [],
      "tags": [
        "variance",
        "drift",
        "inequality",
        "linearity of expectation",
        "cloning",
        "probabilistic drift"
      ],
      "document_id": "03_cloning",
      "section": "## 10.6. Summary of Variance Drift Inequalities",
      "span": {
        "start_line": 6924,
        "end_line": 6956,
        "content_start": 6926,
        "content_end": 6955,
        "header_lines": [
          6925
        ]
      },
      "metadata": {
        "label": "proof-thm-complete-variance-drift"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 20,
        "chapter_file": "chapter_20.json",
        "section_id": "## 10.6. Summary of Variance Drift Inequalities"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "cloning",
      "variance",
      "drift",
      "Lyapunov",
      "contraction",
      "expansion"
    ],
    "content_markdown": ":label: thm-complete-variance-drift\n\nThe cloning operator $\\Psi_{\\text{clone}}$ induces the following drift on the variance components of the Lyapunov function:\n\n**1. Positional Variance (Strong Contraction):**\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x\n$$\n\nwhere $\\kappa_x > 0$ is $N$-independent (from Keystone Principle).\n\n**2. Velocity Variance (Bounded Expansion):**\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v\n$$\n\nwhere $C_v < \\infty$ is a state-independent constant.\n\n**3. Total Internal Variance:**\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)\n$$",
    "raw_directive": "6894: We conclude by summarizing the main drift results for the variance components under $\\Psi_{\\text{clone}}$.\n6895: \n6896: :::{prf:theorem} Complete Variance Drift Characterization for Cloning\n6897: :label: thm-complete-variance-drift\n6898: \n6899: The cloning operator $\\Psi_{\\text{clone}}$ induces the following drift on the variance components of the Lyapunov function:\n6900: \n6901: **1. Positional Variance (Strong Contraction):**\n6902: \n6903: $$\n6904: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x\n6905: $$\n6906: \n6907: where $\\kappa_x > 0$ is $N$-independent (from Keystone Principle).\n6908: \n6909: **2. Velocity Variance (Bounded Expansion):**\n6910: \n6911: $$\n6912: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v\n6913: $$\n6914: \n6915: where $C_v < \\infty$ is a state-independent constant.\n6916: \n6917: **3. Total Internal Variance:**\n6918: \n6919: $$\n6920: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)\n6921: $$\n6922: ",
    "document_id": "03_cloning",
    "section": "## 10.6. Summary of Variance Drift Inequalities",
    "span": {
      "start_line": 6894,
      "end_line": 6922,
      "content_start": 6897,
      "content_end": 6921,
      "header_lines": [
        6895
      ]
    },
    "references": [
      "thm-positional-variance-contraction",
      "thm-bounded-velocity-expansion-cloning",
      "thm-velocity-variance-bounded-expansion"
    ],
    "metadata": {
      "label": "thm-complete-variance-drift"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 20,
      "chapter_file": "chapter_20.json",
      "section_id": "## 10.6. Summary of Variance Drift Inequalities"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-boundary-potential-contraction",
    "title": "Boundary Potential Contraction Under Cloning",
    "type": "theorem",
    "nl_statement": "Under the foundational axioms including the Safe Harbor Axiom, there exist constants κ_b > 0 and C_b < ∞ independent of N such that for any pair of swarms (S_1, S_2), the expected boundary potential after cloning is at most (1 - κ_b) times the original plus C_b. Furthermore, when W_b(S_1, S_2) > \\tilde{C}_b for sufficiently large \\tilde{C}_b, the expected change in boundary potential is negative.",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_b) W_b(S_1, S_2) + C_b"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta W_b] := \\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) - W_b(S_1, S_2)] < 0"
      }
    ],
    "hypotheses": [
      {
        "text": "Under the foundational axioms (Chapter 4) including the Safe Harbor Axiom (Axiom 4.3)",
        "latex": null
      },
      {
        "text": "For any pair of swarms (S_1, S_2)",
        "latex": null
      },
      {
        "text": "When W_b(S_1, S_2) > \\tilde{C}_b for sufficiently large threshold \\tilde{C}_b",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "There exist constants \\kappa_b > 0 and C_b < \\infty, both independent of N, such that \\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_b) W_b(S_1, S_2) + C_b, and the contraction becomes strict with \\mathbb{E}_{\\text{clone}}[\\Delta W_b] < 0",
      "latex": null
    },
    "variables": [
      {
        "symbol": "S_1",
        "name": "S1",
        "description": "First input swarm",
        "constraints": [
          "swarm"
        ],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "S_2",
        "name": "S2",
        "description": "Second input swarm",
        "constraints": [
          "swarm"
        ],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "S'_1",
        "name": "S'1",
        "description": "Cloned version of first swarm",
        "constraints": [
          "swarm"
        ],
        "tags": [
          "swarm",
          "cloned"
        ]
      },
      {
        "symbol": "S'_2",
        "name": "S'2",
        "description": "Cloned version of second swarm",
        "constraints": [
          "swarm"
        ],
        "tags": [
          "swarm",
          "cloned"
        ]
      },
      {
        "symbol": "W_b",
        "name": "Wb",
        "description": "Boundary potential function",
        "constraints": [],
        "tags": [
          "potential",
          "boundary"
        ]
      },
      {
        "symbol": "\\kappa_b",
        "name": "kappa_b",
        "description": "Positive contraction constant",
        "constraints": [
          "> 0"
        ],
        "tags": [
          "constant",
          "contraction"
        ]
      },
      {
        "symbol": "C_b",
        "name": "C_b",
        "description": "Finite additive constant",
        "constraints": [
          "< \\infty"
        ],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "\\tilde{C}_b",
        "name": "Ctilde_b",
        "description": "Sufficiently large threshold for strict contraction",
        "constraints": [
          "large"
        ],
        "tags": [
          "threshold"
        ]
      },
      {
        "symbol": "N",
        "name": "N",
        "description": "Parameter (e.g., dimension or size), independence from constants",
        "constraints": [],
        "tags": [
          "dimension"
        ]
      },
      {
        "symbol": "\\Delta W_b",
        "name": "Delta Wb",
        "description": "Change in boundary potential",
        "constraints": [],
        "tags": [
          "change",
          "potential"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Constants \\kappa_b and C_b are independent of N",
        "confidence": 1.0
      },
      {
        "text": "\\tilde{C}_b is chosen sufficiently large to ensure strict contraction",
        "confidence": 1.0
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-lem-barrier-reduction-measurement",
      "title": null,
      "type": "proof",
      "proves": "thm-boundary-potential-contraction",
      "proof_type": "direct",
      "proof_status": "sketch",
      "content_markdown": ":::{prf:proof}\n:label: proof-lem-barrier-reduction-measurement\n**Proof of {prf:ref}`thm-boundary-potential-contraction`.**\n\nWe analyze the expected change in boundary potential:\n\n$$\n\\Delta W_b = \\sum_{k=1,2} \\left[\\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S'_k)} \\varphi_{\\text{barrier}}(x'_{k,i}) - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\\right]\n$$\n\n**Step 1: Decompose by cloning action**\n\nFor each swarm $k$, split the sum into walkers that clone and walkers that persist:\n\n$$\n\\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]\n$$\n\n**Step 2: Bound contribution from boundary-exposed walkers**\n\nFor walkers in $\\mathcal{E}_{\\text{boundary}}(S_k)$:\n\n- By {prf:ref}`lem-boundary-enhanced-cloning`: $p_{k,i} \\geq p_{\\text{boundary}}(\\phi_{\\text{thresh}})$\n- By {prf:ref}`lem-barrier-reduction-cloning`: $\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] \\leq C_{\\text{jitter}}$\n\nTherefore:\n\n$$\n\\begin{aligned}\n\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} &\\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\\\\n&\\leq \\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{\\text{boundary}} [C_{\\text{jitter}} - \\varphi_{\\text{barrier}}(x_{k,i})]\n\\end{aligned}\n$$\n\nSince $\\varphi_{\\text{barrier}}(x_{k,i}) > \\phi_{\\text{thresh}}$ for $i \\in \\mathcal{E}_{\\text{boundary}}$:\n\n$$\n\\leq -p_{\\text{boundary}} \\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} [\\varphi_{\\text{barrier}}(x_{k,i}) - C_{\\text{jitter}}]\n$$\n\n$$\n\\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]\n$$\n\n**Step 3: Relate to total boundary potential**\n\nThe boundary-exposed mass satisfies:\n\n$$\nM_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\n$$\n\nIf most of $W_b$ comes from exposed walkers (which is true when $W_b$ is large):\n\n$$\nM_{\\text{boundary}}(S_k) \\geq W_b(S_k) - \\frac{k_{\\text{alive}}}{N} \\phi_{\\text{thresh}}\n$$\n\n**Step 4: Combine to get contraction**\n\nCombining Steps 2-3:\n\n$$\n\\mathbb{E}[\\Delta W_b^{(k)}] \\leq -\\frac{p_{\\text{boundary}}}{N} \\left[N \\cdot M_{\\text{boundary}}(S_k) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right] + \\text{(dead walker contribution)}\n$$\n\n$$\n\\leq -p_{\\text{boundary}} M_{\\text{boundary}}(S_k) + C'_{\\text{jitter}} + C_{\\text{dead}}\n$$\n\nUsing $M_{\\text{boundary}} \\approx W_b$ when $W_b$ is large:\n\n$$\n\\leq -p_{\\text{boundary}} W_b(S_k) + C_{\\text{total}}\n$$\n\nSumming over both swarms:\n\n$$\n\\mathbb{E}[\\Delta W_b] \\leq -p_{\\text{boundary}} W_b + 2C_{\\text{total}}\n$$\n\n**Step 5: Express as geometric contraction**\n\nDefining $\\kappa_b := p_{\\text{boundary}}$ and $C_b := 2C_{\\text{total}}$:\n\n$$\n\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b\n$$\n\nThe constant $\\kappa_b > 0$ is independent of $N$ by {prf:ref}`lem-boundary-enhanced-cloning`.",
      "raw_directive": "7461: ### 11.4.3. Proof of Main Theorem\n7462: \n7463: :::{prf:proof}\n7464: :label: proof-lem-barrier-reduction-measurement\n7465: **Proof of {prf:ref}`thm-boundary-potential-contraction`.**\n7466: \n7467: We analyze the expected change in boundary potential:\n7468: \n7469: $$\n7470: \\Delta W_b = \\sum_{k=1,2} \\left[\\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S'_k)} \\varphi_{\\text{barrier}}(x'_{k,i}) - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\\right]\n7471: $$\n7472: \n7473: **Step 1: Decompose by cloning action**\n7474: \n7475: For each swarm $k$, split the sum into walkers that clone and walkers that persist:\n7476: \n7477: $$\n7478: \\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]\n7479: $$\n7480: \n7481: **Step 2: Bound contribution from boundary-exposed walkers**\n7482: \n7483: For walkers in $\\mathcal{E}_{\\text{boundary}}(S_k)$:\n7484: \n7485: - By {prf:ref}`lem-boundary-enhanced-cloning`: $p_{k,i} \\geq p_{\\text{boundary}}(\\phi_{\\text{thresh}})$\n7486: - By {prf:ref}`lem-barrier-reduction-cloning`: $\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] \\leq C_{\\text{jitter}}$\n7487: \n7488: Therefore:\n7489: \n7490: $$\n7491: \\begin{aligned}\n7492: \\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} &\\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\\\\n7493: &\\leq \\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{\\text{boundary}} [C_{\\text{jitter}} - \\varphi_{\\text{barrier}}(x_{k,i})]\n7494: \\end{aligned}\n7495: $$\n7496: \n7497: Since $\\varphi_{\\text{barrier}}(x_{k,i}) > \\phi_{\\text{thresh}}$ for $i \\in \\mathcal{E}_{\\text{boundary}}$:\n7498: \n7499: $$\n7500: \\leq -p_{\\text{boundary}} \\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} [\\varphi_{\\text{barrier}}(x_{k,i}) - C_{\\text{jitter}}]\n7501: $$\n7502: \n7503: $$\n7504: \\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]\n7505: $$\n7506: \n7507: **Step 3: Relate to total boundary potential**\n7508: \n7509: The boundary-exposed mass satisfies:\n7510: \n7511: $$\n7512: M_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\n7513: $$\n7514: \n7515: If most of $W_b$ comes from exposed walkers (which is true when $W_b$ is large):\n7516: \n7517: $$\n7518: M_{\\text{boundary}}(S_k) \\geq W_b(S_k) - \\frac{k_{\\text{alive}}}{N} \\phi_{\\text{thresh}}\n7519: $$\n7520: \n7521: **Step 4: Combine to get contraction**\n7522: \n7523: Combining Steps 2-3:\n7524: \n7525: $$\n7526: \\mathbb{E}[\\Delta W_b^{(k)}] \\leq -\\frac{p_{\\text{boundary}}}{N} \\left[N \\cdot M_{\\text{boundary}}(S_k) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right] + \\text{(dead walker contribution)}\n7527: $$\n7528: \n7529: $$\n7530: \\leq -p_{\\text{boundary}} M_{\\text{boundary}}(S_k) + C'_{\\text{jitter}} + C_{\\text{dead}}\n7531: $$\n7532: \n7533: Using $M_{\\text{boundary}} \\approx W_b$ when $W_b$ is large:\n7534: \n7535: $$\n7536: \\leq -p_{\\text{boundary}} W_b(S_k) + C_{\\text{total}}\n7537: $$\n7538: \n7539: Summing over both swarms:\n7540: \n7541: $$\n7542: \\mathbb{E}[\\Delta W_b] \\leq -p_{\\text{boundary}} W_b + 2C_{\\text{total}}\n7543: $$\n7544: \n7545: **Step 5: Express as geometric contraction**\n7546: \n7547: Defining $\\kappa_b := p_{\\text{boundary}}$ and $C_b := 2C_{\\text{total}}$:\n7548: \n7549: $$\n7550: \\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b\n7551: $$\n7552: \n7553: The constant $\\kappa_b > 0$ is independent of $N$ by {prf:ref}`lem-boundary-enhanced-cloning`.\n7554: ",
      "strategy_summary": "The proof analyzes the expected change in the boundary potential by decomposing it into contributions from cloning and persisting walkers, bounding the cloning effects using referenced lemmas, relating boundary-exposed mass to the total potential, and deriving a geometric contraction inequality that holds when the potential is sufficiently large.",
      "conclusion": {
        "text": "E[W_b(S')] ≤ (1 - κ_b) W_b(S) + C_b, with κ_b > 0 independent of N.",
        "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b \\quad \\text{with} \\quad \\kappa_b > 0 \\text{ independent of } N"
      },
      "assumptions": [
        {
          "text": "Assumptions from lem-boundary-enhanced-cloning and lem-barrier-reduction-cloning hold, including boundary exposure conditions and threshold values.",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "decomposition",
          "text": "Decompose the expected change in boundary potential by cloning action, splitting sums over active walkers into cloning and persisting parts.",
          "latex": "\\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "bounding",
          "text": "Bound the contribution from boundary-exposed walkers using referenced lemmas: p_{k,i} ≥ p_boundary and E[φ_barrier | clone] ≤ C_jitter, leading to a negative term involving the barrier values.",
          "latex": "\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]",
          "references": [
            "lem-boundary-enhanced-cloning",
            "lem-barrier-reduction-cloning"
          ],
          "derived_statement": null
        },
        {
          "order": 3.0,
          "kind": "relation",
          "text": "Relate the boundary-exposed mass M_boundary to the total boundary potential W_b, noting M_boundary ≥ W_b - (k_alive / N) φ_thresh when W_b is large.",
          "latex": "M_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) \\geq W_b(S_k) - \\frac{k_{\\text{alive}}}{N} \\phi_{\\text{thresh}}",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 4.0,
          "kind": "combination",
          "text": "Combine the bounds to get E[Δ W_b^{(k)}] ≤ -p_boundary M_boundary + C'_jitter + C_dead, approximating M_boundary ≈ W_b for large W_b, and sum over swarms.",
          "latex": "\\mathbb{E}[\\Delta W_b] \\leq -p_{\\text{boundary}} W_b + 2C_{\\text{total}}",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 5.0,
          "kind": "contraction",
          "text": "Express the result as a geometric contraction with constants κ_b = p_boundary and C_b = 2 C_total, noting independence from N.",
          "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b",
          "references": [
            "lem-boundary-enhanced-cloning"
          ],
          "derived_statement": null
        }
      ],
      "key_equations": [
        {
          "label": "eq-delta-wb",
          "latex": "\\Delta W_b = \\sum_{k=1,2} \\left[\\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S'_k)} \\varphi_{\\text{barrier}}(x'_{k,i}) - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\\right]",
          "role": "Definition of boundary potential change"
        },
        {
          "label": "eq-decomp-clone",
          "latex": "\\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]",
          "role": "Decomposition by cloning action"
        },
        {
          "label": "eq-bound-exposed",
          "latex": "\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]",
          "role": "Bound for exposed walkers"
        },
        {
          "label": "eq-m-boundary",
          "latex": "M_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})",
          "role": "Definition of boundary-exposed mass"
        },
        {
          "label": "eq-contraction",
          "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b",
          "role": "Final contraction inequality"
        }
      ],
      "references": [
        "thm-boundary-potential-contraction",
        "lem-boundary-enhanced-cloning",
        "lem-barrier-reduction-cloning"
      ],
      "math_tools": [
        {
          "toolName": "Expectation",
          "field": "Probability",
          "description": "The expected value operator computes the average over random outcomes.",
          "roleInProof": "Used to analyze the average change in boundary potential under cloning and movement dynamics.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Inequality"
          ]
        },
        {
          "toolName": "Bounding inequalities",
          "field": "Analysis",
          "description": "Techniques to upper or lower bound expressions using properties of functions and measures.",
          "roleInProof": "Applied to bound the contribution from boundary-exposed walkers and relate it to the total potential for contraction.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Expectation"
          ]
        },
        {
          "toolName": "Geometric contraction",
          "field": "Dynamical Systems",
          "description": "A form of stability where a quantity decreases by a fixed factor plus a constant term.",
          "roleInProof": "Establishes the main contraction result for the boundary potential.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Bounding inequalities"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "note",
          "text": "The contraction holds approximately when W_b is large, as most of the potential comes from exposed walkers."
        },
        {
          "type": "independence",
          "text": "The constant κ_b > 0 is independent of N by lem-boundary-enhanced-cloning."
        }
      ],
      "gaps": [
        {
          "description": "Approximation M_boundary ≈ W_b when W_b is large; rigorous justification for 'most of W_b comes from exposed walkers' is sketched but not fully detailed.",
          "severity": "minor",
          "location_hint": "Step 3 and combination in Step 4"
        },
        {
          "description": "Contributions from dead walkers and persisting walkers are bounded by constants but not explicitly derived in detail.",
          "severity": "minor",
          "location_hint": "Step 1 and Step 4"
        }
      ],
      "tags": [
        "boundary potential",
        "contraction",
        "cloning",
        "expected change",
        "barrier function",
        "swarm dynamics",
        "inequality bound"
      ],
      "document_id": "03_cloning",
      "section": "## 11.4. Proof of Boundary Potential Contraction",
      "span": {
        "start_line": 7461,
        "end_line": 7554,
        "content_start": 7463,
        "content_end": 7553,
        "header_lines": [
          7462
        ]
      },
      "metadata": {
        "label": "proof-lem-barrier-reduction-measurement"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 25,
        "chapter_file": "chapter_25.json",
        "section_id": "## 11.4. Proof of Boundary Potential Contraction"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "boundary-potential",
      "contraction",
      "cloning",
      "swarms",
      "safe-harbor",
      "expectation",
      "inequality"
    ],
    "content_markdown": ":label: thm-boundary-potential-contraction\n\nUnder the foundational axioms (Chapter 4) including the Safe Harbor Axiom (Axiom 4.3), there exist constants $\\kappa_b > 0$ and $C_b < \\infty$, both independent of $N$, such that for any pair of swarms $(S_1, S_2)$:\n\n$$\n\\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_b) W_b(S_1, S_2) + C_b\n$$\n\nFurthermore, when $W_b(S_1, S_2) > \\tilde{C}_b$ for a sufficiently large threshold $\\tilde{C}_b$, the contraction becomes strict:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta W_b] := \\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) - W_b(S_1, S_2)] < 0",
    "raw_directive": "7292: ## 11.3. Main Theorem: Boundary Potential Contraction\n7293: \n7294: :::{prf:theorem} Boundary Potential Contraction Under Cloning\n7295: :label: thm-boundary-potential-contraction\n7296: \n7297: Under the foundational axioms (Chapter 4) including the Safe Harbor Axiom (Axiom 4.3), there exist constants $\\kappa_b > 0$ and $C_b < \\infty$, both independent of $N$, such that for any pair of swarms $(S_1, S_2)$:\n7298: \n7299: $$\n7300: \\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) \\mid S_1, S_2] \\leq (1 - \\kappa_b) W_b(S_1, S_2) + C_b\n7301: $$\n7302: \n7303: Furthermore, when $W_b(S_1, S_2) > \\tilde{C}_b$ for a sufficiently large threshold $\\tilde{C}_b$, the contraction becomes strict:\n7304: \n7305: $$\n7306: \\mathbb{E}_{\\text{clone}}[\\Delta W_b] := \\mathbb{E}_{\\text{clone}}[W_b(S'_1, S'_2) - W_b(S_1, S_2)] < 0\n7307: $$",
    "document_id": "03_cloning",
    "section": "## 11.3. Main Theorem: Boundary Potential Contraction",
    "span": {
      "start_line": 7292,
      "end_line": 7307,
      "content_start": 7295,
      "content_end": 7306,
      "header_lines": [
        7293
      ]
    },
    "references": [
      "thm-boundary-potential-contraction",
      "lem-boundary-enhanced-cloning",
      "lem-barrier-reduction-cloning"
    ],
    "metadata": {
      "label": "thm-boundary-potential-contraction"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 24,
      "chapter_file": "chapter_24.json",
      "section_id": "## 11.3. Main Theorem: Boundary Potential Contraction"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-complete-boundary-drift",
    "title": "Complete Boundary Potential Drift Characterization",
    "type": "theorem",
    "nl_statement": "The cloning operator Ψ_clone induces a drift on the boundary potential W_b satisfying E_clone[ΔW_b] ≤ -κ_b W_b + C_b, where κ_b = p_boundary(φ_thresh) > 0 is N-independent, C_b = O(σ_x² + N^{-1}), ensuring unconditional contraction for W_b > C_b/κ_b and strengthening near the boundary.",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b"
      }
    ],
    "hypotheses": [
      {
        "text": "κ_b = p_boundary(φ_thresh) > 0 is the minimum cloning probability for boundary-exposed walkers",
        "latex": null
      },
      {
        "text": "C_b = O(σ_x² + N^{-1}) accounts for position jitter and dead walker revival",
        "latex": null
      },
      {
        "text": "Both constants are N-independent in the large-N limit",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "The cloning operator Ψ_clone induces the following drift on the boundary potential with unconditional contraction for W_b > C_b/κ_b and strengthening near danger via increasing κ_b with boundary proximity through φ_thresh",
      "latex": null
    },
    "variables": [
      {
        "symbol": "Ψ_clone",
        "name": "cloning operator",
        "description": "Operator that induces drift on boundary potential",
        "constraints": [],
        "tags": [
          "operator"
        ]
      },
      {
        "symbol": "W_b",
        "name": "boundary potential",
        "description": "Potential function for boundary exposure",
        "constraints": [
          "W_b > C_b/κ_b for contraction"
        ],
        "tags": [
          "potential"
        ]
      },
      {
        "symbol": "κ_b",
        "name": "contraction rate",
        "description": "Minimum cloning probability p_boundary(φ_thresh) > 0, increases with boundary proximity",
        "constraints": [
          "κ_b > 0",
          "N-independent"
        ],
        "tags": [
          "rate",
          "probability"
        ]
      },
      {
        "symbol": "C_b",
        "name": "drift constant",
        "description": "Bound O(σ_x² + N^{-1}) for jitter and revival effects",
        "constraints": [
          "N-independent in large-N limit"
        ],
        "tags": [
          "constant"
        ]
      },
      {
        "symbol": "σ_x",
        "name": "position jitter",
        "description": "Standard deviation in position updates",
        "constraints": [],
        "tags": [
          "jitter"
        ]
      },
      {
        "symbol": "N",
        "name": "system size",
        "description": "Number of walkers, large-N limit",
        "constraints": [
          "large N"
        ],
        "tags": [
          "size"
        ]
      },
      {
        "symbol": "p_boundary",
        "name": "boundary probability",
        "description": "Cloning probability function for boundary-exposed walkers",
        "constraints": [],
        "tags": [
          "probability"
        ]
      },
      {
        "symbol": "φ_thresh",
        "name": "threshold potential",
        "description": "Threshold determining boundary proximity",
        "constraints": [],
        "tags": [
          "threshold"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The system is in the large-N limit where constants are independent of N",
        "confidence": 1.0
      },
      {
        "text": "Boundary-exposed walkers are defined via φ_thresh",
        "confidence": 0.9
      },
      {
        "text": "Dead walker revival contributes to C_b",
        "confidence": 0.8
      }
    ],
    "local_refs": [],
    "proof": null,
    "tags": [
      "cloning-operator",
      "boundary-potential",
      "drift",
      "contraction",
      "walkers",
      "threshold",
      "large-N"
    ],
    "content_markdown": ":label: thm-complete-boundary-drift\n\nThe cloning operator $\\Psi_{\\text{clone}}$ induces the following drift on the boundary potential:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b\n$$\n\nwhere:\n- $\\kappa_b = p_{\\text{boundary}}(\\phi_{\\text{thresh}}) > 0$ is the minimum cloning probability for boundary-exposed walkers\n- $C_b = O(\\sigma_x^2 + N^{-1})$ accounts for position jitter and dead walker revival\n- Both constants are **$N$-independent** in the large-$N$ limit\n\n**Key Properties:**\n\n1. **Unconditional contraction:** The drift is negative for all states with $W_b > C_b/\\kappa_b$\n\n2. **Strengthening near danger:** The contraction rate $\\kappa_b$ increases with boundary proximity (through $\\phi_{\\text{thresh}}$)",
    "raw_directive": "7732: We conclude by stating the complete boundary potential drift result.\n7733: \n7734: :::{prf:theorem} Complete Boundary Potential Drift Characterization\n7735: :label: thm-complete-boundary-drift\n7736: \n7737: The cloning operator $\\Psi_{\\text{clone}}$ induces the following drift on the boundary potential:\n7738: \n7739: $$\n7740: \\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b\n7741: $$\n7742: \n7743: where:\n7744: - $\\kappa_b = p_{\\text{boundary}}(\\phi_{\\text{thresh}}) > 0$ is the minimum cloning probability for boundary-exposed walkers\n7745: - $C_b = O(\\sigma_x^2 + N^{-1})$ accounts for position jitter and dead walker revival\n7746: - Both constants are **$N$-independent** in the large-$N$ limit\n7747: \n7748: **Key Properties:**\n7749: \n7750: 1. **Unconditional contraction:** The drift is negative for all states with $W_b > C_b/\\kappa_b$\n7751: \n7752: 2. **Strengthening near danger:** The contraction rate $\\kappa_b$ increases with boundary proximity (through $\\phi_{\\text{thresh}}$)\n7753: ",
    "document_id": "03_cloning",
    "section": "## 11.6. Summary and Drift Inequality",
    "span": {
      "start_line": 7732,
      "end_line": 7753,
      "content_start": 7735,
      "content_end": 7752,
      "header_lines": [
        7733
      ]
    },
    "references": [],
    "metadata": {
      "label": "thm-complete-boundary-drift"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 27,
      "chapter_file": "chapter_27.json",
      "section_id": "## 11.6. Summary and Drift Inequality"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-inter-swarm-bounded-expansion",
    "title": "Bounded Expansion of Inter-Swarm Wasserstein Distance",
    "type": "theorem",
    "nl_statement": "For the coupled cloning operator acting on two swarms (S₁, S₂), the expected change in the hypocoercive Wasserstein distance V_W = W_h²(μ₁, μ₂) = V_loc + V_struct satisfies E_clone[ΔV_W] ≤ C_W, where C_W < ∞ is a state-independent constant. Equivalently, E_clone[V_W(S'₁, S'₂)] ≤ V_W(S₁, S₂) + C_W.",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
      },
      {
        "label": null,
        "latex": "V_W = W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[V_W(S'_1, S'_2)] \\leq V_W(S_1, S_2) + C_W"
      }
    ],
    "hypotheses": [
      {
        "text": "Coupled cloning operator acting on two swarms (S₁, S₂)",
        "latex": null
      },
      {
        "text": "V_W is the total inter-swarm error",
        "latex": "V_W = W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}"
      }
    ],
    "conclusion": {
      "text": "The expected change in the hypocoercive Wasserstein distance satisfies E_clone[ΔV_W] ≤ C_W, where C_W < ∞ is a state-independent constant",
      "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W \\quad (C_W < \\infty)"
    },
    "variables": [
      {
        "symbol": "S_1",
        "name": "S1",
        "description": "First swarm",
        "constraints": [],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "S_2",
        "name": "S2",
        "description": "Second swarm",
        "constraints": [],
        "tags": [
          "swarm"
        ]
      },
      {
        "symbol": "V_W",
        "name": "VW",
        "description": "Total inter-swarm error (hypocoercive Wasserstein distance squared)",
        "constraints": [
          "V_W = W_h^2(μ_1, μ_2) = V_loc + V_struct"
        ],
        "tags": [
          "error",
          "Wasserstein"
        ]
      },
      {
        "symbol": "C_W",
        "name": "CW",
        "description": "State-independent constant bound",
        "constraints": [
          "C_W < ∞"
        ],
        "tags": [
          "constant",
          "bound"
        ]
      },
      {
        "symbol": "μ_1",
        "name": "μ1",
        "description": "Empirical measure of S₁",
        "constraints": [],
        "tags": [
          "measure"
        ]
      },
      {
        "symbol": "μ_2",
        "name": "μ2",
        "description": "Empirical measure of S₂",
        "constraints": [],
        "tags": [
          "measure"
        ]
      },
      {
        "symbol": "S'_1",
        "name": "S'1",
        "description": "Updated first swarm after cloning",
        "constraints": [],
        "tags": [
          "swarm",
          "updated"
        ]
      },
      {
        "symbol": "S'_2",
        "name": "S'2",
        "description": "Updated second swarm after cloning",
        "constraints": [],
        "tags": [
          "swarm",
          "updated"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "S₁ and S₂ are finite particle swarms with empirical measures μ₁ and μ₂",
        "confidence": 0.9
      },
      {
        "text": "The coupled cloning operator preserves the coupling between swarms",
        "confidence": 0.8
      },
      {
        "text": "W_h is a hypocoercive metric on the space of measures",
        "confidence": 0.7
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-inter-swarm-bounded-expansion",
      "title": null,
      "type": "proof",
      "proves": "thm-inter-swarm-bounded-expansion",
      "proof_type": "probabilistic",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-inter-swarm-bounded-expansion\n**Proof.**\n\nThe proof analyzes how the stochastic cloning mechanism affects the distance between the two swarms' empirical measures.\n\n**Step 1: Sources of inter-swarm divergence**\n\nThe coupled cloning operator uses synchronous coupling for all randomness, but divergence still occurs through:\n\n1. **Different companion selections:** Walker $i$ in swarm 1 may select companion $j$ while the same walker in swarm 2 selects companion $k \\neq j$\n\n2. **Different cloning decisions:** The cloning scores $S_{1,i}$ and $S_{2,i}$ depend on the fitness potentials, which differ between swarms when the swarms are in different configurations\n\n3. **Position jitter:** Even when both swarms make the same cloning decision, the Gaussian jitter $\\zeta_i^x$ adds independent noise to each swarm's walker positions\n\n**Step 2: Bounding location error expansion**\n\nThe location error is:\n\n$$\nV_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle\n$$\n\nThe barycenters change based on the cloning decisions. In the worst case, if walker $i$ clones in swarm 1 but not in swarm 2:\n\n$$\n\\Delta\\mu'_x = \\Delta\\mu_x + \\frac{1}{N}(x'_{1,i} - x_{1,i}) - 0\n$$\n\nSince positions are bounded within $\\mathcal{X}_{\\text{valid}}$:\n\n$$\n\\|\\Delta\\mu'_x - \\Delta\\mu_x\\| \\leq \\frac{2D_{\\text{valid}}}{N}\n$$\n\nSquaring and summing over all potential mismatches:\n\n$$\n\\mathbb{E}[\\|\\Delta\\mu'_x\\|^2] \\leq \\|\\Delta\\mu_x\\|^2 + O(D_{\\text{valid}}^2)\n$$\n\nSimilarly for velocity barycenters.\n\n**Step 3: Bounding structural error expansion**\n\nThe structural error $V_{\\text{struct}}$ measures the Wasserstein distance between centered empirical measures. When walkers clone:\n\n- **Synchronized cloning:** Both swarms clone walker $i$ to similar positions (same companion, same jitter) → minimal divergence\n- **Desynchronized cloning:** Only one swarm clones walker $i$ → position divergence bounded by $D_{\\text{valid}}$\n\nThe expected number of desynchronized events is bounded by the differences in cloning probabilities:\n\n$$\n\\mathbb{E}[\\text{# desynchronized}] \\leq \\sum_{i=1}^N |p_{1,i} - p_{2,i}|\n$$\n\nBy the Lipschitz continuity of the cloning probability with respect to swarm configuration (proven in the framework document, Section 15.2):\n\n$$\n|p_{1,i} - p_{2,i}| \\leq L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2)\n$$\n\nCombined with the bounded displacement per desynchronized event:\n\n$$\n\\mathbb{E}[\\Delta V_{\\text{struct}}] \\leq N \\cdot L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2) \\cdot D_{\\text{valid}}^2 + C_{\\text{jitter}}\n$$\n\n**Step 4: Combine and use Wasserstein decomposition**\n\nFrom {prf:ref}`lem-wasserstein-decomposition`:\n\n$$\nV_W = V_{\\text{loc}} + V_{\\text{struct}}\n$$\n\nCombining the bounds from Steps 2-3:\n\n$$\n\\mathbb{E}[\\Delta V_W] \\leq O(D_{\\text{valid}}^2) + O(N \\cdot d_{\\text{Disp}}(S_1, S_2)) + C_{\\text{jitter}}\n$$\n\nIn the drift analysis regime where we consider bounded swarm configurations, $d_{\\text{Disp}}(S_1, S_2)$ is bounded, yielding:\n\n$$\n\\mathbb{E}[\\Delta V_W] \\leq C_W\n$$\n\nfor a state-independent constant $C_W$.",
      "raw_directive": "7872: :::\n7873: \n7874: :::{prf:proof}\n7875: :label: proof-thm-inter-swarm-bounded-expansion\n7876: **Proof.**\n7877: \n7878: The proof analyzes how the stochastic cloning mechanism affects the distance between the two swarms' empirical measures.\n7879: \n7880: **Step 1: Sources of inter-swarm divergence**\n7881: \n7882: The coupled cloning operator uses synchronous coupling for all randomness, but divergence still occurs through:\n7883: \n7884: 1. **Different companion selections:** Walker $i$ in swarm 1 may select companion $j$ while the same walker in swarm 2 selects companion $k \\neq j$\n7885: \n7886: 2. **Different cloning decisions:** The cloning scores $S_{1,i}$ and $S_{2,i}$ depend on the fitness potentials, which differ between swarms when the swarms are in different configurations\n7887: \n7888: 3. **Position jitter:** Even when both swarms make the same cloning decision, the Gaussian jitter $\\zeta_i^x$ adds independent noise to each swarm's walker positions\n7889: \n7890: **Step 2: Bounding location error expansion**\n7891: \n7892: The location error is:\n7893: \n7894: $$\n7895: V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle\n7896: $$\n7897: \n7898: The barycenters change based on the cloning decisions. In the worst case, if walker $i$ clones in swarm 1 but not in swarm 2:\n7899: \n7900: $$\n7901: \\Delta\\mu'_x = \\Delta\\mu_x + \\frac{1}{N}(x'_{1,i} - x_{1,i}) - 0\n7902: $$\n7903: \n7904: Since positions are bounded within $\\mathcal{X}_{\\text{valid}}$:\n7905: \n7906: $$\n7907: \\|\\Delta\\mu'_x - \\Delta\\mu_x\\| \\leq \\frac{2D_{\\text{valid}}}{N}\n7908: $$\n7909: \n7910: Squaring and summing over all potential mismatches:\n7911: \n7912: $$\n7913: \\mathbb{E}[\\|\\Delta\\mu'_x\\|^2] \\leq \\|\\Delta\\mu_x\\|^2 + O(D_{\\text{valid}}^2)\n7914: $$\n7915: \n7916: Similarly for velocity barycenters.\n7917: \n7918: **Step 3: Bounding structural error expansion**\n7919: \n7920: The structural error $V_{\\text{struct}}$ measures the Wasserstein distance between centered empirical measures. When walkers clone:\n7921: \n7922: - **Synchronized cloning:** Both swarms clone walker $i$ to similar positions (same companion, same jitter) → minimal divergence\n7923: - **Desynchronized cloning:** Only one swarm clones walker $i$ → position divergence bounded by $D_{\\text{valid}}$\n7924: \n7925: The expected number of desynchronized events is bounded by the differences in cloning probabilities:\n7926: \n7927: $$\n7928: \\mathbb{E}[\\text{# desynchronized}] \\leq \\sum_{i=1}^N |p_{1,i} - p_{2,i}|\n7929: $$\n7930: \n7931: By the Lipschitz continuity of the cloning probability with respect to swarm configuration (proven in the framework document, Section 15.2):\n7932: \n7933: $$\n7934: |p_{1,i} - p_{2,i}| \\leq L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2)\n7935: $$\n7936: \n7937: Combined with the bounded displacement per desynchronized event:\n7938: \n7939: $$\n7940: \\mathbb{E}[\\Delta V_{\\text{struct}}] \\leq N \\cdot L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2) \\cdot D_{\\text{valid}}^2 + C_{\\text{jitter}}\n7941: $$\n7942: \n7943: **Step 4: Combine and use Wasserstein decomposition**\n7944: \n7945: From {prf:ref}`lem-wasserstein-decomposition`:\n7946: \n7947: $$\n7948: V_W = V_{\\text{loc}} + V_{\\text{struct}}\n7949: $$\n7950: \n7951: Combining the bounds from Steps 2-3:\n7952: \n7953: $$\n7954: \\mathbb{E}[\\Delta V_W] \\leq O(D_{\\text{valid}}^2) + O(N \\cdot d_{\\text{Disp}}(S_1, S_2)) + C_{\\text{jitter}}\n7955: $$\n7956: \n7957: In the drift analysis regime where we consider bounded swarm configurations, $d_{\\text{Disp}}(S_1, S_2)$ is bounded, yielding:\n7958: \n7959: $$\n7960: \\mathbb{E}[\\Delta V_W] \\leq C_W\n7961: $$\n7962: \n7963: for a state-independent constant $C_W$.\n7964: ",
      "strategy_summary": "The proof decomposes the inter-swarm Wasserstein distance into location and structural components, bounds the expected expansion from cloning divergences using synchronous coupling, Lipschitz properties of cloning probabilities, and position bounds, and combines these to show a constant upper bound on the expected change.",
      "conclusion": {
        "text": "The expected change in the Wasserstein distance between the two swarms is bounded by a state-independent constant C_W.",
        "latex": "\\mathbb{E}[\\Delta V_W] \\leq C_W"
      },
      "assumptions": [
        {
          "text": "Walker positions are bounded within the valid domain \\mathcal{X}_{valid} with diameter D_{valid}.",
          "latex": null
        },
        {
          "text": "The cloning probability is Lipschitz continuous with respect to the swarm configuration distance d_{Disp}, with constant L_{clone}.",
          "latex": null
        },
        {
          "text": "The swarms operate in a regime of bounded configurations.",
          "latex": null
        },
        {
          "text": "Synchronous coupling is used for all randomness in the cloning operator.",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "explanation",
          "text": "Identify sources of inter-swarm divergence: different companion selections, different cloning decisions based on fitness potentials, and position jitter from Gaussian noise.",
          "latex": null,
          "references": [],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "bounding",
          "text": "Define the location error V_{loc} and bound its expected squared expansion due to mismatched cloning decisions, using bounded positions to show \\mathbb{E}[\\|\\Delta\\mu'_x\\|^2] \\leq \\|\\Delta\\mu_x\\|^2 + O(D_{valid}^2). Similar bound for velocity.",
          "latex": null,
          "references": [],
          "derived_statement": "\\mathbb{E}[\\Delta V_{loc}] \\leq O(D_{valid}^2)"
        },
        {
          "order": 3.0,
          "kind": "bounding",
          "text": "Bound the structural error V_{struct} expansion by considering synchronized vs. desynchronized cloning; use expected number of desynchronizations bounded by sum of probability differences, which is controlled by Lipschitz continuity: \\mathbb{E}[\\# desynchronized] \\leq \\sum |p_{1,i} - p_{2,i}| \\leq N L_{clone} d_{Disp}(S_1, S_2), leading to \\mathbb{E}[\\Delta V_{struct}] \\leq N L_{clone} d_{Disp}(S_1, S_2) D_{valid}^2 + C_{jitter}.",
          "latex": null,
          "references": [
            "framework-section-15.2"
          ],
          "derived_statement": "\\mathbb{E}[\\Delta V_{struct}] \\leq O(N \\cdot d_{Disp}(S_1, S_2)) + C_{jitter}"
        },
        {
          "order": 4.0,
          "kind": "combination",
          "text": "Decompose V_W = V_{loc} + V_{struct} using the referenced lemma, combine bounds, and under bounded configurations, obtain \\mathbb{E}[\\Delta V_W] \\leq C_W.",
          "latex": null,
          "references": [
            "lem-wasserstein-decomposition"
          ],
          "derived_statement": "\\mathbb{E}[\\Delta V_W] \\leq C_W"
        }
      ],
      "key_equations": [
        {
          "label": "eq-vloc",
          "latex": "V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle",
          "role": "Defines the location error component of the Wasserstein distance."
        },
        {
          "label": "eq-delta-mu-x",
          "latex": "\\Delta\\mu'_x = \\Delta\\mu_x + \\frac{1}{N}(x'_{1,i} - x_{1,i})",
          "role": "Describes barycenter change in worst-case cloning mismatch."
        },
        {
          "label": "eq-location-bound",
          "latex": "\\|\\Delta\\mu'_x - \\Delta\\mu_x\\| \\leq \\frac{2D_{\\text{valid}}}{N}",
          "role": "Bounds the change in position barycenter due to cloning."
        },
        {
          "label": "eq-desync-prob",
          "latex": "\\mathbb{E}[\\# desynchronized] \\leq \\sum_{i=1}^N |p_{1,i} - p_{2,i}|",
          "role": "Bounds the expected number of desynchronized cloning events."
        },
        {
          "label": "eq-clone-lip",
          "latex": "|p_{1,i} - p_{2,i}| \\leq L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2)",
          "role": "Lipschitz bound on cloning probability differences."
        },
        {
          "label": "eq-vw-decomp",
          "latex": "V_W = V_{\\text{loc}} + V_{\\text{struct}}",
          "role": "Decomposition of Wasserstein distance used to combine error bounds."
        },
        {
          "label": "eq-final-bound",
          "latex": "\\mathbb{E}[\\Delta V_W] \\leq C_W",
          "role": "Final bounded expansion result."
        }
      ],
      "references": [
        "lem-wasserstein-decomposition"
      ],
      "math_tools": [
        {
          "toolName": "Wasserstein Distance",
          "field": "Optimal Transport",
          "description": "A metric measuring the distance between probability distributions based on optimal transport.",
          "roleInProof": "Decomposed into location and structural errors to bound inter-swarm divergence expansion.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Empirical Measure"
          ]
        },
        {
          "toolName": "Synchronous Coupling",
          "field": "Probability",
          "description": "A coupling method where random variables share the same randomness to minimize divergence.",
          "roleInProof": "Applied to the cloning operator to control divergence from shared randomness sources.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Gaussian Jitter"
          ]
        },
        {
          "toolName": "Lipschitz Continuity",
          "field": "Analysis",
          "description": "A property ensuring the variation of a function is controlled by the variation of its input.",
          "roleInProof": "Used to bound differences in cloning probabilities between swarms based on configuration distances.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Cloning Probability"
          ]
        },
        {
          "toolName": "Empirical Measure",
          "field": "Statistics",
          "description": "A discrete approximation of a probability distribution based on samples.",
          "roleInProof": "Represents the swarm configurations whose barycenters and centered measures are analyzed for divergence.",
          "levelOfAbstraction": "Notation",
          "relatedTools": [
            "Wasserstein Distance"
          ]
        },
        {
          "toolName": "Gaussian Jitter",
          "field": "Probability",
          "description": "Addition of independent Gaussian noise to positions or variables.",
          "roleInProof": "Contributes to position divergence even under synchronized cloning decisions.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Synchronous Coupling"
          ]
        }
      ],
      "cases": [
        {
          "name": "Synchronized cloning",
          "condition": "Both swarms select the same companion and make the same cloning decision for walker i",
          "summary": "Leads to minimal divergence in positions due to shared jitter and coupling."
        },
        {
          "name": "Desynchronized cloning",
          "condition": "Only one swarm clones walker i (due to probability or selection differences)",
          "summary": "Position divergence bounded by D_{valid}, contributing to structural error expansion."
        }
      ],
      "remarks": [
        {
          "type": "note",
          "text": "The analysis assumes bounded swarm configurations to ensure d_{Disp}(S_1, S_2) is controlled, fitting the drift analysis regime."
        },
        {
          "type": "reference",
          "text": "Jitter constant C_{jitter} arises from independent Gaussian noise even under synchronization."
        }
      ],
      "gaps": [],
      "tags": [
        "stochastic-cloning",
        "inter-swarm-divergence",
        "wasserstein-distance",
        "bounded-expansion",
        "synchronous-coupling",
        "lipschitz-continuity",
        "empirical-measures",
        "drift-analysis"
      ],
      "document_id": "03_cloning",
      "section": "## 12.2. Inter-Swarm Error Under Cloning",
      "span": {
        "start_line": 7872,
        "end_line": 7964,
        "content_start": 7874,
        "content_end": 7963,
        "header_lines": [
          7873
        ]
      },
      "metadata": {
        "label": "proof-thm-inter-swarm-bounded-expansion"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 30,
        "chapter_file": "chapter_30.json",
        "section_id": "## 12.2. Inter-Swarm Error Under Cloning"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "swarm",
      "Wasserstein",
      "cloning operator",
      "bounded expansion",
      "hypocoercive",
      "expectation",
      "error"
    ],
    "content_markdown": ":label: thm-inter-swarm-bounded-expansion\n\nFor the coupled cloning operator acting on two swarms $(S_1, S_2)$, the expected change in the hypocoercive Wasserstein distance satisfies:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\n$$\n\nwhere $V_W = W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}$ is the total inter-swarm error and $C_W < \\infty$ is a state-independent constant.\n\nEquivalently:\n\n$$\n\\mathbb{E}_{\\text{clone}}[V_W(S'_1, S'_2)] \\leq V_W(S_1, S_2) + C_W",
    "raw_directive": "7853: ### 12.2.1. Bounded Expansion of Inter-Swarm Error\n7854: \n7855: :::{prf:theorem} Bounded Expansion of Inter-Swarm Wasserstein Distance\n7856: :label: thm-inter-swarm-bounded-expansion\n7857: \n7858: For the coupled cloning operator acting on two swarms $(S_1, S_2)$, the expected change in the hypocoercive Wasserstein distance satisfies:\n7859: \n7860: $$\n7861: \\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\n7862: $$\n7863: \n7864: where $V_W = W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}$ is the total inter-swarm error and $C_W < \\infty$ is a state-independent constant.\n7865: \n7866: Equivalently:\n7867: \n7868: $$\n7869: \\mathbb{E}_{\\text{clone}}[V_W(S'_1, S'_2)] \\leq V_W(S_1, S_2) + C_W\n7870: $$",
    "document_id": "03_cloning",
    "section": "## 12.2. Inter-Swarm Error Under Cloning",
    "span": {
      "start_line": 7853,
      "end_line": 7870,
      "content_start": 7856,
      "content_end": 7869,
      "header_lines": [
        7854
      ]
    },
    "references": [
      "lem-wasserstein-decomposition"
    ],
    "metadata": {
      "label": "thm-inter-swarm-bounded-expansion"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 30,
      "chapter_file": "chapter_30.json",
      "section_id": "## 12.2. Inter-Swarm Error Under Cloning"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-complete-wasserstein-drift",
    "title": "Complete Wasserstein Decomposition Drift",
    "type": "theorem",
    "nl_statement": "The total inter-swarm Wasserstein distance \\(V_W = V_{\\text{loc}} + V_{\\text{struct}}\\) satisfies \\(\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\\) under the cloning operator, where \\(C_W = C_{\\text{loc}} + C_{\\text{struct}}\\) is a finite state-independent constant, with component bounds \\(\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] \\leq C_{\\text{loc}}\\) and \\(\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}] \\leq C_{\\text{struct}}\\); the kinetic operator yields \\(\\mathbb{E}_{\\text{kin}}[\\Delta V_W] \\leq -\\kappa_W^{\\text{kin}} \\tau V_W + C_W^{\\text{kin}} \\tau\\).",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
      },
      {
        "label": null,
        "latex": "C_W = C_{\\text{loc}} + C_{\\text{struct}}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] \\leq C_{\\text{loc}}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}] \\leq C_{\\text{struct}}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{kin}}[\\Delta V_W] \\leq -\\kappa_W^{\\text{kin}} \\tau V_W + C_W^{\\text{kin}} \\tau"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": null,
      "latex": null
    },
    "variables": [
      {
        "symbol": "V_W",
        "name": "total inter-swarm Wasserstein distance",
        "description": "Decomposes into local and structural components",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "wasserstein",
          "total"
        ]
      },
      {
        "symbol": "V_loc",
        "name": "local Wasserstein component",
        "description": "Due to barycenter desynchronization",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "local",
          "barycenter"
        ]
      },
      {
        "symbol": "V_struct",
        "name": "structural Wasserstein component",
        "description": "Due to jitter noise and rearrangement",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "structural",
          "jitter"
        ]
      },
      {
        "symbol": "C_W",
        "name": "Wasserstein drift constant",
        "description": "State-independent bound \\(C_{\\text{loc}} + C_{\\text{struct}}\\)",
        "constraints": [
          "finite"
        ],
        "tags": [
          "constant",
          "bound"
        ]
      },
      {
        "symbol": "C_loc",
        "name": "local drift constant",
        "description": "From differential cloning rates",
        "constraints": [
          "finite"
        ],
        "tags": [
          "local",
          "cloning"
        ]
      },
      {
        "symbol": "C_struct",
        "name": "structural drift constant",
        "description": "From cloning jitter and rearrangement",
        "constraints": [
          "finite"
        ],
        "tags": [
          "structural",
          "jitter"
        ]
      },
      {
        "symbol": "\\kappa_W^{kin}",
        "name": "kinetic contraction rate",
        "description": "Hypocoercive decay coefficient",
        "constraints": [
          "positive"
        ],
        "tags": [
          "kinetic",
          "contraction"
        ]
      },
      {
        "symbol": "\\tau",
        "name": "time step",
        "description": "For kinetic operator",
        "constraints": [
          "positive"
        ],
        "tags": [
          "time"
        ]
      },
      {
        "symbol": "C_W^{kin}",
        "name": "kinetic Wasserstein constant",
        "description": "Bound in kinetic drift",
        "constraints": [
          "finite"
        ],
        "tags": [
          "kinetic",
          "constant"
        ]
      }
    ],
    "implicit_assumptions": [],
    "local_refs": [
      "cor-component-bounds-vw"
    ],
    "proof": {
      "label": "proof-thm-complete-wasserstein-drift",
      "title": null,
      "type": "proof",
      "proves": "thm-complete-wasserstein-drift",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-complete-wasserstein-drift\n**Proof.**\n\nBy linearity of expectation and the Wasserstein decomposition {prf:ref}`lem-wasserstein-decomposition`:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]\n$$\n\n$$\n= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]\n$$\n\nApplying the component bounds from {prf:ref}`cor-component-bounds-vw`:\n\n$$\n\\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W\n$$\n\nThis establishes the combined drift bound.\n\n**Explicit Constants:**\n\nFrom the proof of {prf:ref}`thm-inter-swarm-bounded-expansion`:\n\n**Location Expansion:** $C_{\\text{loc}}$ arises from the differential expected clone positions between swarms:\n\n$$\nC_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)\n$$\n\nwhich is bounded by the domain diameter and companion selection variance.\n\n**Structural Expansion:** $C_{\\text{struct}}$ is dominated by position jitter:\n\n$$\nC_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})\n$$\n\nwhere $f_{\\text{clone}}$ is the expected fraction of walkers that clone per step and $\\sigma_x^2$ is the jitter variance.",
      "raw_directive": "8040: :::\n8041: \n8042: :::{prf:proof}\n8043: :label: proof-thm-complete-wasserstein-drift\n8044: **Proof.**\n8045: \n8046: By linearity of expectation and the Wasserstein decomposition {prf:ref}`lem-wasserstein-decomposition`:\n8047: \n8048: $$\n8049: \\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]\n8050: $$\n8051: \n8052: $$\n8053: = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]\n8054: $$\n8055: \n8056: Applying the component bounds from {prf:ref}`cor-component-bounds-vw`:\n8057: \n8058: $$\n8059: \\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W\n8060: $$\n8061: \n8062: This establishes the combined drift bound.\n8063: \n8064: **Explicit Constants:**\n8065: \n8066: From the proof of {prf:ref}`thm-inter-swarm-bounded-expansion`:\n8067: \n8068: **Location Expansion:** $C_{\\text{loc}}$ arises from the differential expected clone positions between swarms:\n8069: \n8070: $$\n8071: C_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)\n8072: $$\n8073: \n8074: which is bounded by the domain diameter and companion selection variance.\n8075: \n8076: **Structural Expansion:** $C_{\\text{struct}}$ is dominated by position jitter:\n8077: \n8078: $$\n8079: C_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})\n8080: $$\n8081: \n8082: where $f_{\\text{clone}}$ is the expected fraction of walkers that clone per step and $\\sigma_x^2$ is the jitter variance.\n8083: ",
      "strategy_summary": "The proof uses linearity of expectation on the Wasserstein decomposition to separate local and structural components, then applies established bounds to derive an overall constant bound on the expected drift.",
      "conclusion": {
        "text": "This establishes the combined drift bound \\(\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\\).",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
      },
      "assumptions": [],
      "steps": [
        {
          "order": 1.0,
          "kind": "application",
          "text": "Apply linearity of expectation to the change in Wasserstein potential using the decomposition into local and structural components.",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]",
          "references": [
            "lem-wasserstein-decomposition"
          ],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}} + \\Delta V_{\\text{struct}}]"
        },
        {
          "order": 2.0,
          "kind": "separation",
          "text": "Separate the expectations of the components.",
          "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]",
          "references": [],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]"
        },
        {
          "order": 3.0,
          "kind": "bounding",
          "text": "Apply the component bounds from the corollary.",
          "latex": "\\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W",
          "references": [
            "cor-component-bounds-vw"
          ],
          "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
        },
        {
          "order": 4.0,
          "kind": "elaboration",
          "text": "Derive explicit form of C_loc from the referenced theorem's proof, bounding by domain diameter and selection variance.",
          "latex": "C_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)",
          "references": [
            "thm-inter-swarm-bounded-expansion"
          ],
          "derived_statement": null
        },
        {
          "order": 5.0,
          "kind": "elaboration",
          "text": "Derive explicit form of C_struct, dominated by position jitter and cloning fraction.",
          "latex": "C_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})",
          "references": [
            "thm-inter-swarm-bounded-expansion"
          ],
          "derived_statement": null
        }
      ],
      "key_equations": [
        {
          "label": "eq-wasserstein-linearity",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]",
          "role": "Initial application of linearity to decomposed potential"
        },
        {
          "label": "eq-component-separation",
          "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]",
          "role": "Separation into analyzable components"
        },
        {
          "label": "eq-overall-bound",
          "latex": "\\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W",
          "role": "Combined bound establishing the result"
        },
        {
          "label": "eq-cloc-bound",
          "latex": "C_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)",
          "role": "Explicit bound for location component"
        },
        {
          "label": "eq-cstruct-bound",
          "latex": "C_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})",
          "role": "Explicit bound for structural component"
        }
      ],
      "references": [
        "lem-wasserstein-decomposition",
        "cor-component-bounds-vw",
        "thm-inter-swarm-bounded-expansion"
      ],
      "math_tools": [
        {
          "toolName": "Linearity of expectation",
          "field": "Probability",
          "description": "The property that the expectation of a sum of random variables equals the sum of their expectations, regardless of dependence.",
          "roleInProof": "Separates the expectation of the change in total Wasserstein potential into local and structural components.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Wasserstein decomposition"
          ]
        },
        {
          "toolName": "Wasserstein decomposition",
          "field": "Optimal Transport",
          "description": "Decomposition of the Wasserstein distance or potential into location-based and structural (e.g., matching) components.",
          "roleInProof": "Provides the breakdown of ΔV_W into ΔV_loc and ΔV_struct for separate analysis.",
          "levelOfAbstraction": "Theorem/Lemma",
          "relatedTools": [
            "Linearity of expectation"
          ]
        },
        {
          "toolName": "Big O notation",
          "field": "Asymptotics",
          "description": "Notation for bounding the growth rate of functions.",
          "roleInProof": "Expresses the explicit constants C_loc and C_struct in terms of expectations and variances.",
          "levelOfAbstraction": "Notation",
          "relatedTools": []
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "explicit-constants",
          "text": "Constants derived from the proof of thm-inter-swarm-bounded-expansion."
        },
        {
          "type": "location-expansion",
          "text": "C_loc arises from differential expected clone positions between swarms, bounded by domain diameter and companion selection variance."
        },
        {
          "type": "structural-expansion",
          "text": "C_struct dominated by position jitter, where f_clone is the expected fraction of walkers that clone per step and sigma_x^2 is the jitter variance."
        }
      ],
      "gaps": [],
      "tags": [
        "Wasserstein distance",
        "drift bound",
        "linearity of expectation",
        "clone process",
        "swarm dynamics",
        "optimal transport",
        "position jitter"
      ],
      "document_id": "03_cloning",
      "section": "## 12.2. Inter-Swarm Error Under Cloning",
      "span": {
        "start_line": 8040,
        "end_line": 8083,
        "content_start": 8042,
        "content_end": 8082,
        "header_lines": [
          8041
        ]
      },
      "metadata": {
        "label": "proof-thm-complete-wasserstein-drift"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 30,
        "chapter_file": "chapter_30.json",
        "section_id": "## 12.2. Inter-Swarm Error Under Cloning"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "wasserstein",
      "drift",
      "cloning",
      "kinetic",
      "hypocoercivity",
      "inter-swarm"
    ],
    "content_markdown": ":label: thm-complete-wasserstein-drift\n\nThe total inter-swarm Wasserstein distance $V_W = V_{\\text{loc}} + V_{\\text{struct}}$ satisfies a combined drift inequality under the cloning operator:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\n$$\n\nwhere $C_W < \\infty$ is a state-independent constant satisfying:\n\n$$\nC_W = C_{\\text{loc}} + C_{\\text{struct}}\n$$\n\n**Component Bounds:**\n\nFrom {prf:ref}`cor-component-bounds-vw`, the individual components satisfy:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] &\\leq C_{\\text{loc}} \\\\\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}] &\\leq C_{\\text{struct}}\n\\end{aligned}\n$$\n\nwhere:\n- $C_{\\text{loc}}$ arises from barycenter desynchronization due to differential cloning rates\n- $C_{\\text{struct}}$ arises from jitter noise and structural rearrangement during cloning\n\n**Note on Kinetic Contraction:**\n\nWhile the cloning operator allows bounded expansion of $V_W$, the **kinetic operator** provides contraction. From hypocoercive analysis (Chapter 4 of companion document):\n\n$$\n\\mathbb{E}_{\\text{kin}}[\\Delta V_W] \\leq -\\kappa_W^{\\text{kin}} \\tau V_W + C_W^{\\text{kin}} \\tau\n$$",
    "raw_directive": "7999: :::\n8000: \n8001: :::{prf:theorem} Complete Wasserstein Decomposition Drift\n8002: :label: thm-complete-wasserstein-drift\n8003: \n8004: The total inter-swarm Wasserstein distance $V_W = V_{\\text{loc}} + V_{\\text{struct}}$ satisfies a combined drift inequality under the cloning operator:\n8005: \n8006: $$\n8007: \\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\n8008: $$\n8009: \n8010: where $C_W < \\infty$ is a state-independent constant satisfying:\n8011: \n8012: $$\n8013: C_W = C_{\\text{loc}} + C_{\\text{struct}}\n8014: $$\n8015: \n8016: **Component Bounds:**\n8017: \n8018: From {prf:ref}`cor-component-bounds-vw`, the individual components satisfy:\n8019: \n8020: $$\n8021: \\begin{aligned}\n8022: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] &\\leq C_{\\text{loc}} \\\\\n8023: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}] &\\leq C_{\\text{struct}}\n8024: \\end{aligned}\n8025: $$\n8026: \n8027: where:\n8028: - $C_{\\text{loc}}$ arises from barycenter desynchronization due to differential cloning rates\n8029: - $C_{\\text{struct}}$ arises from jitter noise and structural rearrangement during cloning\n8030: \n8031: **Note on Kinetic Contraction:**\n8032: \n8033: While the cloning operator allows bounded expansion of $V_W$, the **kinetic operator** provides contraction. From hypocoercive analysis (Chapter 4 of companion document):\n8034: \n8035: $$\n8036: \\mathbb{E}_{\\text{kin}}[\\Delta V_W] \\leq -\\kappa_W^{\\text{kin}} \\tau V_W + C_W^{\\text{kin}} \\tau\n8037: $$\n8038: ",
    "document_id": "03_cloning",
    "section": "## 12.2. Inter-Swarm Error Under Cloning",
    "span": {
      "start_line": 7999,
      "end_line": 8038,
      "content_start": 8002,
      "content_end": 8037,
      "header_lines": [
        8000
      ]
    },
    "references": [
      "cor-component-bounds-vw",
      "lem-wasserstein-decomposition",
      "thm-inter-swarm-bounded-expansion"
    ],
    "metadata": {
      "label": "thm-complete-wasserstein-drift"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 30,
      "chapter_file": "chapter_30.json",
      "section_id": "## 12.2. Inter-Swarm Error Under Cloning"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-complete-cloning-drift",
    "title": "Complete Drift Inequality for the Cloning Operator",
    "type": "theorem",
    "nl_statement": "Under foundational axioms, the cloning operator induces bounded or contracting drifts on components of the synergistic Lyapunov function, yielding overall negative drift when variance and boundary terms are sufficiently large.",
    "equations": [
      {
        "label": null,
        "latex": "V_{\\text{total}}(S_1, S_2) = V_W(S_1, S_2) + c_V V_{\\text{Var}}(S_1, S_2) + c_B W_b(S_1, S_2)"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W \\quad \\text{(bounded expansion)}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x \\quad \\text{(strong contraction)}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v \\quad \\text{(bounded expansion)}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b \\quad \\text{(strong contraction)}"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] \\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_v + C_x) + c_B(-\\kappa_b W_b + C_b)"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] < 0 \\quad \\text{when } c_V V_{\\text{Var},x} + c_B W_b > \\frac{C_W + c_V(C_v + C_x) + c_B C_b}{\\min(\\kappa_x, \\kappa_b)}"
      }
    ],
    "hypotheses": [
      {
        "text": "Under the foundational axioms (Chapter 4)",
        "latex": null
      },
      {
        "text": "Individual component drifts hold as specified",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "The cloning operator Ψ_clone induces the stated drift inequalities on the synergistic Lyapunov function V_total, with partial contraction when c_V V_Var,x + c_B W_b exceeds the threshold.",
      "latex": null
    },
    "variables": [
      {
        "symbol": "\\Psi_{\\text{clone}}",
        "name": "cloning operator",
        "description": "Operator inducing drifts on state spaces S1, S2",
        "constraints": [
          "defined under Chapter 4 axioms"
        ],
        "tags": [
          "operator",
          "cloning"
        ]
      },
      {
        "symbol": "V_{\\text{total}}",
        "name": "total Lyapunov function",
        "description": "Synergistic function combining Wasserstein, variance, and boundary terms",
        "constraints": [
          "V_total = V_W + c_V V_Var + c_B W_b"
        ],
        "tags": [
          "Lyapunov",
          "total"
        ]
      },
      {
        "symbol": "V_W",
        "name": "Wasserstein component",
        "description": "Wasserstein distance-based Lyapunov term",
        "constraints": [],
        "tags": [
          "Wasserstein",
          "Lyapunov"
        ]
      },
      {
        "symbol": "V_{\\text{Var}}",
        "name": "variance component",
        "description": "Variance-based Lyapunov term, split into x and v",
        "constraints": [],
        "tags": [
          "variance",
          "Lyapunov"
        ]
      },
      {
        "symbol": "W_b",
        "name": "boundary term",
        "description": "Boundary Wasserstein-like term",
        "constraints": [],
        "tags": [
          "boundary",
          "Wasserstein"
        ]
      },
      {
        "symbol": "c_V",
        "name": "variance coefficient",
        "description": "Weighting constant for variance term",
        "constraints": [
          "positive"
        ],
        "tags": [
          "coefficient"
        ]
      },
      {
        "symbol": "c_B",
        "name": "boundary coefficient",
        "description": "Weighting constant for boundary term",
        "constraints": [
          "positive"
        ],
        "tags": [
          "coefficient"
        ]
      },
      {
        "symbol": "\\kappa_x",
        "name": "x-variance contraction rate",
        "description": "Contraction constant for V_Var,x",
        "constraints": [
          "positive"
        ],
        "tags": [
          "contraction",
          "rate"
        ]
      },
      {
        "symbol": "\\kappa_b",
        "name": "boundary contraction rate",
        "description": "Contraction constant for W_b",
        "constraints": [
          "positive"
        ],
        "tags": [
          "contraction",
          "rate"
        ]
      },
      {
        "symbol": "C_W",
        "name": "Wasserstein bound",
        "description": "Bound for expansion in ΔV_W",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "bound"
        ]
      },
      {
        "symbol": "C_x",
        "name": "x-variance additive term",
        "description": "Additive constant in V_Var,x drift",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "additive"
        ]
      },
      {
        "symbol": "C_v",
        "name": "v-variance bound",
        "description": "Bound for expansion in ΔV_Var,v",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "bound"
        ]
      },
      {
        "symbol": "C_b",
        "name": "boundary additive term",
        "description": "Additive constant in W_b drift",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "additive"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "All constants κ_x, κ_b > 0 ensure contraction where specified",
        "confidence": 1.0
      },
      {
        "text": "c_V, c_B > 0 as weighting factors",
        "confidence": 1.0
      },
      {
        "text": "Expansion bounds C_W, C_v, C_x, C_b ≥ 0",
        "confidence": 1.0
      },
      {
        "text": "V_Var,x and W_b can grow sufficiently large for partial contraction",
        "confidence": 0.9
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-complete-cloning-drift",
      "title": null,
      "type": "proof",
      "proves": "thm-complete-cloning-drift",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-complete-cloning-drift\n**Proof.**\n\nThe total drift is obtained by summing the component drifts with their respective weights:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] &= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\\\\n&= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V (\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]) + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]\n\\end{aligned}\n$$\n\nSubstituting the individual bounds from Theorems 10.3.1, 10.4.1, 11.3.1, and 12.2.1:\n\n$$\n\\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B(-\\kappa_b W_b + C_b)\n$$\n\nRearranging:\n\n$$\n= -c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)\n$$\n\nFor the drift to be negative, we need the contraction terms to dominate:\n\n$$\nc_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b\n$$\n\nThis holds when the weighted variance and boundary potential are sufficiently large.",
      "raw_directive": "8127: :::\n8128: \n8129: :::{prf:proof}\n8130: :label: proof-thm-complete-cloning-drift\n8131: **Proof.**\n8132: \n8133: The total drift is obtained by summing the component drifts with their respective weights:\n8134: \n8135: $$\n8136: \\begin{aligned}\n8137: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] &= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\\\\n8138: &= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V (\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]) + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]\n8139: \\end{aligned}\n8140: $$\n8141: \n8142: Substituting the individual bounds from Theorems 10.3.1, 10.4.1, 11.3.1, and 12.2.1:\n8143: \n8144: $$\n8145: \\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B(-\\kappa_b W_b + C_b)\n8146: $$\n8147: \n8148: Rearranging:\n8149: \n8150: $$\n8151: = -c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)\n8152: $$\n8153: \n8154: For the drift to be negative, we need the contraction terms to dominate:\n8155: \n8156: $$\n8157: c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b\n8158: $$\n8159: \n8160: This holds when the weighted variance and boundary potential are sufficiently large.\n8161: ",
      "strategy_summary": "The proof computes the expected total drift by summing the weighted expectations of individual component changes, substitutes upper bounds from referenced theorems for each term, rearranges to highlight the negative contraction terms versus positive constants, and establishes the condition under which the drift is negative, ensuring stability when variance and boundary potentials are sufficiently large.",
      "conclusion": {
        "text": "The total drift is negative when the contraction terms dominate the constants: c_V κ_x V_{Var,x} + c_B κ_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b. This holds when the weighted variance and boundary potential are sufficiently large.",
        "latex": "$c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b$"
      },
      "assumptions": [],
      "steps": [
        {
          "order": 1.0,
          "kind": "definition",
          "text": "Define the total drift as the weighted sum of component drifts.",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "decomposition",
          "text": "Decompose the variance drift into position and velocity components.",
          "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V (\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]) + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 3.0,
          "kind": "bounding",
          "text": "Apply upper bounds from referenced theorems to each expectation term.",
          "latex": "\\leq C_W + c_V (-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B (-\\kappa_b W_b + C_b)",
          "references": [
            "thm-10.3.1",
            "thm-10.4.1",
            "thm-11.3.1",
            "thm-12.2.1"
          ],
          "derived_statement": null
        },
        {
          "order": 4.0,
          "kind": "rearrangement",
          "text": "Rearrange the bounded expression to separate negative and positive terms.",
          "latex": "= -c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)",
          "references": [],
          "derived_statement": null
        },
        {
          "order": 5.0,
          "kind": "sufficiency",
          "text": "The drift is negative if the negative terms dominate the constant term.",
          "latex": "c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b",
          "references": [],
          "derived_statement": "Drift < 0 under the inequality"
        }
      ],
      "key_equations": [
        {
          "label": "eq-total-drift-sum",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
          "role": "Initial expression for total drift"
        },
        {
          "label": "eq-var-decomp",
          "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]",
          "role": "Decomposition of variance drift"
        },
        {
          "label": "eq-bounds-sub",
          "latex": "\\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B(-\\kappa_b W_b + C_b)",
          "role": "Upper bound after substitution"
        },
        {
          "label": "eq-rearranged-drift",
          "latex": "-c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)",
          "role": "Rearranged bound"
        },
        {
          "label": "eq-negativity-cond",
          "latex": "c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b",
          "role": "Condition for negative drift"
        }
      ],
      "references": [],
      "math_tools": [
        {
          "toolName": "Expectation Operator",
          "field": "Probability Theory",
          "description": "Computes the average value of a random variable, used here for drift analysis.",
          "roleInProof": "Calculates the expected change in the Lyapunov function components to form the total drift.",
          "levelOfAbstraction": "Notation",
          "relatedTools": [
            "Lyapunov Function"
          ]
        },
        {
          "toolName": "Lyapunov Drift Analysis",
          "field": "Stochastic Processes",
          "description": "A method to prove stability by showing that the expected change (drift) of a Lyapunov function is negative outside a compact set.",
          "roleInProof": "Bounds the total drift E[ΔV_total] to be negative under the given condition, implying convergence.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Expectation Operator"
          ]
        },
        {
          "toolName": "Inequality Bounding",
          "field": "Analysis",
          "description": "Technique for deriving upper or lower bounds on expressions using known inequalities.",
          "roleInProof": "Substitutes theorem-provided bounds into the drift expression to obtain an upper bound for E[ΔV_total].",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Lyapunov Drift Analysis"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "sufficiency",
          "text": "This holds when the weighted variance and boundary potential are sufficiently large."
        }
      ],
      "gaps": [],
      "tags": [
        "drift",
        "cloning",
        "variance",
        "boundary",
        "Lyapunov",
        "expectation",
        "contraction",
        "stability"
      ],
      "document_id": "03_cloning",
      "section": "## 12.3. The Complete Lyapunov Drift Under Cloning",
      "span": {
        "start_line": 8127,
        "end_line": 8161,
        "content_start": 8129,
        "content_end": 8160,
        "header_lines": [
          8128
        ]
      },
      "metadata": {
        "label": "proof-thm-complete-cloning-drift"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 31,
        "chapter_file": "chapter_31.json",
        "section_id": "## 12.3. The Complete Lyapunov Drift Under Cloning"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "cloning",
      "drift",
      "Lyapunov",
      "contraction",
      "inequality",
      "operator",
      "synergistic"
    ],
    "content_markdown": ":label: thm-complete-cloning-drift\n\nUnder the foundational axioms (Chapter 4), the cloning operator $\\Psi_{\\text{clone}}$ (see {prf:ref}`def-cloning-operator-formal`) induces the following drift on the synergistic Lyapunov function:\n\n$$\nV_{\\text{total}}(S_1, S_2) = V_W(S_1, S_2) + c_V V_{\\text{Var}}(S_1, S_2) + c_B W_b(S_1, S_2)\n$$\n\n**Individual Component Drifts:**\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{\\text{clone}}[\\Delta V_W] &\\leq C_W \\quad &\\text{(bounded expansion)} \\\\\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] &\\leq -\\kappa_x V_{\\text{Var},x} + C_x \\quad &\\text{(strong contraction)} \\\\\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] &\\leq C_v \\quad &\\text{(bounded expansion)} \\\\\n\\mathbb{E}_{\\text{clone}}[\\Delta W_b] &\\leq -\\kappa_b W_b + C_b \\quad &\\text{(strong contraction)}\n\\end{aligned}\n$$\n\n**Combined Drift:**\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] \\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_v + C_x) + c_B(-\\kappa_b W_b + C_b)\n$$\n\n**Critical Property - Partial Contraction:**\n\nWhen $V_{\\text{Var},x}$ and $W_b$ are sufficiently large relative to the expansion terms, the drift becomes negative:\n\n$$\n\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] < 0 \\quad \\text{when } c_V V_{\\text{Var},x} + c_B W_b > \\frac{C_W + c_V(C_v + C_x) + c_B C_b}{\\min(\\kappa_x, \\kappa_b)}",
    "raw_directive": "8091: ### 12.3.1. Main Result\n8092: \n8093: :::{prf:theorem} Complete Drift Inequality for the Cloning Operator\n8094: :label: thm-complete-cloning-drift\n8095: \n8096: Under the foundational axioms (Chapter 4), the cloning operator $\\Psi_{\\text{clone}}$ (see {prf:ref}`def-cloning-operator-formal`) induces the following drift on the synergistic Lyapunov function:\n8097: \n8098: $$\n8099: V_{\\text{total}}(S_1, S_2) = V_W(S_1, S_2) + c_V V_{\\text{Var}}(S_1, S_2) + c_B W_b(S_1, S_2)\n8100: $$\n8101: \n8102: **Individual Component Drifts:**\n8103: \n8104: $$\n8105: \\begin{aligned}\n8106: \\mathbb{E}_{\\text{clone}}[\\Delta V_W] &\\leq C_W \\quad &\\text{(bounded expansion)} \\\\\n8107: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] &\\leq -\\kappa_x V_{\\text{Var},x} + C_x \\quad &\\text{(strong contraction)} \\\\\n8108: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] &\\leq C_v \\quad &\\text{(bounded expansion)} \\\\\n8109: \\mathbb{E}_{\\text{clone}}[\\Delta W_b] &\\leq -\\kappa_b W_b + C_b \\quad &\\text{(strong contraction)}\n8110: \\end{aligned}\n8111: $$\n8112: \n8113: **Combined Drift:**\n8114: \n8115: $$\n8116: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] \\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_v + C_x) + c_B(-\\kappa_b W_b + C_b)\n8117: $$\n8118: \n8119: **Critical Property - Partial Contraction:**\n8120: \n8121: When $V_{\\text{Var},x}$ and $W_b$ are sufficiently large relative to the expansion terms, the drift becomes negative:\n8122: \n8123: $$\n8124: \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] < 0 \\quad \\text{when } c_V V_{\\text{Var},x} + c_B W_b > \\frac{C_W + c_V(C_v + C_x) + c_B C_b}{\\min(\\kappa_x, \\kappa_b)}\n8125: $$",
    "document_id": "03_cloning",
    "section": "## 12.3. The Complete Lyapunov Drift Under Cloning",
    "span": {
      "start_line": 8091,
      "end_line": 8125,
      "content_start": 8094,
      "content_end": 8124,
      "header_lines": [
        8092
      ]
    },
    "references": [
      "def-cloning-operator-formal"
    ],
    "metadata": {
      "label": "thm-complete-cloning-drift"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 31,
      "chapter_file": "chapter_31.json",
      "section_id": "## 12.3. The Complete Lyapunov Drift Under Cloning"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-synergistic-foster-lyapunov-preview",
    "title": "Synergistic Foster-Lyapunov Condition (Preview)",
    "type": "theorem",
    "nl_statement": "When the coupling constants c_V and c_B are chosen appropriately, the composed operator Ψ_total = Ψ_kin ∘ Ψ_clone satisfies a Foster-Lyapunov drift condition: E_total[V_total(S')] ≤ (1 - κ_total) V_total(S) + C_total for some κ_total > 0 and C_total < ∞, both independent of N. This implies geometric ergodicity of the Markov chain on the alive state space and exponential convergence to the quasi-stationary distribution.",
    "equations": [
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}"
      }
    ],
    "hypotheses": [
      {
        "text": "The coupling constants c_V and c_B are chosen appropriately.",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "The composed operator Ψ_total = Ψ_kin ∘ Ψ_clone satisfies a Foster-Lyapunov drift condition: E_total[V_total(S')] ≤ (1 - κ_total) V_total(S) + C_total for some κ_total > 0 and C_total < ∞, both independent of N. This implies: 1. Geometric ergodicity of the Markov chain on the alive state space. 2. Exponential convergence to the quasi-stationary distribution.",
      "latex": null
    },
    "variables": [
      {
        "symbol": "c_V",
        "name": "coupling constant for V",
        "description": "Coupling constant chosen appropriately.",
        "constraints": [],
        "tags": [
          "coupling"
        ]
      },
      {
        "symbol": "c_B",
        "name": "coupling constant for B",
        "description": "Coupling constant chosen appropriately.",
        "constraints": [],
        "tags": [
          "coupling"
        ]
      },
      {
        "symbol": "Ψ_total",
        "name": "total operator",
        "description": "Composed operator Ψ_kin ∘ Ψ_clone.",
        "constraints": [],
        "tags": [
          "operator"
        ]
      },
      {
        "symbol": "Ψ_kin",
        "name": "kinetic operator",
        "description": "Component operator in the composition.",
        "constraints": [],
        "tags": [
          "operator"
        ]
      },
      {
        "symbol": "Ψ_clone",
        "name": "cloning operator",
        "description": "Component operator in the composition.",
        "constraints": [],
        "tags": [
          "operator"
        ]
      },
      {
        "symbol": "V_total",
        "name": "total Lyapunov function",
        "description": "Lyapunov function for the total process.",
        "constraints": [],
        "tags": [
          "lyapunov"
        ]
      },
      {
        "symbol": "S",
        "name": "state",
        "description": "Current state in the Markov chain.",
        "constraints": [],
        "tags": [
          "state"
        ]
      },
      {
        "symbol": "S'",
        "name": "next state",
        "description": "Next state in the Markov chain.",
        "constraints": [],
        "tags": [
          "state"
        ]
      },
      {
        "symbol": "κ_total",
        "name": "drift constant",
        "description": "Positive constant in the drift inequality, independent of N.",
        "constraints": [
          "κ_total > 0"
        ],
        "tags": [
          "drift"
        ]
      },
      {
        "symbol": "C_total",
        "name": "bound constant",
        "description": "Finite constant in the drift inequality, independent of N.",
        "constraints": [
          "C_total < ∞"
        ],
        "tags": [
          "bound"
        ]
      },
      {
        "symbol": "N",
        "name": "system size",
        "description": "Parameter independent for constants.",
        "constraints": [],
        "tags": [
          "size"
        ]
      },
      {
        "symbol": "E_total",
        "name": "total expectation",
        "description": "Expectation under the total process.",
        "constraints": [],
        "tags": [
          "expectation"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The setting involves a Markov chain on an alive state space with a quasi-stationary distribution.",
        "confidence": 0.9
      },
      {
        "text": "The operators Ψ_kin and Ψ_clone are well-defined in the context of the process.",
        "confidence": 0.8
      },
      {
        "text": "V_total is a valid Lyapunov function for the composed process.",
        "confidence": 0.9
      }
    ],
    "local_refs": [],
    "proof": null,
    "tags": [
      "foster-lyapunov",
      "drift-condition",
      "geometric-ergodicity",
      "markov-chain",
      "synergistic",
      "coupling-constants",
      "quasi-stationary"
    ],
    "content_markdown": ":label: thm-synergistic-foster-lyapunov-preview\n\nWhen the coupling constants $c_V$ and $c_B$ are chosen appropriately, the composed operator $\\Psi_{\\text{total}} = \\Psi_{\\text{kin}} \\circ \\Psi_{\\text{clone}}$ satisfies a Foster-Lyapunov drift condition:\n\n$$\n\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}\n$$\n\nfor some $\\kappa_{\\text{total}} > 0$ and $C_{\\text{total}} < \\infty$, both independent of $N$.\n\n**Consequence:** This drift condition implies:\n1. **Geometric ergodicity** of the Markov chain on the alive state space",
    "raw_directive": "8240: ### 12.4.2. The Synergistic Drift Inequality\n8241: \n8242: :::{prf:theorem} Synergistic Foster-Lyapunov Condition (Preview)\n8243: :label: thm-synergistic-foster-lyapunov-preview\n8244: \n8245: When the coupling constants $c_V$ and $c_B$ are chosen appropriately, the composed operator $\\Psi_{\\text{total}} = \\Psi_{\\text{kin}} \\circ \\Psi_{\\text{clone}}$ satisfies a Foster-Lyapunov drift condition:\n8246: \n8247: $$\n8248: \\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}\n8249: $$\n8250: \n8251: for some $\\kappa_{\\text{total}} > 0$ and $C_{\\text{total}} < \\infty$, both independent of $N$.\n8252: \n8253: **Consequence:** This drift condition implies:\n8254: 1. **Geometric ergodicity** of the Markov chain on the alive state space\n8255: 2. **Exponential convergence** to the quasi-stationary distribution",
    "document_id": "03_cloning",
    "section": "## 12.4. The Synergistic Dissipation Framework",
    "span": {
      "start_line": 8240,
      "end_line": 8255,
      "content_start": 8243,
      "content_end": 8254,
      "header_lines": [
        8241
      ]
    },
    "references": [],
    "metadata": {
      "label": "thm-synergistic-foster-lyapunov-preview"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 32,
      "chapter_file": "chapter_32.json",
      "section_id": "## 12.4. The Synergistic Dissipation Framework"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-main-results-summary",
    "title": "Main Results of the Cloning Analysis (Summary)",
    "type": "theorem",
    "nl_statement": "The cloning operator Ψ_clone establishes the Keystone Principle for detectable geometric structure and corrective pressure, leads to N-uniform positional variance contraction, bounded velocity variance expansion, boundary potential contraction with exponentially suppressed extinction, and provides an N-independent partial contraction of the Lyapunov function, requiring a kinetic operator for the synergistic Foster-Lyapunov condition.",
    "equations": [
      {
        "label": null,
        "latex": "\\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v"
      },
      {
        "label": null,
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b"
      }
    ],
    "hypotheses": [],
    "conclusion": {
      "text": "All drift constants are N-independent, providing partial contraction of the Lyapunov function and foundation for synergistic Foster-Lyapunov condition with kinetic operator.",
      "latex": null
    },
    "variables": [
      {
        "symbol": "\\Psi_{\\text{clone}}",
        "name": "cloning operator",
        "description": "Operator applying corrective cloning pressure in swarm systems",
        "constraints": [
          "N-uniform"
        ],
        "tags": [
          "cloning",
          "pressure"
        ]
      },
      {
        "symbol": "N",
        "name": "swarm size",
        "description": "Number of agents in the swarm",
        "constraints": [
          "large N"
        ],
        "tags": [
          "swarm",
          "scalability"
        ]
      },
      {
        "symbol": "V_{\\text{Var},x}",
        "name": "positional variance",
        "description": "Variance measure for positions in the swarm",
        "constraints": [],
        "tags": [
          "variance",
          "position"
        ]
      },
      {
        "symbol": "\\kappa_x",
        "name": "contraction rate",
        "description": "Positive rate for positional variance contraction",
        "constraints": [
          "\\kappa_x > 0",
          "N-uniform"
        ],
        "tags": [
          "contraction",
          "rate"
        ]
      },
      {
        "symbol": "V_{\\text{Var},v}",
        "name": "velocity variance",
        "description": "Variance measure for velocities in the swarm",
        "constraints": [],
        "tags": [
          "variance",
          "velocity"
        ]
      },
      {
        "symbol": "W_b",
        "name": "boundary potential",
        "description": "Potential measuring proximity to boundaries",
        "constraints": [],
        "tags": [
          "boundary",
          "potential"
        ]
      },
      {
        "symbol": "\\kappa_b",
        "name": "boundary contraction rate",
        "description": "Positive rate for boundary potential contraction",
        "constraints": [
          "\\kappa_b > 0"
        ],
        "tags": [
          "contraction",
          "boundary"
        ]
      },
      {
        "symbol": "V_{\\text{struct}}",
        "name": "structural variance",
        "description": "Measure of geometric structure in positions",
        "constraints": [],
        "tags": [
          "structure",
          "geometry"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Large internal positional variance implies detectable geometric structure",
        "confidence": 1.0
      },
      {
        "text": "Inelastic collisions introduce state-independent perturbations",
        "confidence": 1.0
      },
      {
        "text": "Drift constants are independent of swarm size N for scalability",
        "confidence": 1.0
      },
      {
        "text": "Safe Harbor mechanism removes boundary-proximate walkers",
        "confidence": 1.0
      },
      {
        "text": "Kinetic operator is required to handle bounded expansions",
        "confidence": 0.9
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-main-results-summary",
      "title": null,
      "type": "proof",
      "proves": "thm-main-results-summary",
      "proof_type": "reference",
      "proof_status": "sketch",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-main-results-summary\nThis theorem is proven by systematic consolidation and verification. The complete detailed proof (9/10 rigor, 850 lines) is available in `proofs/proof_20251025_0227_thm_main_results_summary.md`. Here we provide the proof structure:\n\n**Proof Strategy**: Meta-proof via systematic citation. Each of the five summary items is verified by citing the corresponding proven theorem and confirming all dependencies.\n\n**Step 1 - Keystone Principle**: Chapters 5-8 establish the four-link causal chain (variance → structure → fitness → pressure) culminating in the quantitative inequality (Keystone Lemma, Lines 4669-4683). Constants $\\chi(\\epsilon) > 0$ and $g_{\\max}(\\epsilon) < \\infty$ are verified as N-uniform and constructive.\n\n**Step 2 - Positional Variance Contraction**: {prf:ref}`thm-positional-variance-contraction` (Lines 6291-6293) rigorously proves the drift inequality using the Keystone Lemma as primary engine. Contraction rate $\\kappa_x = \\chi(\\epsilon) c_{\\text{struct}} > 0$ verified as N-uniform via variance decomposition.\n\n**Step 3 - Velocity Variance Bounded Expansion**: {prf:ref}`thm-velocity-variance-bounded-expansion` (Lines 6671-6673) establishes state-independent bound $C_v = 4(1 + \\alpha_{\\text{restitution}})^2 V_{\\max}^2$ via inelastic collision analysis and {prf:ref}`axiom-velocity-regularization`.\n\n**Step 4 - Boundary Potential Contraction**: Chapter 11 (Lines 7212, 7232) proves contraction via {prf:ref}`axiom-safe-harbor`. Fitness deficit for boundary walkers creates systematic replacement, yielding $\\kappa_b = c_{\\text{fit}} c_{\\text{barrier}} > 0$ (N-uniform).\n\n**Step 5 - Complete Characterization**: Chapter 12 (Lines 8003-8334) synthesizes all results, verifies N-uniformity of all constants, confirms partial contraction structure (positions/boundary contract, velocities expand bounded), and correctly scopes synergy as foundation for companion document.\n\n**Step 6 - Final Verification**: All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies (Axioms EG-0, EG-2, EG-3, EG-4) verified in Chapter 4.",
      "raw_directive": "8458: :::\n8459: \n8460: :::{prf:proof}\n8461: :label: proof-thm-main-results-summary\n8462: This theorem is proven by systematic consolidation and verification. The complete detailed proof (9/10 rigor, 850 lines) is available in `proofs/proof_20251025_0227_thm_main_results_summary.md`. Here we provide the proof structure:\n8463: \n8464: **Proof Strategy**: Meta-proof via systematic citation. Each of the five summary items is verified by citing the corresponding proven theorem and confirming all dependencies.\n8465: \n8466: **Step 1 - Keystone Principle**: Chapters 5-8 establish the four-link causal chain (variance → structure → fitness → pressure) culminating in the quantitative inequality (Keystone Lemma, Lines 4669-4683). Constants $\\chi(\\epsilon) > 0$ and $g_{\\max}(\\epsilon) < \\infty$ are verified as N-uniform and constructive.\n8467: \n8468: **Step 2 - Positional Variance Contraction**: {prf:ref}`thm-positional-variance-contraction` (Lines 6291-6293) rigorously proves the drift inequality using the Keystone Lemma as primary engine. Contraction rate $\\kappa_x = \\chi(\\epsilon) c_{\\text{struct}} > 0$ verified as N-uniform via variance decomposition.\n8469: \n8470: **Step 3 - Velocity Variance Bounded Expansion**: {prf:ref}`thm-velocity-variance-bounded-expansion` (Lines 6671-6673) establishes state-independent bound $C_v = 4(1 + \\alpha_{\\text{restitution}})^2 V_{\\max}^2$ via inelastic collision analysis and {prf:ref}`axiom-velocity-regularization`.\n8471: \n8472: **Step 4 - Boundary Potential Contraction**: Chapter 11 (Lines 7212, 7232) proves contraction via {prf:ref}`axiom-safe-harbor`. Fitness deficit for boundary walkers creates systematic replacement, yielding $\\kappa_b = c_{\\text{fit}} c_{\\text{barrier}} > 0$ (N-uniform).\n8473: \n8474: **Step 5 - Complete Characterization**: Chapter 12 (Lines 8003-8334) synthesizes all results, verifies N-uniformity of all constants, confirms partial contraction structure (positions/boundary contract, velocities expand bounded), and correctly scopes synergy as foundation for companion document.\n8475: \n8476: **Step 6 - Final Verification**: All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies (Axioms EG-0, EG-2, EG-3, EG-4) verified in Chapter 4.\n8477: ",
      "strategy_summary": "This proof consolidates and verifies the five summary items of the main theorem by systematically citing corresponding proven theorems, lemmas, and axioms while confirming dependencies, N-uniformity of constants, and absence of circular reasoning or overclaiming.",
      "conclusion": {
        "text": "All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies (Axioms EG-0, EG-2, EG-3, EG-4) verified in Chapter 4.",
        "latex": null
      },
      "assumptions": [
        {
          "text": "Axiom EG-0: Framework foundational assumption.",
          "latex": null
        },
        {
          "text": "Axiom EG-2: Safe Harbor axiom for boundary behavior.",
          "latex": null
        },
        {
          "text": "Axiom EG-3: Framework dependency.",
          "latex": null
        },
        {
          "text": "Axiom EG-4: Velocity regularization axiom.",
          "latex": null
        }
      ],
      "steps": [
        {
          "order": 1.0,
          "kind": "verification",
          "text": "Chapters 5-8 establish the four-link causal chain (variance → structure → fitness → pressure) culminating in the quantitative inequality (Keystone Lemma, Lines 4669-4683). Constants χ(ε) > 0 and g_max(ε) < ∞ are verified as N-uniform and constructive.",
          "latex": null,
          "references": [
            "lem-keystone"
          ],
          "derived_statement": null
        },
        {
          "order": 2.0,
          "kind": "citation",
          "text": "{prf:ref}`thm-positional-variance-contraction` (Lines 6291-6293) rigorously proves the drift inequality using the Keystone Lemma as primary engine. Contraction rate κ_x = χ(ε) c_struct > 0 verified as N-uniform via variance decomposition.",
          "latex": null,
          "references": [
            "thm-positional-variance-contraction"
          ],
          "derived_statement": "κ_x = χ(ε) c_struct > 0 (N-uniform)"
        },
        {
          "order": 3.0,
          "kind": "citation",
          "text": "{prf:ref}`thm-velocity-variance-bounded-expansion` (Lines 6671-6673) establishes state-independent bound C_v = 4(1 + α_restitution)^2 V_max^2 via inelastic collision analysis and Axiom EG-4 (velocity regularization).",
          "latex": null,
          "references": [
            "thm-velocity-variance-bounded-expansion"
          ],
          "derived_statement": "C_v = 4(1 + α_restitution)^2 V_max^2"
        },
        {
          "order": 4.0,
          "kind": "verification",
          "text": "Chapter 11 (Lines 7212, 7232) proves contraction via Safe Harbor axiom (EG-2). Fitness deficit for boundary walkers creates systematic replacement, yielding κ_b = c_fit c_barrier > 0 (N-uniform).",
          "latex": null,
          "references": [
            "axiom-eg-2"
          ],
          "derived_statement": "κ_b = c_fit c_barrier > 0 (N-uniform)"
        },
        {
          "order": 5.0,
          "kind": "synthesis",
          "text": "Chapter 12 (Lines 8003-8334) synthesizes all results, verifies N-uniformity of all constants, confirms partial contraction structure (positions/boundary contract, velocities expand bounded), and correctly scopes synergy as foundation for companion document.",
          "latex": null,
          "references": [],
          "derived_statement": "Complete N-uniform partial contraction characterization"
        },
        {
          "order": 6.0,
          "kind": "final-check",
          "text": "All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies verified.",
          "latex": null,
          "references": [
            "axiom-eg-0",
            "axiom-eg-2",
            "axiom-eg-3",
            "axiom-eg-4"
          ],
          "derived_statement": null
        }
      ],
      "key_equations": [
        {
          "label": "eq-keystone-constants",
          "latex": "\\chi(\\epsilon) > 0, \\ g_{\\max}(\\epsilon) < \\infty",
          "role": "N-uniform constants in causal chain"
        },
        {
          "label": "eq-kappa-x",
          "latex": "\\kappa_x = \\chi(\\epsilon) c_{\\text{struct}} > 0",
          "role": "Positional contraction rate"
        },
        {
          "label": "eq-c-v",
          "latex": "C_v = 4(1 + \\alpha_{\\text{restitution}})^2 V_{\\max}^2",
          "role": "Velocity variance bound"
        },
        {
          "label": "eq-kappa-b",
          "latex": "\\kappa_b = c_{\\text{fit}} c_{\\text{barrier}} > 0",
          "role": "Boundary contraction rate"
        }
      ],
      "references": [
        "thm-positional-variance-contraction",
        "thm-velocity-variance-bounded-expansion",
        "axiom-velocity-regularization",
        "axiom-safe-harbor"
      ],
      "math_tools": [
        {
          "toolName": "Variance Decomposition",
          "field": "Probability Theory",
          "description": "Technique for breaking down total variance into components attributable to different sources.",
          "roleInProof": "Used to verify N-uniform contraction rate κ_x in positional variance.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Keystone Lemma"
          ]
        },
        {
          "toolName": "Keystone Lemma",
          "field": "Dynamical Systems",
          "description": "Quantitative inequality establishing a four-link causal chain from variance to selective pressure.",
          "roleInProof": "Primary engine for drift inequality in Step 1 and positional contraction in Step 2.",
          "levelOfAbstraction": "Theorem/Lemma",
          "relatedTools": [
            "Variance Decomposition"
          ]
        },
        {
          "toolName": "Inelastic Collision Analysis",
          "field": "Physics/Mechanics",
          "description": "Modeling of energy dissipation in collisions to bound velocity changes.",
          "roleInProof": "Establishes state-independent bound C_v for velocity variance in Step 3.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Axiom EG-4"
          ]
        }
      ],
      "cases": [],
      "remarks": [
        {
          "type": "reference",
          "text": "Complete detailed proof (9/10 rigor, 850 lines) available in proofs/proof_20251025_0227_thm_main_results_summary.md."
        },
        {
          "type": "scope",
          "text": "Synergy scoped as foundation for companion document; partial contraction (positions/boundary contract, velocities bounded expand)."
        }
      ],
      "gaps": [
        {
          "description": "Full detailed proof omitted; only structure provided here with citations to external file.",
          "severity": "minor",
          "location_hint": "Entire proof structure"
        }
      ],
      "tags": [
        "meta-proof",
        "systematic-citation",
        "verification",
        "consolidation",
        "causal-chain",
        "N-uniformity",
        "contraction",
        "bounded-expansion"
      ],
      "document_id": "03_cloning",
      "section": "## 12.5. Summary of Main Results",
      "span": {
        "start_line": 8458,
        "end_line": 8477,
        "content_start": 8460,
        "content_end": 8476,
        "header_lines": [
          8459
        ]
      },
      "metadata": {
        "label": "proof-thm-main-results-summary"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "03_cloning",
        "chapter_index": 33,
        "chapter_file": "chapter_33.json",
        "section_id": "## 12.5. Summary of Main Results"
      },
      "generated_at": "2025-11-10T12:23:04.016510+00:00",
      "alt_labels": []
    },
    "tags": [
      "cloning operator",
      "keystone principle",
      "variance contraction",
      "lyapunov function",
      "foster-lyapunov",
      "swarm dynamics",
      "drift inequality",
      "boundary potential"
    ],
    "content_markdown": ":label: thm-main-results-summary\n\nThis document has established the following results for the cloning operator $\\Psi_{\\text{clone}}$:\n\n**1. The Keystone Principle (Chapters 5-8):**\n- Large internal positional variance → detectable geometric structure\n- Geometric structure → reliable fitness signal (N-uniform)\n- Fitness signal → corrective cloning pressure\n- **Result:** $\\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)$\n\n**2. Positional Variance Contraction (Chapter 10):**\n- The Keystone Principle translates to rigorous drift inequality\n- **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x$\n- Contraction rate $\\kappa_x > 0$ is **N-uniform**\n\n**3. Velocity Variance Bounded Expansion (Chapter 10):**\n- Inelastic collisions cause state-independent perturbation\n- **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v$\n- Expansion is **bounded**, not growing with system state or size\n\n**4. Boundary Potential Contraction (Chapter 11):**\n- Safe Harbor mechanism systematically removes boundary-proximate walkers\n- **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b$\n- Provides **exponentially suppressed extinction probability**\n\n**5. Complete Characterization (Chapter 12):**\n- All drift constants are **N-independent** (scalable to large swarms)\n- Cloning provides **partial contraction** of the Lyapunov function\n- Requires **kinetic operator** to overcome bounded expansions\n- Foundation for **synergistic Foster-Lyapunov condition**",
    "raw_directive": "8406: ### 12.5.1. Theoretical Contributions\n8407: \n8408: :::{prf:theorem} Main Results of the Cloning Analysis (Summary)\n8409: :label: thm-main-results-summary\n8410: \n8411: This document has established the following results for the cloning operator $\\Psi_{\\text{clone}}$:\n8412: \n8413: **1. The Keystone Principle (Chapters 5-8):**\n8414: - Large internal positional variance → detectable geometric structure\n8415: - Geometric structure → reliable fitness signal (N-uniform)\n8416: - Fitness signal → corrective cloning pressure\n8417: - **Result:** $\\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)$\n8418: \n8419: **2. Positional Variance Contraction (Chapter 10):**\n8420: - The Keystone Principle translates to rigorous drift inequality\n8421: - **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x$\n8422: - Contraction rate $\\kappa_x > 0$ is **N-uniform**\n8423: \n8424: **3. Velocity Variance Bounded Expansion (Chapter 10):**\n8425: - Inelastic collisions cause state-independent perturbation\n8426: - **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v$\n8427: - Expansion is **bounded**, not growing with system state or size\n8428: \n8429: **4. Boundary Potential Contraction (Chapter 11):**\n8430: - Safe Harbor mechanism systematically removes boundary-proximate walkers\n8431: - **Result:** $\\mathbb{E}_{\\text{clone}}[\\Delta W_b] \\leq -\\kappa_b W_b + C_b$\n8432: - Provides **exponentially suppressed extinction probability**\n8433: \n8434: **5. Complete Characterization (Chapter 12):**\n8435: - All drift constants are **N-independent** (scalable to large swarms)\n8436: - Cloning provides **partial contraction** of the Lyapunov function\n8437: - Requires **kinetic operator** to overcome bounded expansions\n8438: - Foundation for **synergistic Foster-Lyapunov condition**\n8439: ",
    "document_id": "03_cloning",
    "section": "## 12.5. Summary of Main Results",
    "span": {
      "start_line": 8406,
      "end_line": 8439,
      "content_start": 8409,
      "content_end": 8438,
      "header_lines": [
        8407
      ]
    },
    "references": [
      "thm-positional-variance-contraction",
      "thm-velocity-variance-bounded-expansion",
      "axiom-velocity-regularization",
      "axiom-safe-harbor"
    ],
    "metadata": {
      "label": "thm-main-results-summary"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "03_cloning",
      "chapter_index": 33,
      "chapter_file": "chapter_33.json",
      "section_id": "## 12.5. Summary of Main Results"
    },
    "generated_at": "2025-11-10T12:23:04.021422+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-mean-field-equation",
    "title": "The Mean-Field Equations for the Euclidean Gas",
    "type": "theorem",
    "nl_statement": "The evolution of the Euclidean Gas in the mean-field limit is governed by a coupled system of equations for the alive density f(t,z) and the dead mass m_d(t).",
    "equations": [
      {
        "label": "eq-mean-field-pde-main",
        "latex": "\\partial_t f = L^\\dagger f - c(z)f + B[f, m_d] + S[f]"
      },
      {
        "label": "eq-dead-mass-ode",
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = \\int_{\\Omega} c(z)f(t,z)\\,\\mathrm{d}z - \\lambda_{\\text{rev}} m_d(t)"
      },
      {
        "label": null,
        "latex": "\\partial_t f(t,z) = -\\nabla\\cdot(A(z) f(t,z)) + \\nabla\\cdot(\\mathsf{D}\\nabla f(t,z)) - c(z)f(t,z) + \\lambda_{\\text{revive}} m_d(t) \\frac{f(t,z)}{m_a(t)} + S[f](t,z)"
      }
    ],
    "hypotheses": [
      {
        "text": "Initial condition for alive density: f(0, ·) = f_0",
        "latex": "f(0, \\cdot) = f_0"
      },
      {
        "text": "Initial condition for dead mass: m_d(0) = 1 - ∫_Ω f_0",
        "latex": "m_d(0) = 1 - \\int_\\Omega f_0"
      },
      {
        "text": "Normalization: m_a(0) + m_d(0) = 1",
        "latex": null
      },
      {
        "text": "Reflecting boundaries for kinetic transport",
        "latex": null
      },
      {
        "text": "Domain Ω with interior killing rate c(z) zero in interior and positive near boundary",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "The coupled system consists of the PDE for alive density and ODE for dead mass, incorporating kinetic transport, killing, revival, and cloning operators.",
      "latex": null
    },
    "variables": [
      {
        "symbol": "f",
        "name": "alive density",
        "description": "Spatial density of alive particles at time t and position z",
        "constraints": [
          "f(t,z) ≥ 0",
          "∫_Ω f(t,z) dz = m_a(t)"
        ],
        "tags": [
          "density",
          "alive"
        ]
      },
      {
        "symbol": "m_d",
        "name": "dead mass",
        "description": "Total mass of dead particles at time t",
        "constraints": [
          "m_d(t) ≥ 0",
          "m_d(t) ≤ 1"
        ],
        "tags": [
          "mass",
          "dead"
        ]
      },
      {
        "symbol": "m_a",
        "name": "alive mass",
        "description": "Total mass of alive particles at time t",
        "constraints": [
          "m_a(t) = ∫_Ω f(t,z) dz",
          "m_a(t) + m_d(t) = 1"
        ],
        "tags": [
          "mass",
          "alive"
        ]
      },
      {
        "symbol": "z",
        "name": "position",
        "description": "Spatial variable in domain Ω",
        "constraints": [
          "z ∈ Ω"
        ],
        "tags": [
          "spatial"
        ]
      },
      {
        "symbol": "t",
        "name": "time",
        "description": "Time variable",
        "constraints": [
          "t ≥ 0"
        ],
        "tags": [
          "temporal"
        ]
      },
      {
        "symbol": "A",
        "name": "drift field",
        "description": "Velocity field for kinetic transport",
        "constraints": [
          "defined on Ω"
        ],
        "tags": [
          "drift",
          "transport"
        ]
      },
      {
        "symbol": "\\mathsf{D}",
        "name": "diffusion tensor",
        "description": "Diffusion coefficient for kinetic transport",
        "constraints": [
          "positive semi-definite"
        ],
        "tags": [
          "diffusion",
          "transport"
        ]
      },
      {
        "symbol": "c",
        "name": "killing rate",
        "description": "Rate of interior killing, zero in interior and positive near boundary",
        "constraints": [
          "c(z) ≥ 0"
        ],
        "tags": [
          "killing"
        ]
      },
      {
        "symbol": "\\lambda_{\\text{revive}}",
        "name": "revival rate",
        "description": "Rate constant for revival from dead mass",
        "constraints": [
          "\\lambda_{\\text{revive}} > 0",
          "typical values 0.1-5"
        ],
        "tags": [
          "revival",
          "rate"
        ]
      },
      {
        "symbol": "S",
        "name": "cloning operator",
        "description": "Mass-neutral internal cloning operator applied to f",
        "constraints": [
          "mass-preserving"
        ],
        "tags": [
          "cloning"
        ]
      },
      {
        "symbol": "B",
        "name": "revival operator",
        "description": "Revival term B[f, m_d] = \\lambda_{\\text{revive}} m_d(t) f / m_a(t)",
        "constraints": [
          "proportional to f"
        ],
        "tags": [
          "revival"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The system operates in the mean-field limit with many particles",
        "confidence": 1.0
      },
      {
        "text": "Domain Ω is a bounded Euclidean domain with reflecting boundaries",
        "confidence": 0.9
      },
      {
        "text": "All operators L^†, B, S are well-defined and preserve non-negativity",
        "confidence": 1.0
      },
      {
        "text": "Initial data f_0 is non-negative with ∫_Ω f_0 ≤ 1",
        "confidence": 0.9
      },
      {
        "text": "Parameters ensure global existence of solutions (e.g., bounded rates)",
        "confidence": 0.8
      }
    ],
    "local_refs": [],
    "proof": null,
    "tags": [
      "mean-field limit",
      "Euclidean gas",
      "alive density",
      "dead mass",
      "coupled system",
      "revival operator",
      "cloning operator",
      "kinetic transport"
    ],
    "content_markdown": ":label: thm-mean-field-equation\n\nThe evolution of the Euclidean Gas in the mean-field limit is governed by a coupled system of equations for the alive density $f(t,z)$ and the dead mass $m_d(t)$:\n\n**Equation for the Alive Density:**\n\n$$\n\\boxed{\n\\partial_t f = L^\\dagger f - c(z)f + B[f, m_d] + S[f]\n}\n$$ (eq-mean-field-pde-main)\n\nwhere $L^\\dagger$ is the transport operator (see {prf:ref}`def-transport-operator`), $c(z)$ is the killing rate (see {prf:ref}`def-killing-operator`), $B[f, m_d]$ is the revival operator (see {prf:ref}`def-revival-operator`), and $S[f]$ is the internal cloning operator (see {prf:ref}`def-cloning-generator`).\n\n**Equation for the Dead Mass:**\n\n$$\n\\boxed{\n\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = \\int_{\\Omega} c(z)f(t,z)\\,\\mathrm{d}z - \\lambda_{\\text{rev}} m_d(t)\n}\n$$ (eq-dead-mass-ode)\n\nsubject to initial conditions $f(0, \\cdot) = f_0$ and $m_d(0) = 1 - \\int_\\Omega f_0$, where $m_a(0) + m_d(0) = 1$.\n\nThe total alive mass is $m_a(t) = \\int_\\Omega f(t,z)\\,\\mathrm{d}z$, and the system conserves the total population: $m_a(t) + m_d(t) = 1$ for all $t$ (see {prf:ref}`thm-mass-conservation`).\n\nIn explicit form, the equation for $f$ is:\n\n$$\n\\partial_t f(t,z) = -\\nabla\\cdot(A(z) f(t,z)) + \\nabla\\cdot(\\mathsf{D}\\nabla f(t,z)) - c(z)f(t,z) + \\lambda_{\\text{revive}} m_d(t) \\frac{f(t,z)}{m_a(t)} + S[f](t,z)\n$$\n\nwhere:\n*   $A(z)$ is the drift field and $\\mathsf{D}$ is the diffusion tensor from the kinetic transport (with reflecting boundaries)\n*   $c(z)$ is the interior killing rate (zero in interior, positive near boundary)\n*   $\\lambda_{\\text{revive}} > 0$ is the revival rate (free parameter, typical values 0.1-5)",
    "raw_directive": "612: By assembling all operators—kinetic transport, interior killing, revival, and internal cloning—we arrive at a **coupled system** that describes the evolution of both the alive density and the dead mass.\n613: \n614: :::{prf:theorem} The Mean-Field Equations for the Euclidean Gas\n615: :label: thm-mean-field-equation\n616: \n617: The evolution of the Euclidean Gas in the mean-field limit is governed by a coupled system of equations for the alive density $f(t,z)$ and the dead mass $m_d(t)$:\n618: \n619: **Equation for the Alive Density:**\n620: \n621: $$\n622: \\boxed{\n623: \\partial_t f = L^\\dagger f - c(z)f + B[f, m_d] + S[f]\n624: }\n625: $$ (eq-mean-field-pde-main)\n626: \n627: where $L^\\dagger$ is the transport operator (see {prf:ref}`def-transport-operator`), $c(z)$ is the killing rate (see {prf:ref}`def-killing-operator`), $B[f, m_d]$ is the revival operator (see {prf:ref}`def-revival-operator`), and $S[f]$ is the internal cloning operator (see {prf:ref}`def-cloning-generator`).\n628: \n629: **Equation for the Dead Mass:**\n630: \n631: $$\n632: \\boxed{\n633: \\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = \\int_{\\Omega} c(z)f(t,z)\\,\\mathrm{d}z - \\lambda_{\\text{rev}} m_d(t)\n634: }\n635: $$ (eq-dead-mass-ode)\n636: \n637: subject to initial conditions $f(0, \\cdot) = f_0$ and $m_d(0) = 1 - \\int_\\Omega f_0$, where $m_a(0) + m_d(0) = 1$.\n638: \n639: The total alive mass is $m_a(t) = \\int_\\Omega f(t,z)\\,\\mathrm{d}z$, and the system conserves the total population: $m_a(t) + m_d(t) = 1$ for all $t$ (see {prf:ref}`thm-mass-conservation`).\n640: \n641: In explicit form, the equation for $f$ is:\n642: \n643: $$\n644: \\partial_t f(t,z) = -\\nabla\\cdot(A(z) f(t,z)) + \\nabla\\cdot(\\mathsf{D}\\nabla f(t,z)) - c(z)f(t,z) + \\lambda_{\\text{revive}} m_d(t) \\frac{f(t,z)}{m_a(t)} + S[f](t,z)\n645: $$\n646: \n647: where:\n648: *   $A(z)$ is the drift field and $\\mathsf{D}$ is the diffusion tensor from the kinetic transport (with reflecting boundaries)\n649: *   $c(z)$ is the interior killing rate (zero in interior, positive near boundary)\n650: *   $\\lambda_{\\text{revive}} > 0$ is the revival rate (free parameter, typical values 0.1-5)\n651: *   $B[f, m_d] = \\lambda_{\\text{revive}} m_d(t) f/m_a$ is the revival operator",
    "document_id": "07_mean_field",
    "section": "## 3. The Mass-Conserving Forward Equation (PDE)",
    "span": {
      "start_line": 612,
      "end_line": 651,
      "content_start": 615,
      "content_end": 650,
      "header_lines": [
        613
      ]
    },
    "references": [
      "def-transport-operator",
      "def-killing-operator",
      "def-revival-operator",
      "def-cloning-generator",
      "thm-mass-conservation"
    ],
    "metadata": {
      "label": "thm-mean-field-equation"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "07_mean_field",
      "chapter_index": 3,
      "chapter_file": "chapter_3.json",
      "section_id": "## 3. The Mass-Conserving Forward Equation (PDE)"
    },
    "generated_at": "2025-11-10T12:23:04.034663+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-mass-conservation",
    "title": "Total Mass Conservation and Population Dynamics",
    "type": "theorem",
    "nl_statement": "Any sufficiently regular solution to the Mean-Field Equations conserves total population mass over time and evolves the alive population mass through revival from the dead population and killing.",
    "equations": [
      {
        "label": null,
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[m_a(t) + m_d(t)\\right] = 0"
      },
      {
        "label": "def-ma",
        "latex": "m_a(t) = \\int_\\Omega f(t,z)\\,\\mathrm{d}z"
      },
      {
        "label": null,
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\lambda_{\\text{rev}} m_d(t) - k_{\\text{killed}}[f](t)"
      }
    ],
    "hypotheses": [
      {
        "text": "Sufficiently regular solution $(f(t,z), m_d(t))$ to the Mean-Field Equations",
        "latex": "$(f(t,z), m_d(t))$"
      }
    ],
    "conclusion": {
      "text": "Total mass $m_a(t) + m_d(t) = 1$ for all $t > 0$ if initially true, and alive mass evolves as $\\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\lambda_{\\text{rev}} m_d(t) - k_{\\text{killed}}[f](t)$",
      "latex": null
    },
    "variables": [
      {
        "symbol": "f",
        "name": "alive population density",
        "description": "Density function for alive population at time t and position z",
        "constraints": [
          "sufficiently regular"
        ],
        "tags": [
          "density",
          "alive"
        ]
      },
      {
        "symbol": "m_d",
        "name": "dead mass",
        "description": "Total mass of dead population at time t",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "mass",
          "dead"
        ]
      },
      {
        "symbol": "m_a",
        "name": "alive mass",
        "description": "Total mass of alive population at time t, defined as integral of f",
        "constraints": [
          "non-negative"
        ],
        "tags": [
          "mass",
          "alive"
        ]
      },
      {
        "symbol": "\\lambda_{\\text{rev}}",
        "name": "revival rate",
        "description": "Rate constant for reviving dead population to alive",
        "constraints": [],
        "tags": [
          "rate",
          "revival"
        ]
      },
      {
        "symbol": "k_{\\text{killed}}",
        "name": "killing functional",
        "description": "Functional applied to f representing killing rate",
        "constraints": [],
        "tags": [
          "functional",
          "killing"
        ]
      },
      {
        "symbol": "\\Omega",
        "name": "spatial domain",
        "description": "Domain over which the integral for m_a is taken",
        "constraints": [],
        "tags": [
          "space",
          "domain"
        ]
      },
      {
        "symbol": "t",
        "name": "time",
        "description": "Time variable for dynamics",
        "constraints": [
          "t > 0"
        ],
        "tags": [
          "time"
        ]
      },
      {
        "symbol": "z",
        "name": "spatial variable",
        "description": "Position variable in the density f",
        "constraints": [],
        "tags": [
          "space"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Initial condition m_a(0) + m_d(0) = 1",
        "confidence": 1.0
      },
      {
        "text": "Non-negativity of masses m_a(t) >= 0 and m_d(t) >= 0 for all t",
        "confidence": 0.9
      },
      {
        "text": "Parameters lambda_rev > 0 and k_killed is a positive operator",
        "confidence": 0.8
      },
      {
        "text": "Omega is a bounded domain",
        "confidence": 0.7
      }
    ],
    "local_refs": [],
    "proof": {
      "label": "proof-thm-mass-conservation",
      "title": null,
      "type": "proof",
      "proves": "thm-mass-conservation",
      "proof_type": "direct",
      "proof_status": "complete",
      "content_markdown": ":::{prf:proof}\n:label: proof-thm-mass-conservation\n**Proof.**\nWe compute the time derivatives of both components and show they sum to zero.\n\n**For the alive mass:** Integrate the equation for $\\partial_t f$ over $\\Omega$:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}\\int_\\Omega f(t,z)\\,\\mathrm{d}z = \\int_\\Omega L^\\dagger f\\,\\mathrm{d}z - \\int_\\Omega c(z)f\\,\\mathrm{d}z + \\int_\\Omega B[f, m_d]\\,\\mathrm{d}z + \\int_\\Omega S[f]\\,\\mathrm{d}z\n$$\n\nEvaluating each term using the properties established in previous sections:\n\n1.  **Transport**: From {prf:ref}`lem-mass-conservation-transport`, $\\int_\\Omega L^\\dagger f\\,\\mathrm{d}z = 0$ (reflecting boundaries)\n2.  **Killing**: By definition, $\\int_\\Omega c(z)f\\,\\mathrm{d}z = k_{\\text{killed}}[f]$\n3.  **Revival**: From {prf:ref}`def-revival-operator`, $\\int_\\Omega B[f, m_d]\\,\\mathrm{d}z = \\lambda_{\\text{revive}} m_d(t)$\n4.  **Internal cloning**: From {prf:ref}`def-cloning-generator`, $\\int_\\Omega S[f]\\,\\mathrm{d}z = 0$\n\nTherefore:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = 0 - k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t) + 0 = -k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\n$$\n\n**For the dead mass:** From the second equation:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\n$$\n\n**Sum:** Adding these two equations:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[m_a(t) + m_d(t)\\right] = \\left[-k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\\right] + \\left[k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\\right] = 0\n$$\n\nThis demonstrates that the total mass is conserved for all time, completing the proof.",
      "raw_directive": "695: :::\n696: \n697: :::{prf:proof}\n698: :label: proof-thm-mass-conservation\n699: **Proof.**\n700: We compute the time derivatives of both components and show they sum to zero.\n701: \n702: **For the alive mass:** Integrate the equation for $\\partial_t f$ over $\\Omega$:\n703: \n704: $$\n705: \\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}\\int_\\Omega f(t,z)\\,\\mathrm{d}z = \\int_\\Omega L^\\dagger f\\,\\mathrm{d}z - \\int_\\Omega c(z)f\\,\\mathrm{d}z + \\int_\\Omega B[f, m_d]\\,\\mathrm{d}z + \\int_\\Omega S[f]\\,\\mathrm{d}z\n706: $$\n707: \n708: Evaluating each term using the properties established in previous sections:\n709: \n710: 1.  **Transport**: From {prf:ref}`lem-mass-conservation-transport`, $\\int_\\Omega L^\\dagger f\\,\\mathrm{d}z = 0$ (reflecting boundaries)\n711: 2.  **Killing**: By definition, $\\int_\\Omega c(z)f\\,\\mathrm{d}z = k_{\\text{killed}}[f]$\n712: 3.  **Revival**: From {prf:ref}`def-revival-operator`, $\\int_\\Omega B[f, m_d]\\,\\mathrm{d}z = \\lambda_{\\text{revive}} m_d(t)$\n713: 4.  **Internal cloning**: From {prf:ref}`def-cloning-generator`, $\\int_\\Omega S[f]\\,\\mathrm{d}z = 0$\n714: \n715: Therefore:\n716: \n717: $$\n718: \\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = 0 - k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t) + 0 = -k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\n719: $$\n720: \n721: **For the dead mass:** From the second equation:\n722: \n723: $$\n724: \\frac{\\mathrm{d}}{\\mathrm{d}t}m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\n725: $$\n726: \n727: **Sum:** Adding these two equations:\n728: \n729: $$\n730: \\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[m_a(t) + m_d(t)\\right] = \\left[-k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\\right] + \\left[k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\\right] = 0\n731: $$\n732: \n733: This demonstrates that the total mass is conserved for all time, completing the proof.\n734: ",
      "strategy_summary": "The proof directly computes the time derivatives of the alive mass \\(m_a(t)\\) and dead mass \\(m_d(t)\\) by integrating the governing equations over the domain \\(\\Omega\\), applies properties of the transport, killing, revival, and cloning operators to simplify each term, and shows that the sum of the derivatives is zero, conserving total mass.",
      "conclusion": {
        "text": null,
        "latex": null
      },
      "assumptions": [],
      "steps": [],
      "key_equations": [
        {
          "label": "eq-da",
          "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t) = \\int_\\Omega L^\\dagger f \\, \\mathrm{d}z - \\int_\\Omega c(z) f \\, \\mathrm{d}z + \\int_\\Omega B[f, m_d] \\, \\mathrm{d}z + \\int_\\Omega S[f] \\, \\mathrm{d}z",
          "role": "Time derivative of alive mass"
        },
        {
          "label": "eq-simplified-da",
          "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t) = -k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)",
          "role": "Simplified alive mass derivative"
        },
        {
          "label": "eq-dd",
          "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)",
          "role": "Dead mass derivative"
        },
        {
          "label": "eq-total",
          "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} [m_a(t) + m_d(t)] = 0",
          "role": "Conservation of total mass"
        }
      ],
      "references": [
        "lem-mass-conservation-transport",
        "def-revival-operator",
        "def-cloning-generator"
      ],
      "math_tools": [
        {
          "toolName": "Adjoint Transport Operator",
          "field": "Partial Differential Equations",
          "description": "The adjoint operator \\(L^\\dagger\\) associated with a transport equation, which preserves integrals under appropriate boundary conditions.",
          "roleInProof": "Used to show that the transport term integrates to zero over \\(\\Omega\\) due to reflective boundaries.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Divergence Theorem"
          ]
        },
        {
          "toolName": "Mass Conservation via Integration",
          "field": "Analysis",
          "description": "Integrating evolution equations over a domain to derive balance laws for total quantities like mass.",
          "roleInProof": "Applied to compute time derivatives of masses by integrating \\(\\partial_t f\\) and the dead mass equation.",
          "levelOfAbstraction": "Technique",
          "relatedTools": [
            "Fundamental Theorem of Calculus"
          ]
        },
        {
          "toolName": "Linear Operators on Function Spaces",
          "field": "Functional Analysis",
          "description": "Operators such as killing, revival, and cloning that act linearly on densities and preserve or transfer mass.",
          "roleInProof": "Properties of these operators (e.g., integral of revival equals \\(\\lambda_{\text{rev}} m_d\\)) are used to evaluate terms in the mass derivatives.",
          "levelOfAbstraction": "Concept",
          "relatedTools": [
            "Adjoint Transport Operator"
          ]
        }
      ],
      "cases": [
        {
          "name": "Alive mass",
          "condition": null,
          "summary": "Compute and simplify \\(\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t)\\) using operator properties to get \\(-k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\\)."
        },
        {
          "name": "Dead mass",
          "condition": null,
          "summary": "Directly from the equation, \\(\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\\)."
        }
      ],
      "remarks": [
        {
          "type": "conclusion",
          "text": "This shows total mass conservation holds due to balancing of killing and revival terms."
        }
      ],
      "gaps": [],
      "tags": [
        "mass-conservation",
        "time-derivative",
        "integration",
        "transport-operator",
        "revival",
        "cloning",
        "conservation-law"
      ],
      "document_id": "07_mean_field",
      "section": "## 3. The Mass-Conserving Forward Equation (PDE)",
      "span": {
        "start_line": 695,
        "end_line": 734,
        "content_start": 697,
        "content_end": 733,
        "header_lines": [
          696
        ]
      },
      "metadata": {
        "label": "proof-thm-mass-conservation"
      },
      "registry_context": {
        "stage": "directives",
        "document_id": "07_mean_field",
        "chapter_index": 3,
        "chapter_file": "chapter_3.json",
        "section_id": "## 3. The Mass-Conserving Forward Equation (PDE)"
      },
      "generated_at": "2025-11-10T12:23:04.034234+00:00",
      "alt_labels": []
    },
    "tags": [
      "mass conservation",
      "population dynamics",
      "mean-field equations",
      "alive population",
      "dead population",
      "revival",
      "killing"
    ],
    "content_markdown": ":label: thm-mass-conservation\n\nAny sufficiently regular solution $(f(t,z), m_d(t))$ to the Mean-Field Equations (see {prf:ref}`thm-mean-field-equation`) satisfies the following properties:\n\n**1. Total Mass Conservation:** The total population is conserved for all time $t>0$:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[m_a(t) + m_d(t)\\right] = 0\n$$\n\nwhere $m_a(t) = \\int_\\Omega f(t,z)\\,\\mathrm{d}z$. This implies that $m_a(t) + m_d(t) = 1$ for all $t$ if this holds initially.\n\n**2. Alive Population Dynamics:** The alive mass evolves according to the balance between killing and revival:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\lambda_{\\text{rev}} m_d(t) - k_{\\text{killed}}[f](t)\n$$",
    "raw_directive": "673: The primary property of this coupled system is that it conserves **total population mass** while allowing the alive and dead populations to exchange mass and reach a dynamic equilibrium.\n674: \n675: :::{prf:theorem} Total Mass Conservation and Population Dynamics\n676: :label: thm-mass-conservation\n677: \n678: Any sufficiently regular solution $(f(t,z), m_d(t))$ to the Mean-Field Equations (see {prf:ref}`thm-mean-field-equation`) satisfies the following properties:\n679: \n680: **1. Total Mass Conservation:** The total population is conserved for all time $t>0$:\n681: \n682: $$\n683: \\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[m_a(t) + m_d(t)\\right] = 0\n684: $$\n685: \n686: where $m_a(t) = \\int_\\Omega f(t,z)\\,\\mathrm{d}z$. This implies that $m_a(t) + m_d(t) = 1$ for all $t$ if this holds initially.\n687: \n688: **2. Alive Population Dynamics:** The alive mass evolves according to the balance between killing and revival:\n689: \n690: $$\n691: \\frac{\\mathrm{d}}{\\mathrm{d}t}m_a(t) = \\lambda_{\\text{rev}} m_d(t) - k_{\\text{killed}}[f](t)\n692: $$\n693: ",
    "document_id": "07_mean_field",
    "section": "## 3. The Mass-Conserving Forward Equation (PDE)",
    "span": {
      "start_line": 673,
      "end_line": 693,
      "content_start": 676,
      "content_end": 692,
      "header_lines": [
        674
      ]
    },
    "references": [
      "thm-mean-field-equation",
      "lem-mass-conservation-transport",
      "def-revival-operator",
      "def-cloning-generator"
    ],
    "metadata": {
      "label": "thm-mass-conservation"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "07_mean_field",
      "chapter_index": 3,
      "chapter_file": "chapter_3.json",
      "section_id": "## 3. The Mass-Conserving Forward Equation (PDE)"
    },
    "generated_at": "2025-11-10T12:23:04.034663+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-killing-rate-consistency",
    "title": "Consistency of the Interior Killing Rate Approximation",
    "type": "theorem",
    "nl_statement": "Under the given regularity assumptions on the domain, integrator, and density, there exists a smooth compactly supported killing rate function c such that the normalized discrete exit probability converges pointwise to c, and the normalized expected discrete killing fraction converges to the continuous killing integral with a specified error bound involving sqrt(tau) and the L1 norm of the density difference.",
    "equations": [
      {
        "label": null,
        "latex": "p_{\\text{exit}}(x,v,\\tau) := \\mathbb{P}\\left(x^+(\\tau; x,v) \\notin X_{\\text{valid}}\\right)"
      },
      {
        "label": null,
        "latex": "\\lim_{\\tau \\to 0} \\frac{1}{\\tau} p_{\\text{exit}}(x,v,\\tau) = c(x,v)"
      },
      {
        "label": null,
        "latex": "c(x,v) = \\begin{cases} \\frac{(v \\cdot n_x(x))^+}{d(x)} \\cdot \\mathbf{1}_{d(x) < \\delta} & \\text{if } x \\in \\mathcal{T}_\\delta \\\\ 0 & \\text{otherwise} \\end{cases}"
      },
      {
        "label": null,
        "latex": "(v \\cdot n_x(x))^+ := \\max(v \\cdot n_x(x), 0)"
      },
      {
        "label": null,
        "latex": "K_{\\text{discrete}}(\\tau) := \\int_\\Omega p_{\\text{exit}}(x,v,\\tau) f^\\tau(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v"
      },
      {
        "label": null,
        "latex": "K_{\\text{continuous}} := \\int_\\Omega c(x,v) f(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v"
      },
      {
        "label": null,
        "latex": "\\lim_{\\tau \\to 0} \\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) = K_{\\text{continuous}}"
      },
      {
        "label": null,
        "latex": "\\left|\\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) - K_{\\text{continuous}}\\right| \\le C \\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)"
      }
    ],
    "hypotheses": [
      {
        "text": "Assumptions on domain regularity (asmp-domain-regularity)",
        "latex": null
      },
      {
        "text": "Assumptions on integrator regularity (asmp-integrator-regularity)",
        "latex": null
      },
      {
        "text": "Assumptions on density regularity for killing (asmp-density-regularity-killing)",
        "latex": null
      }
    ],
    "conclusion": {
      "text": "Existence of smooth c in C^∞_c(Ω) with compact support in T_δ such that: (i) pointwise convergence of normalized exit probability to c(x,v); (ii) uniform convergence of normalized expected killing fraction to continuous killing rate with error bound C(√τ + ||f^τ - f||_{L^1}).",
      "latex": null
    },
    "variables": [
      {
        "symbol": "c",
        "name": "killing rate function",
        "description": "Smooth function with compact support in T_δ, defining the killing rate.",
        "constraints": [
          "c ∈ C^∞_c(Ω)",
          "supp(c) ⊂ T_δ"
        ],
        "tags": [
          "killing",
          "rate"
        ]
      },
      {
        "symbol": "x",
        "name": "position",
        "description": "Spatial variable in domain Ω.",
        "constraints": [
          "x ∈ Ω"
        ],
        "tags": [
          "position",
          "space"
        ]
      },
      {
        "symbol": "v",
        "name": "velocity",
        "description": "Velocity variable.",
        "constraints": [
          "v ∈ V (implicit)"
        ],
        "tags": [
          "velocity"
        ]
      },
      {
        "symbol": "τ",
        "name": "timestep",
        "description": "Discrete timestep size approaching 0.",
        "constraints": [
          "τ > 0",
          "τ → 0"
        ],
        "tags": [
          "timestep",
          "discrete"
        ]
      },
      {
        "symbol": "δ",
        "name": "boundary layer thickness",
        "description": "Parameter defining the thin boundary layer T_δ.",
        "constraints": [
          "δ > 0 small"
        ],
        "tags": [
          "boundary",
          "layer"
        ]
      },
      {
        "symbol": "d(x)",
        "name": "signed distance",
        "description": "Signed distance to the boundary.",
        "constraints": [
          "d(x) < δ in T_δ"
        ],
        "tags": [
          "distance",
          "boundary"
        ]
      },
      {
        "symbol": "n_x(x)",
        "name": "outward normal",
        "description": "Outward unit normal at x on boundary.",
        "constraints": [],
        "tags": [
          "normal",
          "boundary"
        ]
      },
      {
        "symbol": "f",
        "name": "density function",
        "description": "Continuous density function.",
        "constraints": [
          "f ∈ suitable regularity space"
        ],
        "tags": [
          "density",
          "continuous"
        ]
      },
      {
        "symbol": "f^τ",
        "name": "discrete density",
        "description": "Density at discrete timestep τ.",
        "constraints": [
          "||f^τ - f||_{L^1} → 0 as τ → 0 (implicit)"
        ],
        "tags": [
          "density",
          "discrete"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "Ω is a bounded domain with smooth boundary.",
        "confidence": 0.9
      },
      {
        "text": "The integrator x^+(τ; x,v) is accurate to higher order near boundary.",
        "confidence": 0.8
      },
      {
        "text": "f and f^τ are non-negative and integrate to 1 (probability densities).",
        "confidence": 0.7
      }
    ],
    "local_refs": [
      "asmp-domain-regularity",
      "asmp-integrator-regularity",
      "asmp-density-regularity-killing"
    ],
    "proof": null,
    "tags": [
      "killing-rate",
      "consistency",
      "pointwise-convergence",
      "uniform-convergence",
      "exit-probability",
      "error-bound",
      "transport-simulation"
    ],
    "content_markdown": ":label: thm-killing-rate-consistency\n\nUnder the regularity assumptions (see {prf:ref}`assumption-domain-regularity`, {prf:ref}`assumption-integrator-regularity`, and {prf:ref}`assumption-density-regularity-killing`), there exists a smooth killing rate function $c \\in C^\\infty_c(\\Omega)$ (see {prf:ref}`def-killing-operator`) with compact support in $\\mathcal{T}_\\delta$ such that:\n\n**Part (i): Pointwise Convergence of the Exit Rate**\n\nFor each $(x,v) \\in \\Omega$, define the discrete exit probability:\n\n$$\np_{\\text{exit}}(x,v,\\tau) := \\mathbb{P}\\left(x^+(\\tau; x,v) \\notin X_{\\text{valid}}\\right)\n$$\n\nThen:\n\n$$\n\\lim_{\\tau \\to 0} \\frac{1}{\\tau} p_{\\text{exit}}(x,v,\\tau) = c(x,v)\n$$\n\nwhere the killing rate is given explicitly by:\n\n$$\nc(x,v) = \\begin{cases}\n\\frac{(v \\cdot n_x(x))^+}{d(x)} \\cdot \\mathbf{1}_{d(x) < \\delta} & \\text{if } x \\in \\mathcal{T}_\\delta \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nwith $(v \\cdot n_x(x))^+ := \\max(v \\cdot n_x(x), 0)$ denoting the outward normal velocity component.\n\n**Part (ii): Uniform Convergence of the Expected Killing Fraction**\n\nDefine the expected killing fraction in a discrete timestep as:\n\n$$\nK_{\\text{discrete}}(\\tau) := \\int_{\\Omega} p_{\\text{exit}}(x,v,\\tau) f^\\tau(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v\n$$\n\nand the continuous killing rate as:\n\n$$\nK_{\\text{continuous}} := \\int_{\\Omega} c(x,v) f(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v\n$$\n\nThen:\n\n$$\n\\lim_{\\tau \\to 0} \\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) = K_{\\text{continuous}}\n$$\n\nwith the error bound:\n\n$$\n\\left|\\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) - K_{\\text{continuous}}\\right| \\le C \\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)\n$$",
    "raw_directive": "835: #### 4.4.2. Main Theorem: Killing Rate Approximation\n836: \n837: :::{prf:theorem} Consistency of the Interior Killing Rate Approximation\n838: :label: thm-killing-rate-consistency\n839: \n840: Under the regularity assumptions (see {prf:ref}`assumption-domain-regularity`, {prf:ref}`assumption-integrator-regularity`, and {prf:ref}`assumption-density-regularity-killing`), there exists a smooth killing rate function $c \\in C^\\infty_c(\\Omega)$ (see {prf:ref}`def-killing-operator`) with compact support in $\\mathcal{T}_\\delta$ such that:\n841: \n842: **Part (i): Pointwise Convergence of the Exit Rate**\n843: \n844: For each $(x,v) \\in \\Omega$, define the discrete exit probability:\n845: \n846: $$\n847: p_{\\text{exit}}(x,v,\\tau) := \\mathbb{P}\\left(x^+(\\tau; x,v) \\notin X_{\\text{valid}}\\right)\n848: $$\n849: \n850: Then:\n851: \n852: $$\n853: \\lim_{\\tau \\to 0} \\frac{1}{\\tau} p_{\\text{exit}}(x,v,\\tau) = c(x,v)\n854: $$\n855: \n856: where the killing rate is given explicitly by:\n857: \n858: $$\n859: c(x,v) = \\begin{cases}\n860: \\frac{(v \\cdot n_x(x))^+}{d(x)} \\cdot \\mathbf{1}_{d(x) < \\delta} & \\text{if } x \\in \\mathcal{T}_\\delta \\\\\n861: 0 & \\text{otherwise}\n862: \\end{cases}\n863: $$\n864: \n865: with $(v \\cdot n_x(x))^+ := \\max(v \\cdot n_x(x), 0)$ denoting the outward normal velocity component.\n866: \n867: **Part (ii): Uniform Convergence of the Expected Killing Fraction**\n868: \n869: Define the expected killing fraction in a discrete timestep as:\n870: \n871: $$\n872: K_{\\text{discrete}}(\\tau) := \\int_{\\Omega} p_{\\text{exit}}(x,v,\\tau) f^\\tau(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v\n873: $$\n874: \n875: and the continuous killing rate as:\n876: \n877: $$\n878: K_{\\text{continuous}} := \\int_{\\Omega} c(x,v) f(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v\n879: $$\n880: \n881: Then:\n882: \n883: $$\n884: \\lim_{\\tau \\to 0} \\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) = K_{\\text{continuous}}\n885: $$\n886: \n887: with the error bound:\n888: \n889: $$\n890: \\left|\\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) - K_{\\text{continuous}}\\right| \\le C \\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)\n891: $$\n892: ",
    "document_id": "07_mean_field",
    "section": "## 4. Analysis and Properties of the Mean-Field Equations",
    "span": {
      "start_line": 835,
      "end_line": 892,
      "content_start": 838,
      "content_end": 891,
      "header_lines": [
        836
      ]
    },
    "references": [
      "assumption-domain-regularity",
      "assumption-integrator-regularity",
      "assumption-density-regularity-killing",
      "def-killing-operator"
    ],
    "metadata": {
      "label": "thm-killing-rate-consistency"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "07_mean_field",
      "chapter_index": 4,
      "chapter_file": "chapter_4.json",
      "section_id": "## 4. Analysis and Properties of the Mean-Field Equations"
    },
    "generated_at": "2025-11-10T12:23:04.034663+00:00",
    "alt_labels": []
  },
  {
    "label": "thm-mean-field-limit-informal",
    "title": "Mean-Field Limit (Informal Statement)",
    "type": "theorem",
    "nl_statement": "In the joint limit N → ∞ and τ → 0 with τ = O(N^{-α}) for α > 0, the empirical density of the N-particle discrete Fragile Gas dynamics converges weakly to the mean-field density f.",
    "equations": [
      {
        "label": "empirical-density",
        "latex": "f_N^\\tau(t, x, v) := \\frac{1}{N} \\sum_{i=1}^N \\delta(x - X_i^\\tau(t), v - V_i^\\tau(t))"
      },
      {
        "label": "convergence",
        "latex": "f_N^\\tau(t, \\cdot, \\cdot) \\xrightarrow{\\text{weak}} f(t, \\cdot, \\cdot)"
      }
    ],
    "hypotheses": [
      {
        "text": "N-particle discrete Fragile Gas dynamics with timestep τ: (X_i^τ(t), V_i^τ(t))_{i=1}^N",
        "latex": null
      },
      {
        "text": "Empirical density defined as f_N^τ(t, x, v) = (1/N) ∑_{i=1}^N δ(x - X_i^τ(t), v - V_i^τ(t))",
        "latex": "f_N^\\tau(t, x, v) := \\frac{1}{N} \\sum_{i=1}^N \\delta(x - X_i^\\tau(t), v - V_i^\\tau(t))"
      },
      {
        "text": "Joint limit N → ∞, τ → 0 with τ = O(N^{-α}) for α > 0",
        "latex": "\\tau = O(N^{-\\alpha}) \\; \\alpha > 0"
      }
    ],
    "conclusion": {
      "text": "f_N^τ(t, ·, ·) converges weakly to f(t, ·, ·)",
      "latex": "f_N^\\tau(t, \\cdot, \\cdot) \\xrightarrow{\\text{weak}} f(t, \\cdot, \\cdot)"
    },
    "variables": [
      {
        "symbol": "N",
        "name": "number of particles",
        "description": "Number of particles in the system",
        "constraints": [
          "N → ∞"
        ],
        "tags": [
          "particles"
        ]
      },
      {
        "symbol": "τ",
        "name": "timestep",
        "description": "Discrete timestep in the dynamics",
        "constraints": [
          "τ → 0",
          "τ = O(N^{-α}), α > 0"
        ],
        "tags": [
          "discretization"
        ]
      },
      {
        "symbol": "X_i^τ(t)",
        "name": "position",
        "description": "Position of i-th particle at time t",
        "constraints": [],
        "tags": [
          "position"
        ]
      },
      {
        "symbol": "V_i^τ(t)",
        "name": "velocity",
        "description": "Velocity of i-th particle at time t",
        "constraints": [],
        "tags": [
          "velocity"
        ]
      },
      {
        "symbol": "f_N^τ",
        "name": "empirical density",
        "description": "Empirical measure of the particle system",
        "constraints": [],
        "tags": [
          "density",
          "empirical"
        ]
      },
      {
        "symbol": "f",
        "name": "mean-field density",
        "description": "Limiting mean-field density function",
        "constraints": [],
        "tags": [
          "mean-field",
          "limit"
        ]
      }
    ],
    "implicit_assumptions": [
      {
        "text": "The killing rate consistency theorem holds",
        "confidence": 1.0
      },
      {
        "text": "Standard kinetic theory applies to the transport operator L†",
        "confidence": 0.9
      },
      {
        "text": "Law of Large Numbers applies to cloning operators",
        "confidence": 0.9
      },
      {
        "text": "Weak convergence in the space of probability measures",
        "confidence": 1.0
      }
    ],
    "local_refs": [
      "thm-killing-rate-consistency"
    ],
    "proof": null,
    "tags": [
      "mean-field",
      "limit",
      "fragile gas",
      "kinetic theory",
      "weak convergence",
      "empirical density"
    ],
    "content_markdown": ":label: thm-mean-field-limit-informal\n\nLet $(X_i^\\tau(t), V_i^\\tau(t))_{i=1}^N$ be the $N$-particle discrete Fragile Gas dynamics (see {prf:ref}`def-baoab-update-rule` for the kinetic integrator) with timestep $\\tau$, and let:\n\n$$\nf_N^\\tau(t, x, v) := \\frac{1}{N} \\sum_{i=1}^N \\delta(x - X_i^\\tau(t), v - V_i^\\tau(t))\n$$\n\nbe the empirical density. Then, in the joint limit $N \\to \\infty, \\tau \\to 0$ with $\\tau = O(N^{-\\alpha})$ for $\\alpha > 0$:\n\n$$\nf_N^\\tau(t, \\cdot, \\cdot) \\xrightarrow{\\text{weak}} f(t, \\cdot, \\cdot)\n$$",
    "raw_directive": "1339: The killing rate consistency theorem (see {prf:ref}`thm-killing-rate-consistency`) provides the final piece needed to justify our mean-field model. Combined with the standard kinetic theory arguments for the transport operator $L^\\dagger$ from the kinetic generator (see {prf:ref}`def-kinetic-generator`) and the Law of Large Numbers for the cloning operators (Section 2.3), we obtain:\n1340: \n1341: :::{prf:theorem} Mean-Field Limit (Informal Statement)\n1342: :label: thm-mean-field-limit-informal\n1343: \n1344: Let $(X_i^\\tau(t), V_i^\\tau(t))_{i=1}^N$ be the $N$-particle discrete Fragile Gas dynamics (see {prf:ref}`def-baoab-update-rule` for the kinetic integrator) with timestep $\\tau$, and let:\n1345: \n1346: $$\n1347: f_N^\\tau(t, x, v) := \\frac{1}{N} \\sum_{i=1}^N \\delta(x - X_i^\\tau(t), v - V_i^\\tau(t))\n1348: $$\n1349: \n1350: be the empirical density. Then, in the joint limit $N \\to \\infty, \\tau \\to 0$ with $\\tau = O(N^{-\\alpha})$ for $\\alpha > 0$:\n1351: \n1352: $$\n1353: f_N^\\tau(t, \\cdot, \\cdot) \\xrightarrow{\\text{weak}} f(t, \\cdot, \\cdot)\n1354: $$\n1355: ",
    "document_id": "07_mean_field",
    "section": "## 4. Analysis and Properties of the Mean-Field Equations",
    "span": {
      "start_line": 1339,
      "end_line": 1355,
      "content_start": 1342,
      "content_end": 1354,
      "header_lines": [
        1340
      ]
    },
    "references": [
      "def-baoab-update-rule",
      "thm-mean-field-equation"
    ],
    "metadata": {
      "label": "thm-mean-field-limit-informal"
    },
    "registry_context": {
      "stage": "directives",
      "document_id": "07_mean_field",
      "chapter_index": 4,
      "chapter_file": "chapter_4.json",
      "section_id": "## 4. Analysis and Properties of the Mean-Field Equations"
    },
    "generated_at": "2025-11-10T12:23:04.034663+00:00",
    "alt_labels": []
  }
]