[
  {
    "label": "proof-prop-barrier-existence",
    "proves": "prop-barrier-existence",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof constructs the barrier function φ explicitly using the signed distance function ρ to the boundary, ensured smooth by the Tubular Neighborhood Theorem, and a smooth non-increasing cutoff function ψ built from a mollifier; it then verifies smoothness, strict positivity via case analysis, and boundary divergence directly from the form of φ near the boundary.",
    "conclusion": {
      "text": "We have constructed a function φ: X_valid → (0, ∞) satisfying all three properties: φ ∈ C^∞(X_valid), φ(x) > 0 everywhere, and φ(x) → ∞ as x → ∂X_valid.",
      "latex": "We have constructed a function $\\varphi: \\mathcal{X}_{\\text{valid}} \\to (0, \\infty)$ satisfying all three properties: $\\varphi \\in C^{\\infty}(\\mathcal{X}_{\\text{valid}})$, $\\varphi(x) > 0$ everywhere, and $\\varphi(x) \\to \\infty$ as $x \\to \\partial \\mathcal{X}_{\\text{valid}}$."
    },
    "assumptions": [
      {
        "text": "The boundary ∂X_valid is a C^∞ compact manifold without boundary embedded in R^d.",
        "latex": "$\\partial \\mathcal{X}_{\\text{valid}}$ is a $C^{\\infty}$ compact manifold without boundary embedded in $\\mathbb{R}^d$."
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "construction",
        "text": "Define the signed distance function ρ using the Tubular Neighborhood Theorem, which ensures a smooth tubular neighborhood U where ρ is C^∞-smooth.",
        "latex": null,
        "references": [
          "thm-tubular-neighborhood"
        ],
        "derived_statement": "ρ(x) > 0 for x in X_valid ∩ U, with ∇ρ as the outward unit normal."
      },
      {
        "order": 2,
        "kind": "construction",
        "text": "Construct the smooth non-increasing cutoff function ψ: R → [0,1] using a mollifier η, satisfying ψ(t)=1 for t≤1, ψ(t)=0 for t≥2, and ψ'(t)<0 on (1,2).",
        "latex": null,
        "references": [
          "thm-mollifier-rudin"
        ],
        "derived_statement": "ψ is C^∞ and non-increasing."
      },
      {
        "order": 3,
        "kind": "construction",
        "text": "Fix δ < δ_0/3 and define the barrier φ(x) = 1/δ + ψ(ρ(x)/δ) (1/ρ(x) - 1/δ) on X_valid.",
        "latex": null,
        "references": [],
        "derived_statement": "φ: X_valid → (0,∞)."
      },
      {
        "order": 4,
        "kind": "verification",
        "text": "Verify smoothness: ρ and 1/ρ are C^∞ on X_valid, ψ∘(ρ/δ) is C^∞, and φ is constant (hence smooth) where ρ≥3δ, with smooth matching at the transition.",
        "latex": null,
        "references": [],
        "derived_statement": "φ ∈ C^∞(X_valid)."
      },
      {
        "order": 5,
        "kind": "verification",
        "text": "Verify boundary divergence: As x→∂X_valid, ρ(x)→0^+, so for ρ(x)<δ, φ(x)=1/ρ(x)→∞.",
        "latex": null,
        "references": [],
        "derived_statement": "φ(x)→∞ as x→∂X_valid."
      },
      {
        "order": 6,
        "kind": "verification",
        "text": "Verify strict positivity by case analysis on ρ(x).",
        "latex": null,
        "references": [],
        "derived_statement": "φ(x)>0 for all x in X_valid."
      }
    ],
    "key_equations": [
      {
        "label": "eq-signed-distance",
        "latex": "\\rho(x) := \\begin{cases} d(x, \\partial \\mathcal{X}_{\\text{valid}}) & \\text{if } x \\in \\mathcal{X}_{\\text{valid}} \\\\ -d(x, \\partial \\mathcal{X}_{\\text{valid}}) & \\text{if } x \\notin \\mathcal{X}_{\\text{valid}} \\end{cases}",
        "role": "Defines the signed distance function ρ."
      },
      {
        "label": "eq-mollifier",
        "latex": "\\eta(t) := \\begin{cases} \\exp\\left(-\\frac{1}{1-t^2}\\right) & \\text{if } |t| < 1 \\\\ 0 & \\text{if } |t| \\geq 1 \\end{cases}",
        "role": "Standard mollifier used to build the cutoff."
      },
      {
        "label": "eq-cutoff",
        "latex": "\\psi(t) := \\frac{\\int_{t}^{\\infty} \\eta(2s - 3) \\, ds}{\\int_{-\\infty}^{\\infty} \\eta(2s - 3) \\, ds}",
        "role": "Defines the smooth cutoff function ψ."
      },
      {
        "label": "eq-barrier",
        "latex": "\\varphi(x) := \\frac{1}{\\delta} + \\psi\\left(\\frac{\\rho(x)}{\\delta}\\right)\\left( \\frac{1}{\\rho(x)} - \\frac{1}{\\delta} \\right)",
        "role": "Explicit construction of the barrier function φ."
      },
      {
        "label": "eq-positivity-rewrite",
        "latex": "\\varphi(x) = \\frac{1}{\\delta}\\left(1 - \\psi\\left(\\frac{\\rho(x)}{\\delta}\\right)\\right) + \\frac{1}{\\rho(x)} \\psi\\left(\\frac{\\rho(x)}{\\delta}\\right)",
        "role": "Rewritten form used to show positivity in the transition case."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Signed Distance Function",
        "field": "Differential Geometry",
        "description": "Measures the signed Euclidean distance to a boundary manifold, positive inside and negative outside.",
        "roleInProof": "Serves as the base for defining the barrier's behavior near the boundary, capturing distance to ∂X_valid.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Tubular Neighborhood Theorem"
        ]
      },
      {
        "toolName": "Tubular Neighborhood Theorem",
        "field": "Differential Geometry",
        "description": "Asserts the existence of a neighborhood around a smooth submanifold where a smooth projection retraction exists, enabling smooth distance functions.",
        "roleInProof": "Justifies the C^∞ smoothness of the signed distance function ρ in a tubular neighborhood of the boundary.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Signed Distance Function"
        ]
      },
      {
        "toolName": "Mollifier",
        "field": "Real Analysis",
        "description": "A smooth non-negative function with compact support used to construct smooth approximations and cutoffs.",
        "roleInProof": "Used to explicitly construct the smooth non-increasing cutoff function ψ that transitions the barrier from 1/ρ to a constant.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Near boundary: 0 < ρ(x) ≤ δ",
        "condition": "0 < \\rho(x) \\leq \\delta",
        "summary": "ψ(ρ(x)/δ) = 1, so φ(x) = 1/ρ(x) > 0."
      },
      {
        "name": "Far interior: ρ(x) ≥ 2δ",
        "condition": "\\rho(x) \\geq 2\\delta",
        "summary": "ψ(ρ(x)/δ) = 0, so φ(x) = 1/δ > 0."
      },
      {
        "name": "Transition: δ < ρ(x) < 2δ",
        "condition": "\\delta < \\rho(x) < 2\\delta",
        "summary": "ψ(ρ(x)/δ) ∈ (0,1), and φ(x) is a convex combination of positive terms 1/δ and 1/ρ(x), hence > 0."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The choice of δ < δ_0/3 ensures all constructions stay within the smooth tubular neighborhood U."
      },
      {
        "type": "reference",
        "text": "Relies on standard results from differential geometry and analysis for smoothness guarantees."
      }
    ],
    "gaps": [],
    "tags": [
      "barrier-function",
      "signed-distance",
      "smooth-cutoff",
      "tubular-neighborhood",
      "mollifier",
      "smoothness",
      "positivity",
      "boundary-divergence",
      "constructive"
    ]
  },
  {
    "label": "proof-lem-wasserstein-decomposition",
    "proves": "lem-wasserstein-decomposition",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof decomposes the hypocoercive Wasserstein distance by expressing the cost as a quadratic form, centering the measures around their barycenters, expanding the form to separate barycenter and centered components, and showing the cross-term integrates to zero over any coupling, yielding the sum of local and structural terms.",
    "conclusion": {
      "text": "W_h^2(μ_1, μ_2) = V_loc + V_struct",
      "latex": "W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}"
    },
    "assumptions": [
      {
        "text": "The measures μ_1 and μ_2 have finite second moments",
        "latex": null
      },
      {
        "text": "The cost function is quadratic in the phase space differences",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "setup",
        "text": "Introduce notation for phase space, empirical measures over alive walkers, and the hypocoercive cost function as a quadratic form q(Δz).",
        "latex": "c(z_1, z_2) = q(z_1 - z_2) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b \\langle \\Delta x, \\Delta v \\rangle",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "definition",
        "text": "Define barycenters \\bar{z}_k and centered measures \\tilde{μ}_k by subtracting the barycenter from each point.",
        "latex": "\\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{z_{k,i}} \\quad \\delta_{z_{k,i}} = z_{k,i} - \\bar{z}_k",
        "references": [],
        "derived_statement": "Barycenters and centered measures have zero mean."
      },
      {
        "order": 3,
        "kind": "decomposition",
        "text": "Decompose z_1 - z_2 = \\delta_{z_1} - \\delta_{z_2} + \\Delta \\bar{z} for the difference in the quadratic form.",
        "latex": "z_1 - z_2 = \\delta_{z_1} - \\delta_{z_2} + \\Delta \\bar{z}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "expansion",
        "text": "Expand q(z_1 - z_2) = q(\\delta_{z_1} - \\delta_{z_2}) + q(\\Delta \\bar{z}) + 2 \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta \\bar{z} \\rangle_q and integrate over the coupling γ.",
        "latex": "\\int q(z_1 - z_2) d\\gamma = \\int q(\\delta_{z_1} - \\delta_{z_2}) d\\gamma + q(\\Delta \\bar{z}) + 2 \\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta \\bar{z} \\rangle_q d\\gamma",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "vanishing",
        "text": "Show the cross-term integrates to zero because the marginal integrals of the centered coordinates are zero.",
        "latex": "\\int \\delta_{z_1} d\\gamma = 0, \\quad \\int \\delta_{z_2} d\\gamma = 0",
        "references": [],
        "derived_statement": "Cross-term vanishes for any coupling."
      },
      {
        "order": 6,
        "kind": "identification",
        "text": "Identify q(\\Delta \\bar{z}) = V_loc and the remaining integral as the cost for the induced coupling on centered measures, equal to V_struct.",
        "latex": "\\int q(\\delta_{z_1} - \\delta_{z_2}) d\\gamma = \\int q(\\delta_{z_1}' - \\delta_{z_2}') d\\tilde{\\gamma}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "infimum",
        "text": "Take infimum over couplings to get W_h^2(μ_1, μ_2) = V_loc + inf over centered couplings = V_loc + V_struct.",
        "latex": "W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + \\inf_{\\tilde{\\gamma}} \\int c(\\delta_{z_1}, \\delta_{z_2}) d\\tilde{\\gamma} = V_{\\text{loc}} + V_{\\text{struct}}",
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-cost",
        "latex": "c(z_1, z_2) = \\|x_1 - x_2\\|^2 + \\lambda_v \\|v_1 - v_2\\|^2 + b \\langle x_1 - x_2, v_1 - v_2 \\rangle",
        "role": "Defines the hypocoercive cost function."
      },
      {
        "label": "eq-barycenter",
        "latex": "\\bar{z}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} z_{k,i}",
        "role": "Barycenter computation for empirical measures."
      },
      {
        "label": "eq-centered",
        "latex": "\\delta_{z_{k,i}} = z_{k,i} - \\bar{z}_k",
        "role": "Centering the points to form zero-mean measures."
      },
      {
        "label": "eq-decomp-diff",
        "latex": "z_1 - z_2 = \\delta_{z_1} - \\delta_{z_2} + \\Delta \\bar{z}",
        "role": "Decomposition of the difference vector."
      },
      {
        "label": "eq-q-expansion",
        "latex": "q(z_1 - z_2) = q(\\delta_{z_1} - \\delta_{z_2}) + q(\\Delta \\bar{z}) + 2 \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta \\bar{z} \\rangle_q",
        "role": "Expansion of the quadratic form."
      },
      {
        "label": "eq-cross-zero",
        "latex": "\\int \\langle \\delta_{z_1} - \\delta_{z_2}, \\Delta \\bar{z} \\rangle_q d\\gamma = 0",
        "role": "Vanishing of the cross-term."
      },
      {
        "label": "eq-final-decomp",
        "latex": "W_h^2(\\mu_1, \\mu_2) = V_{\\text{loc}} + V_{\\text{struct}}",
        "role": "The main decomposition result."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Optimal Transport",
        "field": "Optimal Transport",
        "description": "Mathematical framework for comparing probability measures via minimal cost transport plans.",
        "roleInProof": "Defines the Wasserstein distance and optimal couplings used to decompose the total cost.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Wasserstein Distance",
          "Coupling"
        ]
      },
      {
        "toolName": "Quadratic Forms",
        "field": "Linear Algebra",
        "description": "Functions of the form q(x) = ⟦x, Ax⟦ where A is symmetric positive semi-definite.",
        "roleInProof": "Expresses the hypocoercive cost and enables expansion and integration of the transport cost.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Inner Product",
          "Bilinear Forms"
        ]
      },
      {
        "toolName": "Barycenters",
        "field": "Probability Theory",
        "description": "The mean or center of mass of a probability measure, generalizing the expectation.",
        "roleInProof": "Used to shift measures to centered versions, separating global shifts from local variations in the decomposition.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Empirical Measures",
          "Centering"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "introductory",
        "text": "This fundamental decomposition theorem for Wasserstein distances with quadratic costs is a consequence of the gluing lemma in optimal transport and the geometry of barycenters. We provide a complete proof adapted to the hypocoercive cost structure."
      },
      {
        "type": "concluding",
        "text": "This decomposition is exact and holds for any pair of measures with finite second moments and any quadratic cost function."
      }
    ],
    "gaps": [],
    "tags": [
      "wasserstein",
      "decomposition",
      "optimal-transport",
      "barycenters",
      "quadratic-form",
      "hypocoercive-cost",
      "coupling"
    ]
  },
  {
    "label": "proof-lem-sx-implies-variance",
    "proves": "lem-sx-implies-variance",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof first constructs a sub-optimal coupling to bound the squared Wasserstein distance V_x,struct by 2(Var_1(x) + Var_2(x)) using the triangle inequality and basic norm inequalities. It then uses the contrapositive to show that if both variances are at most R_spread²/4, then V_x,struct ≤ R_spread², implying the desired consequence.",
    "conclusion": {
      "text": "if $V_{\\text{x,struct}} > R^2_{\\text{spread}}$, then at least one swarm $k$ must have $\\text{Var}_k(x) > R^2_{\\text{spread}} / 4$.",
      "latex": "if $V_{\\text{x,struct}} > R^2_{\\text{spread}}$, then at least one swarm $k$ must have $\\text{Var}_k(x) > R^2_{\\text{spread}} / 4$."
    },
    "assumptions": [
      {
        "text": "The measures $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$ are centered empirical measures of alive walkers in swarms $S_1$ and $S_2$.",
        "latex": "$\\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{x,k,i}}$ where $\\delta_{x,k,i} = x_{k,i} - \\mu_{x,k}$ and $\\mu_{x,k}$ is the barycenter."
      },
      {
        "text": "The swarms have positive numbers of alive walkers $k_1, k_2 > 0$.",
        "latex": "$k_1 = |\\mathcal{A}(S_1)|$, $k_2 = |\\mathcal{A}(S_2)| > 0$."
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "Define centered empirical measures $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_2$.",
        "latex": "$\\tilde{\\mu}_k = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\delta_{\\delta_{x,k,i}}$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "definition",
        "text": "Define $V_{\\text{x,struct}} := W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2)$ as the squared Wasserstein-2 distance.",
        "latex": "$V_{\\text{x,struct}} := W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma(\\delta_{x,1}, \\delta_{x,2})$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "construction",
        "text": "Construct sub-optimal identity-plus-remainder coupling $\\gamma_{\\text{id}}$ for upper bounding the cost.",
        "latex": null,
        "references": [],
        "derived_statement": "Cost of $\\gamma_{\\text{id}}$ at most sum of average squared centered norms."
      },
      {
        "order": 4,
        "kind": "case",
        "text": "Case of equal sizes $k_1 = k_2 = k$: Use identity coupling and norm inequality.",
        "latex": "$\\frac{1}{k} \\sum_{i=1}^k \\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 \\leq 2\\text{Var}_1(x) + 2\\text{Var}_2(x)$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "case",
        "text": "Case of unequal sizes: Use triangle inequality $W_2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq \\sqrt{\\text{Var}_1(x)} + \\sqrt{\\text{Var}_2(x)}$, then square and bound.",
        "latex": "$W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq 2\\text{Var}_1(x) + 2\\text{Var}_2(x)$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 6,
        "kind": "conclusion",
        "text": "Thus, $V_{\\text{x,struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x))$ for any sizes.",
        "latex": "$V_{\\text{x,struct}} = W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x))$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "contrapositive",
        "text": "Assume $\\text{Var}_1(x) \\leq R^2_{\\text{spread}}/4$ and $\\text{Var}_2(x) \\leq R^2_{\\text{spread}}/4$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 8,
        "kind": "derivation",
        "text": "Then $V_{\\text{x,struct}} \\leq 2(R^2_{\\text{spread}}/4 + R^2_{\\text{spread}}/4) = R^2_{\\text{spread}}$.",
        "latex": "$V_{\\text{x,struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\leq R^2_{\\text{spread}}$",
        "references": [],
        "derived_statement": "Contrapositive holds, proving the implication."
      }
    ],
    "key_equations": [
      {
        "label": "eq-var-struct-def",
        "latex": "$V_{\\text{x,struct}} := W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) = \\inf_{\\gamma \\in \\Gamma(\\tilde{\\mu}_1, \\tilde{\\mu}_2)} \\int \\|\\delta_{x,1} - \\delta_{x,2}\\|^2 \\, d\\gamma(\\delta_{x,1}, \\delta_{x,2})$",
        "role": "Definition of structural variance"
      },
      {
        "label": "eq-norm-ineq",
        "latex": "$\\|\\delta_{x,1,i} - \\delta_{x,2,i}\\|^2 \\leq 2\\|\\delta_{x,1,i}\\|^2 + 2\\|\\delta_{x,2,i}\\|^2$",
        "role": "Key inequality for bounding coupling cost"
      },
      {
        "label": "eq-w2-bound",
        "latex": "$W_2^2(\\tilde{\\mu}_1, \\tilde{\\mu}_2) \\leq 2\\text{Var}_1(x) + 2\\text{Var}_2(x)$",
        "role": "Main upper bound on Wasserstein distance"
      },
      {
        "label": "eq-contrap",
        "latex": "$V_{\\text{x,struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\leq R^2_{\\text{spread}}$",
        "role": "Contrapositive derivation"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Wasserstein-2 distance",
        "field": "Optimal Transport",
        "description": "The 2-Wasserstein distance between two probability measures is the square root of the infimum over couplings of the expected squared Euclidean distance between points.",
        "roleInProof": "Defines the structural variance V_x,struct and is bounded using triangle inequality to relate it to internal variances.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Coupling"
        ]
      },
      {
        "toolName": "Optimal Coupling",
        "field": "Probability Theory",
        "description": "A coupling is a joint distribution with given marginals; the optimal one minimizes the transport cost for Wasserstein distance.",
        "roleInProof": "A sub-optimal identity-plus-remainder coupling is constructed to upper-bound the Wasserstein distance cost.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Wasserstein-2 distance"
        ]
      },
      {
        "toolName": "Triangle Inequality",
        "field": "Metric Spaces",
        "description": "For any metric space, d(x,z) ≤ d(x,y) + d(y,z); extends to Wasserstein distances.",
        "roleInProof": "Applied to bound W_2(μ1, μ2) ≤ W_2(μ1, δ_0) + W_2(δ_0, μ2), where δ_0 is the Dirac at the origin.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Wasserstein-2 distance"
        ]
      },
      {
        "toolName": "Norm Inequality",
        "field": "Linear Algebra",
        "description": "The inequality ||a - b||² ≤ 2||a||² + 2||b||² holds for Euclidean norms.",
        "roleInProof": "Used to bound the cost of the identity coupling by twice the sum of variances.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Equal swarm sizes",
        "condition": "$k_1 = k_2 = k$",
        "summary": "Identity coupling cost bounded using norm inequality."
      },
      {
        "name": "Unequal swarm sizes",
        "condition": "$k_1 \\neq k_2$",
        "summary": "Triangle inequality on Wasserstein distances to bound the cost."
      }
    ],
    "remarks": [],
    "gaps": [],
    "tags": [
      "wasserstein-distance",
      "variance",
      "coupling",
      "contrapositive",
      "optimal-transport",
      "triangle-inequality"
    ]
  },
  {
    "label": "proof-lem-V-coercive",
    "proves": "lem-V-coercive",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof first establishes positive-definiteness of a general hypocoercive quadratic form using Sylvester's criterion and eigenvalue analysis under the condition \\(b^2 < 4\\lambda_v\\), deriving a coercivity constant. It then applies this result directly to the location component \\(V_{\\text{loc}}\\) and to the structural component \\(V_{\\text{struct}}\\) via the definition of hypocoercive Wasserstein distance, yielding the desired bounds.",
    "conclusion": {},
    "assumptions": [],
    "steps": [],
    "key_equations": [
      {
        "label": "eq-q-form",
        "latex": "q(\\Delta x, \\Delta v) = \\|\\Delta x\\|^2 + \\lambda_v \\|\\Delta v\\|^2 + b\\langle \\Delta x, \\Delta v \\rangle",
        "role": "Definition of the general hypocoercive quadratic form"
      },
      {
        "label": "eq-Q-matrix",
        "latex": "\\begin{pmatrix} I_d & \\frac{b}{2} I_d \\\\ \\frac{b}{2} I_d & \\lambda_v I_d \\end{pmatrix}",
        "role": "Block matrix representation of the quadratic form"
      },
      {
        "label": "eq-Q-scalar",
        "latex": "\\begin{pmatrix} 1 & b/2 \\\\ b/2 & \\lambda_v \\end{pmatrix}",
        "role": "Scalar reduction for eigenvalue analysis"
      },
      {
        "label": "eq-det-condition",
        "latex": "\\lambda_v - \\frac{b^2}{4} > 0",
        "role": "Sylvester's determinant condition for positive-definiteness"
      },
      {
        "label": "eq-eigenvalues",
        "latex": "\\lambda_{\\pm} = \\frac{1 + \\lambda_v \\pm \\sqrt{(1 - \\lambda_v)^2 + b^2}}{2}",
        "role": "Explicit eigenvalues providing coercivity constant"
      },
      {
        "label": "eq-V-loc",
        "latex": "V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle \\Delta\\mu_x, \\Delta\\mu_v \\rangle",
        "role": "Location component matching the general form"
      },
      {
        "label": "eq-V-struct",
        "latex": "V_{\\text{struct}} = \\inf_{\\gamma} \\int q(\\delta_{x,1} - \\delta_{x,2}, \\delta_{v,1} - \\delta_{v,2}) \\, d\\gamma",
        "role": "Structural component as hypocoercive Wasserstein distance"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Sylvester's criterion",
        "field": "Linear Algebra",
        "description": "A method to determine if a symmetric matrix is positive-definite by checking that all leading principal minors are positive.",
        "roleInProof": "Applied to verify positive-definiteness of the matrix associated with the hypocoercive quadratic form.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Eigenvalue analysis"
        ]
      },
      {
        "toolName": "Eigenvalue analysis",
        "field": "Linear Algebra",
        "description": "Computation and bounding of eigenvalues to assess the definiteness and coercivity of quadratic forms via their matrix representations.",
        "roleInProof": "Used to explicitly bound the smallest eigenvalue, providing the coercivity constant for the quadratic form.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Sylvester's criterion"
        ]
      },
      {
        "toolName": "Wasserstein distance",
        "field": "Optimal Transport",
        "description": "A metric on probability measures defined as the infimum of the expected cost under optimal couplings, here with a hypocoercive quadratic cost.",
        "roleInProof": "Applied to bound the structural component \\(V_{\text{struct}}\\) by relating the hypocoercive version to the standard \\(W_2\\) distance.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Optimal coupling"
        ]
      }
    ],
    "cases": [
      {
        "name": "General hypocoercive quadratic form",
        "condition": "b^2 < 4\\lambda_v",
        "summary": "Prove positive-definiteness via matrix representation, Sylvester's criterion, and eigenvalue bounds."
      },
      {
        "name": "Location component V_loc",
        "condition": "Same as general case",
        "summary": "Direct application of the general coercivity to V_loc."
      },
      {
        "name": "Structural component V_struct",
        "condition": "Same as general case",
        "summary": "Bound via infimum over couplings and relation to standard W_2 distance on centered empirical measures."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The proof assumes the measures are centered empirical measures, and the infimum over permutations provides a lower bound suitable for the lemma."
      }
    ],
    "gaps": [],
    "tags": [
      "coercivity",
      "hypocoercive",
      "quadratic form",
      "positive-definite",
      "Sylvester criterion",
      "eigenvalue analysis",
      "Wasserstein distance",
      "empirical measures"
    ]
  },
  {
    "label": "proof-lem-greedy-preserves-signal",
    "proves": "lem-greedy-preserves-signal",
    "proof_type": "probabilistic",
    "proof_status": "complete",
    "strategy_summary": "The proof derives history-independent probabilistic bounds on expected pairing distances using conditional expectations and softmax probabilities, exploiting geometric separation properties of high- and low-error walker sets to ensure the greedy algorithm preserves detectable signals from the partition structure.",
    "conclusion": {
      "text": "This completes the proof that the greedy pairing algorithm reliably detects the geometric partition structure.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Geometric separation constants $D_H(\\epsilon)$ and $R_L(\\epsilon)$ are N-uniform from Chapter 6.",
        "latex": null
      },
      {
        "text": "Low-error set fraction $|L_k|/k \\geq f_L > 1/2$ is N-uniform.",
        "latex": null
      },
      {
        "text": "Local cluster size $|C_j| \\geq f_c k$ with $f_c > 1/2$ (typically $\\geq 2/3$) is N-uniform for low-error walkers.",
        "latex": null
      },
      {
        "text": "$D_{\\text{valid}}$ is a fixed environmental parameter and $\\epsilon_d$ is a fixed algorithmic parameter.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "framework",
        "text": "Introduce the sequential greedy pairing process with conditional probabilities using softmax distribution and define conditional expected distances.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "insight",
        "text": "Highlight history-independence from geometric properties providing uniform bounds on conditional expectations.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "claim",
        "text": "For high-error walkers $i \\in H_k$, $\\mathbb{E}[d_i \\mid \\mathcal{S}_t, i \\in H_k] \\geq D_H(\\epsilon)$ (simplified from detailed claim).",
        "latex": null,
        "references": [
          "lem-geometric-separation-of-partition"
        ],
        "derived_statement": "$\\mathbb{E}[d_i \\mid U_t, i] \\geq D_H(\\epsilon) \\cdot \\mathbb{P}(c_i \\in U_L \\mid U_t, i)$"
      },
      {
        "order": 4,
        "kind": "step",
        "text": "Apply geometric bounds: distances to low-error walkers $\\geq D_H(\\epsilon)$, within high-error clusters $\\leq R_L(\\epsilon)$ (noted as deterministic).",
        "latex": null,
        "references": [
          "lem-geometric-separation-of-partition"
        ],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "step",
        "text": "Decompose conditional expectation over $U_L$ and $U_H$, lower-bounding by $D_H(\\epsilon)$ times probability of pairing with $U_L$.",
        "latex": null,
        "references": [],
        "derived_statement": "$\\mathbb{E}[d_i \\mid U_t, i] \\geq D_H(\\epsilon) \\cdot \\mathbb{P}(c_i \\in U_L \\mid U_t, i)$"
      },
      {
        "order": 6,
        "kind": "step",
        "text": "Ensure positive probability mass in $U_L$ due to $|L_k|/k \\geq f_L > 1/2$, yielding worst-case lower bound independent of $U_t$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "step",
        "text": "Average over pairing histories using law of total expectation to get unconditional bound $\\mathbb{E}[d_i \\mid \\mathcal{S}_t, i \\in H_k] \\geq D_H(\\epsilon)$, N-uniform.",
        "latex": null,
        "references": [],
        "derived_statement": "$\\mathbb{E}[d_i] = \\mathbb{E}_{U_t}[\\mathbb{E}[d_i \\mid U_t]] \\geq D_H(\\epsilon)$"
      },
      {
        "order": 8,
        "kind": "claim",
        "text": "For low-error walkers $j \\in L_k$, $\\mathbb{E}[d_j \\mid \\mathcal{S}_t, j \\in L_k] \\leq R_L(\\epsilon) + (D_{\\text{valid}} - R_L(\\epsilon)) \\cdot c_k \\exp\\left(-\\frac{[D_H(\\epsilon) - R_L(\\epsilon)]^2}{2\\epsilon_d^2}\\right)$.",
        "latex": null,
        "references": [
          "def-geometric-partition"
        ],
        "derived_statement": null
      },
      {
        "order": 9,
        "kind": "step",
        "text": "Geometric properties: local cluster $C_j$ with $|C_j| \\geq f_c k$, intra-cluster distances $\\leq R_L(\\epsilon)$, extra-cluster $\\geq D_H(\\epsilon)$.",
        "latex": null,
        "references": [
          "def-geometric-partition"
        ],
        "derived_statement": null
      },
      {
        "order": 10,
        "kind": "step",
        "text": "Bound surviving cluster members $|U_t \\cap C_j| \\geq k(f_c - 1) > 0$ in worst-case depletion.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 11,
        "kind": "step",
        "text": "Partition $U_t$ into $U_{\\text{in}}$ (intra-cluster) and $U_{\\text{out}}$ (extra-cluster).",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 12,
        "kind": "step",
        "text": "Lower-bound partition function $Z_j(U_t) \\geq |U_{\\text{in}}| \\exp(-R_L(\\epsilon)^2 / 2\\epsilon_d^2) \\geq k(f_c - 1) \\exp(-R_L(\\epsilon)^2 / 2\\epsilon_d^2)$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 13,
        "kind": "step",
        "text": "Upper-bound tail probability $\\mathbb{P}(c_j \\in U_{\\text{out}}) \\leq c_k \\exp(-[D_H(\\epsilon) - R_L(\\epsilon)]^2 / 2\\epsilon_d^2)$ with $c_k = 1/(f_c - 1)$.",
        "latex": null,
        "references": [],
        "derived_statement": "$p_{\\text{tail}} \\leq c_k \\exp(-\\frac{[D_H - R_L]^2}{2\\epsilon_d^2})$"
      },
      {
        "order": 14,
        "kind": "step",
        "text": "Bound conditional expectation $\\mathbb{E}[d_j \\mid U_t] \\leq R_L(\\epsilon) + (D_{\\text{valid}} - R_L(\\epsilon)) p_{\\text{tail}}$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 15,
        "kind": "step",
        "text": "Extend to unconditional bound via averaging over histories, all constants N-uniform.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-pairing-prob",
        "latex": "\\mathbb{P}(c_i = u \\mid U_t, i) = \\frac{\\exp\\left(-\\frac{d_{\\text{alg}}(i,u)^2}{2\\epsilon_d^2}\\right)}{\\sum_{l \\in U_t \\setminus \\{i\\}} \\exp\\left(-\\frac{d_{\\text{alg}}(i,l)^2}{2\\epsilon_d^2}\\right)} =: \\frac{w_{iu}}{Z_i(U_t)}",
        "role": "Defines the softmax pairing probability."
      },
      {
        "label": "eq-conditional-exp",
        "latex": "\\mathbb{E}[d_i \\mid U_t, i \\in U_t] = \\sum_{u \\in U_t \\setminus \\{i\\}} d_{\\text{alg}}(i, u) \\cdot \\mathbb{P}(c_i = u \\mid U_t, i)",
        "role": "Conditional expected distance for analysis."
      },
      {
        "label": "eq-high-lower",
        "latex": "\\mathbb{E}[d_i \\mid U_t, i] \\geq D_H(\\epsilon) \\cdot \\mathbb{P}(c_i \\in U_L \\mid U_t, i)",
        "role": "Lower bound decomposition for high-error walkers."
      },
      {
        "label": "eq-uncond-high",
        "latex": "\\mathbb{E}[d_i \\mid \\mathcal{S}_t, i \\in H_k] = \\mathbb{E}_{U_t}[\\mathbb{E}[d_i \\mid U_t]] \\geq D_H(\\epsilon)",
        "role": "Unconditional lower bound for high-error."
      },
      {
        "label": "eq-z-lower",
        "latex": "Z_j(U_t) \\geq |U_{\\text{in}}| \\exp\\left(-\\frac{R_L(\\epsilon)^2}{2\\epsilon_d^2}\\right) \\geq k(f_c - 1) \\exp\\left(-\\frac{R_L(\\epsilon)^2}{2\\epsilon_d^2}\\right)",
        "role": "Lower bound on partition function for low-error."
      },
      {
        "label": "eq-tail-prob",
        "latex": "\\mathbb{P}(c_j \\in U_{\\text{out}} \\mid U_t, j) \\leq c_k \\exp\\left(-\\frac{[D_H(\\epsilon) - R_L(\\epsilon)]^2}{2\\epsilon_d^2}\\right)",
        "role": "Upper bound on probability of distant pairing."
      },
      {
        "label": "eq-low-upper",
        "latex": "\\mathbb{E}[d_j \\mid U_t, j] \\leq R_L(\\epsilon) + [D_{\\text{valid}} - R_L(\\epsilon)] p_{\\text{tail}}",
        "role": "Conditional upper bound for low-error walkers."
      }
    ],
    "references": [
      "lem-geometric-separation-of-partition",
      "def-geometric-partition"
    ],
    "math_tools": [
      {
        "toolName": "Conditional Expectation",
        "field": "Probability Theory",
        "description": "The expected value of a random variable given partial information, used to compute averages over possible pairing outcomes.",
        "roleInProof": "Core tool for bounding expected distances at each stage of the sequential pairing process, enabling history-independent unconditional bounds.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Law of Total Expectation"
        ]
      },
      {
        "toolName": "Softmax Distribution",
        "field": "Probability and Machine Learning",
        "description": "A probability distribution derived from exponentials of negative squared distances, normalizing choices in the greedy pairing.",
        "roleInProof": "Defines the pairing probabilities in the algorithm, allowing decomposition of expectations into contributions from nearby and distant walkers.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Partition Function"
        ]
      },
      {
        "toolName": "Partition Function",
        "field": "Statistical Mechanics and Probability",
        "description": "The normalizing constant in the softmax, summing weighted exponentials over possible pairing options.",
        "roleInProof": "Facilitates bounding tail probabilities of pairing with distant walkers by lower-bounding contributions from local clusters.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Softmax Distribution"
        ]
      }
    ],
    "cases": [
      {
        "name": "High-Error Walkers",
        "condition": "$i \\in H_k$",
        "summary": "Lower bound on expected distance using separation to low-error set and positive probability mass."
      },
      {
        "name": "Low-Error Walkers",
        "condition": "$j \\in L_k$",
        "summary": "Upper bound on expected distance using local cluster survival and exponential tail decay for distant pairings."
      }
    ],
    "remarks": [
      {
        "type": "key-insight",
        "text": "Geometric properties provide uniform bounds on conditional expectations independent of pairing history."
      },
      {
        "type": "framework",
        "text": "Analysis relies on sequential stochastic process with softmax probabilities."
      },
      {
        "type": "n-uniform",
        "text": "All constants and bounds are N-uniform, relying on Chapter 6 results."
      }
    ],
    "gaps": [
      {
        "description": "Proof assumes verification against Chapter 6 geometric results for full self-containment; minor dependency on 'corrected' lemma.",
        "severity": "minor",
        "location_hint": "Introductory note and references"
      }
    ],
    "tags": [
      "greedy pairing",
      "probabilistic bounds",
      "geometric partition",
      "conditional expectations",
      "softmax distribution",
      "N-uniform constants"
    ]
  },
  {
    "label": "proof-lem-potential-bounds",
    "proves": "lem-potential-bounds",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof derives uniform lower and upper bounds for the multiplicative potential function V_i directly from the positivity and boundedness of its components (r'_i and d'_i) and the non-negative exponents alpha and beta, minimizing and maximizing the product at the component bounds.",
    "conclusion": {
      "text": "The multiplicative potential V_i satisfies V_{pot,min} <= V_i <= V_{pot,max}, where V_{pot,min} = eta^{alpha + beta} and V_{pot,max} = (g_{A,max} + eta)^{alpha + beta}, and these bounds are finite, positive, and state-independent.",
      "latex": "V_{\\text{pot,min}} \\leq V_i \\leq V_{\\text{pot,max}}"
    },
    "assumptions": [
      {
        "text": "The rescaling function g_A(z) has range (g_{A,min}, g_{A,max}] with g_{A,min} < g_{A,max}.",
        "latex": "g_A(z) \\in (g_{A,\\min}, g_{A,\\max}]"
      },
      {
        "text": "eta > 0 is a finite positive constant.",
        "latex": "\\eta > 0"
      },
      {
        "text": "Exponents alpha >= 0 and beta >= 0.",
        "latex": "\\alpha \\geq 0, \\beta \\geq 0"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "explanation",
        "text": "The rescaled components r'_i = g_A(z_{r,i}) + eta and d'_i = g_A(z_{d,i}) + eta are strictly positive and bounded in (g_{A,min} + eta, g_{A,max} + eta], using absolute bounds (eta, g_{A,max} + eta] for rigor.",
        "latex": null,
        "references": [],
        "derived_statement": "r'_i, d'_i \\in (\\eta, g_{A,\\max} + \\eta]"
      },
      {
        "order": 2,
        "kind": "derivation",
        "text": "Lower bound: V_i is minimized when components are minimal, yielding V_i >= eta^beta * eta^alpha = eta^{alpha + beta}. Thus, V_{pot,min} := eta^{alpha + beta}.",
        "latex": "V_i \\ge (\\eta)^{\\beta} \\cdot (\\eta)^{\\alpha} = \\eta^{\\alpha + \\beta}",
        "references": [],
        "derived_statement": "V_{\\text{pot,min}} := \\eta^{\\alpha + \\beta}"
      },
      {
        "order": 3,
        "kind": "derivation",
        "text": "Upper bound: V_i is maximized when components are maximal, yielding V_i <= (g_{A,max} + eta)^beta * (g_{A,max} + eta)^alpha = (g_{A,max} + eta)^{alpha + beta}. Thus, V_{pot,max} := (g_{A,max} + eta)^{alpha + beta}.",
        "latex": "V_i \\le (g_{A,\\max} + \\eta)^{\\beta} \\cdot (g_{A,\\max} + \\eta)^{\\alpha} = (g_{A,\\max} + \\eta)^{\\alpha + \\beta}",
        "references": [],
        "derived_statement": "V_{\\text{pot,max}} := (g_{A,\\max} + \\eta)^{\\alpha + \\beta}"
      },
      {
        "order": 4,
        "kind": "explanation",
        "text": "Uniformity: Since g_A is bounded and eta is finite positive, both bounds are finite, positive constants independent of state, swarm size N, or dynamics.",
        "latex": null,
        "references": [],
        "derived_statement": "Bounds are state-independent constants"
      }
    ],
    "key_equations": [
      {
        "label": "eq-lower-bound",
        "latex": "V_i \\ge (\\eta)^{\\beta} \\cdot (\\eta)^{\\alpha} = \\eta^{\\alpha + \\beta}",
        "role": "Derives the uniform lower bound V_{pot,min}"
      },
      {
        "label": "eq-upper-bound",
        "latex": "V_i \\le (g_{A,\\max} + \\eta)^{\\beta} \\cdot (g_{A,\\max} + \\eta)^{\\alpha} = (g_{A,\\max} + \\eta)^{\\alpha + \\beta}",
        "role": "Derives the uniform upper bound V_{pot,max}"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Bounded Functions",
        "field": "Real Analysis",
        "description": "Functions with values confined to a closed or open interval, allowing derivation of bounds on compositions and products.",
        "roleInProof": "Establishes the interval (eta, g_{A,max} + eta] for rescaled components to bound the potential.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Monotonicity"
        ]
      },
      {
        "toolName": "Monotonicity of Exponentiation",
        "field": "Algebra",
        "description": "For positive bases and non-negative exponents, the power function is non-decreasing, enabling min/max evaluation at endpoint bases.",
        "roleInProof": "Justifies that the potential is minimized/maximized when components are at their minimum/maximum values.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Bounded Functions"
        ]
      },
      {
        "toolName": "Product Rule for Bounds",
        "field": "Inequalities",
        "description": "For positive terms, the minimum/maximum of a product occurs at the product of minima/maxima when terms are independent.",
        "roleInProof": "Combines bounds on r'_i and d'_i to obtain overall bounds on V_i.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Monotonicity of Exponentiation"
        ]
      }
    ],
    "cases": [
      {
        "name": "Lower Bound",
        "condition": "Components at minimum value eta",
        "summary": "V_i minimized as product of minima raised to powers."
      },
      {
        "name": "Upper Bound",
        "condition": "Components at maximum value g_{A,max} + eta",
        "summary": "V_i maximized as product of maxima raised to powers."
      },
      {
        "name": "Uniformity",
        "condition": "Bounded g_A and eta > 0",
        "summary": "Bounds are finite, positive, and independent of state or parameters like N."
      }
    ],
    "remarks": [
      {
        "type": "uniformity",
        "text": "The bounds V_{pot,min} and V_{pot,max} are state-independent constants, facilitating analysis of swarm dynamics."
      }
    ],
    "gaps": [],
    "tags": [
      "potential bounds",
      "multiplicative potential",
      "uniform bounds",
      "bounded functions",
      "exponentiation",
      "swarm optimization"
    ]
  },
  {
    "label": "proof-prop-bounded-velocity-expansion",
    "proves": "prop-bounded-velocity-expansion",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes a bounded velocity domain using axioms and regularization, bounds per-walker variance changes via inelastic collision analysis and inequalities, decomposes the total variance change into direct resets, barycenter shifts, and status changes, and confirms the overall bound is state-independent relying on algorithmic parameters and domain properties.",
    "conclusion": {
      "text": "The one-step change in the velocity variance component Δ V_{Var,v} due to cloning is bounded by Δ V_{Var,v} ≤ f_{clone} · C_{reset} · V_{max,KE}, where C_{reset} and V_{max,KE} are state-independent constants.",
      "latex": "\\Delta V_{\\text{Var},v} \\leq f_{\\text{clone}} \\cdot C_{\\text{reset}} \\cdot V_{\\max,\\text{KE}}"
    },
    "assumptions": [
      {
        "text": "Compactness of the valid position domain \\mathcal{X}_{valid}.",
        "latex": "\\text{Compactness of } \\mathcal{X}_{\\text{valid}}"
      },
      {
        "text": "Lipschitz continuity of the drift field F(x) with ||F(x)|| ≤ F_{max}.",
        "latex": "\\|F(x)\\| \\leq F_{\\max} \\text{ for all } x \\in \\mathcal{X}_{\\text{valid}}"
      },
      {
        "text": "Presence of friction term -γ v in the kinetic operator.",
        "latex": "-\\gamma v"
      },
      {
        "text": "Velocity regularization via Axiom EG-4 with threshold V_{thresh} and coefficient c_{v_reg}.",
        "latex": "R(x_i, v_i) = R_{\\text{pos}}(x_i) - c_{v_{\\text{reg}}} \\|v_i\\|^2"
      },
      {
        "text": "Cloning fraction f_{clone} and restitution coefficient α_{restitution} are fixed parameters.",
        "latex": null
      },
      {
        "text": "Number of companion walkers M in cloning is fixed.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "part",
        "text": "Establish the domain of possible velocities using compactness, Lipschitz drift, friction, and regularization to bound ||v_i|| ≤ V_{max}.",
        "latex": "\\|v_i\\| \\leq V_{\\max}, \\quad V_{\\max}^2 := \\max\\left\\{ \\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2 \\right\\}",
        "references": [
          "axiom-eg-4",
          "axiom-lipschitz-drift"
        ],
        "derived_statement": "Velocities are state-independently bounded by V_{max}."
      },
      {
        "order": 2,
        "kind": "subpart",
        "text": "For a single cloned walker, bound the variance change Δ_i using triangle inequality.",
        "latex": "\\Delta_i \\leq 4V_{\\max}^2",
        "references": [],
        "derived_statement": "Per-walker variance change is bounded."
      },
      {
        "order": 2.1,
        "kind": "substep",
        "text": "Model the inelastic collision and bound the velocity change ||v_i^{new} - v_i^{old}||^2.",
        "latex": "\\|v_i^{\\text{new}} - v_i^{\\text{old}}\\|^2 \\leq (\\alpha_{\\text{restitution}}^2 + 1) \\|u_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}}^2 + 1) V_{\\max}^2",
        "references": [],
        "derived_statement": "Tighter bound on velocity perturbation from collision."
      },
      {
        "order": 3,
        "kind": "part",
        "text": "Decompose total Δ V_{Var,v} into direct reset, barycenter shift, and status changes.",
        "latex": null,
        "references": [
          "def-lyapunov-vvarv"
        ],
        "derived_statement": "Variance change decomposed into three bounded contributions."
      },
      {
        "order": 3.1,
        "kind": "substep",
        "text": "Bound direct reset contribution for cloned walkers.",
        "latex": "\\left| \\|v_i^{\\text{new}} - \\mu_v^{\\text{new}}\\|^2 - \\|v_i^{\\text{old}} - \\mu_v^{\\text{old}}\\|^2 \\right| \\leq 8(\\alpha_{\\text{restitution}}^2 + 2) V_{\\max}^2",
        "references": [],
        "derived_statement": "Direct reset bounded by O(V_{max}^2)."
      },
      {
        "order": 3.2,
        "kind": "substep",
        "text": "Bound barycenter shift effect on all walkers.",
        "latex": "\\|\\mu_v^{\\text{new}} - \\mu_v^{\\text{old}}\\| \\leq \\frac{n_{\\text{clone}}}{k_{\\text{alive}}} \\cdot 2V_{\\max}, \\quad \\text{contribution} \\leq \\frac{8n_{\\text{clone}}V_{\\max}^2}{N}",
        "references": [],
        "derived_statement": "Shift effect bounded by fraction of clones times V_{max}^2."
      },
      {
        "order": 3.3,
        "kind": "substep",
        "text": "Bound status changes (deaths and revivals).",
        "latex": "\\text{contribution} \\leq \\frac{4n_{\\text{clone}}V_{\\max}^2}{N}",
        "references": [],
        "derived_statement": "Status changes add at most O(n_{clone}/N V_{max}^2)."
      },
      {
        "order": 4,
        "kind": "part",
        "text": "Combine bounds and verify state-independence using regularization.",
        "latex": "|\\Delta V_{\\text{Var},v}| \\leq f_{\\text{clone}} \\cdot 8(\\alpha_{\\text{restitution}}^2 + 4) V_{\\max}^2",
        "references": [
          "axiom-eg-4"
        ],
        "derived_statement": "Total bound is state-independent."
      }
    ],
    "key_equations": [
      {
        "label": "eq-vmax",
        "latex": "V_{\\max}^2 := \\max\\left\\{ \\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2 \\right\\}",
        "role": "Defines the state-independent velocity bound."
      },
      {
        "label": "eq-delta-i",
        "latex": "\\Delta_i := \\|v_i^{\\text{new}} - \\mu_v^{\\text{new}}\\|^2 - \\|v_i^{\\text{old}} - \\mu_v^{\\text{old}}\\|^2",
        "role": "Per-walker variance change."
      },
      {
        "label": "eq-vcom",
        "latex": "V_{\\text{COM}} = \\frac{1}{M+1}\\left(v_i^{\\text{old}} + \\sum_{j=1}^M v_j^{\\text{comp}}\\right)",
        "role": "Center-of-mass velocity in cloning."
      },
      {
        "label": "eq-vnew",
        "latex": "v_i^{\\text{new}} = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R(u_i)",
        "role": "Post-collision velocity."
      },
      {
        "label": "eq-vchange",
        "latex": "\\|v_i^{\\text{new}} - v_i^{\\text{old}}\\|^2 \\leq 4(\\alpha_{\\text{restitution}}^2 + 1) V_{\\max}^2",
        "role": "Bound on velocity perturbation."
      },
      {
        "label": "eq-total-bound",
        "latex": "|\\Delta V_{\\text{Var},v}| \\leq \\frac{n_{\\text{clone}}}{N} \\cdot 8(\\alpha_{\\text{restitution}}^2 + 4) V_{\\max}^2",
        "role": "Combined bound before substituting f_{clone}."
      },
      {
        "label": "eq-conclusion",
        "latex": "\\Delta V_{\\text{Var},v} \\leq f_{\\text{clone}} \\cdot C_{\\text{reset}} \\cdot V_{\\max,\\text{KE}}",
        "role": "Final bounded change with constants."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Triangle Inequality",
        "field": "Analysis",
        "description": "A fundamental inequality for norms stating that the norm of a sum is at most the sum of norms.",
        "roleInProof": "Used repeatedly to bound differences in velocities, barycenters, and variance terms.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Cauchy-Schwarz Inequality"
        ]
      },
      {
        "toolName": "Center of Mass",
        "field": "Classical Mechanics",
        "description": "The average velocity of participating particles in a collision.",
        "roleInProof": "Defines the post-collision velocity in the inelastic cloning mechanism.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      },
      {
        "toolName": "Squared Norm Expansion",
        "field": "Linear Algebra",
        "description": "Decomposition of ||a - b||^2 = ||a||^2 - 2<a,b> + ||b||^2 for bounding variance changes.",
        "roleInProof": "Applied to analyze changes in individual and total variance contributions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Inner Product"
        ]
      },
      {
        "toolName": "Barycenter Shift Bound",
        "field": "Statistics",
        "description": "Bounding the change in mean due to updates in a subset of points.",
        "roleInProof": "Used to bound the effect of cloning on the global velocity mean.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Average"
        ]
      },
      {
        "toolName": "Velocity Regularization",
        "field": "Optimization",
        "description": "Penalty term in fitness to prevent excessive velocities.",
        "roleInProof": "Ensures state-independent velocity bounds via fitness feedback.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "L2 Regularization"
        ]
      }
    ],
    "cases": [
      {
        "name": "Part 1: Velocity Domain",
        "condition": "Compact domain and axioms",
        "summary": "Establishes ||v|| ≤ V_{max}."
      },
      {
        "name": "Part 2: Per-Walker Change",
        "condition": "Single cloning event",
        "summary": "Bounds Δ_i ≤ 4 V_{max}^2 using collisions."
      },
      {
        "name": "Part 3: Total Change Decomposition",
        "condition": "Cloning with n_{clone} walkers",
        "summary": "Bounds direct, shift, and status contributions."
      },
      {
        "name": "Part 4: State-Independence",
        "condition": "Regularization active",
        "summary": "Verifies constants depend only on parameters."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The bound is tight in the worst case but improved by restitution α < 1 and regularization preventing high velocities."
      },
      {
        "type": "claim",
        "text": "V_{max} is ensured by feedback in viable states with negligible extinction probability."
      }
    ],
    "gaps": [],
    "tags": [
      "velocity variance",
      "cloning",
      "bounded change",
      "state-independent",
      "inelastic collision",
      "Lyapunov function",
      "regularization",
      "triangle inequality"
    ]
  },
  {
    "label": "proof-lem-V_Varx-implies-variance",
    "proves": "lem-V_Varx-implies-variance",
    "proof_type": "contradiction",
    "proof_status": "complete",
    "strategy_summary": "The proof assumes the premise that the total intra-swarm positional error \\(V_{Var,x}\\) exceeds \\(R_{total\\_var,x}^2\\) and, for contradiction, assumes both swarms have intra-swarm errors at most half of that bound; it then derives that \\(V_{Var,x} \\leq R_{total\\_var,x}^2\\), contradicting the premise and establishing that at least one swarm must exceed the half-bound.",
    "conclusion": {
      "text": "The assumption that both intra-swarm variances are ≤ R_{total_var,x}^2 / 2 must be false, so at least one swarm has (1/N) ∑ ||δ_{x,k,i}||^2 > R_{total_var,x}^2 / 2.",
      "latex": null
    },
    "assumptions": [],
    "steps": [],
    "key_equations": [],
    "references": [],
    "math_tools": [
      {
        "toolName": "Proof by Contradiction",
        "field": "Mathematical Logic",
        "description": "A method where the negation of the statement to be proved is assumed true, and this leads to a logical inconsistency.",
        "roleInProof": "Structures the entire argument by assuming both intra-swarm variances are bounded and deriving a contradiction with the total variance premise.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Summation",
          "Inequality"
        ]
      },
      {
        "toolName": "Summation",
        "field": "Analysis",
        "description": "The operation of adding a sequence of terms, often used to aggregate errors or variances.",
        "roleInProof": "Used to express the total intra-swarm error as the sum of the two swarm contributions.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Inequality"
        ]
      },
      {
        "toolName": "Triangle Inequality (Bounded Sum)",
        "field": "Analysis",
        "description": "A principle bounding the sum of non-negative terms by the sum of their individual bounds.",
        "roleInProof": "Bounds the total variance by adding the assumed bounds on each swarm's contribution.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Summation"
        ]
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "proof",
      "contradiction",
      "variance",
      "swarms",
      "inequality",
      "positional error"
    ]
  },
  {
    "label": "proof-lem-phase-space-packing",
    "proves": "lem-phase-space-packing",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes pairwise identities linking hypocoercive variance to squared distances in position and velocity spaces, partitions pairs based on algorithmic distance into close and far sets, bounds the variance contributions from each partition using the assumption λ_v ≤ λ_alg, and inverts the inequality to derive an upper bound on the fraction of close pairs.",
    "conclusion": {
      "text": "f_{\\text{close}} < \\frac{D_{\\text{valid}}^2 - 2\\mathrm{Var}_h(S_k)}{D_{\\text{valid}}^2 - d_{\\text{close}}^2}",
      "latex": "f_{\\text{close}} < \\frac{D_{\\text{valid}}^2 - 2\\mathrm{Var}_h(S_k)}{D_{\\text{valid}}^2 - d_{\\text{close}}^2}"
    },
    "assumptions": [
      {
        "text": "λ_v ≤ λ_alg",
        "latex": "\\lambda_v \\le \\lambda_{\\text{alg}}"
      },
      {
        "text": "k ≥ 2",
        "latex": "k \\ge 2"
      },
      {
        "text": "d_close < D_valid",
        "latex": "d_{\\text{close}} < D_{\\text{valid}}"
      },
      {
        "text": "Var_h(S_k) > d_close^2 / 2 for g(Var_h) < 1",
        "latex": "\\mathrm{Var}_h(S_k) > \\frac{d_{\\text{close}}^2}{2}"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "identity-establishment",
        "text": "Establish pairwise identities for positional and velocity variances, then combine with λ_v to get the hypocoercive variance in terms of pairwise distances.",
        "latex": "2k^2 \\mathrm{Var}_h(S_k) = \\sum_{i,j} \\left( \\|x_i - x_j\\|^2 + \\lambda_v \\|v_i - v_j\\|^2 \\right)",
        "references": [],
        "derived_statement": "\\mathrm{Var}_h(S_k) = \\frac{1}{k^2} \\sum_{i<j} \\left( \\|x_i - x_j\\|^2 + \\lambda_v \\|v_i - v_j\\|^2 \\right)"
      },
      {
        "order": 2,
        "kind": "partitioning",
        "text": "Partition unique pairs into P_close (N_close pairs with d_alg(i,j) < d_close) and P_far (N_far pairs with d_alg(i,j) ≥ d_close).",
        "latex": null,
        "references": [],
        "derived_statement": "\\mathrm{Var}_h(S_k) = \\frac{1}{k^2} \\left( \\sum_{(i,j) \\in P_{\\text{close}}} (...) + \\sum_{(i,j) \\in P_{\\text{far}}} (...) \\right)"
      },
      {
        "order": 3,
        "kind": "bounding",
        "text": "Bound close pairs by d_close^2 using λ_v ≤ λ_alg, and far pairs by D_valid^2, leading to variance upper bound in terms of f_close.",
        "latex": "\\|x_i - x_j\\|^2 + \\lambda_v \\|v_i - v_j\\|^2 \\le d_{\\text{alg}}(i,j)^2 < d_{\\text{close}}^2 for close; \\le D_{\\text{valid}}^2 for far",
        "references": [],
        "derived_statement": "\\mathrm{Var}_h(S_k) \\le \\frac{k-1}{2k} \\left( f_{\\text{close}} (d_{\\text{close}}^2 - D_{\\text{valid}}^2) + D_{\\text{valid}}^2 \\right)"
      },
      {
        "order": 4,
        "kind": "inversion",
        "text": "Use (k-1)/(2k) < 1/2 to simplify, solve for f_close by inverting the inequality (reversing due to negative factor).",
        "latex": "f_{\\text{close}} < \\frac{D_{\\text{valid}}^2 - 2\\mathrm{Var}_h(S_k)}{D_{\\text{valid}}^2 - d_{\\text{close}}^2}",
        "references": [],
        "derived_statement": "f_{\\text{close}} \\le g(\\mathrm{Var}_h(S_k)) where g is affine decreasing, and g < 1 when \\mathrm{Var}_h > d_{\\text{close}}^2 / 2"
      }
    ],
    "key_equations": [
      {
        "label": "eq-var-x-identity",
        "latex": "2k^2 \\mathrm{Var}_x(S_k) = \\sum_{i=1}^k \\sum_{j=1}^k \\|x_i - x_j\\|^2",
        "role": "Positional variance pairwise identity"
      },
      {
        "label": "eq-var-v-identity",
        "latex": "2k^2 \\mathrm{Var}_v(S_k) = \\sum_{i=1}^k \\sum_{j=1}^k \\|v_i - v_j\\|^2",
        "role": "Velocity variance pairwise identity"
      },
      {
        "label": "eq-var-h-identity",
        "latex": "\\mathrm{Var}_h(S_k) = \\frac{1}{k^2} \\sum_{i<j} \\left( \\|x_i - x_j\\|^2 + \\lambda_v \\|v_i - v_j\\|^2 \\right)",
        "role": "Hypocoercive variance in terms of pairs"
      },
      {
        "label": "eq-d-alg",
        "latex": "d_{\\text{alg}}(i,j)^2 = \\|x_i - x_j\\|^2 + \\lambda_{\\text{alg}} \\|v_i - v_j\\|^2",
        "role": "Definition of algorithmic distance"
      },
      {
        "label": "eq-var-h-bound",
        "latex": "\\mathrm{Var}_h(S_k) \\le \\frac{1}{k^2} \\left( N_{\\text{close}} \\cdot d_{\\text{close}}^2 + N_{\\text{far}} \\cdot D_{\\text{valid}}^2 \\right)",
        "role": "Variance bound after partitioning"
      },
      {
        "label": "eq-f-close-bound",
        "latex": "f_{\\text{close}} < \\frac{D_{\\text{valid}}^2 - 2\\mathrm{Var}_h(S_k)}{D_{\\text{valid}}^2 - d_{\\text{close}}^2}",
        "role": "Final upper bound on fraction of close pairs"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Variance Pairwise Expansion",
        "field": "Statistics",
        "description": "Identity expressing the variance of a set of points as the average of squared pairwise distances.",
        "roleInProof": "Used to relate hypocoercive variance to sums of squared position and velocity differences.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Euclidean Norm"
        ]
      },
      {
        "toolName": "Set Partitioning",
        "field": "Combinatorics",
        "description": "Dividing a collection into disjoint subsets based on a criterion, here algorithmic distance.",
        "roleInProof": "Partitions pairs into close and far sets to separately bound variance contributions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Binomial Coefficients"
        ]
      },
      {
        "toolName": "Linear Bounding",
        "field": "Analysis",
        "description": "Applying inequalities to bound linear combinations under monotonicity assumptions like λ_v ≤ λ_alg.",
        "roleInProof": "Bounds the hypocoercive terms for close and far pairs using domain diameters.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Triangle Inequality"
        ]
      },
      {
        "toolName": "Inequality Inversion",
        "field": "Algebra",
        "description": "Solving inequalities by isolating variables and reversing directions when dividing by negative quantities.",
        "roleInProof": "Inverts the variance bound to obtain the upper limit on the close pair fraction.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Close Pairs (P_close)",
        "condition": "d_alg(i,j) < d_close",
        "summary": "Bounded by d_close^2 using λ_v ≤ λ_alg"
      },
      {
        "name": "Far Pairs (P_far)",
        "condition": "d_alg(i,j) ≥ d_close",
        "summary": "Bounded by D_valid^2 = D_x^2 + λ_alg D_v^2"
      }
    ],
    "remarks": [
      {
        "type": "verification",
        "text": "g(Var_h) < 1 when Var_h > d_close^2 / 2, ensuring the bound is meaningful."
      }
    ],
    "gaps": [],
    "tags": [
      "phase-space",
      "packing-argument",
      "hypocoercivity",
      "variance-identities",
      "pairwise-distances",
      "algorithmic-distance",
      "bounding-inequalities"
    ]
  },
  {
    "label": "proof-lem-var-x-implies-var-h",
    "proves": "lem-var-x-implies-var-h",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes the inequality between hypocoercive variance and position variance using the definition and non-negativity properties, then directly applies it to the threshold condition.",
    "conclusion": {
      "text": "If $\\mathrm{Var}_x(S_k) > R^2_{\\text{var}}$, then $\\mathrm{Var}_h(S_k) > R^2_{\\text{var}}$.",
      "latex": "\\mathrm{Var}_h(S_k) \\ge \\mathrm{Var}_x(S_k) > R^2_{\\text{var}}"
    },
    "assumptions": [
      {
        "text": "$\\lambda_v > 0$",
        "latex": "\\lambda_v > 0"
      },
      {
        "text": "$\\mathrm{Var}_v(S_k) \\ge 0$",
        "latex": "\\mathrm{Var}_v(S_k) \\ge 0"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "By definition, the hypocoercive variance is $\\mathrm{Var}_h(S_k) := \\mathrm{Var}_x(S_k) + \\lambda_v \\mathrm{Var}_v(S_k)$",
        "latex": "\\mathrm{Var}_h(S_k) := \\mathrm{Var}_x(S_k) + \\lambda_v \\mathrm{Var}_v(S_k)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "inequality",
        "text": "Since $\\lambda_v > 0$ and $\\mathrm{Var}_v(S_k) \\ge 0$, it follows that $\\mathrm{Var}_h(S_k) \\ge \\mathrm{Var}_x(S_k)$",
        "latex": "\\mathrm{Var}_h(S_k) = \\mathrm{Var}_x(S_k) + \\lambda_v \\mathrm{Var}_v(S_k) \\ge \\mathrm{Var}_x(S_k)",
        "references": [],
        "derived_statement": "\\mathrm{Var}_h(S_k) \\ge \\mathrm{Var}_x(S_k)"
      },
      {
        "order": 3,
        "kind": "implication",
        "text": "Therefore, if $\\mathrm{Var}_x(S_k) > R^2_{\\text{var}}$, then $\\mathrm{Var}_h(S_k) > R^2_{\\text{var}}$",
        "latex": "\\mathrm{Var}_h(S_k) \\ge \\mathrm{Var}_x(S_k) > R^2_{\\text{var}}",
        "references": [],
        "derived_statement": "\\mathrm{Var}_h(S_k) > R^2_{\\text{var}}"
      }
    ],
    "key_equations": [
      {
        "label": "def-var-h",
        "latex": "\\mathrm{Var}_h(S_k) := \\mathrm{Var}_x(S_k) + \\lambda_v \\mathrm{Var}_v(S_k)",
        "role": "definition of hypocoercive variance"
      },
      {
        "label": "ineq-var-h-x",
        "latex": "\\mathrm{Var}_h(S_k) \\ge \\mathrm{Var}_x(S_k)",
        "role": "key inequality from non-negativity"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Variance",
        "field": "Probability",
        "description": "A measure of the dispersion of a random variable around its mean.",
        "roleInProof": "Used to define hypocoercive variance and leverage its non-negativity to derive the inequality Var_h >= Var_x.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "hypocoercivity",
      "variance",
      "inequality",
      "non-negativity"
    ]
  },
  {
    "label": "proof-lem-outlier-fraction-lower-bound",
    "proves": "lem-outlier-fraction-lower-bound",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof derives a lower bound on the fraction of outliers by lower-bounding the total hypocoercive norm sum over the outlier set using the swarm's variance and upper-bounding it via the maximum single-walker contribution times the outlier count, assuming large variance.",
    "conclusion": {
      "text": "The fraction of outliers satisfies \\frac{|O_k|}{k} > \\frac{(1-\\varepsilon_O) R^2_h}{D_h^2}, where f_O = (1-\\varepsilon_O) R^2_h / D_h^2 is a positive constant independent of the number of walkers.",
      "latex": "\\frac{|O_k|}{k} > \\frac{(1-\\varepsilon_O) R^2_h}{D_h^2}"
    },
    "assumptions": [
      {
        "text": "The valid domain \\mathcal{X}_{valid} is convex.",
        "latex": "\\mathcal{X}_{\\text{valid}} \\text{ is convex}"
      },
      {
        "text": "The hypocoercive variance satisfies \\mathrm{Var}_h(S_k) > R_h^2.",
        "latex": "\\mathrm{Var}_h(S_k) > R_h^2"
      },
      {
        "text": "Velocities are bounded by the velocity domain diameter D_v.",
        "latex": "\\|v_{k,i}\\| \\le D_v \\ \\forall i"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "recall",
        "text": "Recall the total hypocoercive sum T_k = \\sum_{j \\in \\mathcal{A}_k} (\\|\\delta_{x,k,j}\\|^2 + \\lambda_v \\|\\delta_{v,k,j}\\|^2) = k \\cdot \\mathrm{Var}_h(S_k), and the outlier property \\sum_{i \\in O_k} (\\|\\delta_{x,k,i}\\|^2 + \\lambda_v \\|\\delta_{v,k,i}\\|^2) \\ge (1-\\varepsilon_O) T_k.",
        "latex": "T_k = \\sum_{j \\in \\mathcal{A}_k} \\left(\\Vert\\delta_{x,k,j}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,j}\\Vert^2\\right) = k \\cdot \\mathrm{Var}_h(S_k) \\\\ \\sum_{i \\in O_k} \\left(\\Vert\\delta_{x,k,i}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,i}\\Vert^2\\right) \\ge (1-\\varepsilon_O) T_k = (1-\\varepsilon_O) k \\cdot \\mathrm{Var}_h(S_k)",
        "references": [
          "def-hypocoercive-variance",
          "def-global-kinematic-outlier-set"
        ],
        "derived_statement": "(1-\\varepsilon_O) k \\cdot \\mathrm{Var}_h(S_k) lower bound on outlier sum"
      },
      {
        "order": 2,
        "kind": "bound",
        "text": "For any walker i, \\|\\delta_{x,k,i}\\| \\le D_x and \\|\\delta_{v,k,i}\\| \\le D_v, so \\|\\delta_{x,k,i}\\|^2 + \\lambda_v \\|\\delta_{v,k,i}\\|^2 \\le D_h^2 = D_x^2 + \\lambda_v D_v^2.",
        "latex": "\\Vert\\delta_{x,k,i}\\Vert \\le D_x, \\ \\Vert\\delta_{v,k,i}\\Vert \\le D_v \\\\ \\Vert\\delta_{x,k,i}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,i}\\Vert^2 \\le D_x^2 + \\lambda_v D_v^2 = D_h^2",
        "references": [
          "def-valid-domain"
        ],
        "derived_statement": "Single-walker hypocoercive norm \\le D_h^2"
      },
      {
        "order": 3,
        "kind": "bound",
        "text": "Upper bound the outlier sum: \\sum_{i \\in O_k} (...) \\le |O_k| \\cdot D_h^2.",
        "latex": "\\sum_{i \\in O_k} \\left(\\Vert\\delta_{x,k,i}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,i}\\Vert^2\\right) \\le |O_k| \\cdot D_h^2",
        "references": [],
        "derived_statement": "Outlier sum \\le |O_k| D_h^2"
      },
      {
        "order": 4,
        "kind": "combine",
        "text": "Combine bounds: (1-\\varepsilon_O) k \\cdot \\mathrm{Var}_h(S_k) \\le |O_k| \\cdot D_h^2. With \\mathrm{Var}_h(S_k) > R_h^2, get (1-\\varepsilon_O) k R_h^2 < |O_k| D_h^2, so \\frac{|O_k|}{k} > \\frac{(1-\\varepsilon_O) R_h^2}{D_h^2}.",
        "latex": "(1-\\varepsilon_O) k \\cdot \\mathrm{Var}_h(S_k) \\le |O_k| \\cdot D_h^2 \\\\ (1-\\varepsilon_O) k R_h^2 < |O_k| D_h^2 \\\\ \\frac{|O_k|}{k} > \\frac{(1-\\varepsilon_O) R_h^2}{D_h^2}",
        "references": [],
        "derived_statement": "Lower bound on outlier fraction"
      }
    ],
    "key_equations": [
      {
        "label": "eq-T_k",
        "latex": "T_k = \\sum_{j \\in \\mathcal{A}_k} \\left(\\Vert\\delta_{x,k,j}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,j}\\Vert^2\\right) = k \\cdot \\mathrm{Var}_h(S_k)",
        "role": "Total hypocoercive variance sum"
      },
      {
        "label": "eq-outlier-lower",
        "latex": "\\sum_{i \\in O_k} \\left(\\Vert\\delta_{x,k,i}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,i}\\Vert^2\\right) \\ge (1-\\varepsilon_O) T_k",
        "role": "Lower bound on outlier sum"
      },
      {
        "label": "eq-single-bound",
        "latex": "\\Vert\\delta_{x,k,i}\\Vert^2 + \\lambda_v \\Vert\\delta_{v,k,i}\\Vert^2 \\le D_h^2",
        "role": "Upper bound per walker"
      },
      {
        "label": "eq-outlier-upper",
        "latex": "\\sum_{i \\in O_k} (...) \\le |O_k| \\cdot D_h^2",
        "role": "Upper bound on outlier sum"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\frac{|O_k|}{k} > \\frac{(1-\\varepsilon_O) R_h^2}{D_h^2}",
        "role": "Lower bound on outlier fraction"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Hypocoercive norm",
        "field": "Dynamical Systems",
        "description": "A norm that weights positional and velocity deviations to capture hypocoercivity in phase space.",
        "roleInProof": "Used to measure individual and collective deviations in the swarm, enabling bounds on variance and outlier contributions.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Euclidean norm"
        ]
      },
      {
        "toolName": "Domain diameter",
        "field": "Geometry",
        "description": "The supremum of distances between points in a bounded domain, providing a uniform bound on deviations.",
        "roleInProof": "Establishes the upper bound D_h^2 on single-walker hypocoercive norms within the valid domain.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Euclidean norm"
        ]
      },
      {
        "toolName": "Population variance",
        "field": "Statistics",
        "description": "The average squared deviation from the mean, here adapted to hypocoercive norms in phase space.",
        "roleInProof": "Links the total hypocoercive dispersion T_k to k * Var_h(S_k), forming the lower bound on the outlier sum.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Hypocoercive norm"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The bound f_O is independent of the total number of walkers N and depends only on fixed parameters like ε_O, R_h, and domain diameters."
      }
    ],
    "gaps": [],
    "tags": [
      "hypocoercivity",
      "variance",
      "outliers",
      "lower bound",
      "phase space",
      "geometric bound",
      "swarm dynamics"
    ]
  },
  {
    "label": "proof-lem-outlier-cluster-fraction-lower-bound",
    "proves": "lem-outlier-cluster-fraction-lower-bound",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof decomposes the total variance using the Law of Total Variance into within-cluster and between-cluster components, establishes an upper bound on within-cluster variance via cluster diameters, derives a lower bound on the weighted variance of cluster centers, and applies an outlier argument to these centers to obtain a positive lower bound on the fraction of walkers in outlier clusters.",
    "conclusion": {
      "text": "The fraction of walkers in the high-error set satisfies \\frac{|H_k(\\epsilon)|}{k} > f_H(\\varepsilon), where f_H(\\varepsilon) = \\frac{(1-\\varepsilon_O) \\left(R^2_{\\mathrm{var}} - (D_{\\mathrm{diam}}(\\epsilon)/2)^2\\right)}{D_{\\mathrm{valid}}^2} > 0 is an N-uniform constant.",
      "latex": "\\frac{|H_k(\\epsilon)|}{k} > \\frac{(1-\\varepsilon_O) \\left(R^2_{\\mathrm{var}} - \\left(\\frac{D_{\\mathrm{diam}}(\\epsilon)}{2}\\right)^2\\right)}{D_{\\mathrm{valid}}^2}"
    },
    "assumptions": [
      {
        "text": "The global variance satisfies \\mathrm{Var}_k(x) > R^2_{\\mathrm{var}}.",
        "latex": "\\mathrm{Var}_k(x) > R^2_{\\mathrm{var}}"
      },
      {
        "text": "Each cluster G_m has diameter at most D_{\\mathrm{diam}}(\\varepsilon), chosen small enough so that R^2_{\\mathrm{var}} - (D_{\\mathrm{diam}}(\\varepsilon)/2)^2 > 0.",
        "latex": "\\mathrm{diam}(G_m) \\le D_{\\mathrm{diam}}(\\varepsilon) \\quad \\text{and} \\quad R^2_{\\mathrm{var}} - \\left(\\frac{D_{\\mathrm{diam}}(\\varepsilon)}{2}\\right)^2 > 0"
      },
      {
        "text": "Cluster centers \\mu_m satisfy \\|\\mu_m - \\mu\\| \\le D_{\\mathrm{valid}}.",
        "latex": "\\|\\mu_m - \\mu\\| \\le D_{\\mathrm{valid}}"
      },
      {
        "text": "The high-error set H_k(\\varepsilon) is the union of outlier clusters O_M, where \\sum_{m \\in O_M} |G_m| \\|\\mu_m - \\mu\\|^2 \\ge (1 - \\varepsilon_O) \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2.",
        "latex": "\\sum_{m \\in O_M} |G_m| \\|\\mu_m - \\mu\\|^2 \\ge (1 - \\varepsilon_O) \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "decomposition",
        "text": "Apply the Law of Total Variance to decompose the total sum of squared deviations: k \\cdot \\mathrm{Var}_k(x) = \\sum_{m=1}^M |G_m| \\mathrm{Var}(G_m) + \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2.",
        "latex": "k \\cdot \\mathrm{Var}_k(x) = \\sum_{m=1}^M \\sum_{i \\in G_m} \\|x_i - \\mu\\|^2 = \\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) + \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2",
        "references": [],
        "derived_statement": "Total variance = within-cluster + between-cluster variance."
      },
      {
        "order": 2,
        "kind": "bound",
        "text": "Bound the within-cluster variance: \\mathrm{Var}(G_m) \\le (D_{\\mathrm{diam}}(\\varepsilon)/2)^2, so \\sum_{m=1}^M |G_m| \\mathrm{Var}(G_m) \\le k (D_{\\mathrm{diam}}(\\varepsilon)/2)^2.",
        "latex": "\\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) \\le k \\left(\\frac{D_{\\mathrm{diam}}(\\epsilon)}{2}\\right)^2",
        "references": [],
        "derived_statement": "Within-cluster sum of squares \\le k (D_{\\mathrm{diam}}(\\varepsilon)/2)^2."
      },
      {
        "order": 3,
        "kind": "lower-bound",
        "text": "Derive lower bound on between-cluster variance: \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2 > k R^2_{\\mathrm{var}} - k (D_{\\mathrm{diam}}(\\varepsilon)/2)^2 = k R^2_{\\mathrm{means}}, with R^2_{\\mathrm{means}} > 0.",
        "latex": "\\frac{1}{k} \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2 > R^2_{\\mathrm{means}} > 0 \\quad \\text{where} \\quad R^2_{\\mathrm{means}} = R^2_{\\mathrm{var}} - \\left(\\frac{D_{\\mathrm{diam}}(\\varepsilon)}{2}\\right)^2",
        "references": [],
        "derived_statement": "Weighted variance of cluster centers > R^2_{\\mathrm{means}} > 0."
      },
      {
        "order": 4,
        "kind": "application",
        "text": "Apply outlier argument to cluster centers: For outlier clusters O_M, \\sum_{m \\in O_M} |G_m| \\|\\mu_m - \\mu\\|^2 \\ge (1 - \\varepsilon_O) k R^2_{\\mathrm{means}}, and bound above by D^2_{\\mathrm{valid}} |H_k(\\varepsilon)|.",
        "latex": "(1 - \\varepsilon_O) k R^2_{\\mathrm{means}} < |H_k(\\varepsilon)| D^2_{\\mathrm{valid}}",
        "references": [
          "lem-outlier-fraction-lower-bound"
        ],
        "derived_statement": "Size of high-error set bounded below via outlier contribution."
      },
      {
        "order": 5,
        "kind": "conclusion",
        "text": "Rearrange to obtain the lower bound on the fraction: \\frac{|H_k(\\varepsilon)|}{k} > \\frac{(1 - \\varepsilon_O) R^2_{\\mathrm{means}}}{D^2_{\\mathrm{valid}}} = f_H(\\varepsilon) > 0.",
        "latex": "\\frac{|H_k(\\epsilon)|}{k} > \\frac{(1-\\varepsilon_O) R^2_{\\mathrm{means}}}{D_{\\mathrm{valid}}^2}",
        "references": [],
        "derived_statement": "N-uniform lower bound on high-error fraction established."
      }
    ],
    "key_equations": [
      {
        "label": "eq-total-variance-decomp",
        "latex": "k \\cdot \\mathrm{Var}_k(x) = \\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) + \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2",
        "role": "Decomposition of total variance into within and between components."
      },
      {
        "label": "eq-within-bound",
        "latex": "\\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) \\le k \\left(\\frac{D_{\\mathrm{diam}}(\\epsilon)}{2}\\right)^2",
        "role": "Upper bound on within-cluster sum of squares."
      },
      {
        "label": "eq-between-lower",
        "latex": "\\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2 > k \\left( R^2_{\\mathrm{var}} - \\left(\\frac{D_{\\mathrm{diam}}(\\epsilon)}{2}\\right)^2 \\right)",
        "role": "Lower bound on between-cluster sum of squares."
      },
      {
        "label": "eq-outlier-contribution",
        "latex": "\\sum_{m \\in O_M} |G_m| \\|\\mu_m - \\mu\\|^2 \\ge (1-\\varepsilon_O) \\sum_{m=1}^M |G_m| \\|\\mu_m - \\mu\\|^2 > (1-\\varepsilon_O) k R^2_{\\mathrm{means}}",
        "role": "Lower bound on outlier clusters' variance contribution."
      },
      {
        "label": "eq-final-inequality",
        "latex": "\\frac{|H_k(\\epsilon)|}{k} > \\frac{(1-\\varepsilon_O) \\left(R^2_{\\mathrm{var}} - (D_{\\mathrm{diam}}(\\epsilon)/2)^2\\right)}{D_{\\mathrm{valid}}^2}",
        "role": "Final lower bound on the high-error fraction."
      }
    ],
    "references": [
      "lem-outlier-fraction-lower-bound"
    ],
    "math_tools": [
      {
        "toolName": "Law of Total Variance",
        "field": "Statistics",
        "description": "Decomposes the total variance of a random variable into the expected variance within subpopulations plus the variance of the subpopulation means.",
        "roleInProof": "Used to separate the swarm's total variance into within-cluster and between-cluster sums of squares, enabling isolation of large between-cluster variance.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      },
      {
        "toolName": "Variance Bound by Diameter",
        "field": "Geometry",
        "description": "For a set of points with diameter D, the variance is at most (D/2)^2, achieved when points are at the extremes.",
        "roleInProof": "Provides a uniform upper bound on within-cluster variance based on the clustering algorithm's diameter guarantee.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      },
      {
        "toolName": "Outlier Detection via Weighted Variance",
        "field": "Statistics",
        "description": "Identifies a subset of weighted points (outliers) whose contribution to total weighted variance is at least a fixed fraction, bounded by maximum distance.",
        "roleInProof": "Applied to the weighted cluster centers to bound the size of the high-error set from below.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Law of Total Variance"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "uniformity",
        "text": "The bound f_H(\\varepsilon) is N-uniform, depending only on system parameters \\varepsilon_O, R^2_{\\mathrm{var}}, D_{\\mathrm{diam}}(\\varepsilon), D_{\\mathrm{valid}}."
      },
      {
        "type": "reference",
        "text": "The outlier argument in Step 4 mirrors the mean-field case from lem-outlier-fraction-lower-bound."
      }
    ],
    "gaps": [],
    "tags": [
      "variance decomposition",
      "law of total variance",
      "clustering",
      "outlier fraction",
      "constructive proof",
      "between-cluster variance",
      "N-uniform bound"
    ]
  },
  {
    "label": "proof-cor-vvarx-to-high-error-fraction",
    "proves": "cor-vvarx-to-high-error-fraction",
    "proof_type": "reference",
    "proof_status": "complete",
    "strategy_summary": "The proof chains implications from total positional variance to individual swarm variance, then to hypocoercive variance, and finally applies regime-specific lemmas from the epsilon-dichotomy to establish a uniform lower bound on the high-error fraction in at least one swarm.",
    "conclusion": {
      "text": "We have rigorously shown that for any ε > 0, if the total intra-swarm positional variance V_{Var,x} is sufficiently large, then at least one swarm k is guaranteed to have a large hypocoercive variance, which in turn guarantees that the fraction of alive walkers in its unified high-error set H_k(ε) is bounded below by the positive, N-uniform constant f_H(ε). This establishes the direct causal link from the Lyapunov function's positional variance component to the guaranteed existence of a substantial high-error population.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Total intra-swarm positional variance exceeds a threshold: V_{Var,x} > R^2_{total_var,x}",
        "latex": null
      },
      {
        "text": "Hypocoercive variance includes positional variance: Var_h(S_k) >= Var_x(S_k)",
        "latex": null
      },
      {
        "text": "ε > 0 is arbitrary",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "implication",
        "text": "From Total Positional Variance to Single-Swarm Positional Variance: By lem-V_Varx-implies-variance, if V_{Var,x} > R^2_{total_var,x}, then at least one swarm k has Var_x(S_k) > R^2_{total_var,x}/2. Define R^2_{var} := R^2_{total_var,x}/2.",
        "latex": "Var_x(S_k) > \\frac{R^2_{\\text{total_var},x}}{2}",
        "references": [
          "lem-V_Varx-implies-variance"
        ],
        "derived_statement": "Var_x(S_k) > R^2_{var}"
      },
      {
        "order": 2,
        "kind": "inequality",
        "text": "From Positional Variance to Hypocoercive Variance: Since Var_h(S_k) = Var_x(S_k) + λ_v Var_v(S_k) >= Var_x(S_k) by the bridging lemma, Var_x(S_k) > R^2_{var} implies Var_h(S_k) > R^2_{var}. This meets the premise for epsilon-dichotomy lemmas.",
        "latex": "Var_h(S_k) > R^2_{\\text{var}}",
        "references": [
          "bridging-lemma-section-6.4.2"
        ],
        "derived_statement": "Var_h(S_k) > R^2_{var}"
      },
      {
        "order": 3,
        "kind": "case-application",
        "text": "From Hypocoercive Variance to High-Error Fraction: With Var_h(S_k) > R^2_{var}, apply epsilon-dichotomy: In large-ε regime (ε > D_swarm), H_k(ε) = O_k and |H_k(ε)|/k >= f_O > 0 by lem-outlier-fraction-lower-bound. In small-ε regime (ε <= D_swarm), H_k(ε) = C_k(ε) and |H_k(ε)|/k >= f_{H,cluster}(ε) > 0 by lem-outlier-cluster-fraction-lower-bound.",
        "latex": null,
        "references": [
          "def-unified-high-low-error-sets",
          "lem-outlier-fraction-lower-bound",
          "lem-outlier-cluster-fraction-lower-bound"
        ],
        "derived_statement": "|H_k(ε)|/k >= f_H(ε) > 0 for some k"
      },
      {
        "order": 4,
        "kind": "unification",
        "text": "Define the Unified Lower Bound: f_H(ε) := min(f_O, f_{H,cluster}(ε)), which is positive and N-uniform since both components are.",
        "latex": "f_H(\\epsilon) := \\min(f_O, f_{H,\\text{cluster}}(\\epsilon))",
        "references": [],
        "derived_statement": "f_H(ε) > 0, N-uniform"
      },
      {
        "order": 5,
        "kind": "conclusion",
        "text": "This links large V_{Var,x} to existence of a swarm k with substantial high-error fraction bounded by f_H(ε).",
        "latex": null,
        "references": [],
        "derived_statement": "Corollary established"
      }
    ],
    "key_equations": [
      {
        "label": "eq-varx-swarm",
        "latex": "\\mathrm{Var}_x(S_k) > \\frac{R^2_{\\text{total_var},x}}{2}",
        "role": "Lower bound on individual swarm positional variance"
      },
      {
        "label": "eq-varh-swarm",
        "latex": "\\mathrm{Var}_h(S_k) > R^2_{\\text{var}}",
        "role": "Lower bound on hypocoercive variance"
      },
      {
        "label": "eq-fh-unified",
        "latex": "f_H(\\epsilon) := \\min(f_O, f_{H,\\text{cluster}}(\\epsilon))",
        "role": "Unified lower bound on high-error fraction"
      }
    ],
    "references": [
      "lem-V_Varx-implies-variance",
      "def-unified-high-low-error-sets",
      "lem-outlier-fraction-lower-bound",
      "lem-outlier-cluster-fraction-lower-bound"
    ],
    "math_tools": [
      {
        "toolName": "Positional Variance",
        "field": "Statistics",
        "description": "A measure of the spread in position coordinates within a swarm.",
        "roleInProof": "Serves as the starting point, linking total variance across swarms to a large variance in at least one swarm via pigeonhole principle.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Hypocoercive Variance"
        ]
      },
      {
        "toolName": "Hypocoercive Variance",
        "field": "Dynamical Systems",
        "description": "A combined variance metric incorporating both positional and velocity components to capture dissipative behavior.",
        "roleInProof": "Extends the positional variance lower bound to ensure the premises of the epsilon-dichotomy lemmas are met.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Positional Variance"
        ]
      },
      {
        "toolName": "Epsilon-Dichotomy",
        "field": "Swarm Dynamics",
        "description": "A analytical framework that bifurcates the problem into large-epsilon (outlier-dominated) and small-epsilon (cluster-dominated) regimes for error analysis.",
        "roleInProof": "Provides the mechanism to derive high-error fraction bounds in both regimes, unified by a minimum lower bound.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Outlier Sets",
          "Clustering Outliers"
        ]
      }
    ],
    "cases": [
      {
        "name": "Large-ε regime",
        "condition": "ε > D_swarm",
        "summary": "H_k(ε) = O_k (global kinematic outliers); |H_k(ε)|/k >= f_O > 0 by lem-outlier-fraction-lower-bound"
      },
      {
        "name": "Small-ε regime",
        "condition": "ε <= D_swarm",
        "summary": "H_k(ε) = C_k(ε) (clustering-based outliers); |H_k(ε)|/k >= f_{H,cluster}(ε) > 0 by lem-outlier-cluster-fraction-lower-bound"
      }
    ],
    "remarks": [
      {
        "type": "synthesis",
        "text": "This corollary directly combines the chapter's lemmas to bridge Lyapunov variance to error fractions without new derivations."
      }
    ],
    "gaps": [],
    "tags": [
      "variance",
      "hypocoercivity",
      "outlier-fraction",
      "epsilon-dichotomy",
      "swarm-analysis",
      "lyapunov-function",
      "synthesis"
    ]
  },
  {
    "label": "proof-geometric-separation-all-regimes",
    "proves": "thm-geometric-separation-all-regimes",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof leverages clustering properties to establish within-cluster cohesion via diameter bounds and between-cluster separation through variance decomposition into within- and between-cluster components, then applies the reverse triangle inequality to derive a positive lower bound on distances between high-error and low-error clusters, ensuring geometric isolation under admissibility conditions.",
    "conclusion": {
      "text": "High-error clusters are geometrically isolated from low-error clusters, ensuring $D_H(\\epsilon) > R_L(\\epsilon)$ under the admissibility conditions.",
      "latex": "$D_H(\\epsilon) > R_L(\\epsilon)$"
    },
    "assumptions": [
      {
        "text": "Premise: $\\mathrm{Var}_x(S_k) > R^2_{\\mathrm{var}}$",
        "latex": "\\mathrm{Var}_x(S_k) > R^2_{\\mathrm{var}}"
      },
      {
        "text": "Admissibility condition: $D_{\\text{diam}}(\\epsilon) = c_d \\cdot \\epsilon < 2\\sqrt{R^2_{\\mathrm{var}}}$",
        "latex": "D_{\\text{diam}}(\\epsilon) = c_d \\cdot \\epsilon < 2\\sqrt{R^2_{\\mathrm{var}}}"
      },
      {
        "text": "Positivity verification: $\\sqrt{(1-\\varepsilon_O) R^2_{\\mathrm{means}}} - \\sqrt{\\frac{\\varepsilon_O R^2_{\\mathrm{means}} k}{|L_k(\\epsilon)|}} > D_{\\text{diam}}(\\epsilon)$",
        "latex": "\\sqrt{(1-\\varepsilon_O) R^2_{\\mathrm{means}}} - \\sqrt{\\frac{\\varepsilon_O R^2_{\\mathrm{means}} k}{|L_k(\\epsilon)|}} > D_{\\text{diam}}(\\epsilon)"
      }
    ],
    "steps": [],
    "key_equations": [],
    "references": [
      "def-unified-high-low-error-sets"
    ],
    "math_tools": [
      {
        "toolName": "Law of Total Variance",
        "field": "Statistics",
        "description": "Decomposes the total variance of a dataset into the sum of within-group variances and the variance of group means.",
        "roleInProof": "Used to separate the hypocoercive variance into within-cluster and between-cluster components, allowing isolation of the between-cluster term as a measure of separation.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Variance Decomposition"
        ]
      },
      {
        "toolName": "Reverse Triangle Inequality",
        "field": "Metric Geometry",
        "description": "States that for points a, b, c in a metric space, d(a, c) >= |d(a, b) - d(b, c)|, providing a lower bound on distances.",
        "roleInProof": "Applied to bound the minimum positional distance between walkers in high-error and low-error clusters by subtracting within-cluster radii from center separations.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Triangle Inequality"
        ]
      },
      {
        "toolName": "Cluster Diameter",
        "field": "Clustering Algorithms",
        "description": "The maximum distance between any two points within a cluster, controlling the cohesion of the cluster.",
        "roleInProof": "Bounds the internal spread of clusters to limit within-cluster variance and ensure that separation bounds remain positive.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Clustering Radius"
        ]
      },
      {
        "toolName": "Hypocoercive Variance",
        "field": "Dynamical Systems",
        "description": "A combined variance measure in phase space incorporating positional and velocity components with a coupling parameter.",
        "roleInProof": "Links the positional variance premise to overall phase-space separation in the algorithmic metric.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Phase-Space Metric"
        ]
      }
    ],
    "cases": [
      {
        "name": "Case 1: Within High-Error Set",
        "condition": "Walker $j \\in H_k(\\epsilon)$ in the same cluster $G_h$ as $i$",
        "summary": "Distances bounded by cluster diameter: $d_{\\text{alg}}(i,j) \\le D_{\\text{diam}}(\\epsilon) = R_L(\\epsilon)$, showing cohesion within high-error clusters but not isolation."
      },
      {
        "name": "Case 2: Between Different Sets",
        "condition": "Walker $j \\in L_k(\\epsilon)$ in low-error cluster $G_\\ell$",
        "summary": "Use reverse triangle inequality on cluster centers and radii to derive $d_{\\text{alg}}(i,j) \\ge D_H(\\epsilon) > R_L(\\epsilon)$, ensuring separation."
      }
    ],
    "remarks": [],
    "gaps": [
      {
        "description": "The proof mentions 'admissibility constraints derived in Step 9 below' for guaranteeing the positivity condition, but Step 9 is not provided in the text.",
        "severity": "major",
        "location_hint": "End of Step 8"
      },
      {
        "description": "The simplification of the low-error center bound uses $|L_k(\\epsilon)| \\approx k(1-f_H(\\epsilon))$, but exact justification for this approximation is not detailed.",
        "severity": "minor",
        "location_hint": "Step 7 and definition of $D_H(\\epsilon)$"
      }
    ],
    "tags": [
      "clustering",
      "geometric-separation",
      "variance-decomposition",
      "hypocoercivity",
      "phase-space-metric",
      "reverse-triangle-inequality",
      "isolation-bounds"
    ]
  },
  {
    "label": "proof-thm-geometry-guarantees-variance",
    "proves": "thm-geometry-guarantees-variance",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof constructs a lower bound on the expected variance of distance measurements by first invoking geometric guarantees to establish a positive gap in expected distances between high- and low-error subpopulations, then using the law of total variance to bound the variance of these expectations from below, and finally deriving a key inequality that relates the expected empirical variance to this variance of expectations.",
    "conclusion": {
      "text": "A large internal positional variance (Var_x >= R_var^2) is sufficient to guarantee a non-zero expected variance in the raw distance measurements, bounded below by the positive constant kappa_meas(epsilon).",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Var_x >= R_var^2 (high positional variance premise)",
        "latex": "Var_x \\geq R_{var}^2"
      },
      {
        "text": "Geometric separation in the d_alg metric with D_H(epsilon) > R_L(epsilon) guaranteed by the Unified Condition (Section 6.5.4)",
        "latex": "D_H(\\epsilon) > R_L(\\epsilon)"
      },
      {
        "text": "Positive fractional sizes f_H and f_L bounded below by N-uniform constants",
        "latex": null
      },
      {
        "text": "Application of Sequential Stochastic Greedy Pairing Operator preserves signal separation",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "invocation",
        "text": "Invoke geometric guarantees from Chapter 6 to establish unified high-error set H_k and low-error set L_k with positive fractions f_H and f_L, and distinct properties in d_alg metric quantified by D_H(epsilon) and R_L(epsilon). Use lem-greedy-preserves-signal to obtain separation in expected distances: mu_d(H_k) >= D_H(epsilon) and mu_d(L_k) <= R_L(epsilon) + C_tail(epsilon), yielding mu_d(H_k) - mu_d(L_k) >= kappa'_gap(epsilon) > 0.",
        "latex": null,
        "references": [
          "cor-vvarx-to-high-error-fraction",
          "lem-geometric-separation-of-partition",
          "lem-greedy-preserves-signal"
        ],
        "derived_statement": "mu_d(H_k) - mu_d(L_k) >= kappa'_gap(epsilon) > 0"
      },
      {
        "order": 2,
        "kind": "derivation",
        "text": "Apply the law of total variance to the set of expected distances E_d partitioned into H_k and L_k, yielding Var(E_d) >= f_H f_L (mu_d(H_k) - mu_d(L_k))^2 >= f_H f_L (kappa'_gap(epsilon))^2 > 0.",
        "latex": null,
        "references": [],
        "derived_statement": "Var(E_d) >= f_H f_L (kappa'_gap(epsilon))^2 > 0"
      },
      {
        "order": 3,
        "kind": "derivation",
        "text": "Decompose E[Var(d)] by expanding (d_i - bar d)^2 for each i, showing the cross-term vanishes, and obtaining E[Var(d)] = average Var(d_i) + Var(E_d) + Var(bar d), all terms non-negative, hence E[Var(d)] >= Var(E_d).",
        "latex": null,
        "references": [],
        "derived_statement": "E[Var(d)] >= Var(E_d)"
      },
      {
        "order": 4,
        "kind": "assembly",
        "text": "Combine steps: E[Var(d)] >= Var(E_d) >= f_H f_L (kappa'_gap(epsilon))^2, defining kappa_meas(epsilon) := f_H f_L (kappa'_gap(epsilon))^2 > 0 as the uniform lower bound.",
        "latex": null,
        "references": [],
        "derived_statement": "E[Var(d)] >= kappa_meas(epsilon) > 0"
      }
    ],
    "key_equations": [
      {
        "label": "eq-kappa-gap",
        "latex": "\\kappa'_{\\text{gap}}(\\epsilon) := D_H(\\epsilon) - R_L(\\epsilon) - C_{\\text{tail}}(\\epsilon) > 0",
        "role": "Guaranteed positive gap in subpopulation mean expected distances"
      },
      {
        "label": "eq-var-between",
        "latex": "\\operatorname{Var}(E_d) \\ge f_H f_L (\\mu_d(H_k) - \\mu_d(L_k))^2",
        "role": "Between-group variance lower bound from law of total variance"
      },
      {
        "label": "eq-key-inequality",
        "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge \\operatorname{Var}(E_d)",
        "role": "Key inequality linking expected variance to variance of expectations"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\ge f_H f_L (\\kappa'_{\\text{gap}}(\\epsilon))^2 = \\kappa_{\\text{meas}}(\\varepsilon)",
        "role": "Final lower bound on expected measurement variance"
      }
    ],
    "references": [
      "cor-vvarx-to-high-error-fraction",
      "lem-geometric-separation-of-partition",
      "lem-greedy-preserves-signal"
    ],
    "math_tools": [
      {
        "toolName": "Law of Total Variance",
        "field": "Probability and Statistics",
        "description": "Decomposes the total variance of a random variable into within-group and between-group components for a partitioned sample.",
        "roleInProof": "Applied to bound the variance of expected distances by the positive between-group variance due to subpopulation separation.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      },
      {
        "toolName": "Decomposition of Expected Sample Variance",
        "field": "Probability and Statistics",
        "description": "Expands the expected value of the empirical variance into within-walker variances, variance of expectations, and variance of the sample mean.",
        "roleInProof": "Used to derive the inequality E[Var(d)] >= Var(E_d) by showing non-negative terms in the expansion.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Law of Total Variance"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "All constants (f_H, f_L, kappa'_gap) are positive, N-uniform, and epsilon-dependent, ensuring uniformity in the guarantees."
      }
    ],
    "gaps": [],
    "tags": [
      "variance-decomposition",
      "geometric-separation",
      "subpopulations",
      "expected-distances",
      "law-of-total-variance",
      "greedy-pairing",
      "constructive-proof"
    ]
  },
  {
    "label": "proof-prop-satisfiability-of-snr-gamma",
    "proves": "prop-satisfiability-of-snr-gamma",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof demonstrates that the maximum noise variance Var_max(d') is a fixed constant independent of γ, while the guaranteed signal variance κ_var(d') scales quadratically with γ, allowing a sufficiently large γ to ensure κ_var(d') > Var_max(d') and satisfy the signal-to-noise condition.",
    "conclusion": {
      "text": "The Signal-to-Noise Condition is not a restrictive assumption on the environment but is a design criterion that can always be satisfied by appropriately tuning the algorithm's sensitivity γ. This holds for any valid rescale function, including the Canonical choice.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Axiom of a Well-Behaved Rescale Function: g_A has a bounded range (g_{A,min}, g_{A,max}) and a uniform lower bound g'_{min} > 0 on its derivative over compact sets.",
        "latex": null
      },
      {
        "text": "High-error state guarantees Var(d) ≥ κ_meas(d) > 0 (from thm-geometry-guarantees-variance).",
        "latex": null
      },
      {
        "text": "Patched standard deviation σ'_d is bounded above by σ'_{max} (from def-max-patched-std).",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "noise-term",
        "text": "The Noise Term (Var_max(d')): A Fixed, γ-Independent Constant. The rescaled values d' are bounded in (g_{A,min} + η, g_{A,max} + η), and Popoviciu's inequality gives Var_max(d') = (1/4)(g_{A,max} - g_{A,min})^2, independent of γ.",
        "latex": null,
        "references": [],
        "derived_statement": "Var_max(d') = \\frac{1}{4}(g_{A,\\max} - g_{A,\\min})^2"
      },
      {
        "order": 2,
        "kind": "signal-term-raw",
        "text": "Raw and Standardized Signal: Var(d) ≥ κ_meas(d) > 0, and Var(z_d) = Var(d) / (σ'_d)^2 ≥ κ_meas(d) / (σ'_{max})^2 = κ_var(z) > 0.",
        "latex": null,
        "references": [
          "thm-geometry-guarantees-variance",
          "def-max-patched-std"
        ],
        "derived_statement": "\\operatorname{Var}(z_d) \\ge \\frac{\\kappa_{\\mathrm{meas}}(d)}{(\\sigma'_{\\max})^2} =: \\kappa_{\\mathrm{var}}(z) > 0"
      },
      {
        "order": 3,
        "kind": "signal-term-amplification",
        "text": "Signal Amplification: Input u = γ z_d, so Var(u) = γ^2 Var(z_d) ≥ γ^2 κ_var(z).",
        "latex": null,
        "references": [],
        "derived_statement": "\\operatorname{Var}(u) = \\gamma^{2} \\operatorname{Var}(z_d) \\geq \\gamma^{2} \\kappa_{\\mathrm{var}}(z)"
      },
      {
        "order": 4,
        "kind": "signal-term-rescaled",
        "text": "Rescaled Signal (κ_var(d')): Using Taylor expansion and Mean Value Theorem, Var(d') ≥ (inf_{c ∈ Z_eff} g'_A(c))^2 Var(u), so κ_var(d') ≥ (g'_{min})^2 γ^2 κ_var(z).",
        "latex": null,
        "references": [],
        "derived_statement": "\\kappa_{\\mathrm{var}}(d') \\ge (g'_{\\min})^2 \\cdot \\gamma^2 \\kappa_{\\mathrm{var}}(z)"
      },
      {
        "order": 5,
        "kind": "satisfiability",
        "text": "Proving Satisfiability: Set κ_var(d') > Var_max(d'), yielding γ > \\frac{g_{A,\\max} - g_{A,\\min}}{2 \\cdot g'_{\\min} \\cdot \\sqrt{\\kappa_{\\mathrm{var}}(z)}}, a fixed positive value, so such a γ exists.",
        "latex": null,
        "references": [],
        "derived_statement": "\\gamma > \\frac{g_{A,\\max} - g_{A,\\min}}{2 \\cdot g'_{\\min} \\cdot \\sqrt{\\kappa_{\\mathrm{var}}(z)}}"
      }
    ],
    "key_equations": [
      {
        "label": "eq-var-max",
        "latex": "\\operatorname{Var}_{\\max}(d') := \\frac{1}{4}(\\max(d') - \\min(d'))^2 = \\frac{1}{4}(g_{A,\\max} - g_{A,\\min})^2",
        "role": "Defines the fixed maximum variance bound"
      },
      {
        "label": "eq-var-z",
        "latex": "\\operatorname{Var}(z_d) \\ge \\frac{\\kappa_{\\mathrm{meas}}(d)}{(\\sigma'_{\\max})^2} =: \\kappa_{\\mathrm{var}}(z) > 0",
        "role": "Lower bound on Z-score variance"
      },
      {
        "label": "eq-var-u",
        "latex": "\\operatorname{Var}(u) = \\gamma^{2} \\operatorname{Var}(z_d) \\geq \\gamma^{2} \\kappa_{\\mathrm{var}}(z)",
        "role": "Variance after amplification by γ"
      },
      {
        "label": "eq-var-d-approx",
        "latex": "\\operatorname{Var}(d') = \\operatorname{Var}(g_A(u)) \\approx (g'_A(\\mu_u))^2 \\operatorname{Var}(u)",
        "role": "Taylor approximation for rescaled variance"
      },
      {
        "label": "eq-var-d-bound",
        "latex": "\\operatorname{Var}(d') \\ge (\\inf_{c \\in Z_{\\mathrm{eff}}} g'_A(c))^2 \\operatorname{Var}(u)",
        "role": "Rigorous lower bound using Mean Value Theorem"
      },
      {
        "label": "eq-kappa-var",
        "latex": "\\kappa_{\\mathrm{var}}(d') \\ge (g'_{\\min})^2 \\cdot \\gamma^2 \\kappa_{\\mathrm{var}}(z)",
        "role": "Guaranteed lower bound on signal variance"
      },
      {
        "label": "eq-snr-ineq",
        "latex": "(g'_{\\min})^2 \\cdot \\gamma^2 \\kappa_{\\mathrm{var}}(z) > \\frac{1}{4}(g_{A,\\max} - g_{A,\\min})^2",
        "role": "Signal-to-noise condition"
      },
      {
        "label": "eq-gamma-bound",
        "latex": "\\gamma > \\frac{g_{A,\\max} - g_{A,\\min}}{2 \\cdot g'_{\\min} \\cdot \\sqrt{\\kappa_{\\mathrm{var}}(z)}}",
        "role": "Sufficient γ to satisfy the condition"
      }
    ],
    "references": [
      "thm-geometry-guarantees-variance",
      "def-max-patched-std"
    ],
    "math_tools": [
      {
        "toolName": "Popoviciu's inequality",
        "field": "Statistics",
        "description": "Provides an upper bound on the variance of a bounded random variable as one-quarter the square of the range.",
        "roleInProof": "Used to establish the fixed maximum variance Var_max(d') for rescaled values in a bounded interval.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      },
      {
        "toolName": "Taylor expansion",
        "field": "Calculus",
        "description": "Approximates a differentiable function near a point using its derivatives, particularly the first-order linear approximation.",
        "roleInProof": "Approximates the variance of the rescaled signal g_A(u) as (g'_A(μ_u))^2 Var(u) in the small-signal limit.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Mean Value Theorem"
        ]
      },
      {
        "toolName": "Mean Value Theorem",
        "field": "Calculus",
        "description": "States that for a continuous function on a closed interval, there exists a point where the derivative equals the average rate of change.",
        "roleInProof": "Provides a rigorous lower bound on Var(g_A(u)) using the infimum of the derivative over the effective input range.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Taylor expansion"
        ]
      },
      {
        "toolName": "Z-score standardization",
        "field": "Statistics",
        "description": "Transforms data to have mean zero and variance one by subtracting the mean and dividing by the standard deviation.",
        "roleInProof": "Standardizes raw distances d to z_d, preserving a lower bound on variance via the bounded patched standard deviation.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "goal",
        "text": "Prove that γ can be chosen such that κ_var(d') > Var_max(d'), ensuring the signal dominates the noise."
      },
      {
        "type": "example",
        "text": "For the Canonical Logistic Rescale g_A(z) = 2/(1 + e^{-z}), Var_max(d') = 1."
      }
    ],
    "gaps": [],
    "tags": [
      "signal-to-noise",
      "variance-bound",
      "rescale-function",
      "signal-amplification",
      "popoviciu-inequality",
      "taylor-expansion",
      "mean-value-theorem",
      "gamma-tuning"
    ]
  },
  {
    "label": "proof-lem-variance-to-gap",
    "proves": "lem-variance-to-gap",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes an identity linking empirical variance to the average of squared pairwise differences, bounds this sum using the maximum pairwise gap, and combines the bound with the given lower bound on variance to derive the inequality relating the maximum gap to the variance threshold.",
    "conclusion": {
      "text": "Δ_max ≥ √(2κ)",
      "latex": "\\Delta_{\\max} \\geq \\sqrt{2\\kappa}"
    },
    "assumptions": [
      {
        "text": "Var({v_i}) ≥ κ for a set {v_i} of k real numbers",
        "latex": "\\mathrm{Var}(\\{v_i\\}) \\geq \\kappa"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "identity",
        "text": "The empirical variance Var({v_i}) = (1/k)∑_i v_i² - ((1/k)∑_i v_i)² can be expressed as Var({v_i}) = (1/(2k²)) ∑_{i=1}^k ∑_{j=1}^k (v_i - v_j)². This identity is established by expanding the squared term in the double summation.",
        "latex": "\\mathrm{Var}(\\{v_i\\}) = \\frac{1}{2k^2} \\sum_{i=1}^k \\sum_{j=1}^k (v_i - v_j)^2",
        "references": [],
        "derived_statement": "Pairwise variance identity"
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "Let Δ_max := max_{i,j} |v_i - v_j|. Each (v_i - v_j)² ≤ Δ_max², so the double sum ≤ k² Δ_max², yielding Var({v_i}) ≤ (1/2) Δ_max².",
        "latex": "\\sum_{i=1}^k \\sum_{j=1}^k (v_i - v_j)^2 \\le k^2 \\Delta_{\\max}^2 \\implies \\mathrm{Var}(\\{v_i\\}) \\le \\frac{1}{2} \\Delta_{\\max}^2",
        "references": [],
        "derived_statement": "Variance upper bound in terms of maximum gap"
      },
      {
        "order": 3,
        "kind": "derivation",
        "text": "Given Var({v_i}) ≥ κ, combine with the upper bound: κ ≤ Var({v_i}) ≤ (1/2) Δ_max², so Δ_max² ≥ 2κ, and thus Δ_max ≥ √(2κ).",
        "latex": "\\kappa \\le \\frac{1}{2} \\Delta_{\\max}^2 \\implies \\Delta_{\\max}^2 \\ge 2\\kappa \\implies \\Delta_{\\max} \\ge \\sqrt{2\\kappa}",
        "references": [],
        "derived_statement": "Desired inequality"
      }
    ],
    "key_equations": [
      {
        "label": "eq-var-empirical",
        "latex": "\\mathrm{Var}(\\{v_i\\}) = \\frac{1}{k}\\sum_i v_i^2 - \\left(\\frac{1}{k}\\sum_i v_i\\right)^2",
        "role": "Standard empirical variance formula"
      },
      {
        "label": "eq-var-pairwise",
        "latex": "\\mathrm{Var}(\\{v_i\\}) = \\frac{1}{2k^2} \\sum_{i=1}^k \\sum_{j=1}^k (v_i - v_j)^2",
        "role": "Pairwise identity for variance"
      },
      {
        "label": "eq-bound-sum",
        "latex": "\\sum_{i=1}^k \\sum_{j=1}^k (v_i - v_j)^2 \\le k^2 \\Delta_{\\max}^2",
        "role": "Bounding the double sum"
      },
      {
        "label": "eq-var-bound",
        "latex": "\\mathrm{Var}(\\{v_i\\}) \\le \\frac{1}{2} \\Delta_{\\max}^2",
        "role": "Upper bound on variance"
      },
      {
        "label": "eq-final-ineq",
        "latex": "\\Delta_{\\max}^2 \\ge 2\\kappa",
        "role": "Key inequality before taking square root"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Empirical Variance",
        "field": "Statistics",
        "description": "The variance of a finite sample, computed as the average squared deviation from the mean.",
        "roleInProof": "Serves as the starting point for relating variance to pairwise differences and applying the maximum gap bound.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The pairwise variance identity is a standard result obtained by algebraic expansion."
      }
    ],
    "gaps": [],
    "tags": [
      "variance",
      "empirical variance",
      "pairwise differences",
      "bounding",
      "inequality",
      "gap"
    ]
  },
  {
    "label": "proof-lem-rescale-derivative-lower-bound",
    "proves": "lem-rescale-derivative-lower-bound",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof demonstrates a uniform positive lower bound on the derivative of the canonical logistic rescaling function by establishing the compactness of the domain of standardized scores and applying the Extreme Value Theorem to the continuous and strictly positive derivative.",
    "conclusion": {
      "text": "The minimum value of g'_A(z) on Z_supp, denoted g'_min, is a strictly positive constant.",
      "latex": null
    },
    "assumptions": [],
    "steps": [],
    "key_equations": [
      {
        "label": "g_A",
        "latex": "g_A(z) = \\frac{2}{1 + e^{-z}}",
        "role": "canonical logistic rescaling function"
      },
      {
        "label": "g'_A",
        "latex": "g'_A(z) = \\frac{2 e^{-z}}{(1 + e^{-z})^2}",
        "role": "derivative of the rescaling function"
      },
      {
        "label": "Z_supp",
        "latex": "Z_{\\text{supp}} = \\left[ -\\frac{2 V_{\\max}}{\\sigma'_{\\min,\\text{patch}}}, \\frac{2 V_{\\max}}{\\sigma'_{\\min,\\text{patch}}} \\right]",
        "role": "compact support interval for standardized scores"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Extreme Value Theorem",
        "field": "Real Analysis",
        "description": "A continuous real-valued function on a compact set in Euclidean space attains its maximum and minimum values.",
        "roleInProof": "Used to ensure that the continuous derivative g'_A attains a minimum on the compact interval Z_supp.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "compactness",
      "extreme value theorem",
      "logistic function",
      "derivative",
      "lower bound",
      "continuity",
      "real analysis"
    ]
  },
  {
    "label": "proof-lem-raw-gap-to-rescaled-gap",
    "proves": "lem-raw-gap-to-rescaled-gap",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes a uniform lower bound on the z-score gap from the raw value gap using the bounded patched standard deviation, then propagates this to the rescaled gap via the Mean Value Theorem and a uniform lower bound on the rescaling function's derivative over its compact support.",
    "conclusion": {
      "text": "|g_A(z_a) - g_A(z_b)| ≥ κ_rescaled(κ_raw), where κ_rescaled(κ_raw) = g'_min · (κ_raw / σ'_max) provides a strictly positive, N-uniform lower bound for any κ_raw > 0.",
      "latex": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\left(\\frac{\\kappa_{\\mathrm{raw}}}{\\sigma'_{\\max}}\\right) = \\kappa_{\\mathrm{rescaled}}(\\kappa_{\\mathrm{raw}})"
    },
    "assumptions": [
      {
        "text": "The raw value gap |v_a - v_b| is bounded below by κ_raw > 0.",
        "latex": null
      },
      {
        "text": "The patched standard deviation σ' is bounded above by the constant σ'_max.",
        "latex": null
      },
      {
        "text": "The rescaling function g_A is continuously differentiable with derivative bounded below by g'_min > 0 on the compact operational range Z_supp.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "derivation",
        "text": "Express the z-score gap in terms of the raw value gap and patched standard deviation.",
        "latex": "|z_a - z_b| = \\frac{|v_a - v_b|}{\\sigma'}",
        "references": [],
        "derived_statement": "|z_a - z_b| = \\frac{|v_a - v_b|}{\\sigma'}"
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "Apply the lower bound on the numerator and upper bound on the denominator to obtain a uniform lower bound κ_z on the z-score gap.",
        "latex": "|z_a - z_b| \\ge \\frac{\\kappa_{\\mathrm{raw}}}{\\sigma'_{\\max}} =: \\kappa_z > 0",
        "references": [
          "def-max-patched-std"
        ],
        "derived_statement": "|z_a - z_b| \\ge \\kappa_z"
      },
      {
        "order": 3,
        "kind": "application",
        "text": "Apply the Mean Value Theorem to the rescaling function g_A between z_a and z_b, introducing an intermediate point c.",
        "latex": "|g_A(z_a) - g_A(z_b)| = |g'_A(c)| \\cdot |z_a - z_b|",
        "references": [],
        "derived_statement": "|g_A(z_a) - g_A(z_b)| = |g'_A(c)| \\cdot |z_a - z_b|"
      },
      {
        "order": 4,
        "kind": "bounding",
        "text": "Use the uniform lower bound on the derivative g'_A(c) ≥ g'_min > 0 since c is in the compact Z_supp, combined with the z-score gap bound.",
        "latex": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\kappa_z",
        "references": [
          "lem-rescale-derivative-lower-bound"
        ],
        "derived_statement": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\kappa_z"
      },
      {
        "order": 5,
        "kind": "substitution",
        "text": "Substitute κ_z to obtain the final rescaled gap bound in terms of κ_raw.",
        "latex": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\left(\\frac{\\kappa_{\\mathrm{raw}}}{\\sigma'_{\\max}}\\right) = \\kappa_{\\mathrm{rescaled}}(\\kappa_{\\mathrm{raw}})",
        "references": [],
        "derived_statement": "|g_A(z_a) - g_A(z_b)| \\ge \\kappa_{\\mathrm{rescaled}}(\\kappa_{\\mathrm{raw}})"
      },
      {
        "order": 6,
        "kind": "conclusion",
        "text": "Since g'_min and σ'_max are positive N-uniform constants, the bound is strictly positive and uniform for any κ_raw > 0.",
        "latex": null,
        "references": [],
        "derived_statement": "Raw gap propagates to guaranteed rescaled gap."
      }
    ],
    "key_equations": [
      {
        "label": "eq-zscore-gap",
        "latex": "|z_a - z_b| = \\frac{|v_a - v_b|}{\\sigma'}",
        "role": "Expresses z-score difference in terms of raw values"
      },
      {
        "label": "eq-kappa-z",
        "latex": "|z_a - z_b| \\ge \\frac{\\kappa_{\\mathrm{raw}}}{\\sigma'_{\\max}} =: \\kappa_z > 0",
        "role": "Uniform lower bound on z-score gap"
      },
      {
        "label": "eq-mvt-rescale",
        "latex": "|g_A(z_a) - g_A(z_b)| = |g'_A(c)| \\cdot |z_a - z_b|",
        "role": "Mean Value Theorem application"
      },
      {
        "label": "eq-rescaled-bound",
        "latex": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\kappa_z",
        "role": "Intermediate rescaled gap bound"
      },
      {
        "label": "eq-final-rescaled",
        "latex": "|g_A(z_a) - g_A(z_b)| \\ge g'_{\\min} \\cdot \\left(\\frac{\\kappa_{\\mathrm{raw}}}{\\sigma'_{\\max}}\\right) = \\kappa_{\\mathrm{rescaled}}(\\kappa_{\\mathrm{raw}})",
        "role": "Final propagated gap bound"
      }
    ],
    "references": [
      "def-max-patched-std",
      "lem-rescale-derivative-lower-bound"
    ],
    "math_tools": [
      {
        "toolName": "Mean Value Theorem",
        "field": "Calculus",
        "description": "If a function is continuous on the closed interval [a, b] and differentiable on the open interval (a, b), then there exists at least one point c in (a, b) such that f'(c) = (f(b) - f(a)) / (b - a).",
        "roleInProof": "Applied to the continuously differentiable rescaling function g_A on the compact interval between z_a and z_b to bound the difference |g_A(z_a) - g_A(z_b)| by the absolute value of the derivative at some intermediate point times |z_a - z_b|.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "concluding",
        "text": "This completes the proof that a raw measurement gap robustly propagates to a guaranteed rescaled value gap."
      }
    ],
    "gaps": [],
    "tags": [
      "signal gap",
      "z-score standardization",
      "rescaling",
      "mean value theorem",
      "uniform bound",
      "derivative lower bound",
      "patched standard deviation"
    ]
  },
  {
    "label": "proof-lem-variance-to-mean-separation",
    "proves": "lem-variance-to-mean-separation",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof applies the Law of Total Variance to decompose the empirical variance into between-group and within-group terms, derives an exact expression for the between-group variance in terms of the squared mean difference, bounds the within-group variance using Popoviciu's inequality, and combines these to establish a lower bound on the mean separation under the given premises.",
    "conclusion": {},
    "assumptions": [],
    "steps": [],
    "key_equations": [],
    "references": [],
    "math_tools": [
      {
        "toolName": "Law of Total Variance",
        "field": "Statistics",
        "description": "Decomposes the total variance of a dataset into the variance between subset means and the average variance within subsets.",
        "roleInProof": "Provides the key decomposition used to isolate the between-group variance related to mean separation.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Popoviciu Inequality"
        ]
      },
      {
        "toolName": "Popoviciu's Inequality",
        "field": "Statistics",
        "description": "States that for any bounded set of numbers in [a, b], the variance is at most (b - a)^2 / 4.",
        "roleInProof": "Yields a uniform upper bound on the within-group variances to subtract from the total variance.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Law of Total Variance"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "sharpness",
        "text": "The upper bound on within-group variance is sharp, attained when subsets consist of values at the interval endpoints."
      },
      {
        "type": "positivity",
        "text": "The lower bound is strictly positive when κ_var > Var_max, and the prefactor is uniformly bounded due to f_min > 0."
      }
    ],
    "gaps": [],
    "tags": [
      "variance decomposition",
      "law of total variance",
      "popoviciu inequality",
      "mean separation",
      "empirical statistics",
      "upper bound",
      "lower bound"
    ]
  },
  {
    "label": "proof-thm-derivation-of-stability-condition",
    "proves": "thm-derivation-of-stability-condition",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof formalizes the intelligent targeting condition via expected log-fitness, decomposes it into a trade-off between diversity and reward signals using linearity of expectation, derives uniform bounds on signal gaps via variance-to-mean-separation lemmas under adversarial conditions, and assembles these bounds to obtain the necessary and sufficient stability inequality.",
    "conclusion": {
      "text": "The necessary and sufficient condition for intelligent targeting and stability is that the guaranteed minimum logarithmic diversity signal gap exceeds the maximum adversarial logarithmic reward signal gap: \\(\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max} + \\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)\\).",
      "latex": "\\beta \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max} + \\eta}\\right) > \\alpha \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)"
    },
    "assumptions": [
      {
        "text": "High-error states guarantee raw measurement variance \\(\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon) > 0\\).",
        "latex": "\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon) > 0"
      },
      {
        "text": "Signal-to-Noise Condition: \\(\\kappa_{\\text{var}}(d') > \\operatorname{Var}_{\\max}(d')\\), satisfied by gain parameter \\(\\gamma\\).",
        "latex": "\\kappa_{\\text{var}}(d') > \\operatorname{Var}_{\\max}(d')"
      },
      {
        "text": "Rescaled values lie in bounded ranges: diversity \\([\\eta, g_{A,\\max} + \\eta]\\), reward near \\([\\eta, \\cdot]\\).",
        "latex": "[\\eta, g_{A,\\max} + \\eta]"
      },
      {
        "text": "Fitness potential is multiplicative: \\(V_{\\text{fit}} = (d')^\\beta (r')^\\alpha\\).",
        "latex": "V_{\\text{fit}} = (d')^\\beta (r')^\\alpha"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "formalization",
        "text": "Formalize the condition for intelligent targeting: the expected log-fitness of the high-error population H_k is less than that of the low-error population L_k.",
        "latex": "\\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]",
        "references": [],
        "derived_statement": "Targeting condition in terms of expected log-fitness."
      },
      {
        "order": 2,
        "kind": "decomposition",
        "text": "Decompose using linearity of expectation and log definition to isolate signal trade-off.",
        "latex": "\\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right)",
        "references": [],
        "derived_statement": "Core trade-off inequality (*)."
      },
      {
        "order": 3,
        "kind": "bounding",
        "text": "Derive lower bound for LHS diversity signal gap via causal chain: geometry to variance, rescaling, SNR condition, and apply lem-variance-to-mean-separation.",
        "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\varepsilon)}{g_{A,\\max}+\\eta}\\right)",
        "references": [
          "thm-geometry-guarantees-variance",
          "lem-variance-to-mean-separation",
          "prop-satisfiability-of-snr-gamma"
        ],
        "derived_statement": "Guaranteed minimum diversity logarithmic gap."
      },
      {
        "order": 4,
        "kind": "bounding",
        "text": "Derive upper bound for RHS reward signal gap symmetrically, applying lem-variance-to-mean-separation to adversarial case.",
        "latex": "\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)",
        "references": [
          "lem-variance-to-mean-separation"
        ],
        "derived_statement": "Maximum adversarial reward logarithmic gap."
      },
      {
        "order": 5,
        "kind": "assembly",
        "text": "Substitute bounds into (*) to obtain the necessary and sufficient stability condition, ensuring it holds uniformly for any swarm.",
        "latex": null,
        "references": [],
        "derived_statement": "Final stability inequality."
      }
    ],
    "key_equations": [
      {
        "label": "eq-targeting-condition",
        "latex": "\\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in H_k] < \\mathbb{E}[\\ln(V_{\\text{fit}}) \\mid i \\in L_k]",
        "role": "Formal condition for intelligent targeting"
      },
      {
        "label": "eq-trade-off",
        "latex": "\\beta \\left( \\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\right) > \\alpha \\left( \\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\right)",
        "role": "Decomposed signal trade-off inequality"
      },
      {
        "label": "eq-mean-separation",
        "latex": "|\\mathbb{E}[d'|H_k] - \\mathbb{E}[d'|L_k]| \\ge \\frac{1}{\\sqrt{f_H f_L}} \\sqrt{\\kappa_{\\mathrm{var}}(d') - \\operatorname{Var}_{\\max}(d')}",
        "role": "Uniform bound from variance-to-mean-separation"
      },
      {
        "label": "eq-diversity-gap",
        "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},d'}(\\epsilon)}{g_{A,\\max}+\\eta}\\right)",
        "role": "Lower bound on diversity log-gap"
      },
      {
        "label": "eq-reward-gap",
        "latex": "\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\text{mean},r'}}{\\eta}\\right)",
        "role": "Upper bound on reward log-gap"
      }
    ],
    "references": [
      "lem-variance-to-gap",
      "prop-satisfiability-of-snr-gamma",
      "thm-geometry-guarantees-variance",
      "lem-variance-to-mean-separation"
    ],
    "math_tools": [
      {
        "toolName": "Linearity of Expectation",
        "field": "Probability Theory",
        "description": "The expected value of a linear combination is the linear combination of expected values.",
        "roleInProof": "Decomposes the expected log-fitness into separate contributions from diversity and reward signals.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Expectation"
        ]
      },
      {
        "toolName": "Variance-to-Mean-Separation Lemma",
        "field": "Statistics",
        "description": "Provides a lower bound on the absolute difference between conditional means of subsets given the total variance and maximum subset variance.",
        "roleInProof": "Establishes uniform separations between mean rescaled values of high-error and low-error populations for both diversity and reward signals.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Chebyshev's Inequality"
        ]
      },
      {
        "toolName": "Logarithmic Bounding",
        "field": "Analysis",
        "description": "Bounds the difference in logarithms based on range compression and mean separations.",
        "roleInProof": "Converts mean separations in rescaled values to logarithmic gaps for fitness comparison.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Concavity of Logarithm"
        ]
      },
      {
        "toolName": "Signal-to-Noise Condition",
        "field": "Signal Processing",
        "description": "Ensures that the variance of the signal exceeds the maximum noise variance via gain parameter choice.",
        "roleInProof": "Guarantees the applicability of variance-to-mean-separation by satisfying premise conditions.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Variance Analysis"
        ]
      }
    ],
    "cases": [
      {
        "name": "Diversity Signal (LHS)",
        "condition": "High-error guarantees variance \\(\\mathbb{E}[\\operatorname{Var}(d)] \\geq \\kappa_{\\text{meas}}(\\varepsilon)\\)",
        "summary": "Derives minimum guaranteed logarithmic gap using geometry, rescaling, SNR, and mean-separation lemma."
      },
      {
        "name": "Reward Signal (RHS)",
        "condition": "Adversarial raw gap \\(\\kappa_r'\\)",
        "summary": "Derives maximum possible logarithmic gap using symmetric application of mean-separation lemma under compression at range bottom."
      }
    ],
    "remarks": [
      {
        "type": "clarity",
        "text": "The bounds are N-uniform and hold for worst-case adversarial swarms, ensuring robustness."
      },
      {
        "type": "rigor",
        "text": "The final condition compares means of populations, avoiding reliance on individual values."
      }
    ],
    "gaps": [],
    "tags": [
      "intelligent targeting",
      "stability condition",
      "signal trade-off",
      "uniform bounds",
      "diversity signal",
      "reward signal",
      "variance separation",
      "logarithmic gap"
    ]
  },
  {
    "label": "proof-lem-log-gap-lower-bound",
    "proves": "lem-log-gap-lower-bound",
    "proof_type": "variational",
    "proof_status": "complete",
    "strategy_summary": "The proof leverages extremal distributions for the concave logarithm function to establish tight lower bounds on E[ln(X)] - E[ln(Y)] under mean constraints, reduces the problem to minimizing a one-dimensional convex function over valid μ_Y, identifies the minimum at the boundary μ_Y = V_max - κ, and simplifies to the stated conservative bound.",
    "conclusion": {
      "text": "For random variables X, Y supported on [V_min, V_max] with E[X] ≥ E[Y] + κ, we have E[ln(X)] - E[ln(Y)] ≥ ln(1 + κ / V_max).",
      "latex": "\\mathbb{E}[\\ln(X)] - \\mathbb{E}[\\ln(Y)] \\ge \\ln\\left(1 + \\frac{\\kappa}{V_{\\max}}\\right)"
    },
    "assumptions": [
      {
        "text": "X and Y are random variables taking values in the interval [V_min, V_max].",
        "latex": "X, Y \\in [V_{\\min}, V_{\\max}]"
      },
      {
        "text": "The means satisfy E[X] ≥ E[Y] + κ with κ > 0.",
        "latex": "\\mathbb{E}[X] \\ge \\mathbb{E}[Y] + \\kappa"
      },
      {
        "text": "V_min > 0 to ensure the logarithm is defined.",
        "latex": "V_{\\min} > 0"
      },
      {
        "text": "κ < V_max to ensure feasible means.",
        "latex": "\\kappa < V_{\\max}"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "explanation",
        "text": "Recall that for the strictly concave function ln(t), the minimum E[ln(X)] for fixed mean μ_X is achieved by a two-point distribution on {V_min, V_max}, and the maximum E[ln(Y)] for fixed mean μ_Y is achieved by the deterministic Y = μ_Y via Jensen's inequality.",
        "latex": null,
        "references": [],
        "derived_statement": "Extremal distributions: min E[ln(X)] via two-point, max E[ln(Y)] = ln(μ_Y)."
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "The difference E[ln(X)] - E[ln(Y)] is at least E[ln(X_min)] - ln(μ_Y), where X_min is the two-point distribution with mean μ_X and probabilities P(X_min = V_min) = (V_max - μ_X)/(V_max - V_min), P(X_min = V_max) = (μ_X - V_min)/(V_max - V_min).",
        "latex": "P(X_{\\min} = V_{\\min}) = \\frac{V_{\\max} - \\mu_X}{V_{\\max} - V_{\\min}}, \\quad P(X_{\\min} = V_{\\max}) = \\frac{\\mu_X - V_{\\min}}{V_{\\max} - V_{\\min}}",
        "references": [],
        "derived_statement": "Lower bound on difference using extremals."
      },
      {
        "order": 3,
        "kind": "reduction",
        "text": "Minimize E[ln(X_min)] - ln(μ_Y) over μ_X ≥ μ_Y + κ, μ_X, μ_Y ∈ [V_min, V_max]. Since E[ln(X_min)] increases in μ_X, set μ_X = μ_Y + κ, reducing to min h(μ_Y) = E[ln(X_min, μ_Y + κ)] - ln(μ_Y) for μ_Y ∈ [V_min, V_max - κ].",
        "latex": null,
        "references": [],
        "derived_statement": "One-dimensional optimization on boundary."
      },
      {
        "order": 4,
        "kind": "analysis",
        "text": "Show h(μ_Y) is strictly convex: E[ln(X_min, μ)] = C_0 + C_1 μ with C_1 > 0, so h(μ_Y) = linear in μ_Y minus ln(μ_Y), hence strictly convex. Thus, minimum at endpoint μ_Y = V_min or V_max - κ.",
        "latex": "\\mathbb{E}[\\ln(X_{\\min,\\mu})] = \\ln(V_{\\max}) + \\frac{V_{\\max} - \\mu}{V_{\\max} - V_{\\min}}(\\ln(V_{\\min}) - \\ln(V_{\\max}))",
        "references": [],
        "derived_statement": "h(μ_Y) strictly convex, min at endpoint."
      },
      {
        "order": 5,
        "kind": "evaluation",
        "text": "The minimum occurs at μ_Y = V_max - κ (due to flattening of log at higher values), with μ_X = V_max. Here, both extremals degenerate to deterministic: E[ln(X)] = ln(V_max), E[ln(Y)] = ln(V_max - κ), so difference ln(V_max / (V_max - κ)) = ln(1 + κ/(V_max - κ)).",
        "latex": "\\ln\\left(1 + \\frac{\\kappa}{V_{\\max} - \\kappa}\\right)",
        "references": [],
        "derived_statement": "Tight bound at right endpoint."
      },
      {
        "order": 6,
        "kind": "simplification",
        "text": "The lemma uses the looser bound ln(1 + κ/V_max), which is valid since κ/V_max < κ/(V_max - κ) and ln(1 + ·) is increasing.",
        "latex": "\\ln\\left(1 + \\frac{\\kappa}{V_{\\max}}\\right) < \\ln\\left(1 + \\frac{\\kappa}{V_{\\max} - \\kappa}\\right)",
        "references": [],
        "derived_statement": "Conservative simplification to stated bound."
      }
    ],
    "key_equations": [
      {
        "label": "eq-two-point-probs",
        "latex": "P(X_{\\min} = V_{\\min}) = \\frac{V_{\\max} - \\mu_X}{V_{\\max} - V_{\\min}}, \\quad P(X_{\\min} = V_{\\max}) = \\frac{\\mu_X - V_{\\min}}{V_{\\max} - V_{\\min}}",
        "role": "Defines the extremal two-point distribution for min E[ln(X)]."
      },
      {
        "label": "eq-e-log-xmin",
        "latex": "\\mathbb{E}[\\ln(X_{\\min,\\mu})] = \\ln(V_{\\max}) + \\frac{V_{\\max} - \\mu}{V_{\\max} - V_{\\min}}(\\ln(V_{\\min}) - \\ln(V_{\\max}))",
        "role": "Explicit linear form of E[ln(X_min)] in μ, used to show convexity of h."
      },
      {
        "label": "eq-h-muy",
        "latex": "h(\\mu_Y) = [C_0 + C_1(\\mu_Y + \\kappa)] - \\ln(\\mu_Y)",
        "role": "Reduced objective function for minimization."
      },
      {
        "label": "eq-tight-bound",
        "latex": "\\ln\\left(\\frac{V_{\\max}}{V_{\\max} - \\kappa}\\right) = \\ln\\left(1 + \\frac{\\kappa}{V_{\\max} - \\kappa}\\right)",
        "role": "Tight worst-case lower bound at boundary."
      },
      {
        "label": "eq-loose-bound",
        "latex": "\\ln\\left(1 + \\frac{\\kappa}{V_{\\max}}\\right)",
        "role": "Simplified conservative lower bound stated in the lemma."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Jensen's Inequality",
        "field": "Convex Analysis",
        "description": "For a concave function f, the expectation satisfies E[f(X)] ≤ f(E[X]), with equality if X is constant.",
        "roleInProof": "Used to show that the maximum of E[ln(Y)] for fixed mean μ_Y is achieved by the deterministic distribution Y = μ_Y.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Concavity"
        ]
      },
      {
        "toolName": "Extremal Distributions",
        "field": "Probability Theory",
        "description": "Distributions that achieve the minimum or maximum expectation of a concave or convex function over random variables with fixed mean and support constraints.",
        "roleInProof": "Applied to identify the two-point distribution minimizing E[ln(X)] for fixed mean μ_X on [V_min, V_max].",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Jensen's Inequality",
          "Two-Point Distributions"
        ]
      },
      {
        "toolName": "Two-Point Distributions",
        "field": "Probability Theory",
        "description": "Distributions supported on exactly two points that extremize linear functionals or expectations under moment constraints.",
        "roleInProof": "Specifically used as the minimizer for E[ln(X)] due to the strict concavity of the logarithm.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Extremal Distributions"
        ]
      },
      {
        "toolName": "Convex Functions",
        "field": "Real Analysis",
        "description": "A function h is convex if for all x, y and λ ∈ [0,1], h(λx + (1-λ)y) ≤ λ h(x) + (1-λ) h(y); minima on intervals occur at endpoints for strictly convex functions.",
        "roleInProof": "Demonstrates that the reduced function h(μ_Y) is strictly convex, so its minimum is at an endpoint of [V_min, V_max - κ].",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Endpoint μ_Y = V_min",
        "condition": "μ_Y = V_min, μ_X = V_min + κ",
        "summary": "Evaluated but not the minimum; logarithmic gap larger due to steeper log at low values."
      },
      {
        "name": "Endpoint μ_Y = V_max - κ",
        "condition": "μ_Y = V_max - κ, μ_X = V_max",
        "summary": "Achieves the minimum difference ln(1 + κ/(V_max - κ)) due to flatter log at high values."
      }
    ],
    "remarks": [
      {
        "type": "insight",
        "text": "The worst-case occurs at high values because the derivative of ln(t) decreases, making the gap smaller for fixed mean difference κ."
      },
      {
        "type": "simplification",
        "text": "The bound ln(1 + κ/V_max) is looser but analytically simpler, valid since κ/(V_max - κ) > κ/V_max."
      }
    ],
    "gaps": [],
    "tags": [
      "extremal distributions",
      "concave functions",
      "Jensen inequality",
      "two-point distribution",
      "convex optimization",
      "lower bound",
      "logarithmic gap",
      "probability bounds"
    ]
  },
  {
    "label": "proof-lem-log-gap-upper-bound",
    "proves": "lem-log-gap-upper-bound",
    "proof_type": "variational",
    "proof_status": "complete",
    "strategy_summary": "The proof maximizes the difference E[ln(X)] - E[ln(Y)] by using Jensen's inequality for the maximum (deterministic X) and extremal two-point distributions for the minimum (Y), then optimizes over means mu_X and mu_Y under the constraint |mu_X - mu_Y| <= kappa, finding the worst case at the lower support boundary.",
    "conclusion": {
      "text": "|E[ln(X)] - E[ln(Y)]| <= ln(1 + kappa / V_min)",
      "latex": "|\\mathbb{E}[\\ln(X)] - \\mathbb{E}[\\ln(Y)]| \\le \\ln\\left(1 + \\frac{\\kappa}{V_{\\min}}\\right)"
    },
    "assumptions": [
      {
        "text": "X and Y are random variables with support in [V_min, V_max]",
        "latex": "X, Y \\in [V_{\\min}, V_{\\max}]"
      },
      {
        "text": "The means satisfy |mu_X - mu_Y| <= kappa",
        "latex": "|\\mu_X - \\mu_Y| \\le \\kappa"
      },
      {
        "text": "mu_X, mu_Y in [V_min, V_max]",
        "latex": "\\mu_X, \\mu_Y \\in [V_{\\min}, V_{\\max}]"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "explanation",
        "text": "Use extremal distribution theory for the concave function ln(t). To maximize E[ln(X)] for fixed mu_X, use deterministic X = mu_X by Jensen's inequality. To minimize E[ln(Y)] for fixed mu_Y, use two-point distribution Y_min on {V_min, V_max}.",
        "latex": null,
        "references": [],
        "derived_statement": "E[ln(X)] <= ln(mu_X); E[ln(Y)] >= E[ln(Y_min)]"
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "The difference E[ln(X)] - E[ln(Y)] <= ln(mu_X) - E[ln(Y_min)], where Y_min has masses P(Y_min = V_min) = (V_max - mu_Y)/(V_max - V_min), P(Y_min = V_max) = (mu_Y - V_min)/(V_max - V_min).",
        "latex": null,
        "references": [],
        "derived_statement": "E[ln(X)] - E[ln(Y)] <= ln(mu_X) - [(V_max - mu_Y)/(V_max - V_min) ln(V_min) + (mu_Y - V_min)/(V_max - V_min) ln(V_max)]"
      },
      {
        "order": 3,
        "kind": "optimization",
        "text": "Maximize ln(mu_X) - E[ln(Y_min)] over mu_X, mu_Y in [V_min, V_max] with |mu_X - mu_Y| <= kappa. The maximum occurs at mu_Y = V_min, mu_X = V_min + kappa, due to the curvature of ln near V_min.",
        "latex": null,
        "references": [],
        "derived_statement": "Worst-case: mu_Y = V_min, mu_X = V_min + kappa"
      },
      {
        "order": 4,
        "kind": "computation",
        "text": "For mu_Y = V_min, Y_min is deterministic at V_min, so E[ln(Y_min)] = ln(V_min). For X deterministic at mu_X, ln(mu_X) = ln(V_min + kappa). Thus, the bound is ln((V_min + kappa)/V_min) = ln(1 + kappa/V_min).",
        "latex": null,
        "references": [],
        "derived_statement": "ln(1 + kappa/V_min)"
      },
      {
        "order": 5,
        "kind": "extension",
        "text": "By symmetry, the bound holds for the reverse difference, yielding the absolute value bound.",
        "latex": null,
        "references": [],
        "derived_statement": "|E[ln(X)] - E[ln(Y)]| <= ln(1 + kappa/V_min)"
      }
    ],
    "key_equations": [
      {
        "label": "eq-y-min-masses",
        "latex": "P(Y_{\\min} = V_{\\min}) = \\frac{V_{\\max} - \\mu_Y}{V_{\\max} - V_{\\min}}, \\quad P(Y_{\\min} = V_{\\max}) = \\frac{\\mu_Y - V_{\\min}}{V_{\\max} - V_{\\min}}",
        "role": "Probabilities for the extremal two-point distribution"
      },
      {
        "label": "eq-e-ln-y-min",
        "latex": "\\mathbb{E}[\\ln(Y_{\\min})] = \\frac{V_{\\max} - \\mu_Y}{V_{\\max} - V_{\\min}} \\ln(V_{\\min}) + \\frac{\\mu_Y - V_{\\min}}{V_{\\max} - V_{\\min}} \\ln(V_{\\max})",
        "role": "Expectation of ln under extremal distribution"
      },
      {
        "label": "eq-upper-bound",
        "latex": "\\mathbb{E}[\\ln(X)] - \\mathbb{E}[\\ln(Y)] \\le \\ln(\\mu_X) - \\mathbb{E}[\\ln(Y_{\\min})]",
        "role": "Key inequality from extremal cases"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\ln\\left(1 + \\frac{\\kappa}{V_{\\min}}\\right)",
        "role": "Computed worst-case upper bound"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Jensen's Inequality",
        "field": "Convex Analysis",
        "description": "For a concave function f, the expectation E[f(X)] is at most f(E[X]), with equality for deterministic X.",
        "roleInProof": "Bounds the maximum of E[ln(X)] by ln(mu_X) for concave ln.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Concavity"
        ]
      },
      {
        "toolName": "Extremal Distributions",
        "field": "Probability Theory",
        "description": "For concave objectives, extremal expectations under fixed mean and support constraints are achieved at distributions with mass on boundaries, often two-point.",
        "roleInProof": "Identifies the minimizing distribution for E[ln(Y)] as a two-point mass on V_min and V_max.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Jensen's Inequality",
          "Moment Constraints"
        ]
      },
      {
        "toolName": "Symmetry Argument",
        "field": "Mathematical Analysis",
        "description": "Exploiting symmetry in the problem to reduce to one-sided cases and extend bounds to absolute values.",
        "roleInProof": "Simplifies to bounding one-sided difference and mirrors for the absolute gap.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Worst-case configuration",
        "condition": "mu_Y = V_min, mu_X = V_min + kappa",
        "summary": "The extremal two-point for Y degenerates to deterministic at V_min, maximizing the gap."
      },
      {
        "name": "Symmetric case",
        "condition": "mu_X = V_min, mu_Y = V_min + kappa",
        "summary": "Mirrors the bound for E[ln(Y)] - E[ln(X)]."
      }
    ],
    "remarks": [
      {
        "type": "insight",
        "text": "The steepest curvature of ln near V_min drives the worst case to the lower boundary."
      },
      {
        "type": "symmetry",
        "text": "The one-sided bound extends to absolute value by swapping X and Y."
      }
    ],
    "gaps": [],
    "tags": [
      "extremal distributions",
      "Jensen's inequality",
      "concave functions",
      "logarithmic gap",
      "two-point distribution",
      "symmetry",
      "variational optimization"
    ]
  },
  {
    "label": "proof-prop-corrective-signal-bound",
    "proves": "prop-corrective-signal-bound",
    "proof_type": "reference",
    "proof_status": "complete",
    "strategy_summary": "The proof applies a variance-to-mean separation lemma to guarantee a positive difference in means between high-error and low-error populations, leveraging the signal-to-noise condition and population fractions. It then uses a log-gap lower bound lemma to translate this mean separation into a positive lower bound on the difference in expected logarithms of rescaled diversity values.",
    "conclusion": {
      "text": "The expected logarithmic separation is bounded below by a positive quantity: $\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right) > 0$.",
      "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right)"
    },
    "assumptions": [
      {
        "text": "Var(d') ≥ κ_{d', var}",
        "latex": "\\operatorname{Var}(d') \\ge \\kappa_{d', \\text{var}}"
      },
      {
        "text": "Signal-to-Noise Condition is satisfied",
        "latex": null
      },
      {
        "text": "Population fractions f_H and f_L are N-uniform and bounded below by f_min > 0",
        "latex": "f_H, f_L \\ge f_{\\min} > 0"
      },
      {
        "text": "Rescaled values d' in [η, g_{A,max} + η]",
        "latex": "d' \\in [\\eta, g_{A,\\max} + \\eta]"
      },
      {
        "text": "High-error walkers have larger expected raw distance: E[d|H_k] > E[d|L_k]",
        "latex": "\\mathbb{E}[d|H_k] > \\mathbb{E}[d|L_k]"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "lemma-application",
        "text": "Apply the variance-to-mean separation lemma using Var(d') ≥ κ_{d', var}, signal-to-noise condition, and population fractions f_H, f_L ≥ f_min > 0.",
        "latex": null,
        "references": [
          "lem-variance-to-mean-separation"
        ],
        "derived_statement": "|μ_{d'}(H_k) - μ_{d'}(L_k)| ≥ κ_{d', mean} > 0"
      },
      {
        "order": 1.1,
        "kind": "directional-argument",
        "text": "Geometric separation (from Chapter 6) ensures E[d|H_k] > E[d|L_k], preserved through monotonic rescaling, so μ_{d'}(H_k) > μ_{d'}(L_k) + κ_{d', mean}.",
        "latex": null,
        "references": [
          "lem-geometric-separation-of-partition"
        ],
        "derived_statement": "μ_{d'}(H_k) ≥ μ_{d'}(L_k) + κ_{d', mean}"
      },
      {
        "order": 2,
        "kind": "lemma-application",
        "text": "Apply the log-gap lower bound lemma with X ~ d'|H_k, Y ~ d'|L_k, κ = κ_{d', mean}, V_max = g_{A,max} + η.",
        "latex": null,
        "references": [
          "lem-log-gap-lower-bound"
        ],
        "derived_statement": "E[ln(d')|H_k] - E[ln(d')|L_k] ≥ ln(1 + κ_{d', mean}/(g_{A,max} + η)) > 0"
      }
    ],
    "key_equations": [
      {
        "label": "eq-mean-separation",
        "latex": "|\\mu_{d'}(H_k) - \\mu_{d'}(L_k)| \\ge \\kappa_{d', \\text{mean}} > 0",
        "role": "Guaranteed mean separation"
      },
      {
        "label": "eq-directional-mean",
        "latex": "\\mu_{d'}(H_k) \\ge \\mu_{d'}(L_k) + \\kappa_{d', \\text{mean}}",
        "role": "Directional mean separation"
      },
      {
        "label": "eq-log-separation",
        "latex": "\\mathbb{E}[\\ln(d')|H_k] - \\mathbb{E}[\\ln(d')|L_k] \\ge \\ln\\left(1 + \\frac{\\kappa_{d', \\text{mean}}}{g_{A,\\max}+\\eta}\\right)",
        "role": "Final logarithmic separation bound"
      }
    ],
    "references": [
      "lem-variance-to-mean-separation",
      "lem-log-gap-lower-bound",
      "lem-geometric-separation-of-partition"
    ],
    "math_tools": [
      {
        "toolName": "Variance-to-Mean Separation",
        "field": "Statistics",
        "description": "A lemma that bounds the separation between population means given a minimum variance and signal-to-noise conditions.",
        "roleInProof": "Used to establish a guaranteed positive mean separation in rescaled diversity values between high-error and low-error sets.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Signal-to-Noise Condition"
        ]
      },
      {
        "toolName": "Log-Gap Lower Bound",
        "field": "Analysis",
        "description": "A lemma providing a lower bound on the difference of expected logarithms of random variables with separated means and bounded support.",
        "roleInProof": "Applied to derive a positive lower bound on the expected log-difference from the mean separation.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Jensen's Inequality"
        ]
      },
      {
        "toolName": "N-Uniform Distribution",
        "field": "Probability",
        "description": "A distribution assumption ensuring population fractions are bounded away from zero.",
        "roleInProof": "Supports the application of the variance-to-mean separation lemma by guaranteeing non-degenerate population sizes.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Population Fractions"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "directionality",
        "text": "The inequality direction is preserved due to the monotonicity of the rescaling function and the geometric isolation of high-error walkers."
      },
      {
        "type": "positivity",
        "text": "Since κ_{d', mean} > 0, the logarithmic lower bound is strictly positive."
      }
    ],
    "gaps": [],
    "tags": [
      "variance-separation",
      "mean-separation",
      "logarithmic-gap",
      "corrective-signal",
      "population-fractions",
      "signal-to-noise"
    ]
  },
  {
    "label": "proof-prop-adversarial-signal-bound-naive",
    "proves": "prop-adversarial-signal-bound-naive",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof derives an upper bound on the adversarial signal by first establishing the maximum possible mean separation of rescaled rewards between subpopulations, then applying a lemma to convert this into a bound on the difference of expected logarithms.",
    "conclusion": {
      "text": "|\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k]| \\le \\ln\\left(1 + \\frac{g_{A,\\max}}{\\eta}\\right)",
      "latex": "|\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k]| \\le \\ln\\left(1 + \\frac{g_{A,\\max}}{\\eta}\\right)"
    },
    "assumptions": [
      {
        "text": "Rescaled reward values r' are contained in the interval [\\eta, g_{A,\\max} + \\eta]",
        "latex": "r' \\in [\\eta, g_{A,\\max} + \\eta]"
      },
      {
        "text": "Mean rewards of subpopulations lie within the support interval of r'",
        "latex": "\\mu_{r'}(L_k), \\mu_{r'}(H_k) \\in [\\eta, g_{A,\\max} + \\eta]"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "bounding",
        "text": "Bound the maximum possible mean separation between subpopulations L_k and H_k. Since means lie within the interval [\\eta, g_{A,\\max} + \\eta], the difference is at most g_{A,\\max}. Define \\kappa_{r', \\text{mean, max}} := g_{A,\\max}.",
        "latex": "|\\mu_{r'}(L_k) - \\mu_{r'}(H_k)| \\le g_{A,\\max}",
        "references": [],
        "derived_statement": "\\kappa_{r', \\text{mean, max}} := g_{A,\\max}"
      },
      {
        "order": 2,
        "kind": "application",
        "text": "Apply the log-gap upper bound lemma to the distributions of r' in L_k and H_k, using \\kappa = \\kappa_{r', \\text{mean, max}} and minimum value V_{\\min} = \\eta, yielding the bound on the logarithmic mean separation.",
        "latex": "|\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k]| \\le \\ln\\left(1 + \\frac{\\kappa_{r', \\text{mean, max}}}{\\eta}\\right) = \\ln\\left(1 + \\frac{g_{A,\\max}}{\\eta}\\right)",
        "references": [
          "lem-log-gap-upper-bound"
        ],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-mean-separation",
        "latex": "|\\mu_{r'}(L_k) - \\mu_{r'}(H_k)| \\le g_{A,\\max}",
        "role": "Bounds the maximum mean difference"
      },
      {
        "label": "eq-log-separation",
        "latex": "|\\mathbb{E}[\\ln(r')|L_k] - \\mathbb{E}[\\ln(r')|H_k]| \\le \\ln\\left(1 + \\frac{g_{A,\\max}}{\\eta}\\right)",
        "role": "Final upper bound on adversarial signal"
      }
    ],
    "references": [
      "lem-log-gap-upper-bound"
    ],
    "math_tools": [
      {
        "toolName": "Bound on mean separation",
        "field": "Probability",
        "description": "The difference in means of random variables supported on a bounded interval is at most the length of the interval.",
        "roleInProof": "Used to bound the maximum possible difference in expected rescaled rewards between low- and high-error sets.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      },
      {
        "toolName": "Log-gap upper bound lemma",
        "field": "Probability",
        "description": "An upper bound on the difference of expected logarithms of two distributions based on their mean difference and the minimum support value.",
        "roleInProof": "Applied to obtain the logarithmic mean separation bound from the mean separation and minimum reward value.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Jensen's inequality"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "explanation",
        "text": "This bound holds under the weakest assumptions, considering the most adversarial configuration of mean rewards without landscape regularity constraints."
      }
    ],
    "gaps": [],
    "tags": [
      "adversarial signal",
      "mean separation",
      "logarithmic bound",
      "upper bound",
      "rescaled rewards",
      "expectation",
      "proof"
    ]
  },
  {
    "label": "proof-prop-raw-reward-mean-gap-bound",
    "proves": "prop-raw-reward-mean-gap-bound",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof rewrites the mean reward difference as an average over pairwise differences, applies the triangle inequality to bound the absolute sum by the sum of absolutes, uses the Lipschitz property to relate reward differences to distances, and further bounds distances by the domain diameter to obtain the final upper bound.",
    "conclusion": {
      "text": "The mean reward difference is bounded by L_R \\cdot D_{\\mathrm{valid}}, denoted as \\kappa_{\\mathrm{raw},r,\\text{adv}}.",
      "latex": "\\left| \\frac{1}{|L_k|} \\sum_{l \\in L_k} R(x_l) - \\frac{1}{|H_k|} \\sum_{h \\in H_k} R(x_h) \\right| \\leq L_R D_{\\mathrm{valid}} = \\kappa_{\\mathrm{raw},r,\\text{adv}}"
    },
    "assumptions": [
      {
        "text": "The reward function R is L_R-Lipschitz continuous.",
        "latex": "|R(x) - R(y)| \\leq L_R d(x, y)"
      },
      {
        "text": "The valid domain has finite diameter D_{\\mathrm{valid}}.",
        "latex": "D_{\\mathrm{valid}} = \\sup_{x,y \\in \\mathrm{valid}} d(x,y) < \\infty"
      }
    ],
    "steps": [],
    "key_equations": [
      {
        "label": "eq-mean-reward-diff",
        "latex": "\\left| \\frac{1}{|L_k|} \\sum_{l \\in L_k} R(x_l) - \\frac{1}{|H_k|} \\sum_{h \\in H_k} R(x_h) \\right| = \\frac{1}{|L_k| |H_k|} \\left| \\sum_{l,h} (R(x_l) - R(x_h)) \\right|",
        "role": "initial-expression"
      },
      {
        "label": "eq-triangle-bound",
        "latex": "\\left| \\sum_{l,h} (R(x_l) - R(x_h)) \\right| \\leq \\sum_{l,h} |R(x_l) - R(x_h)|",
        "role": "triangle-inequality"
      },
      {
        "label": "eq-lipschitz-bound",
        "latex": "\\sum_{l,h} |R(x_l) - R(x_h)| \\leq L_R \\sum_{l,h} d(x_l, x_h)",
        "role": "lipschitz-application"
      },
      {
        "label": "eq-diameter-bound",
        "latex": "L_R \\sum_{l,h} d(x_l, x_h) \\leq |L_k| |H_k| L_R D_{\\mathrm{valid}}",
        "role": "diameter-bound"
      },
      {
        "label": "eq-final-gap",
        "latex": "\\left| \\frac{1}{|L_k|} \\sum_{l} R(x_l) - \\frac{1}{|H_k|} \\sum_{h} R(x_h) \\right| \\leq L_R D_{\\mathrm{valid}} = \\kappa_{\\mathrm{raw},r,\\text{adv}}",
        "role": "conclusion"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Triangle Inequality",
        "field": "Analysis",
        "description": "For any numbers a_i, |\\sum a_i| \\leq \\sum |a_i|.",
        "roleInProof": "Bounds the absolute value of the sum of reward differences by the sum of their absolute values.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Lipschitz Continuity"
        ]
      },
      {
        "toolName": "Lipschitz Continuity",
        "field": "Analysis",
        "description": "A function f satisfies |f(x) - f(y)| \\leq L d(x, y) for some constant L and distance d.",
        "roleInProof": "Bounds each individual |R(x_l) - R(x_h)| by L_R times the distance d(x_l, x_h).",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Triangle Inequality"
        ]
      },
      {
        "toolName": "Diameter of a Metric Space",
        "field": "Metric Spaces",
        "description": "The diameter D of a set is the supremum of distances d(x, y) for x, y in the set.",
        "roleInProof": "Provides an upper bound D_{\\mathrm{valid}} for all pairwise distances d(x_l, x_h) in the valid domain.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "interpretation",
        "text": "This maximum possible raw reward gap, \\kappa_{\\mathrm{raw},r,\\text{adv}}, represents the tightest axiom-based constraint on how deceptive the landscape can be."
      }
    ],
    "gaps": [],
    "tags": [
      "reward-gap",
      "lipschitz-continuity",
      "triangle-inequality",
      "diameter-bound",
      "mean-difference"
    ]
  },
  {
    "label": "proof-prop-log-reward-gap-axiom-bound",
    "proves": "prop-log-reward-gap-axiom-bound",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof first derives a uniform bound on the maximum difference between any two rescaled reward values using Lipschitz continuity of the rescaling function and raw reward properties. It then shows that the difference in means between subpopulations is at most this maximum pairwise difference. Finally, it applies a referenced lemma on logarithmic gaps to obtain the bound on the expected log-reward difference.",
    "conclusion": {
      "text": "The one-sided expected logarithmic reward gap is bounded as E[ln(r') | L_k] - E[ln(r') | H_k] ≤ ln(1 + κ_rescaled(L_R D_valid) / η).",
      "latex": "$\\mathbb{E}[\\ln(r') \\mid L_k] - \\mathbb{E}[\\ln(r') \\mid H_k] \\le \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_R D_{\\text{valid}})}{\\eta}\\right)$"
    },
    "assumptions": [
      {
        "text": "The rescaling function g_A is Lipschitz continuous with constant L_g (maximum derivative).",
        "latex": null
      },
      {
        "text": "The patched standard deviation σ'_R is bounded below by σ'_{min,patch} > 0.",
        "latex": null
      },
      {
        "text": "Raw rewards satisfy |R_a - R_b| ≤ L_R D_valid due to Lipschitz property.",
        "latex": null
      },
      {
        "text": "Rescaled rewards r' are bounded below by η > 0.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "bound",
        "text": "Establish a uniform upper bound on the maximum microscopic gap |r'_a - r'_b| between any two rescaled reward values using Lipschitz continuity of g_A, the lower bound on σ'_R, and the bound on raw reward differences.",
        "latex": null,
        "references": [],
        "derived_statement": "|r'_a - r'_b| ≤ κ_rescaled(L_R D_valid)"
      },
      {
        "order": 2,
        "kind": "inequality",
        "text": "Argue that the mean separation |μ_{r'}(L_k) - μ_{r'}(H_k)| between low-error and high-error subpopulations cannot exceed the maximum microscopic gap, as it is a weighted average of pairwise differences.",
        "latex": null,
        "references": [],
        "derived_statement": "|μ_{r'}(L_k) - μ_{r'}(H_k)| ≤ κ_rescaled(L_R D_valid)"
      },
      {
        "order": 3,
        "kind": "application",
        "text": "Apply the lemma for upper-bounding logarithmic gaps to the bounded mean separation, with X as the distribution of r' in L_k, Y in H_k, κ = κ_{r',mean,adv} = κ_rescaled(L_R D_valid), and V_min = η, yielding the bound on the expected log-reward difference.",
        "latex": null,
        "references": [
          "lem-log-gap-upper-bound"
        ],
        "derived_statement": "|E[ln(r') | L_k] - E[ln(r') | H_k]| ≤ ln(1 + κ_rescaled(L_R D_valid)/η)"
      }
    ],
    "key_equations": [
      {
        "label": "eq-micro-gap",
        "latex": "$|r'_a - r'_b| = |g_A(z_a) - g_A(z_b)| \\le L_g |z_a - z_b| = \\frac{L_g}{\\sigma'_R} |R_a - R_b| \\le \\frac{L_g}{\\sigma'_{\\min,\\text{patch}}} (L_R D_{\\text{valid}}) = \\kappa_{\\mathrm{rescaled}}(L_R D_{\\text{valid}})$",
        "role": "Bounds the maximum microscopic rescaled reward gap."
      },
      {
        "label": "eq-mean-sep",
        "latex": "$|\\mu_{r'}(L_k) - \\mu_{r'}(H_k)| \\le \\max_{a,b} |r'_a - r'_b| \\le \\kappa_{\\mathrm{rescaled}}(L_R D_{\\text{valid}})$",
        "role": "Bounds the macroscopic mean separation by the microscopic maximum."
      },
      {
        "label": "eq-log-bound",
        "latex": "$|\\mathbb{E}[\\ln(r') \\mid L_k] - \\mathbb{E}[\\ln(r') \\mid H_k]| \\le \\ln\\left(1 + \\frac{\\kappa_{r',\\text{mean,adv}}}{\\eta}\\right) = \\ln\\left(1 + \\frac{\\kappa_{\\mathrm{rescaled}}(L_R D_{\\text{valid}})}{\\eta}\\right)$",
        "role": "Final bound on the logarithmic mean separation using the referenced lemma."
      }
    ],
    "references": [
      "lem-log-gap-upper-bound"
    ],
    "math_tools": [
      {
        "toolName": "Lipschitz Continuity",
        "field": "Real Analysis",
        "description": "A function f is Lipschitz continuous with constant L if |f(x) - f(y)| ≤ L |x - y| for all x, y, often derived from bounded derivatives.",
        "roleInProof": "Applied to the rescaling function g_A and raw rewards R to bound microscopic differences in rescaled rewards |r'_a - r'_b| in terms of raw reward gaps.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Bounded Derivative"
        ]
      },
      {
        "toolName": "Expectation of Differences",
        "field": "Probability Theory",
        "description": "The absolute difference between expectations |E[X] - E[Y]| is bounded by the expected absolute difference E[|X - Y|], which in turn is at most the maximum |X - Y| for bounded supports.",
        "roleInProof": "Used to bound the mean rescaled reward separation |μ_{r'}(L_k) - μ_{r'}(H_k)| by the maximum microscopic gap.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Jensen's Inequality"
        ]
      },
      {
        "toolName": "Logarithmic Gap Bound",
        "field": "Inequality Theory",
        "description": "A lemma providing an upper bound on the difference in expected logarithms of two distributions based on their mean separation and a minimum value.",
        "roleInProof": "Directly applied to bound the difference in expected log-rescaled rewards using the established mean separation.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Jensen's Inequality",
          "Concavity of Logarithm"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The bound applies to the one-sided difference E[ln(r') | L_k] - E[ln(r') | H_k] since the absolute value bound implies the one-sided version."
      }
    ],
    "gaps": [],
    "tags": [
      "Lipschitz continuity",
      "rescaled rewards",
      "mean separation",
      "logarithmic bound",
      "signal propagation",
      "microscopic gap",
      "adversarial robustness"
    ]
  },
  {
    "label": "proof-thm-stability-condition-final-corrected",
    "proves": "thm-stability-condition-final-corrected",
    "proof_type": "reference",
    "proof_status": "complete",
    "strategy_summary": "The proof directly assembles the lower bound on the corrective signal from the referenced proposition prop-corrective-signal-bound and the upper bound on the adversarial signal from prop-log-reward-gap-axiom-bound, substituting them into the core trade-off inequality β × (Corrective Gap) > α × (Adversarial Gap) to establish the final stability condition for intelligence.",
    "conclusion": {
      "text": "The inequality β × (Corrective Gap) > α × (Adversarial Gap), with Corrective Gap lower bounded by the result from prop-corrective-signal-bound and Adversarial Gap upper bounded by the result from prop-log-reward-gap-axiom-bound, yields the final corrected stability condition.",
      "latex": null
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "explanation",
        "text": "The condition for intelligence requires the guaranteed minimum of the corrective signal to exceed the allowed maximum of the adversarial signal, as per the core trade-off inequality.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "reference",
        "text": "Lower bound for the LHS (Corrective Signal): Given by prop-corrective-signal-bound.",
        "latex": null,
        "references": [
          "prop-corrective-signal-bound"
        ],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "reference",
        "text": "Upper bound for the RHS (Adversarial Signal): Given by prop-log-reward-gap-axiom-bound (axiom-based bound).",
        "latex": null,
        "references": [
          "prop-log-reward-gap-axiom-bound"
        ],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "substitution",
        "text": "Substitute the lower bound for the corrective signal and the upper bound for the adversarial signal into the inequality β × (Corrective Gap) > α × (Adversarial Gap).",
        "latex": null,
        "references": [
          "prop-corrective-signal-bound",
          "prop-log-reward-gap-axiom-bound"
        ],
        "derived_statement": "Final corrected stability condition."
      }
    ],
    "key_equations": [
      {
        "label": "eq-stability-tradeoff",
        "latex": "\\beta \\times (\\text{Corrective Gap}) > \\alpha \\times (\\text{Adversarial Gap})",
        "role": "Core trade-off inequality into which bounds are substituted."
      }
    ],
    "references": [
      "prop-corrective-signal-bound",
      "prop-log-reward-gap-axiom-bound"
    ],
    "math_tools": [],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "This proof provides the final, corrected version of the stability condition by assembling preceding bounds."
      }
    ],
    "gaps": [],
    "tags": [
      "stability-condition",
      "corrective-signal",
      "adversarial-signal",
      "bounds-assembly",
      "trade-off-inequality",
      "intelligence-condition"
    ]
  },
  {
    "label": "proof-lem-unfit-fraction-lower-bound",
    "proves": "lem-unfit-fraction-lower-bound",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof leverages the zero-sum property of deviations from the mean fitness to equate positive and negative deviations, then uses case analysis on the mean's position within the fitness range to derive a lower bound on the unfit set size via uniform potential bounds.",
    "conclusion": {
      "text": "The fraction of unfit walkers satisfies |U_k|/k ≥ f_U(ε), where f_U(ε) = κ_{V,gap}(ε) / (2 (V_{pot,max} - V_{pot,min})) is a strictly positive, N-uniform, and ε-dependent constant.",
      "latex": "$\\frac{|U_k|}{k} \\ge f_U(\\epsilon) = \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2(V_{\\text{pot,max}} - V_{\\text{pot,min}})}$"
    },
    "assumptions": [
      {
        "text": "V_{pot,max} and V_{pot,min} are N-uniform bounds on the fitness potential from Lemma on potential bounds.",
        "latex": "$V_{\\text{pot,max}}$ and $V_{\\text{pot,min}}$ are the N-uniform bounds on the fitness potential from [](#lem-potential-bounds)."
      },
      {
        "text": "κ_{V,gap}(ε) is an ε-dependent gap in the fitness range, with V_{max,k} - V_{min,k} ≥ κ_{V,gap}(ε).",
        "latex": "$V_{\\max,k} - V_{\\min,k} \\ge \\kappa_{V,\\text{gap}}(\\epsilon)$"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "principle",
        "text": "By the definition of the mean μ_{V,k}, the sum of all deviations from the mean is zero. Let F_k be the fit set (complement of U_k). Partitioning the sum over these two sets shows that the total positive deviation equals the magnitude of the total negative deviation.",
        "latex": "\\sum_{i \\in F_k} (V_{k,i} - \\mu_{V,k}) = \\sum_{j \\in U_k} (\\mu_{V,k} - V_{k,j})",
        "references": [],
        "derived_statement": "Balanced deviations principle."
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "The total range of fitness values, V_{max,k} - V_{min,k}, can be partitioned at the mean: V_{max,k} - V_{min,k} = (V_{max,k} - μ_{V,k}) + (μ_{V,k} - V_{min,k}). Since both terms are non-negative, at least one is ≥ half the range. Using the premise, max((V_{max,k} - μ_{V,k}), (μ_{V,k} - V_{min,k})) ≥ κ_{V,gap}(ε)/2.",
        "latex": "\\max\\left( (V_{\\max,k} - \\mu_{V,k}), (\\mu_{V,k} - V_{\\min,k}) \\right) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "references": [],
        "derived_statement": "Dominant deviation bound."
      },
      {
        "order": 3,
        "kind": "case",
        "text": "Case A: If (V_{max,k} - μ_{V,k}) ≥ κ_{V,gap}(ε)/2. The sum of positive deviations ≥ this value, so sum of negative deviations ≥ κ_{V,gap}(ε)/2. Bound by |U_k| times max deviation (V_{pot,max} - V_{pot,min}): |U_k| · (V_{pot,max} - V_{pot,min}) ≥ κ_{V,gap}(ε)/2.",
        "latex": "|U_k| \\cdot (V_{\\text{pot,max}} - V_{\\text{pot,min}}) \\ge \\sum_{j \\in U_k} (\\mu_{V,k} - V_{k,j}) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "references": [
          "lem-potential-bounds"
        ],
        "derived_statement": "Lower bound on |U_k| in Case A."
      },
      {
        "order": 4,
        "kind": "case",
        "text": "Case B: If (μ_{V,k} - V_{min,k}) ≥ κ_{V,gap}(ε)/2. Symmetric argument gives lower bound on |F_k|, implying upper bound on |U_k|. The Case A bound provides the worst-case lower bound for |U_k|.",
        "latex": "|F_k| \\cdot (V_{\\text{pot,max}} - V_{\\text{pot,min}}) \\ge \\sum_{i \\in F_k} (V_{i,k} - \\mu_{V,k}) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "references": [
          "lem-potential-bounds"
        ],
        "derived_statement": "Upper bound on |U_k| via |F_k| in Case B; Case A is tighter for lower bound."
      },
      {
        "order": 5,
        "kind": "conclusion",
        "text": "Rearranging the inequality from Case A and dividing by k gives |U_k|/k ≥ κ_{V,gap}(ε) / (2 (V_{pot,max} - V_{pot,min})), a positive N-uniform constant f_U(ε).",
        "latex": "\\frac{|U_k|}{k} \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2(V_{\\text{pot,max}} - V_{\\text{pot,min}})}",
        "references": [],
        "derived_statement": "Final fraction bound."
      }
    ],
    "key_equations": [
      {
        "label": "eq-balanced-deviations",
        "latex": "\\sum_{i \\in F_k} (V_{k,i} - \\mu_{V,k}) = \\sum_{j \\in U_k} (\\mu_{V,k} - V_{k,j})",
        "role": "Equates positive and negative deviations from the mean."
      },
      {
        "label": "eq-dominant-deviation",
        "latex": "\\max\\left( (V_{\\max,k} - \\mu_{V,k}), (\\mu_{V,k} - V_{\\min,k}) \\right) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "role": "Bounds the larger half of the fitness range relative to the mean."
      },
      {
        "label": "eq-unfit-bound",
        "latex": "|U_k| \\cdot (V_{\\text{pot,max}} - V_{\\text{pot,min}}) \\ge \\sum_{j \\in U_k} (\\mu_{V,k} - V_{k,j}) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "role": "Lower bounds the size of the unfit set in Case A."
      },
      {
        "label": "eq-fit-bound",
        "latex": "|F_k| \\cdot (V_{\\text{pot,max}} - V_{\\text{pot,min}}) \\ge \\sum_{i \\in F_k} (V_{i,k} - \\mu_{V,k}) \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2}",
        "role": "Lower bounds the fit set size in Case B."
      },
      {
        "label": "eq-final-fraction",
        "latex": "\\frac{|U_k|}{k} \\ge \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2(V_{\\text{pot,max}} - V_{\\text{pot,min}})}",
        "role": "Concludes the lower bound on the unfit fraction."
      }
    ],
    "references": [
      "lem-potential-bounds"
    ],
    "math_tools": [
      {
        "toolName": "Principle of Balanced Deviations",
        "field": "Statistics",
        "description": "The sum of deviations from the arithmetic mean over a set is zero, allowing partitioning into positive and negative components that balance each other.",
        "roleInProof": "Equates the total positive deviations in the fit set to the total negative deviations in the unfit set, enabling bounds on set sizes.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Arithmetic Mean"
        ]
      },
      {
        "toolName": "Case Analysis",
        "field": "Mathematical Proof Techniques",
        "description": "Dividing a proof into exhaustive cases based on conditions to handle different scenarios separately.",
        "roleInProof": "Handles the two possible dominant halves of the fitness range relative to the mean.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Max Function"
        ]
      },
      {
        "toolName": "Uniform Bounds",
        "field": "Analysis",
        "description": "Constants independent of certain parameters (e.g., dimension N) that bound quantities uniformly.",
        "roleInProof": "Provides N-uniform limits on potential range to ensure the lower bound is N-uniform.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Epsilon-Dependence"
        ]
      },
      {
        "toolName": "Arithmetic Mean",
        "field": "Statistics",
        "description": "The average value of a set of numbers, serving as a central tendency measure.",
        "roleInProof": "Defines the reference point μ_{V,k} for deviations in the fitness values.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Principle of Balanced Deviations"
        ]
      },
      {
        "toolName": "Max Function",
        "field": "Mathematical Analysis",
        "description": "The maximum of a set of values, used to capture the larger component.",
        "roleInProof": "Identifies the dominant deviation direction to bound the total deviation.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Case Analysis"
        ]
      }
    ],
    "cases": [
      {
        "name": "Case A",
        "condition": "(V_{max,k} - μ_{V,k}) ≥ κ_{V,gap}(ε)/2",
        "summary": "Dominant positive deviation; directly bounds |U_k| via negative deviations and potential range."
      },
      {
        "name": "Case B",
        "condition": "(μ_{V,k} - V_{min,k}) ≥ κ_{V,gap}(ε)/2",
        "summary": "Dominant negative deviation; bounds |F_k|, implying |U_k| is not too large, but Case A gives the global lower bound."
      }
    ],
    "remarks": [
      {
        "type": "explanation",
        "text": "Case B provides an upper bound on the unfit set, but the proof relies on Case A for the worst-case lower bound, ensuring positivity of f_U(ε)."
      },
      {
        "type": "uniformity",
        "text": "The bound f_U(ε) inherits N-uniformity from the potential bounds in Lemma lem-potential-bounds and the gap function."
      }
    ],
    "gaps": [],
    "tags": [
      "balanced deviations",
      "mean fitness",
      "case analysis",
      "lower bound",
      "unfit fraction",
      "fitness potential"
    ]
  },
  {
    "label": "proof-thm-unfit-high-error-overlap-fraction",
    "proves": "thm-unfit-high-error-overlap-fraction",
    "proof_type": "contradiction",
    "proof_status": "complete",
    "strategy_summary": "Assume vanishing overlap between unfit and high-error sets, implying high-error walkers are mostly fit with above-average fitness, which contradicts the Stability Condition guaranteeing that high-error walkers have below-average fitness as a weighted average effect.",
    "conclusion": {
      "text": "The overlap fraction must be bounded below by a strictly positive constant, specifically an N-uniform constant monotonic in the fitness gap from the Stability Condition.",
      "latex": "$f_{UH} \\geq f_{UH}(\\varepsilon) > 0$, where $f_{UH}(\\varepsilon)$ is monotonic in the fitness gap."
    },
    "assumptions": [
      {
        "text": "The swarm k has a large structural error.",
        "latex": null
      },
      {
        "text": "The Stability Condition is satisfied.",
        "latex": null
      },
      {
        "text": "Both high-error (H_k) and low-error (L_k) sets are non-empty with non-vanishing fractions (f_H > 0, f_L > 0).",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "setup",
        "text": "Assume premises hold: large structural error in swarm k and Stability Condition satisfied. For contradiction, assume vanishing overlap: f_UH = |U_k ∩ H_k|/k ≈ 0.",
        "latex": "$f_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0$",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "consequence",
        "text": "If overlap ≈0, then H_k ≈ H_k ∩ F_k, where F_k is the fit set with V_{k,j} > μ_{V,k} for j in F_k. Thus, expected fitness in H_k > mean: E[V | i ∈ H_k] > μ_{V,k}.",
        "latex": "$\\mathbb{E}[V \\mid i \\in H_k] > \\mu_{V,k}$",
        "references": [],
        "derived_statement": "E[V_fit | H_k] > μ_{V,k} (*)"
      },
      {
        "order": 3,
        "kind": "application",
        "text": "By Stability Condition, E[V | i ∈ H_k] < E[V | i ∈ L_k]. Swarm mean μ_{V,k} = f_H E[V|H_k] + f_L E[V|L_k], and since f_H >0, f_L>0, the mean lies strictly between, so E[V | i ∈ H_k] < μ_{V,k}.",
        "latex": "$\\mathbb{E}[V \\mid i \\in H_k] < \\mathbb{E}[V \\mid i \\in L_k]$ and $\\mu_{V,k} = f_H \\mathbb{E}[V|H_k] + f_L \\mathbb{E}[V|L_k]$",
        "references": [
          "thm-stability-condition-final-corrected"
        ],
        "derived_statement": "E[V_fit | H_k] < μ_{V,k} (**)"
      },
      {
        "order": 4,
        "kind": "contradiction",
        "text": "(*) implies E[V | H_k] > μ_{V,k}, while (**) implies E[V | H_k] < μ_{V,k}, a direct contradiction.",
        "latex": null,
        "references": [],
        "derived_statement": "Contradiction in fitness expectation."
      },
      {
        "order": 5,
        "kind": "conclusion",
        "text": "Assumption of vanishing overlap is false; thus, overlap fraction bounded below by positive constant from detailed distribution analysis.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-fuh",
        "latex": "$f_{UH} = \\frac{|U_k \\cap H_k|}{k} \\approx 0$",
        "role": "Definition of vanishing overlap assumption."
      },
      {
        "label": "eq-fit-high",
        "latex": "$\\mathbb{E}[V \\mid i \\in H_k] > \\mu_{V,k}$",
        "role": "Consequence of high-error set being mostly fit."
      },
      {
        "label": "eq-stability",
        "latex": "$\\mathbb{E}[V \\mid i \\in H_k] < \\mathbb{E}[V \\mid i \\in L_k]$",
        "role": "Guarantee from Stability Condition."
      },
      {
        "label": "eq-weighted-mean",
        "latex": "$\\mu_{V,k} = f_H \\mathbb{E}[V|H_k] + f_L \\mathbb{E}[V|L_k]$",
        "role": "Swarm mean as weighted average, implying strict inequality."
      }
    ],
    "references": [
      "thm-stability-condition-final-corrected"
    ],
    "math_tools": [
      {
        "toolName": "Proof by Contradiction",
        "field": "Mathematical Logic",
        "description": "A proof technique that assumes the negation of the statement to be proven and derives a logical contradiction.",
        "roleInProof": "Structures the entire argument by assuming zero overlap and showing inconsistency with the Stability Condition.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Expectation"
        ]
      },
      {
        "toolName": "Conditional Expectation",
        "field": "Probability Theory",
        "description": "The expected value of a random variable given that it belongs to a specific subset or event.",
        "roleInProof": "Used to compare fitness expectations in high-error and low-error populations against the swarm mean.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Weighted Average"
        ]
      },
      {
        "toolName": "Weighted Average",
        "field": "Statistics",
        "description": "A mean computed as a sum of values weighted by their proportions.",
        "roleInProof": "Establishes that the swarm mean fitness lies strictly between high-error and low-error expectations when both fractions are positive.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Conditional Expectation"
        ]
      },
      {
        "toolName": "Set Intersection and Cardinality",
        "field": "Set Theory",
        "description": "Measures the size of overlap between sets using intersection and division by total size for fractions.",
        "roleInProof": "Defines the overlap fraction f_UH and assumes it approaches zero to derive consequences.",
        "levelOfAbstraction": "Notation",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "Detailed analysis of underlying distributions provides the explicit lower bound f_UH(ε) as an N-uniform constant monotonic in the fitness gap."
      }
    ],
    "gaps": [],
    "tags": [
      "contradiction",
      "stability-condition",
      "fitness-expectation",
      "set-overlap",
      "high-error",
      "unfit-population",
      "swarm-walkers"
    ]
  },
  {
    "label": "proof-lem-mean-companion-fitness-gap",
    "proves": "lem-mean-companion-fitness-gap",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof derives an algebraic expression for the mean companion fitness and its difference from an individual's fitness, bounds this gap using the population fractions of unfit and fit groups, and lower-bounds the inter-group mean difference via variance decomposition and the fitness range constraint.",
    "conclusion": {
      "text": "For i ∈ U_k, μ_{comp,i} - V_{k,i} ≥ \frac{f_U f_F}{(k-1)(f_F + f_U^2 / f_F)} κ_{V,gap}(ε)",
      "latex": "\\mu_{\\text{comp},i} - V_{k,i} \\geq \\frac{f_U f_F}{(k-1)(f_F + f_U^2 / f_F)} \\kappa_{V,\\text{gap}}(\\epsilon)"
    },
    "assumptions": [
      {
        "text": "k ≥ 2 (number of alive walkers)",
        "latex": null
      },
      {
        "text": "f_U + f_F = 1, f_U, f_F > 0 (population fractions of unfit and fit sets)",
        "latex": null
      },
      {
        "text": "V_{k,j} ∈ [V_{min,k}, V_{max,k}] for all j ∈ A_k, with range κ_{V,gap}(ε) = V_{max,k} - V_{min,k}",
        "latex": null
      },
      {
        "text": "U_k and F_k partition the alive walkers A_k, with V_{k,i} ≤ μ_{V,k} for i ∈ U_k",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "algebraic derivation",
        "text": "Express the mean companion fitness μ_{comp,i} for i ∈ U_k as the average fitness of other alive walkers, yielding μ_{comp,i} = (1/(k-1)) (k μ_{V,k} - V_{k,i}).",
        "latex": "\\mu_{\\text{comp},i} = \\frac{1}{k-1} \\left( k \\mu_{V,k} - V_{k,i} \\right)",
        "references": [],
        "derived_statement": "μ_{comp,i} - V_{k,i} = \\frac{k}{k-1} (\\mu_{V,k} - V_{k,i})"
      },
      {
        "order": 2,
        "kind": "inequality bound",
        "text": "Decompose μ_{V,k} = f_U μ_U + f_F μ_F and assume worst case V_{k,i} = μ_U for i ∈ U_k, leading to μ_{V,k} - V_{k,i} ≥ f_F (μ_F - μ_U), hence μ_{comp,i} - V_{k,i} ≥ (k/(k-1)) f_F (μ_F - μ_U) ≥ f_F / (k-1) (μ_F - μ_U).",
        "latex": "\\mu_{V,k} = f_U \\mu_U + f_F \\mu_F \\quad \\Rightarrow \\quad \\mu_{\\text{comp},i} - V_{k,i} \\geq \\frac{f_F}{k-1} (\\mu_F - \\mu_U)",
        "references": [],
        "derived_statement": "Lower bound using population fractions"
      },
      {
        "order": 3,
        "kind": "variance analysis",
        "text": "Use variance decomposition Var_{V,k} ≥ f_U f_F (μ_F - μ_U)^2 and bound Var_{V,k} ≤ (1/4) κ_{V,gap}^2(ε) to get μ_F - μ_U ≥ (1/2) √(1/(f_U f_F)) κ_{V,gap}(ε), refined to μ_F - μ_U ≥ (f_U / (f_F + f_U^2 / f_F)) κ_{V,gap}(ε) via weighted average optimization.",
        "latex": "\\text{Var}_{V,k} \\geq f_U f_F (\\mu_F - \\mu_U)^2 \\leq \\frac{1}{4} \\kappa_{V,\\text{gap}}^2(\\epsilon) \\quad \\Rightarrow \\quad \\mu_F - \\mu_U \\geq \\frac{f_U}{f_F + f_U^2 / f_F} \\kappa_{V,\\text{gap}}(\\epsilon)",
        "references": [],
        "derived_statement": "Bound on inter-group mean difference"
      },
      {
        "order": 4,
        "kind": "assembly",
        "text": "Combine bounds from previous steps to obtain the final lower bound on the companion fitness gap.",
        "latex": "\\mu_{\\text{comp},i} - V_{k,i} \\geq \\frac{f_U f_F}{(k-1)(f_F + f_U^2 / f_F)} \\kappa_{V,\\text{gap}}(\\epsilon)",
        "references": [],
        "derived_statement": "Final positive bound ensuring N-uniformity"
      }
    ],
    "key_equations": [
      {
        "label": "eq-mu-comp",
        "latex": "\\mu_{\\text{comp},i} = \\frac{1}{k-1} \\sum_{j \\neq i} V_{k,j} = \\frac{1}{k-1} \\left( k \\mu_{V,k} - V_{k,i} \\right)",
        "role": "Algebraic expression for mean companion fitness"
      },
      {
        "label": "eq-gap-diff",
        "latex": "\\mu_{\\text{comp},i} - V_{k,i} = \\frac{k}{k-1} (\\mu_{V,k} - V_{k,i})",
        "role": "Difference between companion mean and individual fitness"
      },
      {
        "label": "eq-mean-decomp",
        "latex": "\\mu_{V,k} = f_U \\mu_U + f_F \\mu_F",
        "role": "Decomposition of overall mean using group fractions"
      },
      {
        "label": "eq-var-decomp",
        "latex": "\\text{Var}_{V,k} = f_U \\text{Var}_U + f_F \\text{Var}_F + f_U f_F (\\mu_U - \\mu_F)^2",
        "role": "Variance decomposition for between-group bound"
      },
      {
        "label": "eq-var-bound",
        "latex": "\\text{Var}_{V,k} \\leq \\frac{1}{4} \\kappa_{V,\\text{gap}}^2(\\epsilon)",
        "role": "Upper bound on variance from fitness range"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\mu_{\\text{comp},i} - V_{k,i} \\geq \\frac{f_U f_F}{(k-1)(f_F + f_U^2 / f_F)} \\kappa_{V,\\text{gap}}(\\epsilon)",
        "role": "Final lower bound on the fitness gap"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Algebraic manipulation of means",
        "field": "Algebra",
        "description": "Rearranging sums and averages to express differences between individual and group means.",
        "roleInProof": "Used in Step 1 to derive the difference μ_comp,i - V_{k,i} as (k/(k-1))(μ_{V,k} - V_{k,i}).",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Weighted average decomposition"
        ]
      },
      {
        "toolName": "Variance decomposition",
        "field": "Statistics",
        "description": "Decomposes total variance into within-group variances and between-group variance term f_U f_F (μ_U - μ_F)^2.",
        "roleInProof": "Applied in Step 3 to bound (μ_F - μ_U)^2 from below using total variance.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Total variance",
          "Group variances"
        ]
      },
      {
        "toolName": "Popov’s inequality for bounded variables",
        "field": "Probability",
        "description": "For a random variable bounded in [m, M], Var(X) ≤ ((M - m)/2)^2.",
        "roleInProof": "Used to upper-bound total variance Var_{V,k} ≤ (1/4) κ_{V,gap}^2(ε) in Step 3.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Bounded variance"
        ]
      },
      {
        "toolName": "Weighted average constraint",
        "field": "Analysis",
        "description": "Expresses overall mean as convex combination of group means, used to optimize group mean separation under range constraints.",
        "roleInProof": "Employed in Step 3 to derive the tight lower bound on μ_F - μ_U involving f_U and f_F.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Convex combination"
        ]
      }
    ],
    "cases": [
      {
        "name": "Worst-case assumption for unfit walker",
        "condition": "V_{k,i} = \\mu_U for i \\in U_k",
        "summary": "Assumes the unfit walker's fitness equals the unfit group mean to minimize the gap μ_{V,k} - V_{k,i}."
      }
    ],
    "remarks": [
      {
        "type": "conservative bound",
        "text": "The factor k/(k-1) ≥ 1 for k ≥ 2 allows a looser bound μ_{comp,i} - V_{k,i} ≥ (f_F /(k-1)) (μ_F - μ_U), but the tighter assembly uses the refined inter-group bound."
      },
      {
        "type": "justification of tight bound",
        "text": "The refined bound on μ_F - μ_U arises from extremal configuration where unfit set concentrates near μ_{V,k} and fit set balances the mean while spanning the range, yielding the coefficient f_U / (f_F + f_U^2 / f_F). For balanced fractions f_U = f_F = 1/2, it simplifies to κ_{V,gap}/2."
      },
      {
        "type": "N-uniformity",
        "text": "The bound is positive and depends on k via 1/(k-1) but does not vanish as k → ∞ if f_U, f_F bounded away from 0."
      }
    ],
    "gaps": [
      {
        "description": "The justification for the tight bound on μ_F - μ_U in Step 3 is sketched via extremal configuration but lacks a full optimization proof; it relies on intuitive weighted-average constraints.",
        "severity": "minor",
        "location_hint": "Step 3, refined bound paragraph"
      }
    ],
    "tags": [
      "companion fitness",
      "fitness gap",
      "population fractions",
      "variance decomposition",
      "bounded variables",
      "algebraic bound",
      "group means"
    ]
  },
  {
    "label": "proof-lem-unfit-cloning-pressure",
    "proves": "lem-unfit-cloning-pressure",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof demonstrates that unfit walkers have strictly higher average companion fitness than their own, ensuring a positive average cloning score bounded below uniformly. Applying Jensen's inequality to the concave cloning probability function then guarantees a positive cloning probability for these walkers.",
    "conclusion": {
      "text": "For any unfit walker i, the cloning probability satisfies p_{k,i} ≥ p_u(ε, k) > 0, where p_u is an N-uniform lower bound.",
      "latex": "$p_{k,i} \\ge \\pi(S_u(\\epsilon, k)) =: p_u(\\epsilon, k) > 0$"
    },
    "assumptions": [
      {
        "text": "Walker i is in the unfit set U_k, so V_{k,i} ≤ μ_{V,k}.",
        "latex": null
      },
      {
        "text": "k ≥ 2 alive walkers.",
        "latex": null
      },
      {
        "text": "Fitness distributions satisfy non-degeneracy condition ensuring κ_{V,gap}(ε) > 0.",
        "latex": null
      },
      {
        "text": "Positive unfit and fit population fractions f_U, f_F > 0.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "bound",
        "text": "Establish lower bound on average companion fitness gap for unfit walker i: μ_{comp,i} - V_{k,i} ≥ Δ_min(ε, f_U, f_F, k) > 0, via referenced lemma.",
        "latex": "\\mu_{\\text{comp},i} - V_{k,i} \\ge \\frac{f_F f_U}{(k-1)(f_F + f_U^2/f_F)} \\kappa_{V,\\text{gap}}(\\epsilon) =: \\Delta_{\\min}(\\epsilon, f_U, f_F, k) > 0",
        "references": [
          "lem-mean-companion-fitness-gap"
        ],
        "derived_statement": "Fitness gap bound Δ_min > 0."
      },
      {
        "order": 2,
        "kind": "inequality",
        "text": "Bound average cloning score below: S_{avg,i} ≥ Δ_min / (V_{pot,max} + ε_{clone}) =: S_u(ε, k) > 0.",
        "latex": "S_{\\text{avg},i} \\ge \\frac{\\Delta_{\\min}(\\epsilon, f_U, f_F, k)}{V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}}} =: S_u(\\epsilon, k) > 0",
        "references": [],
        "derived_statement": "Positive average score S_u > 0."
      },
      {
        "order": 3,
        "kind": "application",
        "text": "Apply Jensen's inequality to concave π: p_{k,i} = E[π(S(V_c, V_i))] ≥ π(S_{avg,i}) ≥ π(S_u(ε, k)) =: p_u(ε, k) > 0.",
        "latex": "p_{k,i} = \\mathbb{E}_c[\\pi(S(V_c, V_i))] \\ge \\pi(\\mathbb{E}_c[S(V_c, V_i)]) = \\pi(S_{\\text{avg},i}) \\ge \\pi(S_u(\\epsilon, k)) =: p_u(\\epsilon, k) > 0",
        "references": [],
        "derived_statement": "Positive cloning probability p_u > 0."
      }
    ],
    "key_equations": [
      {
        "label": "eq-delta-min",
        "latex": "\\mu_{\\text{comp},i} - V_{k,i} \\ge \\frac{f_F f_U}{(k-1)(f_F + f_U^2/f_F)} \\kappa_{V,\\text{gap}}(\\epsilon) =: \\Delta_{\\min}(\\epsilon, f_U, f_F, k) > 0",
        "role": "Lower bound on fitness gap."
      },
      {
        "label": "eq-s-avg",
        "latex": "S_{\\text{avg},i} = (\\mu_{\\text{comp},i} - V_i) / (V_i + \\varepsilon_{\\text{clone}})",
        "role": "Average cloning score definition."
      },
      {
        "label": "eq-s-u",
        "latex": "S_{\\text{avg},i} \\ge \\frac{\\Delta_{\\min}(\\epsilon, f_U, f_F, k)}{V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}}} =: S_u(\\epsilon, k) > 0",
        "role": "Lower bound on average score."
      },
      {
        "label": "eq-pi-jensen",
        "latex": "p_{k,i} \\ge \\pi(S_{\\text{avg},i})",
        "role": "Jensen's application to π."
      },
      {
        "label": "eq-p-u",
        "latex": "p_{k,i} \\ge \\pi(S_u(\\epsilon, k)) =: p_u(\\epsilon, k) > 0",
        "role": "Final positive probability bound."
      }
    ],
    "references": [
      "lem-mean-companion-fitness-gap"
    ],
    "math_tools": [
      {
        "toolName": "Jensen's Inequality",
        "field": "Real Analysis",
        "description": "For a concave function f and random variable X, E[f(X)] ≤ f(E[X]).",
        "roleInProof": "Used to bound the expected cloning probability below by the probability of the expected score, since the clipping function π is concave on non-negative scores.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "uniformity",
        "text": "All bounds are N-uniform and strictly positive for k ≥ 2 under non-degeneracy."
      },
      {
        "type": "concavity",
        "text": "The function π(S) is concave for non-negative S, enabling Jensen's inequality."
      }
    ],
    "gaps": [],
    "tags": [
      "unfit walkers",
      "cloning probability",
      "fitness gap",
      "Jensen's inequality",
      "N-uniform bound",
      "companion fitness",
      "average score"
    ]
  },
  {
    "label": "proof-cor-cloning-pressure-target-set",
    "proves": "cor-cloning-pressure-target-set",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes the result by observing that the target set is a subset of the unfit set, so the lower bound on cloning probability from the referenced lemma applies directly to the subset.",
    "conclusion": {
      "text": "The lower bound on the cloning probability holds for every member of the critical target set $I_{\\text{target}}$ as a subset of $U_k$.",
      "latex": null
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "observation",
        "text": "The critical target set $I_{\\text{target}}$ is, by definition, a subset of the unfit set $U_k$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "reference",
        "text": "The preceding lemma {prf:ref}`lem-mean-companion-fitness-gap` establishes a lower bound on the cloning probability for every member of $U_k$.",
        "latex": null,
        "references": [
          "lem-mean-companion-fitness-gap"
        ],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "deduction",
        "text": "Therefore, the lower bound holds for every member of any subset of $U_k$, including $I_{\\text{target}}$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [],
    "references": [
      "lem-mean-companion-fitness-gap"
    ],
    "math_tools": [
      {
        "toolName": "Subset Inclusion",
        "field": "Set Theory",
        "description": "The property that any statement holding for all elements of a set also holds for all elements of its subsets.",
        "roleInProof": "Used to transfer the lower bound on cloning probability from the unfit set to the target set as a subset.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "cloning probability",
      "subset inclusion",
      "unfit set",
      "lower bound",
      "direct consequence",
      "fitness gap"
    ]
  },
  {
    "label": "proof-lem-variance-concentration-Hk",
    "proves": "lem-variance-concentration-Hk",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof analyzes the contribution of H_k(ε) to total variance in two regimes: mean-field, where it directly follows from the outlier set definition, and local-interaction, where variance decomposition isolates between-cluster effects captured by outlier clusters.",
    "conclusion": {},
    "assumptions": [],
    "steps": [],
    "key_equations": [
      {
        "label": "eq-variance-decomp",
        "latex": "S_k = k \\cdot \\mathrm{Var}_k(x) = \\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) + \\sum_{m=1}^M |G_m|\\|\\mu_m - \\mu\\|^2",
        "role": "Decomposition of total variance into within and between cluster components"
      },
      {
        "label": "eq-within-bound",
        "latex": "\\sum_{m=1}^M |G_m|\\mathrm{Var}(G_m) \\le k \\left(\\frac{D_{\\mathrm{diam}}(\\epsilon)}{2}\\right)^2",
        "role": "Upper bound on total within-cluster variance contribution"
      },
      {
        "label": "eq-outlier-between",
        "latex": "\\sum_{m \\in O_M} |G_m|\\|\\mu_m - \\mu\\|^2 \\ge (1-\\varepsilon_O) \\sum_{m=1}^M |G_m|\\|\\mu_m - \\mu\\|^2",
        "role": "Guarantee on outlier clusters capturing between-cluster variance"
      },
      {
        "label": "eq-deviation-expansion",
        "latex": "\\|x_i - \\mu\\|^2 = \\|x_i - \\mu_m\\|^2 + \\|\\mu_m - \\mu\\|^2 + 2\\langle x_i - \\mu_m, \\mu_m - \\mu \\rangle",
        "role": "Expansion of squared deviation from global mean via cluster mean"
      },
      {
        "label": "eq-sum-Hk",
        "latex": "\\sum_{i \\in H_k(\\epsilon)} \\|\\delta_{x,k,i}\\||^2 = \\sum_{m \\in O_M} |G_m|\\mathrm{Var}(G_m) + \\sum_{m \\in O_M} |G_m|\\|\\mu_m - \\mu\\|^2",
        "role": "Sum of squared deviations over outlier clusters after cross-term vanishes"
      },
      {
        "label": "eq-lower-bound",
        "latex": "\\sum_{i \\in H_k(\\epsilon)} \\|\\delta_{x,k,i}\\||^2 \\ge (1-\\varepsilon_O) k R^2_{\\mathrm{means}}",
        "role": "Lower bound on contribution from H_k(ε) to total variance"
      },
      {
        "label": "eq-fraction",
        "latex": "\\frac{\\sum_{i \\in H_k(\\epsilon)} \\|\\delta_{x,k,i}\\||^2}{S_k} \\ge \\frac{(1-\\varepsilon_O) R^2_{\\mathrm{means}}}{R^2_{\\mathrm{var}}}",
        "role": "Fraction of total variance captured by H_k(ε)"
      }
    ],
    "references": [
      "def-unified-high-low-error-sets",
      "lem-outlier-cluster-fraction-lower-bound"
    ],
    "math_tools": [
      {
        "toolName": "Law of Total Variance",
        "field": "Probability and Statistics",
        "description": "Decomposes the total variance of a random variable into the expected variance within subpopulations plus the variance of subpopulation means.",
        "roleInProof": "Decomposes total sum of squared deviations into within-cluster and between-cluster components to isolate the contribution from outlier clusters.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "ANOVA",
          "Variance Decomposition",
          "Clustering"
        ]
      },
      {
        "toolName": "Variance Bound via Diameter",
        "field": "Geometry and Statistics",
        "description": "Provides an upper bound on the variance within a bounded set using the square of half its diameter.",
        "roleInProof": "Bounds the within-cluster variance contributions to demonstrate that between-cluster variance dominates in the high-variance regime.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Euclidean Diameter",
          "Chebyshev Inequality",
          "Bounded Variance"
        ]
      },
      {
        "toolName": "Cross-Term Vanishing in Expansion",
        "field": "Linear Algebra",
        "description": "In the expansion of squared norms involving deviations from cluster and global means, the cross-term sums to zero due to the definition of the center of mass.",
        "roleInProof": "Simplifies the sum of squared deviations over outlier clusters by eliminating the cross-term, allowing clean separation of within and between components.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Vector Expansion",
          "Center of Mass",
          "Zero-Mean Property"
        ]
      }
    ],
    "cases": [
      {
        "name": "Mean-Field Regime",
        "condition": "\\epsilon > D_{\\text{swarm}}",
        "summary": "H_k(\\epsilon) = O_k by definition, capturing at least (1-\\varepsilon_O) of total sum of squared deviations, so c_H = 1-\\varepsilon_O."
      },
      {
        "name": "Local-Interaction Regime",
        "condition": "\\epsilon \\leq D_{\\text{swarm}}",
        "summary": "Variance decomposition and bounds show outlier clusters in H_k(\\epsilon) capture a positive fraction c_H > 0 of total variance, with explicit lower bound involving R^2_means and R^2_var."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The constant c_H is N-uniform, independent of system size."
      },
      {
        "type": "definition",
        "text": "R^2_means := R^2_var - (D_diam(ε)/2)^2 > 0 by high-variance assumption."
      }
    ],
    "gaps": [],
    "tags": [
      "variance-decomposition",
      "outlier-clusters",
      "law-total-variance",
      "regime-analysis",
      "cluster-bounds",
      "between-within-variance",
      "high-variance-regime"
    ]
  },
  {
    "label": "proof-lem-error-concentration-target-set",
    "proves": "lem-error-concentration-target-set",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof constructs explicit N-uniform constants for error concentration in the target set by chaining linear bounds: relating total structural error to high-variance swarm variance, lower-bounding error in the high-error set, upper-bounding error outside the target, and assembling into a normalized linear inequality.",
    "conclusion": {
      "text": "The N-normalized error in the target set satisfies \\frac{1}{N} E(I_{\\text{target}}) \\ge c_{\\text{err}}(\\epsilon) V_{\\text{struct}} - g_{\\text{err}}(\\epsilon), where c_{\\text{err}}(\\epsilon) := \\frac{c_H(\\epsilon)}{4} > 0 and g_{\\text{err}}(\\epsilon) := \\left(\\frac{c_H(\\epsilon)}{2} + 5\\right) D_{\\text{valid}}^2 \\ge 0 are strictly N-uniform constants.",
      "latex": "\\frac{1}{N} E(I_{\\text{target}}) \\ge \\frac{c_H}{4} V_{\\text{struct}} - \\left(\\frac{c_H}{2} + 5\\right) D_{\\text{valid}}^2"
    },
    "assumptions": [
      {
        "text": "Positions of walkers lie in the valid domain \\mathcal{X}_{\\text{valid}} of finite diameter D_{\\text{valid}}.",
        "latex": null
      },
      {
        "text": "Supporting lemmas provide N-uniform constants c_H(\\epsilon) > 0 from variance concentration in H_k(\\epsilon).",
        "latex": null
      },
      {
        "text": "Fractional sizes |H_k|/k \\ge f_H(\\epsilon) and |I_{\\text{target}}|/k \\ge f_{UH}(\\epsilon) have N-uniform lower bounds.",
        "latex": null
      },
      {
        "text": "Number of alive walkers k \\le N.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "bound-variance",
        "text": "Establish linear lower bound on high-variance swarm sum S_k from total error: S_k \\ge \\frac{N V_{\\text{struct}}}{2} - S_j \\ge \\frac{N V_{\\text{struct}}}{2} - N D_{\\text{valid}}^2.",
        "latex": "S_k \\ge \\frac{N \\cdot V_{\\mathrm{struct}}}{2} - N \\cdot D_{\\mathrm{valid}}^2 \\quad (*_1)",
        "references": [
          "prf-lem-V_Varx-implies-variance"
        ],
        "derived_statement": "(*1)"
      },
      {
        "order": 2,
        "kind": "error-lower-bound",
        "text": "Lower bound error in high-error set H_k using squared norm inequality and variance concentration: \\frac{1}{N} E(H_k) \\ge \\frac{c_H}{4} V_{\\text{struct}} - \\left(\\frac{c_H}{2} + 1\\right) D_{\\text{valid}}^2.",
        "latex": "\\frac{1}{N}E(H_k) \\ge \\frac{c_H}{4} V_{\\mathrm{struct}} - \\left(\\frac{c_H}{2} + 1\\right) D_{\\mathrm{valid}}^2 \\quad (*_2)",
        "references": [
          "prf-lem-variance-concentration-Hk"
        ],
        "derived_statement": "(*2)"
      },
      {
        "order": 3,
        "kind": "complement-upper-bound",
        "text": "Upper bound error in H_k \\setminus I_{\\text{target}}: E(H_k \\setminus I_{\\text{target}}) \\le k \\cdot 4 D_{\\text{valid}}^2, so \\frac{1}{N} E(H_k \\setminus I_{\\text{target}}) \\le 4 D_{\\text{valid}}^2.",
        "latex": "E(H_k \\setminus I_{\\text{target}}) \\le |H_k \\setminus I_{\\text{target}}| \\cdot 4D_{\\mathrm{valid}}^2 \\le k \\cdot 4D_{\\mathrm{valid}}^2",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "assembly",
        "text": "Combine bounds: \\frac{1}{N} E(I_{\\text{target}}) = \\frac{1}{N} E(H_k) - \\frac{1}{N} E(H_k \\setminus I_{\\text{target}}) \\ge \\frac{c_H}{4} V_{\\text{struct}} - \\left(\\frac{c_H}{2} + 5\\right) D_{\\text{valid}}^2, defining c_{\\text{err}} and g_{\\text{err}}.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-Sk-lower",
        "latex": "S_k \\ge \\frac{N \\cdot V_{\\mathrm{struct}}}{2} - N \\cdot D_{\\mathrm{valid}}^2",
        "role": "Lower bound on high-variance sum (*1)"
      },
      {
        "label": "eq-EHk-lower",
        "latex": "\\frac{1}{N}E(H_k) \\ge \\frac{c_H}{4} V_{\\mathrm{struct}} - \\left(\\frac{c_H}{2} + 1\\right) D_{\\mathrm{valid}}^2",
        "role": "Lower bound on normalized error in H_k (*2)"
      },
      {
        "label": "eq-complement-upper",
        "latex": "E(H_k \\setminus I_{\\text{target}}) \\le k \\cdot 4D_{\\mathrm{valid}}^2",
        "role": "Upper bound on error in complement"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\frac{1}{N}E(I_{\\text{target}}) \\ge \\frac{c_H}{4} V_{\\mathrm{struct}} - \\left(\\frac{c_H}{2} + 5\\right) D_{\\mathrm{valid}}^2",
        "role": "Final N-normalized linear lower bound"
      }
    ],
    "references": [
      "prf-lem-V_Varx-implies-variance",
      "def-variance-conversions",
      "prf-lem-variance-concentration-Hk"
    ],
    "math_tools": [
      {
        "toolName": "Squared norm inequality",
        "field": "Linear Algebra",
        "description": "The inequality \\|a - b\\|^2 \\geq (1/2)\\|a\\|^2 - \\|b\\|^2 for vectors a and b.",
        "roleInProof": "Relates squared errors \\|\\Delta\\delta_{x,i}\\|^2 to deviations \\|\\delta_{x,k,i}\\|^2 and \\|\\delta_{x,j,i}\\|^2, enabling lower bounds on error sums.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      },
      {
        "toolName": "Uniform bounding",
        "field": "Analysis",
        "description": "Using domain diameter to bound maximum deviations and errors, e.g., \\|\\delta\\|^2 \\leq D^2.",
        "roleInProof": "Provides worst-case upper bounds on low-variance swarm variance and complement set errors to ensure N-uniformity.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Squared norm inequality"
        ]
      },
      {
        "toolName": "Variance concentration lemma",
        "field": "Probability",
        "description": "Lemma bounding the concentration of variance within high-error subsets like H_k(\\epsilon).",
        "roleInProof": "Lower-bounds the sum of deviations in H_k using c_H S_k.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "notation",
        "text": "Uses N-normalized structural error V_{\\text{struct}} and un-normalized sums like S_k = N V_{\\text{Var},x}(S_k)."
      },
      {
        "type": "N-uniformity",
        "text": "Bounds are made N-uniform by replacing k/N \\le 1 with 1 in worst case; relies on fixed D_{\\text{valid}} and c_H > 0."
      }
    ],
    "gaps": [],
    "tags": [
      "error-concentration",
      "N-uniform",
      "constructive",
      "variance-bounding",
      "Lyapunov-error",
      "target-set",
      "inequality-chaining"
    ]
  },
  {
    "label": "proof-prop-n-uniformity-keystone-addendum",
    "proves": "lem-quantitative-keystone",
    "proof_type": "construction",
    "proof_status": "complete",
    "strategy_summary": "The proof constructs a lower bound on the error-weighted cloning activity Ew in the high-error regime by leveraging N-uniform guarantees on minimum cloning probabilities in the critical target set and error concentration within that set, yielding a linear relation to the structural variance V_struct minus an offset. A global offset g_max(ε) is then defined to extend this inequality uniformly across all regimes, ensuring N-independence of the constants.",
    "conclusion": {
      "text": "E_w \\ge \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon), where \\chi(\\epsilon) and g_{\\max}(\\epsilon) are N-uniform constants.",
      "latex": "E_w \\ge \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)"
    },
    "assumptions": [
      {
        "text": "High-error regime: V_{\\text{struct}} > R^2_{\\text{spread}}",
        "latex": "V_{\\text{struct}} > R^2_{\\text{spread}}"
      },
      {
        "text": "Swarm k=1 is the high-variance swarm",
        "latex": null
      },
      {
        "text": "Non-empty critical target set I_{\\text{target}} = I_{11} \\cap U_1 \\cap H_1(\\epsilon)",
        "latex": "I_{\\text{target}} = I_{11} \\cap U_1 \\cap H_1(\\epsilon)"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "setup",
        "text": "Assume the initial state (S_1, S_2) is in the high-error regime. Without loss of generality, let swarm k=1 be the high-variance swarm, guaranteeing a non-empty critical target set I_{\\text{target}}. Define E_w as the error-weighted cloning activity.",
        "latex": null,
        "references": [],
        "derived_statement": "E_w := \\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2"
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "Bound E_w below by the sum over the critical target set I_{\\text{target}} \\subseteq I_{11}, focusing on p_{1,i} since swarm 1 is high-variance.",
        "latex": null,
        "references": [],
        "derived_statement": "E_w \\ge \\frac{1}{N}\\sum_{i \\in I_{\\text{target}}} p_{1,i}\\|\\Delta\\delta_{x,i}\\|^2"
      },
      {
        "order": 3,
        "kind": "decomposition",
        "text": "Decompose the sum using averages \\bar{p}_{target} and \\bar{E}_{target}, including covariance, but simplify to a direct lower bound using the N-uniform minimum p_{1,i} \\ge p_u(\\epsilon) from the unfit cloning pressure lemma.",
        "latex": null,
        "references": [
          "lem-unfit-cloning-pressure"
        ],
        "derived_statement": "E_w \\ge \\frac{p_u(\\epsilon)}{N}\\sum_{i \\in I_{\\text{target}}} \\|\\Delta\\delta_{x,i}\\|^2"
      },
      {
        "order": 4,
        "kind": "substitution",
        "text": "Substitute the error concentration bound from the lemma on H_k to relate the sum to V_{\\text{struct}}.",
        "latex": null,
        "references": [
          "lem-variance-concentration-Hk"
        ],
        "derived_statement": "E_w \\ge p_u(\\epsilon) \\cdot (c_{\\text{err}}(\\epsilon) V_{\\mathrm{struct}} - g_{\\text{err}}(\\epsilon))"
      },
      {
        "order": 5,
        "kind": "definition",
        "text": "Define N-uniform constants \\chi(\\epsilon) = p_u(\\epsilon) c_{\\text{err}}(\\epsilon) and g_{\\text{partial}}(\\epsilon) = p_u(\\epsilon) g_{\\text{err}}(\\epsilon) for the high-error regime.",
        "latex": null,
        "references": [],
        "derived_statement": "E_w \\ge \\chi(\\epsilon) V_{\\text{struct}} - g_{\\text{partial}}(\\epsilon)"
      },
      {
        "order": 6,
        "kind": "globalization",
        "text": "Define global offset g_{\\max}(\\epsilon) = \\max(g_{\\text{partial}}(\\epsilon), \\chi(\\epsilon) R^2_{\\text{spread}}) to extend the inequality to all states.",
        "latex": null,
        "references": [],
        "derived_statement": "E_w \\ge \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon) \\text{ for all states}"
      }
    ],
    "key_equations": [
      {
        "label": "eq-Ew",
        "latex": "E_w := \\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2",
        "role": "Definition of error-weighted cloning activity"
      },
      {
        "label": "eq-avg-p",
        "latex": "\\bar{p}_{\\text{target}} = \\frac{1}{|I_{\\text{target}}|}\\sum_{i \\in I_{\\text{target}}} p_{1,i}",
        "role": "Average cloning probability over target set"
      },
      {
        "label": "eq-avg-E",
        "latex": "\\bar{E}_{\\text{target}} = \\frac{1}{|I_{\\text{target}}|}\\sum_{i \\in I_{\\text{target}}} \\|\\Delta\\delta_{x,i}\\|^2",
        "role": "Average error over target set"
      },
      {
        "label": "eq-decomp",
        "latex": "\\sum_{i \\in I_{\\text{target}}} p_{1,i}\\|\\Delta\\delta_{x,i}\\|^2 = |I_{\\text{target}}| \\left( \\bar{p}_{\\text{target}} \\cdot \\bar{E}_{\\text{target}} + \\text{Cov}(p_{1,i}, \\|\\Delta\\delta_{x,i}\\|^2) \\right)",
        "role": "Statistical decomposition of the sum"
      },
      {
        "label": "eq-lower-pu",
        "latex": "E_w \\ge \\frac{p_u(\\epsilon)}{N}\\sum_{i \\in I_{\\text{target}}} \\|\\Delta\\delta_{x,i}\\|^2",
        "role": "Lower bound using minimum cloning probability"
      },
      {
        "label": "eq-subst-err",
        "latex": "E_w \\ge p_u(\\epsilon) \\cdot (c_{\\text{err}}(\\epsilon)V_{\\mathrm{struct}} - g_{\\text{err}}(\\epsilon))",
        "role": "Substitution of error concentration bound"
      },
      {
        "label": "eq-chi-g",
        "latex": "E_w \\ge \\chi(\\epsilon) V_{\\text{struct}} - g_{\\text{partial}}(\\epsilon)",
        "role": "High-error regime inequality with defined constants"
      },
      {
        "label": "eq-gmax",
        "latex": "g_{\\max}(\\epsilon) := \\max\\bigl(g_{\\text{partial}}(\\epsilon),\\, \\chi(\\epsilon) R^2_{\\text{spread}}\\bigr)",
        "role": "Global offset definition"
      }
    ],
    "references": [
      "lem-quantitative-keystone",
      "lem-unfit-cloning-pressure",
      "lem-variance-concentration-Hk"
    ],
    "math_tools": [
      {
        "toolName": "Lower Bound Inequality",
        "field": "Analysis",
        "description": "Technique for establishing minimum values of sums or expressions using non-negativity and minimum terms.",
        "roleInProof": "Applied to bound the weighted sum Ew by replacing cloning probabilities with their N-uniform minimum p_u(ε) and using error concentration results.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Error Concentration"
        ]
      },
      {
        "toolName": "Statistical Decomposition",
        "field": "Statistics",
        "description": "Decomposition of sums into averages and covariance terms to analyze joint behavior of variables.",
        "roleInProof": "Used to express the sum over the target set in terms of average cloning probability, average error, and covariance, though simplified to direct bounding for robustness.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Covariance"
        ]
      },
      {
        "toolName": "Covariance",
        "field": "Statistics",
        "description": "Measure of the linear correlation between two variables, which can be positive or negative.",
        "roleInProof": "Appears in the decomposition but is bounded away by switching to a minimum probability argument to avoid negative impacts.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Statistical Decomposition"
        ]
      },
      {
        "toolName": "Error Concentration",
        "field": "Probability",
        "description": "Bounding the proportion of total error captured by a subset like the high-error set.",
        "roleInProof": "Directly substitutes the bound from the Error Concentration Lemma to link the target set error sum to V_struct.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Lower Bound Inequality"
        ]
      }
    ],
    "cases": [
      {
        "name": "High-Error Regime",
        "condition": "V_{\\text{struct}} > R^2_{\\text{spread}}",
        "summary": "Constructive lower bound on Ew using target set concentration and unfit cloning guarantees, yielding \\chi V_{\\text{struct}} - g_{\\text{partial}}"
      },
      {
        "name": "Global Extension",
        "condition": "All system states",
        "summary": "Define g_{\\max} to cover low-error regime by offsetting up to \\chi R^2_{\\text{spread}}, ensuring uniform inequality"
      }
    ],
    "remarks": [
      {
        "type": "construction",
        "text": "All constants \\chi(\\epsilon) and g_{\\max}(\\epsilon) are N-uniform and derived from prior lemmas, independent of system size N."
      },
      {
        "type": "simplification",
        "text": "Covariance decomposition is introduced but replaced by direct minimum bounding for robustness against negative covariance."
      }
    ],
    "gaps": [],
    "tags": [
      "n-uniform",
      "keystone-lemma",
      "high-error-regime",
      "error-concentration",
      "cloning-probability",
      "lower-bound",
      "constructive-proof"
    ]
  },
  {
    "label": "proof-prop-n-uniformity-keystone",
    "proves": "prop-n-uniformity-keystone",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes N-independence of χ(ε) and g_max(ε) by decomposing them into constituent components, verifying each one's independence from N through tracing dependencies to geometric, parametric, and probabilistic properties that do not scale with swarm size.",
    "conclusion": {
      "text": "Both χ(ε) and g_max(ε) are strictly independent of N, depending only on ε and fixed system parameters.",
      "latex": "\\chi(\\epsilon) \\text{ and } g_{\\max}(\\epsilon) \\text{ are strictly independent of } N"
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "decomposition",
        "text": "Decompose p_u(ε) and verify each component's N-independence: p_max, ε_clone, V_pot,max, κ_V,gap(ε) via thm-geometry-guarantees-variance.",
        "latex": null,
        "references": [
          "thm-geometry-guarantees-variance"
        ],
        "derived_statement": "p_u(ε) is N-independent"
      },
      {
        "order": 2,
        "kind": "decomposition",
        "text": "Decompose c_err(ε) ∝ λ₂ · c_H · f_UH(ε): λ₂ via Lemma 3.4.1, c_H via lem-variance-concentration-Hk (mean-field and local regimes), f_UH(ε) via thm-unfit-high-error-overlap-fraction and population fractions.",
        "latex": null,
        "references": [
          "lem-variance-concentration-Hk",
          "thm-unfit-high-error-overlap-fraction",
          "lem-outlier-fraction-lower-bound"
        ],
        "derived_statement": "c_err(ε) is N-independent"
      },
      {
        "order": 3,
        "kind": "decomposition",
        "text": "Decompose g_err(ε) = g'_err + (1 - f_UH(ε)) · 4 D_valid², verifying each term.",
        "latex": null,
        "references": [
          "lem-variance-concentration-Hk"
        ],
        "derived_statement": "g_err(ε) is N-independent"
      },
      {
        "order": 4,
        "kind": "composition",
        "text": "Compose χ(ε) = p_u(ε) · c_err(ε) and g_max(ε) = max(p_u(ε) · g_err(ε), χ(ε) R²_spread), confirming overall N-independence.",
        "latex": null,
        "references": [],
        "derived_statement": "χ(ε) and g_max(ε) are N-independent"
      }
    ],
    "key_equations": [
      {
        "label": "eq-p_u",
        "latex": "p_u(\\epsilon) = \\frac{1}{p_{\\max}} \\left( \\frac{\\kappa_{V,\\text{gap}}(\\epsilon)}{2(V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}})} \\right)",
        "role": "Definition of p_u(ε)"
      },
      {
        "label": "eq-g_err",
        "latex": "g_{\\text{err}}(\\epsilon) := g'_{\\text{err}} + (1 - f_{UH}(\\epsilon)) \\cdot 4D_{\\mathrm{valid}}^2",
        "role": "Definition of g_err(ε)"
      },
      {
        "label": "eq-chi",
        "latex": "\\chi(\\epsilon) = p_u(\\epsilon) \\cdot c_{\\text{err}}(\\epsilon)",
        "role": "Definition of χ(ε)"
      },
      {
        "label": "eq-g_max",
        "latex": "g_{\\max}(\\epsilon) = \\max(p_u(\\epsilon) \\cdot g_{\\text{err}}(\\epsilon), \\chi(\\epsilon)R^2_{\\text{spread}})",
        "role": "Definition of g_max(ε)"
      }
    ],
    "references": [
      "thm-geometry-guarantees-variance",
      "lem-variance-concentration-Hk",
      "thm-unfit-high-error-overlap-fraction",
      "lem-outlier-fraction-lower-bound"
    ],
    "math_tools": [
      {
        "toolName": "Coercivity Lemma",
        "field": "Dynamical Systems",
        "description": "A lemma bounding the coercivity of Lyapunov functions via minimum eigenvalues.",
        "roleInProof": "Provides N-independent bound for λ₂ in c_err(ε).",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Lyapunov Stability"
        ]
      },
      {
        "toolName": "Variance Concentration",
        "field": "Probability Theory",
        "description": "Technique for bounding variance in mean-field or local-interaction regimes using geometric constants.",
        "roleInProof": "Yields N-independent c_H in c_err(ε).",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Chebyshev Inequality"
        ]
      },
      {
        "toolName": "Phase-Space Geometry",
        "field": "Geometric Analysis",
        "description": "Analysis of separations and diameters in phase space for outlier and cluster definitions.",
        "roleInProof": "Ensures κ_V,gap(ε) and related terms are N-independent in p_u(ε).",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Packing Arguments"
        ]
      },
      {
        "toolName": "Overlap Fraction Bounds",
        "field": "Optimization",
        "description": "Lower bounds on fractions of unfit and high-error populations using geometric packing.",
        "roleInProof": "Provides N-uniform f_UH(ε) in c_err(ε) and g_err(ε).",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Fractional Coverage"
        ]
      }
    ],
    "cases": [
      {
        "name": "Part 1",
        "condition": "p_u(ε) components",
        "summary": "All components (p_max, ε_clone, V_pot,max, κ_V,gap(ε)) are N-independent."
      },
      {
        "name": "Part 2",
        "condition": "c_err(ε) components",
        "summary": "λ₂, c_H (mean-field/local), f_UH(ε) all N-independent."
      },
      {
        "name": "Part 3",
        "condition": "g_err(ε) components",
        "summary": "g'_err, f_UH(ε), D_valid all N-independent."
      },
      {
        "name": "Part 4",
        "condition": "Composite functions",
        "summary": "Products and max of N-independent terms remain N-independent."
      }
    ],
    "remarks": [
      {
        "type": "conclusion",
        "text": "p_u(ε) is strictly independent of N."
      },
      {
        "type": "conclusion",
        "text": "c_err(ε) is strictly independent of N."
      },
      {
        "type": "conclusion",
        "text": "g_err(ε) is strictly independent of N."
      }
    ],
    "gaps": [],
    "tags": [
      "n-independence",
      "uniformity",
      "verification",
      "components",
      "swarm-systems",
      "geometric-properties",
      "variance-concentration"
    ]
  },
  {
    "label": "proof-lem-dead-walker-clone-prob",
    "proves": "lem-dead-walker-clone-prob",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof directly calculates the cloning score for a dead walker using the given fitness potential bounds and the revival axiom, demonstrating that the score strictly exceeds the random threshold with probability 1.",
    "conclusion": {
      "text": "we have $S_i > T_i$ with probability 1.",
      "latex": "$S_i > T_i$ with probability 1"
    },
    "assumptions": [
      {
        "text": "Revival axiom: $\\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}} > p_{\\max}$",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "setup",
        "text": "For a dead walker $i$, the fitness potential is $V_{\\text{fit},i} = 0$.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "bound",
        "text": "Any alive companion $c_i$ has $V_{\\text{fit},c_i} \\geq \\eta^{\\alpha+\\beta}$ by lem-potential-bounds.",
        "latex": null,
        "references": [
          "lem-potential-bounds"
        ],
        "derived_statement": "$V_{\\text{fit},c_i} \\geq \\eta^{\\alpha+\\beta}$"
      },
      {
        "order": 3,
        "kind": "calculation",
        "text": "The cloning score is $S_i = \\frac{V_{\\text{fit},c_i} - 0}{0 + \\varepsilon_{\\text{clone}}} = \\frac{V_{\\text{fit},c_i}}{\\varepsilon_{\\text{clone}}} \\geq \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}$",
        "latex": "$S_i = \\frac{V_{\\text{fit},c_i}}{\\varepsilon_{\\text{clone}}} \\geq \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}$",
        "references": [],
        "derived_statement": "$S_i \\geq \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}$"
      },
      {
        "order": 4,
        "kind": "application",
        "text": "By the revival axiom: $\\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}} > p_{\\max}$",
        "latex": null,
        "references": [
          "revival-axiom"
        ],
        "derived_statement": "$S_i > p_{\\max}$"
      },
      {
        "order": 5,
        "kind": "conclusion",
        "text": "Since $T_i \\in [0, p_{\\max}]$, we have $S_i > T_i$ with probability 1.",
        "latex": null,
        "references": [],
        "derived_statement": "$S_i > T_i$ with probability 1"
      }
    ],
    "key_equations": [
      {
        "label": "eq-cloning-score",
        "latex": "S_i = \\frac{V_{\\text{fit},c_i} - 0}{0 + \\varepsilon_{\\text{clone}}} = \\frac{V_{\\text{fit},c_i}}{\\varepsilon_{\\text{clone}}} \\geq \\frac{\\eta^{\\alpha+\\beta}}{\\varepsilon_{\\text{clone}}}",
        "role": "Defines and bounds the cloning score for a dead walker"
      }
    ],
    "references": [
      "lem-potential-bounds"
    ],
    "math_tools": [],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "dead-walker",
      "cloning-score",
      "fitness-potential",
      "probability",
      "revival-axiom"
    ]
  },
  {
    "label": "proof-prop-expected-displacement-cloning",
    "proves": "prop-expected-displacement-cloning",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof conditions the expected squared displacement on the cloning action, computing it as a weighted average of the displacement under cloning (bounded by D_max) and zero under persistence.",
    "conclusion": {},
    "assumptions": [],
    "steps": [],
    "key_equations": [],
    "references": [],
    "math_tools": [
      {
        "toolName": "Conditional Expectation",
        "field": "Probability Theory",
        "description": "The expected value of a random variable given additional information or events.",
        "roleInProof": "Used to express the overall expectation as a convex combination based on the cloning probability.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Cloning",
        "condition": "a_i = clone with probability p_i",
        "summary": "Position sampled from Q_δ(x_{c_i}, ·), ||Δx_i|| ≤ D_max so E[||Δx_i||² | clone] ≤ D_max²"
      },
      {
        "name": "Persistence",
        "condition": "a_i = persist with probability 1 - p_i",
        "summary": "Zero displacement, E[||Δx_i||² | persist] = 0"
      }
    ],
    "remarks": [],
    "gaps": [],
    "tags": [
      "expected displacement",
      "cloning",
      "probability",
      "bounding",
      "conditional expectation"
    ]
  },
  {
    "label": "proof-lem-variance-change-decomposition",
    "proves": "lem-variance-change-decomposition",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof recalls the N-normalized variance definition and decomposes the change in variance after cloning into separate contributions from modifications to alive walkers and the addition of revived dead walkers, preserving uniform N-normalization.",
    "conclusion": {
      "text": "This decomposition preserves the N-normalization, ensuring all subsequent bounds are N-uniform.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "V_{\\text{Var},x} is N-normalized per walker slot as per def-variance-conversions.",
        "latex": null
      },
      {
        "text": "After cloning, all walkers are alive (dead walkers revived).",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "recall",
        "text": "Recall that V_{\\text{Var},x}(S_k) = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2.",
        "latex": "V_{\\text{Var},x}(S_k) = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "references": [
          "def-variance-conversions"
        ],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "definition",
        "text": "After cloning, all walkers are alive, so V_{\\text{Var},x}(S'_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2.",
        "latex": "V_{\\text{Var},x}(S'_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "computation",
        "text": "The change is \\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2 - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2.",
        "latex": "\\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2 - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "decomposition",
        "text": "Split the first sum into alive and dead walkers: \\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N}\\sum_{i \\in \\mathcal{A}(S_k)} \\left[\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2\\right] + \\frac{1}{N}\\sum_{i \\in \\mathcal{D}(S_k)} \\|\\delta'_{x,k,i}\\|^2.",
        "latex": "\\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N}\\sum_{i \\in \\mathcal{A}(S_k)} \\left[\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2\\right] + \\frac{1}{N}\\sum_{i \\in \\mathcal{D}(S_k)} \\|\\delta'_{x,k,i}\\|^2",
        "references": [],
        "derived_statement": "Decomposition of variance change."
      }
    ],
    "key_equations": [
      {
        "label": "eq-v-var-sk",
        "latex": "V_{\\text{Var},x}(S_k) = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "role": "Pre-cloning variance"
      },
      {
        "label": "eq-v-var-sk-prime",
        "latex": "V_{\\text{Var},x}(S'_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2",
        "role": "Post-cloning variance"
      },
      {
        "label": "eq-delta-v",
        "latex": "\\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\delta'_{x,k,i}\\|^2 - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "role": "Variance change"
      },
      {
        "label": "eq-decomp-delta",
        "latex": "\\Delta V_{\\text{Var},x}^{(k)} = \\frac{1}{N}\\sum_{i \\in \\mathcal{A}(S_k)} \\left[\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2\\right] + \\frac{1}{N}\\sum_{i \\in \\mathcal{D}(S_k)} \\|\\delta'_{x,k,i}\\|^2",
        "role": "Decomposed variance change"
      }
    ],
    "references": [
      "def-variance-conversions"
    ],
    "math_tools": [
      {
        "toolName": "Euclidean norm",
        "field": "Linear Algebra",
        "description": "The squared Euclidean norm measures the displacement of walker positions.",
        "roleInProof": "Used to compute variance as average squared deviations.",
        "levelOfAbstraction": "Notation",
        "relatedTools": []
      },
      {
        "toolName": "Summation decomposition",
        "field": "Analysis",
        "description": "Splitting a sum over a full set into disjoint subsets.",
        "roleInProof": "Separates the variance change into alive and dead walker contributions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "This decomposition preserves the N-normalization, ensuring all subsequent bounds are N-uniform."
      }
    ],
    "gaps": [],
    "tags": [
      "variance",
      "decomposition",
      "cloning",
      "N-normalization",
      "walkers",
      "alive-dead"
    ]
  },
  {
    "label": "proof-lem-keystone-contraction-alive",
    "proves": "lem-keystone-contraction-alive",
    "proof_type": "direct",
    "proof_status": "sketch",
    "strategy_summary": "The proof conditions on whether stably alive walkers clone or persist in swarms, deriving a contraction in variance from cloning resets via the Keystone Lemma's bound on cloning probabilities for erroneous walkers, while bounding perturbation terms from jitter and barycenter shifts.",
    "conclusion": {
      "text": "The expected total change in variance for stably alive walkers is bounded above by a negative term proportional to the structural variance from the Keystone Lemma, plus controlled error terms from jitter and persistence shifts.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Walkers i belong to I_{11}, the set of stably alive walkers in both swarms.",
        "latex": null
      },
      {
        "text": "Cloning probabilities p_{k,i} are defined based on position errors, with parameters epsilon, sigma_x, N, and functions chi(epsilon), g_max(epsilon).",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "case-introduction",
        "text": "Consider Case 1: Walker i clones in at least one swarm k.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "definition",
        "text": "The updated centered position after cloning is delta'_{x,k,i} = x'_{k,i} - mu'_{x,k}, where x'_{k,i} = x_{k,c_i} + sigma_x zeta_i^x.",
        "latex": "\\delta'_{x,k,i} = x'_{k,i} - \\mu'_{x,k} \\quad x'_{k,i} = x_{k,c_i} + \\sigma_x \\zeta_i^x",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "insight",
        "text": "From the Keystone Lemma, walkers with large ||Delta delta_{x,i}|| have high cloning probability, resetting positions to reduce large errors: E[||delta'_{x,k,i}||^2 | clone] << ||delta_{x,k,i}||^2 when ||delta_{x,k,i}||^2 is large.",
        "latex": "\\mathbb{E}[\\|\\delta'_{x,k,i}\\|^2 \\mid \\text{clone}] \\ll \\|\\delta_{x,k,i}\\|^2",
        "references": [
          "lem-quantitative-keystone"
        ],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "lemma-application",
        "text": "Apply the Keystone Lemma: (1/N) sum_{i in I_{11}} (p_{1,i} + p_{2,i}) ||Delta delta_{x,i}||^2 >= chi(epsilon) V_struct - g_max(epsilon).",
        "latex": "\\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)",
        "references": [
          "lem-quantitative-keystone"
        ],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "bound-derivation",
        "text": "The expected change conditional on i in I_{11} is E[||delta'_{x,k,i}||^2 - ||delta_{x,k,i}||^2 | i in I_{11}] <= -p_{k,i} * (1/4) ||Delta delta_{x,i}||^2 + p_{k,i} * C_{jitter}, where C_{jitter} = O(sigma_x^2).",
        "latex": "\\mathbb{E}[\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2 \\mid i \\in I_{11}] \\leq -p_{k,i} \\cdot \\frac{1}{4}\\|\\Delta\\delta_{x,i}\\|^2 + p_{k,i} \\cdot C_{\\text{jitter}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 6,
        "kind": "summation",
        "text": "Summing over i in I_{11} and k=1,2: E[sum_{i,k} (||delta'_{x,k,i}||^2 - ||delta_{x,k,i}||^2)] <= -(1/4) sum_i (p_{1,i} + p_{2,i}) ||Delta delta_{x,i}||^2 + C_{jitter} sum_i (p_{1,i} + p_{2,i}).",
        "latex": "\\mathbb{E}\\left[\\sum_{i \\in I_{11}} \\sum_{k=1,2} \\left(\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2\\right)\\right] \\leq -\\frac{1}{4}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 + C_{\\text{jitter}} \\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "normalization",
        "text": "Multiply the Keystone Lemma by N: sum_i (p_{1,i} + p_{2,i}) ||Delta delta_{x,i}||^2 >= N [chi(epsilon) V_struct - g_max(epsilon)].",
        "latex": "\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq N \\left[\\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)\\right]",
        "references": [
          "lem-quantitative-keystone"
        ],
        "derived_statement": null
      },
      {
        "order": 8,
        "kind": "substitution",
        "text": "Substitute to get <= - (N chi(epsilon)/4) V_struct + (N g_max(epsilon)/4) + C_{jitter} N = N [ -chi(epsilon)/4 V_struct + g_max(epsilon)/4 + C_{jitter} ].",
        "latex": "\\leq N \\left[-\\frac{\\chi(\\epsilon)}{4} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{4} + C_{\\text{jitter}}\\right]",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 9,
        "kind": "case-introduction",
        "text": "Case 2: Walker persists in both swarms; position changes only due to barycenter shifts: ||delta'_{x,k,i}||^2 - ||delta_{x,k,i}||^2 = O(||mu'_{x,k} - mu_{x,k}||^2), bounded by C_pers.",
        "latex": "\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2 = O(\\||\\mu'_{x,k} - \\mu_{x,k}\\|^2)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 10,
        "kind": "combination",
        "text": "Combining both cases yields the overall bound on variance change.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-clone-position",
        "latex": "\\delta'_{x,k,i} = x'_{k,i} - \\mu'_{x,k} \\quad x'_{k,i} = x_{k,c_i} + \\sigma_x \\zeta_i^x",
        "role": "Defines updated centered position after cloning"
      },
      {
        "label": "eq-keystone-lemma",
        "latex": "\\frac{1}{N}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq \\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)",
        "role": "Quantitative bound from Keystone Lemma on cloning-weighted errors"
      },
      {
        "label": "eq-expectation-change",
        "latex": "\\mathbb{E}[\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2 \\mid i \\in I_{11}] \\leq -p_{k,i} \\cdot \\frac{1}{4}\\|\\Delta\\delta_{x,i}\\|^2 + p_{k,i} \\cdot C_{\\text{jitter}}",
        "role": "Bound on variance change conditional on cloning probability"
      },
      {
        "label": "eq-summed-change",
        "latex": "\\mathbb{E}\\left[\\sum_{i \\in I_{11}} \\sum_{k=1,2} \\left(\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2\\right)\\right] \\leq -\\frac{1}{4}\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 + C_{\\text{jitter}} \\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})",
        "role": "Aggregated expectation over all stably alive walkers and swarms"
      },
      {
        "label": "eq-normalized-keystone",
        "latex": "\\sum_{i \\in I_{11}} (p_{1,i} + p_{2,i})\\|\\Delta\\delta_{x,i}\\|^2 \\geq N \\left[\\chi(\\epsilon) V_{\\text{struct}} - g_{\\max}(\\epsilon)\\right]",
        "role": "Un-normalized form of Keystone Lemma for substitution"
      },
      {
        "label": "eq-final-contraction",
        "latex": "N \\left[-\\frac{\\chi(\\epsilon)}{4} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{4} + C_{\\text{jitter}}\\right]",
        "role": "Final bound for Case 1 after substitution"
      },
      {
        "label": "eq-persistence-shift",
        "latex": "\\|\\delta'_{x,k,i}\\|^2 - \\|\\delta_{x,k,i}\\|^2 = O(\\||\\mu'_{x,k} - \\mu_{x,k}\\|^2)",
        "role": "Bound for variance change in persistence case"
      }
    ],
    "references": [
      "lem-quantitative-keystone"
    ],
    "math_tools": [
      {
        "toolName": "Conditional Expectation",
        "field": "Probability",
        "description": "Computing expectations given specific events or conditions, such as cloning or persistence.",
        "roleInProof": "Used to bound the change in squared centered position norms conditional on cloning events and to aggregate over walkers.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Triangle Inequality"
        ]
      },
      {
        "toolName": "Triangle Inequality",
        "field": "Metric Geometry",
        "description": "A fundamental inequality for bounding distances or norms in vector spaces.",
        "roleInProof": "Applied to derive the negative contraction term in the expected variance change after position resets during cloning.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Conditional Expectation"
        ]
      },
      {
        "toolName": "Gaussian Jitter",
        "field": "Stochastic Processes",
        "description": "Addition of Gaussian noise to positions, modeling small random perturbations.",
        "roleInProof": "Accounts for the bounded variance increase due to position jitter in cloned walkers.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Case 1: Walker clones in at least one swarm",
        "condition": "i clones in swarm k=1 or 2",
        "summary": "Cloning resets positions of erroneous walkers, leading to contraction bounded by Keystone Lemma minus jitter."
      },
      {
        "name": "Case 2: Walker persists in both swarms",
        "condition": "i persists without cloning in k=1 and 2",
        "summary": "Variance change bounded by barycenter shifts, yielding controlled contribution C_pers."
      }
    ],
    "remarks": [
      {
        "type": "insight",
        "text": "The key mechanism is that cloning preferentially targets walkers with large inter-swarm position discrepancies, as quantified by the Keystone Lemma."
      },
      {
        "type": "quantitative",
        "text": "Constants like 1/4 and C_jitter are derived from triangle inequality and Gaussian variance; precise values depend on model parameters."
      }
    ],
    "gaps": [
      {
        "description": "The inequality E[||delta'||^2 | clone] << ||delta||^2 is qualitative; a precise constant bound is not provided.",
        "severity": "minor",
        "location_hint": "Early in Case 1"
      },
      {
        "description": "The persistence contribution C_pers is stated as bounded but not explicitly computed or bounded in terms of parameters.",
        "severity": "minor",
        "location_hint": "Case 2"
      },
      {
        "description": "The overall combined bound is referenced as 'the stated bound' but not explicitly written in the proof text.",
        "severity": "moderate",
        "location_hint": "Conclusion"
      }
    ],
    "tags": [
      "variance analysis",
      "cloning probability",
      "centered positions",
      "Keystone Lemma",
      "barycenter shifts",
      "persistence",
      "expectation bounds"
    ]
  },
  {
    "label": "proof-lem-dead-walker-revival-bounded",
    "proves": "lem-dead-walker-revival-bounded",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof directly bounds the squared norm of centered positions for revived dead walkers using the triangle inequality on distances within the bounded convex valid domain, shows the barycenter remains bounded, and aggregates these to obtain a deterministic upper bound on the variance contribution proportional to the fraction of dead walkers times the domain diameter squared.",
    "conclusion": {
      "text": "The contribution from dead walker revival is bounded by a term proportional to the number of dead walkers divided by $N$, multiplied by the square of the domain diameter. This is a deterministic upper bound that holds for all states.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "The valid domain $\\mathcal{X}_{\\text{valid}}$ is convex and bounded with finite diameter $D_{\\text{valid}}$.",
        "latex": null
      },
      {
        "text": "The cloning process ensures all new positions $x'_{k,i}$ lie in $\\mathcal{X}_{\\text{valid}}$, e.g., via rejection or projection.",
        "latex": null
      },
      {
        "text": "Dead walkers have zero fitness potential and clone with probability 1, as per referenced lemma.",
        "latex": null
      }
    ],
    "steps": [],
    "key_equations": [
      {
        "label": "eq-new-position",
        "latex": "x'_{k,i} = x_{k,c_i} + \\sigma_x \\zeta_i^x",
        "role": "Defines the position of a revived dead walker after cloning from an alive companion with Gaussian jitter."
      },
      {
        "label": "eq-centered-position",
        "latex": "\\delta'_{x,k,i} = x'_{k,i} - \\mu'_{x,k}",
        "role": "Centered position of the revived walker relative to the new barycenter."
      },
      {
        "label": "eq-barycenter",
        "latex": "\\mu'_{x,k} = \\frac{1}{N} \\sum_{j=1}^{N} x'_{k,j}",
        "role": "New barycenter after all cloning and revival."
      },
      {
        "label": "eq-triangle-bound",
        "latex": "\\|\\delta'_{x,k,i}\\| \\leq \\|x'_{k,i}\\| + \\|\\mu'_{x,k}\\|",
        "role": "Triangle inequality application for centering bound."
      },
      {
        "label": "eq-variance-contrib",
        "latex": "\\Delta V_{\\text{Var},x}^{(k,\\text{status})} = \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\|\\delta'_{x,k,i}\\|^2",
        "role": "Variance contribution from dead walkers in one swarm."
      }
    ],
    "references": [
      "lem-dead-walker-clone-prob"
    ],
    "math_tools": [
      {
        "toolName": "Triangle Inequality",
        "field": "Metric Spaces",
        "description": "For any vectors a and b in a normed space, ||a - b|| ≤ ||a|| + ||b||.",
        "roleInProof": "Applied to bound the norm of the centered revived position δ'_{x,k,i} by the sum of bounds on the new position and barycenter norms.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      },
      {
        "toolName": "Convexity of Averages",
        "field": "Convex Analysis",
        "description": "The convex combination (e.g., barycenter) of points in a convex set remains within the set.",
        "roleInProof": "Ensures the new barycenter μ'_{x,k} lies in the valid domain X_valid, inheriting its diameter bound.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Triangle Inequality"
        ]
      },
      {
        "toolName": "Expectation Linearity",
        "field": "Probability Theory",
        "description": "The expectation of a sum is the sum of expectations, applicable to bounded random variables.",
        "roleInProof": "Justifies that the deterministic position bounds imply the same bound in expectation over the cloning process.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The derived bound uses 4 D_valid^2 per walker, yielding a factor of 4/N |D| D_valid^2 overall, but the lemma likely employs a tighter constant of 2 via more precise centering analysis; the O(|D|/N D_valid^2) scaling remains intact."
      }
    ],
    "gaps": [
      {
        "description": "The proof sketches a bound with constant 4 but notes the lemma uses a tighter constant (possibly 2); a detailed geometric argument for the tighter bound is omitted.",
        "severity": "minor",
        "location_hint": "Step 4 (summing and expectation)"
      }
    ],
    "tags": [
      "dead-walkers",
      "cloning",
      "variance-bound",
      "triangle-inequality",
      "barycenter",
      "convex-set",
      "domain-diameter",
      "expected-value"
    ]
  },
  {
    "label": "proof-lem-velocity-noise-propagation",
    "proves": "thm-positional-variance-contraction",
    "proof_type": "direct",
    "proof_status": "sketch",
    "strategy_summary": "The proof combines bounds from Lemmas 10.3.4 and 10.3.5 to obtain an inequality for the expected change in positional variance, relates the structural variance term back to the total variance using Lemma 10.3.6, and rescales to demonstrate a geometric contraction in the variance functional independent of the swarm size N.",
    "conclusion": {
      "text": "The expected positional variance contracts geometrically: \\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x, where \\kappa_x > 0 is independent of N.",
      "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x"
    },
    "assumptions": [
      {
        "text": "The structural error satisfies V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}, which holds when both swarms have similar numbers of alive walkers.",
        "latex": "V_{\\text{struct}} \\geq \\frac{1}{2} V_{\\text{Var},x}"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "combination",
        "text": "Combine Lemmas 10.3.4 and 10.3.5 to bound the expected change in variance.",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] = \\sum_{k=1,2} \\mathbb{E}[\\Delta V_{\\text{Var},x}^{(k,\\text{alive})} + \\Delta V_{\\text{Var},x}^{(k,\\text{status})}] \\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|",
        "references": [
          "lem-10.3.4",
          "lem-10.3.5"
        ],
        "derived_statement": "Initial bound on \\Delta V_{\\text{Var},x}"
      },
      {
        "order": 2,
        "kind": "relation",
        "text": "Use Lemma 10.3.6 to relate V_{\\text{struct}} to V_{\\text{Var},x} under the assumption, absorbing bounded terms into C_{\\text{total}}.",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}",
        "references": [
          "lem-sx-implies-variance"
        ],
        "derived_statement": "Simplified bound with contraction in V_{\\text{Var},x}"
      },
      {
        "order": 3,
        "kind": "rescaling",
        "text": "Define \\kappa_x and rescale using N-normalization to obtain the geometric contraction form.",
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x",
        "references": [],
        "derived_statement": "Final contraction inequality"
      }
    ],
    "key_equations": [
      {
        "label": "eq-combined-bound",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{2N} V_{\\text{struct}} + \\frac{g_{\\max}(\\epsilon)}{N} + C_{\\text{pers}} + \\frac{8 D_{\\text{valid}}^2}{N} \\sum_{k} |\\mathcal{D}(S_k)|",
        "role": "Initial combined inequality from lemmas"
      },
      {
        "label": "eq-related-variance",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\frac{\\chi(\\epsilon)}{4N} V_{\\text{Var},x} + C_{\\text{total}}",
        "role": "Bound after relating structural to total variance"
      },
      {
        "label": "eq-geometric-contraction",
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{Var},x}(S')] \\leq (1 - \\kappa_x) V_{\\text{Var},x}(S) + C_x",
        "role": "Final contraction result"
      }
    ],
    "references": [
      "thm-positional-variance-contraction",
      "lem-sx-implies-variance"
    ],
    "math_tools": [
      {
        "toolName": "Lyapunov Function",
        "field": "Dynamical Systems",
        "description": "A function used to prove stability or convergence by showing its decrease along system trajectories.",
        "roleInProof": "V_var,x serves as a Lyapunov functional whose expected decrease implies contraction in positional variance.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Contraction Mapping"
        ]
      },
      {
        "toolName": "Expectation Operator",
        "field": "Probability Theory",
        "description": "The integral average over a probability measure, used to analyze average behavior in stochastic settings.",
        "roleInProof": "Applied to compute the expected change in variance under cloning and updates.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Variance"
        ]
      },
      {
        "toolName": "Geometric Contraction",
        "field": "Analysis",
        "description": "A form of inequality showing that a quantity decreases by a fixed factor less than 1 plus a constant term.",
        "roleInProof": "Derives the final form E[V'(S)] <= (1 - kappa) V(S) + C to establish convergence.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Lyapunov Function",
          "Gronwall Inequality"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The contraction constant \\kappa_x > 0 is independent of N due to the N-uniformity of the Keystone Lemma."
      }
    ],
    "gaps": [
      {
        "description": "Detailed derivation of the combination of Lemmas 10.3.4 and 10.3.5 is omitted; assumes direct summation of their bounds.",
        "severity": "minor",
        "location_hint": "Initial inequality"
      },
      {
        "description": "Precise definition of 'typical variance' and rescaling details for \\kappa_x are not fully expanded.",
        "severity": "moderate",
        "location_hint": "Step 2"
      }
    ],
    "tags": [
      "variance-contraction",
      "expected-change",
      "geometric-decay",
      "stochastic-process",
      "swarm-dynamics",
      "lyapunov-function",
      "n-uniformity"
    ]
  },
  {
    "label": "proof-thm-velocity-variance-bounded-expansion",
    "proves": "thm-velocity-variance-bounded-expansion",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes a state- and N-independent bound on the expected change in velocity variance by first bounding individual velocities, then the velocity changes in collisions, decomposing the variance change into direct resets, barycenter shifts, and random rotations, and finally summing the bounded contributions.",
    "conclusion": {
      "text": "The expected change in velocity variance is bounded by a constant C_v independent of state and N.",
      "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq C_v"
    },
    "assumptions": [
      {
        "text": "Axiom EG-4: Velocity regularization bounds all velocities by V_max based on physical parameters.",
        "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}"
      },
      {
        "text": "Inelastic collision with restitution coefficient alpha_restitution and random rotations.",
        "latex": "v'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)"
      },
      {
        "text": "Momentum conservation in collisions.",
        "latex": null
      },
      {
        "text": "Normalization by N and probabilities p_i summing appropriately.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "bound",
        "text": "Establish boundedness of velocity domain using Axiom EG-4.",
        "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}",
        "references": [
          "axiom-eg-4"
        ],
        "derived_statement": "All velocities are uniformly bounded by state-independent constant."
      },
      {
        "order": 2,
        "kind": "bound",
        "text": "Bound the squared velocity change for a walker in collision.",
        "latex": "\\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2",
        "references": [],
        "derived_statement": "Individual velocity updates are bounded."
      },
      {
        "order": 3,
        "kind": "decomposition",
        "text": "Decompose variance change into direct resets, barycenter shift, and random rotations, each bounded.",
        "latex": null,
        "references": [],
        "derived_statement": "Each component's contribution to variance change is controlled by constants."
      },
      {
        "order": 4,
        "kind": "summing",
        "text": "Sum bounds over walkers with N-normalization to get total expected variance change bound.",
        "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}} =: C_v",
        "references": [],
        "derived_statement": "Overall bound is state- and N-independent."
      }
    ],
    "key_equations": [
      {
        "label": "eq-vmax",
        "latex": "\\|v_i\\| \\leq V_{\\max} := \\sqrt{\\max\\left\\{\\frac{2F_{\\max}}{\\gamma}, V_{\\text{thresh}}^2\\right\\}}",
        "role": "Velocity bound from axiom."
      },
      {
        "label": "eq-velocity-update",
        "latex": "v'_i = V_{\\text{COM}} + \\alpha_{\\text{restitution}} \\cdot R_i(u_i)",
        "role": "Post-collision velocity formula."
      },
      {
        "label": "eq-change-bound",
        "latex": "\\|v'_i - v_i\\|^2 \\leq 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2",
        "role": "Bound on squared velocity change."
      },
      {
        "label": "eq-variance-change",
        "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq \\frac{1}{N} \\sum_{i=1}^N p_i \\cdot 4(\\alpha_{\\text{restitution}} + 1)^2 V_{\\max}^2 + C_{\\text{bary}}",
        "role": "Decomposed expected variance change."
      },
      {
        "label": "eq-final-bound",
        "latex": "\\mathbb{E}[\\Delta V_{\\text{Var},v}] \\leq C_v",
        "role": "Final constant bound."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Vector norms",
        "field": "Linear Algebra",
        "description": "Measures the magnitude of velocity vectors to bound changes.",
        "roleInProof": "Used to bound velocity magnitudes and squared differences in collision updates.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Euclidean norm"
        ]
      },
      {
        "toolName": "Expectation",
        "field": "Probability",
        "description": "Computes the average change in variance under random collision outcomes.",
        "roleInProof": "Bounds the expected variance change by linearity over walker contributions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Variance"
        ]
      },
      {
        "toolName": "Inelastic collision model",
        "field": "Physics",
        "description": "Models velocity updates in multi-particle collisions with restitution coefficient.",
        "roleInProof": "Defines the velocity post-collision formula involving center-of-mass and rotations.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Center of mass",
          "Restitution coefficient"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The bound is state-independent, relying only on physical parameters like V_max and alpha_restitution."
      },
      {
        "type": "note",
        "text": "N-independence arises from normalization canceling the sum over N walkers."
      }
    ],
    "gaps": [],
    "tags": [
      "velocity variance",
      "inelastic collision",
      "bounded expansion",
      "swarm model",
      "velocity regularization",
      "momentum conservation",
      "random rotation"
    ]
  },
  {
    "label": "proof-cor-structural-error-contraction",
    "proves": "cor-structural-error-contraction",
    "proof_type": "reference",
    "proof_status": "sketch",
    "strategy_summary": "The proof references a lemma to bound the structural variance by the sum of individual variances and argues that contraction in the individual variances directly implies contraction in the structural variance, with the contraction constant depending on related parameters.",
    "conclusion": {
      "text": "The structural variance V_struct contracts with constant κ_struct depending on κ_x and normalization relationships.",
      "latex": null
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "reference",
        "text": "Invoke lemma lem-sx-implies-variance.",
        "latex": null,
        "references": [
          "lem-sx-implies-variance"
        ],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "equation",
        "text": "Establish the bound V_struct ≤ 2(Var_1(x) + Var_2(x)), where Var_k(x) = (1/k_alive) ∑_{i ∈ A(S_k)} ||δ_{x,k,i}||^2.",
        "latex": "V_{\\text{struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\newline \\text{where } \\text{Var}_k(x) = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "references": [],
        "derived_statement": "Bound on structural variance"
      },
      {
        "order": 3,
        "kind": "implication",
        "text": "Contraction of V_{Var,x} (proportional to the sum of these variances) implies contraction of V_struct.",
        "latex": null,
        "references": [],
        "derived_statement": "Contraction implication"
      },
      {
        "order": 4,
        "kind": "note",
        "text": "The constant κ_struct depends on κ_x and the relationship between N-normalized and k_alive-normalized variances.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-struct-bound",
        "latex": "V_{\\text{struct}} \\leq 2(\\text{Var}_1(x) + \\text{Var}_2(x)) \\newline \\text{where } \\text{Var}_k(x) = \\frac{1}{k_{\\text{alive}}} \\sum_{i \\in \\mathcal{A}(S_k)} \\|\\delta_{x,k,i}\\|^2",
        "role": "Key bounding inequality from the lemma"
      }
    ],
    "references": [
      "lem-sx-implies-variance"
    ],
    "math_tools": [
      {
        "toolName": "Variance",
        "field": "Probability",
        "description": "A measure of the dispersion of a random variable or set of values around their mean.",
        "roleInProof": "Used to bound and analyze the contraction of the structural variance V_struct via individual component variances.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Norm"
        ]
      },
      {
        "toolName": "Euclidean Norm",
        "field": "Linear Algebra",
        "description": "A function that assigns a length or size to each vector in a space.",
        "roleInProof": "Appears in the definition of individual variances as the squared norm of delta terms.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Variance"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The constant κ_struct depends on κ_x and the relationship between N-normalized and k_alive-normalized variances."
      }
    ],
    "gaps": [
      {
        "description": "The proof sketch does not explicitly detail the proportionality of V_{Var,x} to the sum of variances or the exact mechanism of contraction propagation.",
        "severity": "minor",
        "location_hint": "Implication from individual variances to structural contraction"
      }
    ],
    "tags": [
      "contraction",
      "variance",
      "structural error",
      "bounding",
      "lemma reference"
    ]
  },
  {
    "label": "proof-thm-complete-variance-drift",
    "proves": "thm-complete-variance-drift",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof directly combines the established drift inequalities for positional and velocity variances using linearity of expectation to derive the total internal variance drift inequality.",
    "conclusion": {
      "text": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)",
      "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)"
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "reference",
        "text": "Recall the positional variance contraction inequality.",
        "latex": null,
        "references": [
          "thm-positional-variance-contraction"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x"
      },
      {
        "order": 2,
        "kind": "reference",
        "text": "Recall the bounded velocity variance expansion inequality.",
        "latex": null,
        "references": [
          "thm-bounded-velocity-expansion-cloning",
          "thm-velocity-variance-bounded-expansion"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v"
      },
      {
        "order": 3,
        "kind": "application",
        "text": "Apply linearity of expectation to the total variance change.",
        "latex": null,
        "references": [],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x} + \\Delta V_{\\text{Var},v}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]"
      },
      {
        "order": 4,
        "kind": "inequality",
        "text": "Combine the inequalities to obtain the total drift bound.",
        "latex": null,
        "references": [],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq (-\\kappa_x V_{\\text{Var},x} + C_x) + C_v = -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)"
      }
    ],
    "key_equations": [
      {
        "label": "eq-positional-drift",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] \\leq -\\kappa_x V_{\\text{Var},x} + C_x",
        "role": "Component inequality for positional variance"
      },
      {
        "label": "eq-velocity-drift",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}] \\leq C_v",
        "role": "Component inequality for velocity variance"
      },
      {
        "label": "eq-total-drift",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] \\leq -\\kappa_x V_{\\text{Var},x} + (C_x + C_v)",
        "role": "Final total variance drift inequality"
      }
    ],
    "references": [
      "thm-positional-variance-contraction",
      "thm-bounded-velocity-expansion-cloning",
      "thm-velocity-variance-bounded-expansion"
    ],
    "math_tools": [
      {
        "toolName": "Linearity of Expectation",
        "field": "Probability Theory",
        "description": "The expectation of the sum of random variables equals the sum of their individual expectations, regardless of dependence.",
        "roleInProof": "Applied to separate the expected change in total variance into positional and velocity components.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "variance",
      "drift",
      "inequality",
      "linearity of expectation",
      "cloning",
      "probabilistic drift"
    ]
  },
  {
    "label": "proof-lem-fitness-gradient-boundary",
    "proves": "lem-fitness-gradient-boundary",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof proceeds by tracing the impact of boundary proximity on the raw reward difference through subsequent transformations including floor addition, Z-score standardization, and fitness potential computation, demonstrating preservation of ordering at each step and deriving a positive lower bound on the fitness gap using the mean value theorem.",
    "conclusion": {
      "text": "The boundary proximity creates a systematic fitness deficit: walker i (closer to boundary) has fitness potential at least f(Δ_barrier) lower than walker j (farther from boundary), where f is a positive, N-uniform, monotonically increasing function of the barrier difference.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Walkers i and j have similar positions and velocities, implying R_pos(x_i) ≈ R_pos(x_j) and ||v_i|| ≈ ||v_j||.",
        "latex": null
      },
      {
        "text": "Walkers i and j have similar diversity measurements, i.e., z_{d,i} ≈ z_{d,j}.",
        "latex": null
      },
      {
        "text": "The patched standard deviation σ'_\tilde{r} > 0 and is bounded above by some σ'_max due to boundedness axioms.",
        "latex": null
      },
      {
        "text": "Parameters α, β > 0, η > 0, ensuring positivity and strict increase of the power function.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "The raw reward for walker i is defined as r_i = R_pos(x_i) - c_v_reg ||v_i||^2 - φ_barrier(x_i). For walkers i and j with similar positions and velocities but i closer to the boundary (φ_barrier(x_i) > φ_barrier(x_j)), the raw reward difference is approximately -Δ_barrier < 0, so r_i < r_j.",
        "latex": "r_i = R_{\\text{pos}}(x_i) - c_{v_{\\text{reg}}} \\|v_i\\|^2 - \\varphi_{\\text{barrier}}(x_i) \\[ r_i - r_j \\approx -\\Delta_{\\text{barrier}} < 0 \\]",
        "references": [],
        "derived_statement": "r_i < r_j"
      },
      {
        "order": 2,
        "kind": "transformation",
        "text": "Adding a positive floor η > 0 to ensure positivity: \tilde{r}_i = r_i + η, \tilde{r}_j = r_j + η. Since a constant is added, the ordering is preserved: \tilde{r}_i < \tilde{r}_j.",
        "latex": "\\tilde{r}_i = r_i + \\eta, \\quad \\tilde{r}_j = r_j + \\eta \\[ \\tilde{r}_i - \\tilde{r}_j = r_i - r_j = -\\Delta_{\\text{barrier}} < 0 \\]",
        "references": [],
        "derived_statement": "\\tilde{r}_i < \\tilde{r}_j"
      },
      {
        "order": 3,
        "kind": "standardization",
        "text": "Z-scores are computed as z_{r,i} = (\tilde{r}_i - μ_\tilde{r}) / σ'_\tilde{r}, similarly for j. Since \tilde{r}_i < \tilde{r}_j and σ'_\tilde{r} > 0, the ordering is preserved: z_{r,i} < z_{r,j}.",
        "latex": "z_{r,i} = \\frac{\\tilde{r}_i - \\mu_{\\tilde{r}}}{\\sigma'_{\\tilde{r}}}, \\quad z_{r,j} = \\frac{\\tilde{r}_j - \\mu_{\\tilde{r}}}{\\sigma'_{\\tilde{r}}} \\[ z_{r,i} < z_{r,j} \\]",
        "references": [],
        "derived_statement": "z_{r,i} < z_{r,j}"
      },
      {
        "order": 4,
        "kind": "computation",
        "text": "Fitness potential V_{fit,i} = (α z_{d,i} + β z_{r,i} + η)^{α+β}, similarly for j. With z_{d,i} ≈ z_{d,j} and z_{r,i} < z_{r,j}, the argument is smaller for i, and since x^{α+β} is strictly increasing for x > 0, V_{fit,i} < V_{fit,j}.",
        "latex": "V_{\\text{fit},i} = (\\alpha z_{d,i} + \\beta z_{r,i} + \\eta)^{\\alpha+\\beta} \\[ \\alpha z_{d,i} + \\beta z_{r,i} + \\eta < \\alpha z_{d,j} + \\beta z_{r,j} + \\eta \\] V_{\\text{fit},i} < V_{\\text{fit},j}",
        "references": [],
        "derived_statement": "V_{\\text{fit},i} < V_{\\text{fit},j}"
      },
      {
        "order": 5,
        "kind": "bounding",
        "text": "Using the mean value theorem on the power function, V_{fit,j} - V_{fit,i} = (u_j - u_i) · (α + β) ξ^{α + β - 1} ≥ (β Δ_barrier / σ'_\tilde{r}) · (α + β) η^{α + β - 1} = f(Δ_barrier), where u_i, u_j are the arguments and ξ > η.",
        "latex": "u_i := \\alpha z_{d,i} + \\beta z_{r,i} + \\eta, \\quad u_j := \\alpha z_{d,j} + \\beta z_{r,j} + \\eta \\[ V_{\\text{fit},j} - V_{\\text{fit},i} = (u_j - u_i) \\cdot (\\alpha + \\beta) \\xi^{\\alpha + \\beta - 1} \\geq \\frac{\\beta \\Delta_{\\text{barrier}}}{\\sigma'_{\\tilde{r}}} \\cdot (\\alpha + \\beta) \\eta^{\\alpha + \\beta - 1} =: f(\\Delta_{\\text{barrier}}) \\]",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 6,
        "kind": "analysis",
        "text": "The function f(Δ) = c_β Δ, with c_β a positive constant independent of N (using σ'_max), is linear in the barrier difference and N-uniform.",
        "latex": "f(\\Delta) = c_{\\beta} \\Delta \\quad c_{\\beta} := \\frac{\\beta (\\alpha + \\beta)}{\\sigma'_{\\max}} \\eta^{\\alpha + \\beta - 1}",
        "references": [],
        "derived_statement": "f is positive, N-uniform, monotonically increasing"
      }
    ],
    "key_equations": [
      {
        "label": "eq-raw-reward",
        "latex": "r_i = R_{\\text{pos}}(x_i) - c_{v_{\\text{reg}}} \\|v_i\\|^2 - \\varphi_{\\text{barrier}}(x_i)",
        "role": "Definition of raw reward for walker i"
      },
      {
        "label": "eq-reward-diff",
        "latex": "r_i - r_j \\approx -[\\varphi_{\\text{barrier}}(x_i) - \\varphi_{\\text{barrier}}(x_j)] = -\\Delta_{\\text{barrier}} < 0",
        "role": "Raw reward difference due to boundary penalty"
      },
      {
        "label": "eq-floored-reward",
        "latex": "\\tilde{r}_i = r_i + \\eta, \\quad \\tilde{r}_j = r_j + \\eta",
        "role": "Addition of floor to ensure positivity, preserves ordering"
      },
      {
        "label": "eq-z-score",
        "latex": "z_{r,i} = \\frac{\\tilde{r}_i - \\mu_{\\tilde{r}}}{\\sigma'_{\\tilde{r}}}",
        "role": "Standardization of floored rewards, preserves ordering"
      },
      {
        "label": "eq-fitness-potential",
        "latex": "V_{\\text{fit},i} = (\\alpha z_{d,i} + \\beta z_{r,i} + \\eta)^{\\alpha+\\beta}",
        "role": "Computation of fitness potential, preserves ordering via monotonicity"
      },
      {
        "label": "eq-mvt-bound",
        "latex": "V_{\\text{fit},j} - V_{\\text{fit},i} \\geq \\frac{\\beta \\Delta_{\\text{barrier}}}{\\sigma'_{\\tilde{r}}} \\cdot (\\alpha + \\beta) \\eta^{\\alpha + \\beta - 1} =: f(\\Delta_{\\text{barrier}})",
        "role": "Lower bound on fitness gap using mean value theorem"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Z-score Standardization",
        "field": "Statistics",
        "description": "A normalization technique that transforms data to have mean zero and standard deviation one by subtracting the mean and dividing by the standard deviation.",
        "roleInProof": "Normalizes the floored rewards while preserving their relative ordering due to subtraction of the same mean and division by a positive standard deviation.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Standard Deviation"
        ]
      },
      {
        "toolName": "Mean Value Theorem",
        "field": "Real Analysis",
        "description": "For a function continuous on [a, b] and differentiable on (a, b), there exists some c in (a, b) such that f'(c) = (f(b) - f(a)) / (b - a).",
        "roleInProof": "Applied to the power function in the fitness potential to obtain a lower bound on the difference between fitness potentials of two walkers.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Rolle's Theorem"
        ]
      },
      {
        "toolName": "Monotonicity of Increasing Functions",
        "field": "Calculus",
        "description": "A function f is strictly increasing if for all x < y, f(x) < f(y), preserving inequalities under composition.",
        "roleInProof": "Ensures that inequalities in rewards and intermediate arguments propagate through additions, scalings, and the power function to the final fitness potentials.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Power Function"
        ]
      }
    ],
    "cases": [
      {
        "name": null,
        "condition": null,
        "summary": null
      }
    ],
    "remarks": [
      {
        "type": "N-uniformity",
        "text": "The proportionality constant c_β is independent of the number of walkers N, ensuring the bound holds uniformly."
      },
      {
        "type": null,
        "text": null
      }
    ],
    "gaps": [],
    "tags": [
      "fitness-potential",
      "boundary-effect",
      "reward-difference",
      "z-score-standardization",
      "mean-value-theorem",
      "monotonicity",
      "linear-bound"
    ]
  },
  {
    "label": "proof-lem-boundary-enhanced-cloning",
    "proves": "lem-boundary-enhanced-cloning",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof establishes a positive lower bound on the cloning probability for boundary-exposed walkers by sequentially bounding the fitness penalty relative to interior walkers, the probability of selecting a safe interior companion, the resulting cloning score, and the threshold comparison, ensuring the bound holds independently of the population size.",
    "conclusion": {
      "text": "The cloning probability p_i for a boundary-exposed walker satisfies p_i >= p_boundary(phi_thresh) > 0, independent of population size N and depending only on phi_thresh and algorithmic parameters.",
      "latex": "$p_i \\geq p_{\\text{boundary}}(\\phi_{\\text{thresh}}) > 0$"
    },
    "assumptions": [
      {
        "text": "i is a boundary-exposed walker, so varphi_barrier(x_i) > phi_thresh.",
        "latex": "$i \\in \\mathcal{E}_{\\text{boundary}}(S)$, $\\varphi_{\\text{barrier}}(x_i) > \\phi_{\\text{thresh}}$"
      },
      {
        "text": "Interior walkers j satisfy varphi_barrier(x_j) = 0.",
        "latex": "$\\varphi_{\\text{barrier}}(x_j) = 0$ for $j \\in \\mathcal{I}_{\\text{safe}}$"
      },
      {
        "text": "Threshold T_i ~ Uniform(0, p_max).",
        "latex": "$T_i \\sim \\text{Uniform}(0, p_{\\max})$"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "fitness-penalty",
        "text": "By lem-fitness-gradient-boundary, boundary walker i has lower fitness than some interior walker j: V_fit,i < V_fit,j - f(phi_thresh).",
        "latex": "$V_{\\text{fit},i} < V_{\\text{fit},j} - f(\\phi_{\\text{thresh}})$",
        "references": [
          "lem-fitness-gradient-boundary"
        ],
        "derived_statement": "Lower fitness difference established."
      },
      {
        "order": 2,
        "kind": "selection-probability",
        "text": "In the companion selection operator (def-decision-operator), P(c_i in I_safe) >= p_interior > 0, where I_safe = {j : varphi_barrier(x_j) = 0}.",
        "latex": "$P(c_i \\in \\mathcal{I}_{\\text{safe}}) \\geq p_{\\text{interior}} > 0$",
        "references": [
          "def-decision-operator"
        ],
        "derived_statement": "Non-zero probability of selecting safe interior companion."
      },
      {
        "order": 3,
        "kind": "cloning-score",
        "text": "Conditioning on interior companion j, S_i = (V_fit,j - V_fit,i)/(V_fit,i + epsilon_clone) >= f(phi_thresh)/(V_pot,max + epsilon_clone) =: s_min(phi_thresh).",
        "latex": "$S_i = \\frac{V_{\\text{fit},j} - V_{\\text{fit},i}}{V_{\\text{fit},i} + \\varepsilon_{\\text{clone}}} \\geq \\frac{f(\\phi_{\\text{thresh}})}{V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}}} =: s_{\\text{min}}(\\phi_{\\text{thresh}})$",
        "references": [],
        "derived_statement": "Lower bound on cloning score."
      },
      {
        "order": 4,
        "kind": "cloning-probability",
        "text": "p_i = P(S_i > T_i) * P(c_i in I_safe) >= P(s_min > T_i) * p_interior, and since T_i ~ Uniform(0, p_max), P(s_min > T_i) = min(1, s_min / p_max), so p_i >= min(1, s_min(phi_thresh)/p_max) * p_interior =: p_boundary(phi_thresh) > 0.",
        "latex": "$p_i = P(S_i > T_i) \\cdot P(c_i \\in \\mathcal{I}_{\\text{safe}}) \\geq P(s_{\\text{min}} > T_i) \\cdot p_{\\text{interior}} = \\min\\left(1, \\frac{s_{\\text{min}}(\\phi_{\\text{thresh}})}{p_{\\max}}\\right) \\cdot p_{\\text{interior}} =: p_{\\text{boundary}}(\\phi_{\\text{thresh}}) > 0$",
        "references": [],
        "derived_statement": "Positive lower bound on cloning probability independent of N."
      }
    ],
    "key_equations": [
      {
        "label": "eq-fitness-ineq",
        "latex": "$V_{\\text{fit},i} < V_{\\text{fit},j} - f(\\phi_{\\text{thresh}})$",
        "role": "Fitness penalty bound"
      },
      {
        "label": "eq-selection-prob",
        "latex": "$P(c_i \\in \\mathcal{I}_{\\text{safe}}) \\geq p_{\\text{interior}} > 0$",
        "role": "Companion selection lower bound"
      },
      {
        "label": "eq-cloning-score",
        "latex": "$S_i \\geq \\frac{f(\\phi_{\\text{thresh}})}{V_{\\text{pot,max}} + \\varepsilon_{\\text{clone}}} =: s_{\\text{min}}(\\phi_{\\text{thresh}})$",
        "role": "Cloning score lower bound"
      },
      {
        "label": "eq-cloning-prob",
        "latex": "$p_i \\geq \\min\\left(1, \\frac{s_{\\text{min}}(\\phi_{\\text{thresh}})}{p_{\\max}}\\right) \\cdot p_{\\text{interior}} =: p_{\\text{boundary}}(\\phi_{\\text{thresh}}) > 0$",
        "role": "Final cloning probability lower bound"
      }
    ],
    "references": [
      "lem-fitness-gradient-boundary",
      "def-decision-operator"
    ],
    "math_tools": [
      {
        "toolName": "Uniform Distribution",
        "field": "Probability",
        "description": "A continuous probability distribution where all values in an interval are equally likely.",
        "roleInProof": "Used to model the random threshold T_i, enabling computation of the probability P(s_min > T_i).",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Probability Bounds"
        ]
      },
      {
        "toolName": "Lower Bound Inequality",
        "field": "Analysis",
        "description": "A technique to establish a minimum value for a quantity using inequalities.",
        "roleInProof": "Applied throughout to derive successive lower bounds on fitness differences, selection probabilities, scores, and final cloning probability.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Uniform Distribution"
        ]
      },
      {
        "toolName": "Conditional Probability",
        "field": "Probability",
        "description": "Probability of an event given that another event has occurred.",
        "roleInProof": "Used to condition the cloning score on selecting an interior companion, leading to the score lower bound.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Lower Bound Inequality"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "independence",
        "text": "This bound is independent of N and depends only on phi_thresh and the algorithmic parameters."
      }
    ],
    "gaps": [],
    "tags": [
      "boundary-exposed",
      "fitness-penalty",
      "companion-selection",
      "cloning-probability",
      "uniform-threshold",
      "lower-bound"
    ]
  },
  {
    "label": "proof-lem-barrier-reduction-cloning",
    "proves": "lem-barrier-reduction-cloning",
    "proof_type": "probabilistic",
    "proof_status": "sketch",
    "strategy_summary": "The proof analyzes the expected barrier penalty after cloning in two cases: when the companion is in the safe interior, where small Gaussian jitter keeps the new position safe with high probability, bounding the expectation by a small constant; and in the general case, where smoothness allows a Taylor approximation to show the expected penalty remains close to that of the companion.",
    "conclusion": {
      "text": "The expected barrier penalty after cloning is bounded by a small constant in the safe case and approximates the companion's penalty plus a controlled error in the general case, ensuring reduction under appropriate conditions.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "The barrier function \\(\\varphi_{\\text{barrier}}\\) is smooth (twice differentiable with bounded Hessian) in the interior.",
        "latex": "\\varphi_{\\text{barrier}} smooth"
      },
      {
        "text": "The jitter variance \\(\\sigma_x\\) is sufficiently small (\\(\\sigma_x < \\delta_{\\text{safe}}\\)) to control probabilistic escape from the safe region.",
        "latex": "\\sigma_x < \\delta_{\\text{safe}}"
      },
      {
        "text": "The safe interior \\(\\mathcal{I}_{\\text{safe}}\\) has positive width \\(\\delta_{\\text{safe}}\\) where \\(\\varphi_{\\text{barrier}} = 0\\).",
        "latex": "\\mathcal{I}_{\\text{safe}} has width \\delta_{\\text{safe}} > 0"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "Define the cloned position of walker i from companion c_i as x'_i = x_{c_i} + \\sigma_x \\zeta_i^x where \\zeta_i^x ~ \\mathcal{N}(0, I_d).",
        "latex": "x'_i = x_{c_i} + \\sigma_x \\zeta_i^x \\quad \\zeta_i^x \\sim \\mathcal{N}(0, I_d)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "case-start",
        "text": "Case 1: Companion in safe interior (c_i \\in \\mathcal{I}_{\\text{safe}}).",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "claim",
        "text": "\\varphi_{\\text{barrier}}(x_{c_i}) = 0 by definition.",
        "latex": "\\varphi_{\\text{barrier}}(x_{c_i}) = 0",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "calculation",
        "text": "With small \\sigma_x < \\delta_{\\text{safe}}, the probability that x'_i stays in safe region is high: P(\\varphi_{\\text{barrier}}(x'_i) = 0) \\geq 1 - \\epsilon_{\\text{jitter}}.",
        "latex": "P(\\varphi_{\\text{barrier}}(x'_i) = 0) \\geq 1 - \\epsilon_{\\text{jitter}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "bound",
        "text": "In worst case, \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\leq \\epsilon_{\\text{jitter}} \\cdot \\varphi_{\\text{barrier,max}} =: C_{\\text{jitter}}.",
        "latex": "\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\leq \\epsilon_{\\text{jitter}} \\cdot \\varphi_{\\text{barrier,max}} =: C_{\\text{jitter}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 6,
        "kind": "case-start",
        "text": "Case 2: General companion position.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "approximation",
        "text": "The expected barrier is centered around the companion's: \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\approx \\varphi_{\\text{barrier}}(x_{c_i}) + O(\\sigma_x^2 \\|\\nabla \\varphi_{\\text{barrier}}(x_{c_i})\\|^2).",
        "latex": "\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\approx \\varphi_{\\text{barrier}}(x_{c_i}) + O(\\sigma_x^2 \\|\\nabla \\varphi_{\\text{barrier}}(x_{c_i})\\|^2)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 8,
        "kind": "justification",
        "text": "The second-order term is bounded by smoothness of \\varphi_{\\text{barrier}} in the interior.",
        "latex": null,
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-cloning-position",
        "latex": "x'_i = x_{c_i} + \\sigma_x \\zeta_i^x \\quad \\zeta_i^x \\sim \\mathcal{N}(0, I_d)",
        "role": "Defines the random cloning mechanism"
      },
      {
        "label": "eq-safe-prob",
        "latex": "P(\\varphi_{\\text{barrier}}(x'_i) = 0) \\geq 1 - \\epsilon_{\\text{jitter}}",
        "role": "Probabilistic guarantee for safe cloning"
      },
      {
        "label": "eq-jitter-bound",
        "latex": "\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\leq \\epsilon_{\\text{jitter}} \\cdot \\varphi_{\\text{barrier,max}} =: C_{\\text{jitter}}",
        "role": "Bounds expectation in safe case"
      },
      {
        "label": "eq-general-approx",
        "latex": "\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\approx \\varphi_{\\text{barrier}}(x_{c_i}) + O(\\sigma_x^2 \\|\\nabla \\varphi_{\\text{barrier}}(x_{c_i})\\|^2)",
        "role": "Approximation for general case"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Gaussian Distribution",
        "field": "Probability",
        "description": "The multivariate normal distribution used to model random perturbations.",
        "roleInProof": "Generates the jitter in cloning to place the new walker position probabilistically near the companion.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      },
      {
        "toolName": "Taylor Expansion",
        "field": "Analysis",
        "description": "Second-order approximation for smooth functions to estimate changes under small perturbations.",
        "roleInProof": "Approximates the barrier function at the perturbed position to bound its expectation in the general case.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "smoothness"
        ]
      },
      {
        "toolName": "Smoothness Assumption",
        "field": "Analysis",
        "description": "Assumption that the function is twice differentiable with bounded Hessian, ensuring local quadratic behavior.",
        "roleInProof": "Justifies the bounded second-order term in the approximation for the barrier penalty.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Taylor Expansion"
        ]
      }
    ],
    "cases": [
      {
        "name": "Companion in safe interior",
        "condition": "c_i \\in \\mathcal{I}_{\\text{safe}}",
        "summary": "Jitter keeps x'_i safe with high probability, bounding \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] \\leq C_{\\text{jitter}} small."
      },
      {
        "name": "General companion",
        "condition": "Arbitrary c_i",
        "summary": "Smoothness yields \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_i)] close to \\varphi_{\\text{barrier}}(x_{c_i}), with bounded perturbation error."
      }
    ],
    "remarks": [
      {
        "type": "approximation",
        "text": "The analysis relies on a second-order Taylor expansion, assuming sufficient smoothness to control higher-order terms."
      },
      {
        "type": "probabilistic",
        "text": "High-probability statements use concentration properties of the Gaussian, though exact constants like \\epsilon_{\\text{jitter}} depend on the barrier geometry."
      }
    ],
    "gaps": [
      {
        "description": "The proof sketches bounds but does not explicitly show how this leads to overall barrier reduction for the lemma, e.g., relating to the companion's penalty or aggregating over walkers.",
        "severity": "major",
        "location_hint": "Transition between cases and conclusion"
      },
      {
        "description": "The O(\\sigma_x^2 \\|\\nabla \\|^2) term is stated as bounded but without deriving the explicit constant from smoothness assumptions.",
        "severity": "minor",
        "location_hint": "End of Case 2"
      }
    ],
    "tags": [
      "barrier-penalty",
      "cloning",
      "gaussian-jitter",
      "safe-region",
      "smoothness",
      "expectation-bound",
      "taylor-approximation"
    ]
  },
  {
    "label": "proof-lem-barrier-reduction-measurement",
    "proves": "thm-boundary-potential-contraction",
    "proof_type": "direct",
    "proof_status": "sketch",
    "strategy_summary": "The proof analyzes the expected change in the boundary potential by decomposing it into contributions from cloning and persisting walkers, bounding the cloning effects using referenced lemmas, relating boundary-exposed mass to the total potential, and deriving a geometric contraction inequality that holds when the potential is sufficiently large.",
    "conclusion": {
      "text": "E[W_b(S')] ≤ (1 - κ_b) W_b(S) + C_b, with κ_b > 0 independent of N.",
      "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b \\quad \\text{with} \\quad \\kappa_b > 0 \\text{ independent of } N"
    },
    "assumptions": [
      {
        "text": "Assumptions from lem-boundary-enhanced-cloning and lem-barrier-reduction-cloning hold, including boundary exposure conditions and threshold values.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "decomposition",
        "text": "Decompose the expected change in boundary potential by cloning action, splitting sums over active walkers into cloning and persisting parts.",
        "latex": "\\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "Bound the contribution from boundary-exposed walkers using referenced lemmas: p_{k,i} ≥ p_boundary and E[φ_barrier | clone] ≤ C_jitter, leading to a negative term involving the barrier values.",
        "latex": "\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]",
        "references": [
          "lem-boundary-enhanced-cloning",
          "lem-barrier-reduction-cloning"
        ],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "relation",
        "text": "Relate the boundary-exposed mass M_boundary to the total boundary potential W_b, noting M_boundary ≥ W_b - (k_alive / N) φ_thresh when W_b is large.",
        "latex": "M_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) \\geq W_b(S_k) - \\frac{k_{\\text{alive}}}{N} \\phi_{\\text{thresh}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "combination",
        "text": "Combine the bounds to get E[Δ W_b^{(k)}] ≤ -p_boundary M_boundary + C'_jitter + C_dead, approximating M_boundary ≈ W_b for large W_b, and sum over swarms.",
        "latex": "\\mathbb{E}[\\Delta W_b] \\leq -p_{\\text{boundary}} W_b + 2C_{\\text{total}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "contraction",
        "text": "Express the result as a geometric contraction with constants κ_b = p_boundary and C_b = 2 C_total, noting independence from N.",
        "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b",
        "references": [
          "lem-boundary-enhanced-cloning"
        ],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-delta-wb",
        "latex": "\\Delta W_b = \\sum_{k=1,2} \\left[\\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S'_k)} \\varphi_{\\text{barrier}}(x'_{k,i}) - \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})\\right]",
        "role": "Definition of boundary potential change"
      },
      {
        "label": "eq-decomp-clone",
        "latex": "\\mathbb{E}[\\Delta W_b^{(k)}] = \\frac{1}{N} \\sum_{i \\in \\mathcal{A}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] + \\frac{1}{N} \\sum_{i \\in \\mathcal{D}(S_k)} \\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i})]",
        "role": "Decomposition by cloning action"
      },
      {
        "label": "eq-bound-exposed",
        "latex": "\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} p_{k,i} \\left[\\mathbb{E}[\\varphi_{\\text{barrier}}(x'_{k,i}) \\mid \\text{clone}] - \\varphi_{\\text{barrier}}(x_{k,i})\\right] \\leq -p_{\\text{boundary}} \\left[\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i}) - |\\mathcal{E}_{\\text{boundary}}| C_{\\text{jitter}}\\right]",
        "role": "Bound for exposed walkers"
      },
      {
        "label": "eq-m-boundary",
        "latex": "M_{\\text{boundary}}(S_k) = \\frac{1}{N}\\sum_{i \\in \\mathcal{E}_{\\text{boundary}}(S_k)} \\varphi_{\\text{barrier}}(x_{k,i})",
        "role": "Definition of boundary-exposed mass"
      },
      {
        "label": "eq-contraction",
        "latex": "\\mathbb{E}[W_b(S')] \\leq (1 - \\kappa_b) W_b(S) + C_b",
        "role": "Final contraction inequality"
      }
    ],
    "references": [
      "lem-boundary-enhanced-cloning",
      "lem-barrier-reduction-cloning"
    ],
    "math_tools": [
      {
        "toolName": "Expectation",
        "field": "Probability",
        "description": "The expected value operator computes the average over random outcomes.",
        "roleInProof": "Used to analyze the average change in boundary potential under cloning and movement dynamics.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Inequality"
        ]
      },
      {
        "toolName": "Bounding inequalities",
        "field": "Analysis",
        "description": "Techniques to upper or lower bound expressions using properties of functions and measures.",
        "roleInProof": "Applied to bound the contribution from boundary-exposed walkers and relate it to the total potential for contraction.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Expectation"
        ]
      },
      {
        "toolName": "Geometric contraction",
        "field": "Dynamical Systems",
        "description": "A form of stability where a quantity decreases by a fixed factor plus a constant term.",
        "roleInProof": "Establishes the main contraction result for the boundary potential.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Bounding inequalities"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "The contraction holds approximately when W_b is large, as most of the potential comes from exposed walkers."
      },
      {
        "type": "independence",
        "text": "The constant κ_b > 0 is independent of N by lem-boundary-enhanced-cloning."
      }
    ],
    "gaps": [
      {
        "description": "Approximation M_boundary ≈ W_b when W_b is large; rigorous justification for 'most of W_b comes from exposed walkers' is sketched but not fully detailed.",
        "severity": "minor",
        "location_hint": "Step 3 and combination in Step 4"
      },
      {
        "description": "Contributions from dead walkers and persisting walkers are bounded by constants but not explicitly derived in detail.",
        "severity": "minor",
        "location_hint": "Step 1 and Step 4"
      }
    ],
    "tags": [
      "boundary potential",
      "contraction",
      "cloning",
      "expected change",
      "barrier function",
      "swarm dynamics",
      "inequality bound"
    ]
  },
  {
    "label": "proof-cor-bounded-boundary-exposure",
    "proves": "cor-bounded-boundary-exposure",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof iterates the Foster-Lyapunov drift inequality to express the expected Lyapunov function value as a geometric decay term plus a summed constant, then takes the limit as time goes to infinity, where the decay vanishes and the infinite geometric series sums to yield the desired bound.",
    "conclusion": {
      "text": "The limsup of the expected Lyapunov function value is bounded by C_b / kappa_b.",
      "latex": "\\limsup_{t \\to \\infty} \\mathbb{E}[W_b(S_t)] \\leq \\frac{C_b}{\\kappa_b}"
    },
    "assumptions": [
      {
        "text": "The Foster-Lyapunov drift condition holds: \\mathbb{E}[W_b(S_{t+1}) | S_t] \\leq (1 - \\kappa_b) W_b(S_t) + C_b for some \\kappa_b > 0, C_b < \\infty.",
        "latex": "\\mathbb{E}[W_b(S_{t+1}) | S_t] \\leq (1 - \\kappa_b) W_b(S_t) + C_b \\; \\forall t, \\; \\text{with} \\; \\kappa_b > 0, \\; C_b < \\infty"
      },
      {
        "text": "The process starts from some initial state S_0 with finite W_b(S_0).",
        "latex": "W_b(S_0) < \\infty"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "initial inequality",
        "text": "Apply the Foster-Lyapunov drift condition.",
        "latex": "\\mathbb{E}[W_b(S_{t+1})] \\leq (1 - \\kappa_b) W_b(S_t) + C_b",
        "references": [
          "thm-foster-lyapunov-drift"
        ],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "iteration",
        "text": "Take expectations and iterate the inequality over time steps.",
        "latex": "\\mathbb{E}[W_b(S_t)] \\leq (1 - \\kappa_b)^t W_b(S_0) + C_b \\sum_{j=0}^{t-1} (1 - \\kappa_b)^j",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "limit",
        "text": "As t approaches infinity, the first term decays to zero since |1 - \\kappa_b| < 1, and evaluate the infinite sum.",
        "latex": "\\sum_{j=0}^{\\infty} (1 - \\kappa_b)^j = \\frac{1}{\\kappa_b}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "conclusion",
        "text": "Obtain the limsup bound on the expectation.",
        "latex": "\\limsup_{t \\to \\infty} \\mathbb{E}[W_b(S_t)] \\leq \\frac{C_b}{\\kappa_b}",
        "references": [],
        "derived_statement": "Bounded expectation established"
      }
    ],
    "key_equations": [
      {
        "label": "eq-drift-condition",
        "latex": "\\mathbb{E}[W_b(S_{t+1})] \\leq (1 - \\kappa_b) W_b(S_t) + C_b",
        "role": "Starting drift inequality"
      },
      {
        "label": "eq-iterated-bound",
        "latex": "\\mathbb{E}[W_b(S_t)] \\leq (1 - \\kappa_b)^t W_b(S_0) + C_b \\sum_{j=0}^{t-1} (1 - \\kappa_b)^j",
        "role": "Iterated form after t steps"
      },
      {
        "label": "eq-geometric-sum",
        "latex": "\\sum_{j=0}^{\\infty} (1 - \\kappa_b)^j = \\frac{1}{\\kappa_b}",
        "role": "Infinite series evaluation"
      },
      {
        "label": "eq-final-bound",
        "latex": "\\limsup_{t \\to \\infty} \\mathbb{E}[W_b(S_t)] \\leq \\frac{C_b}{\\kappa_b}",
        "role": "Asymptotic bound"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Foster-Lyapunov Drift Condition",
        "field": "Stochastic Processes",
        "description": "A stability criterion for Markov chains using a Lyapunov function that drifts downward outside a compact set with a uniform rate.",
        "roleInProof": "Provides the key inequality bounding the expected change in the Lyapunov function W_b, enabling iteration and limit analysis.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Lyapunov Function"
        ]
      },
      {
        "toolName": "Geometric Series Summation",
        "field": "Real Analysis",
        "description": "The sum of an infinite geometric series \\sum_{j=0}^{\\infty} r^j = 1/(1-r) for |r| < 1.",
        "roleInProof": "Used to evaluate the limit of the summed constant terms in the iterated drift inequality, converging to 1/\\kappa_b.",
        "levelOfAbstraction": "Technique",
        "relatedTools": []
      },
      {
        "toolName": "Limit Superior",
        "field": "Real Analysis",
        "description": "The limsup of a sequence is the largest limit point, providing an upper bound on asymptotic behavior.",
        "roleInProof": "Applied to the expected Lyapunov function to capture the worst-case asymptotic bound as t approaches infinity.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Expectation"
        ]
      },
      {
        "toolName": "Conditional Expectation",
        "field": "Probability Theory",
        "description": "The expected value of a random variable given information up to a certain time, here used in the drift.",
        "roleInProof": "Underlies the \\mathbb{E} notation in the drift condition and iterations for the state process S_t.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Lyapunov Function"
        ]
      },
      {
        "toolName": "Lyapunov Function",
        "field": "Dynamical Systems",
        "description": "A non-negative function that decreases along trajectories to prove stability or convergence.",
        "roleInProof": "W_b serves as the function whose expectation is bounded, central to applying the drift condition.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Foster-Lyapunov Drift Condition"
        ]
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "Foster-Lyapunov",
      "drift condition",
      "geometric series",
      "stochastic approximation",
      "bounded expectation",
      "Markov chain stability"
    ]
  },
  {
    "label": "proof-cor-extinction-suppression",
    "proves": "cor-extinction-suppression",
    "proof_type": "probabilistic",
    "proof_status": "complete",
    "strategy_summary": "The proof bounds the fraction of walkers near the extinction boundary using a barrier function and the equilibrium condition on average barrier values, then applies Hoeffding's inequality to show that the probability of all remaining walkers simultaneously crossing into extinction decays exponentially with the swarm size N.",
    "conclusion": {
      "text": "The probability of total extinction in one step satisfies P(extinction) ≤ exp(-N · c_extinct) where c_extinct > 0 depends on the safe fraction and noise parameters.",
      "latex": "P(\\text{extinction}) \\leq \\exp(-N \\cdot c_{\\text{extinct}})"
    },
    "assumptions": [
      {
        "text": "Swarm operates in the quasi-stationary regime with W_b ≤ C_b / κ_b",
        "latex": null
      },
      {
        "text": "The barrier function φ_barrier diverges to infinity near the boundary ∂X_valid",
        "latex": null
      },
      {
        "text": "Walker position updates include bounded perturbation noise with characteristic scale σ_noise",
        "latex": null
      },
      {
        "text": "The equilibrium bound ensures C_b / (κ_b φ_min) < 1",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "setup",
        "text": "Consider a swarm in the quasi-stationary regime where W_b ≤ C_b / κ_b. Recall the barrier function φ_barrier(x) → ∞ as x → ∂X_valid. Define X_extinct := {x ∈ X_valid : d(x, ∂X_valid) < d_extinct} as the boundary layer.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "definition",
        "text": "Since φ_barrier grows to infinity at the boundary and is continuous, define φ_min := inf_{x ∈ X_extinct} φ_barrier(x) > 0, depending only on the geometry of X_valid.",
        "latex": "\\varphi_{\\min} := \\inf_{x \\in \\mathcal{X}_{\\text{extinct}}} \\varphi_{\\text{barrier}}(x) > 0",
        "references": [],
        "derived_statement": "φ_min > 0"
      },
      {
        "order": 3,
        "kind": "inequality",
        "text": "From W_b = (1/N) ∑ φ_barrier(x_i) ≤ C_b / κ_b, bound the number of walkers N_ext in X_extinct: N_ext · φ_min ≤ N · W_b ≤ N · C_b / κ_b, so N_ext ≤ N · C_b / (κ_b φ_min).",
        "latex": "N_{\\text{ext}} \\leq N \\cdot \\frac{C_b}{\\kappa_b \\varphi_{\\min}}",
        "references": [],
        "derived_statement": "Upper bound on N_ext"
      },
      {
        "order": 4,
        "kind": "definition",
        "text": "The number of safe walkers that must cross is N_cross := N - N_ext ≥ N (1 - C_b / (κ_b φ_min)) =: N · f_safe, with f_safe ∈ (0,1).",
        "latex": "N_{\\text{cross}} := N - N_{\\text{ext}} \\geq N \\left(1 - \\frac{C_b}{\\kappa_b \\varphi_{\\min}}\\right) =: N \\cdot f_{\\text{safe}}",
        "references": [],
        "derived_statement": "f_safe > 0 for large φ_min"
      },
      {
        "order": 5,
        "kind": "inequality",
        "text": "For a safe walker at distance d > d_extinct + 2σ_noise, crossing requires deviation Δd > 2σ_noise. By Hoeffding's inequality, p_cross ≤ exp(- (Δd)^2 / (2 σ_noise^2)).",
        "latex": "p_{\\text{cross}} \\leq \\exp\\left(-\\frac{(\\Delta d)^2}{2\\sigma_{\\text{noise}}^2}\\right)",
        "references": [
          "hoeffding-inequality"
        ],
        "derived_statement": "Bound on single crossing probability"
      },
      {
        "order": 6,
        "kind": "union-bound",
        "text": "Probability of all N · f_safe safe walkers crossing: P(extinction) ≤ p_cross^{N · f_safe} = exp(- N · f_safe · (Δd)^2 / (2 σ_noise^2)) = exp(-N · c_extinct), with c_extinct := f_safe · (Δd)^2 / (2 σ_noise^2) > 0.",
        "latex": "P(\\text{extinction}) \\leq \\exp(-N \\cdot c_{\\text{extinct}})",
        "references": [],
        "derived_statement": "Exponential decay"
      },
      {
        "order": 7,
        "kind": "parameter-analysis",
        "text": "c_extinct ≥ (1 - C_b / (κ_b φ_min)) · d_safe^2 / (2 σ_noise^2) > 0 when C_b / (κ_b φ_min) < 1, guaranteed by equilibrium.",
        "latex": "c_{\\text{extinct}} \\geq \\left(1 - \\frac{C_b}{\\kappa_b \\varphi_{\\min}}\\right) \\cdot \\frac{d_{\\text{safe}}^2}{2\\sigma_{\\text{noise}}^2}",
        "references": [],
        "derived_statement": "Positive lower bound on c_extinct"
      }
    ],
    "key_equations": [
      {
        "label": "eq-phi-min",
        "latex": "\\varphi_{\\min} := \\inf_{x \\in \\mathcal{X}_{\\text{extinct}}} \\varphi_{\\text{barrier}}(x) > 0",
        "role": "Minimum barrier value in extinction zone"
      },
      {
        "label": "eq-n-ext-bound",
        "latex": "N_{\\text{ext}} \\leq N \\cdot \\frac{C_b}{\\kappa_b \\varphi_{\\min}}",
        "role": "Upper bound on number of walkers near extinction"
      },
      {
        "label": "eq-f-safe",
        "latex": "f_{\\text{safe}} = 1 - \\frac{C_b}{\\kappa_b \\varphi_{\\min}}",
        "role": "Fraction of safe walkers"
      },
      {
        "label": "eq-p-cross",
        "latex": "p_{\\text{cross}} \\leq \\exp\\left(-\\frac{(\\Delta d)^2}{2\\sigma_{\\text{noise}}^2}\\right)",
        "role": "Single walker crossing probability bound"
      },
      {
        "label": "eq-extinct-prob",
        "latex": "P(\\text{extinction}) \\leq \\exp(-N \\cdot c_{\\text{extinct}})",
        "role": "Final exponential suppression bound"
      },
      {
        "label": "eq-c-extinct-lower",
        "latex": "c_{\\text{extinct}} \\geq \\left(1 - \\frac{C_b}{\\kappa_b \\varphi_{\\min}}\\right) \\cdot \\frac{d_{\\text{safe}}^2}{2\\sigma_{\\text{noise}}^2}",
        "role": "Lower bound on extinction rate constant"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Barrier function",
        "field": "Dynamical Systems",
        "description": "A scalar function that diverges to infinity as the state approaches the boundary of the valid domain, used to quantify distance from unsafe regions.",
        "roleInProof": "Employs the barrier to establish a minimum value in the extinction zone and bound the number of walkers there based on the average barrier value.",
        "levelOfAbstraction": "Concept",
        "relatedTools": []
      },
      {
        "toolName": "Hoeffding's inequality",
        "field": "Probability Theory",
        "description": "A concentration inequality that provides an exponential bound on the probability that the sum of bounded independent random variables deviates from its expected value.",
        "roleInProof": "Used to bound the tail probability of a single walker's position deviating enough to cross into the extinction zone.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Chernoff bound"
        ]
      }
    ],
    "cases": [],
    "remarks": [],
    "gaps": [],
    "tags": [
      "exponential suppression",
      "extinction probability",
      "concentration inequality",
      "Hoeffding",
      "barrier function",
      "walker distribution",
      "quasi-stationary regime"
    ]
  },
  {
    "label": "proof-thm-inter-swarm-bounded-expansion",
    "proves": "thm-inter-swarm-bounded-expansion",
    "proof_type": "probabilistic",
    "proof_status": "complete",
    "strategy_summary": "The proof decomposes the inter-swarm Wasserstein distance into location and structural components, bounds the expected expansion from cloning divergences using synchronous coupling, Lipschitz properties of cloning probabilities, and position bounds, and combines these to show a constant upper bound on the expected change.",
    "conclusion": {
      "text": "The expected change in the Wasserstein distance between the two swarms is bounded by a state-independent constant C_W.",
      "latex": "\\mathbb{E}[\\Delta V_W] \\leq C_W"
    },
    "assumptions": [
      {
        "text": "Walker positions are bounded within the valid domain \\mathcal{X}_{valid} with diameter D_{valid}.",
        "latex": null
      },
      {
        "text": "The cloning probability is Lipschitz continuous with respect to the swarm configuration distance d_{Disp}, with constant L_{clone}.",
        "latex": null
      },
      {
        "text": "The swarms operate in a regime of bounded configurations.",
        "latex": null
      },
      {
        "text": "Synchronous coupling is used for all randomness in the cloning operator.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "explanation",
        "text": "Identify sources of inter-swarm divergence: different companion selections, different cloning decisions based on fitness potentials, and position jitter from Gaussian noise.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "bounding",
        "text": "Define the location error V_{loc} and bound its expected squared expansion due to mismatched cloning decisions, using bounded positions to show \\mathbb{E}[\\|\\Delta\\mu'_x\\|^2] \\leq \\|\\Delta\\mu_x\\|^2 + O(D_{valid}^2). Similar bound for velocity.",
        "latex": null,
        "references": [],
        "derived_statement": "\\mathbb{E}[\\Delta V_{loc}] \\leq O(D_{valid}^2)"
      },
      {
        "order": 3,
        "kind": "bounding",
        "text": "Bound the structural error V_{struct} expansion by considering synchronized vs. desynchronized cloning; use expected number of desynchronizations bounded by sum of probability differences, which is controlled by Lipschitz continuity: \\mathbb{E}[\\# desynchronized] \\leq \\sum |p_{1,i} - p_{2,i}| \\leq N L_{clone} d_{Disp}(S_1, S_2), leading to \\mathbb{E}[\\Delta V_{struct}] \\leq N L_{clone} d_{Disp}(S_1, S_2) D_{valid}^2 + C_{jitter}.",
        "latex": null,
        "references": [
          "framework-section-15.2"
        ],
        "derived_statement": "\\mathbb{E}[\\Delta V_{struct}] \\leq O(N \\cdot d_{Disp}(S_1, S_2)) + C_{jitter}"
      },
      {
        "order": 4,
        "kind": "combination",
        "text": "Decompose V_W = V_{loc} + V_{struct} using the referenced lemma, combine bounds, and under bounded configurations, obtain \\mathbb{E}[\\Delta V_W] \\leq C_W.",
        "latex": null,
        "references": [
          "lem-wasserstein-decomposition"
        ],
        "derived_statement": "\\mathbb{E}[\\Delta V_W] \\leq C_W"
      }
    ],
    "key_equations": [
      {
        "label": "eq-vloc",
        "latex": "V_{\\text{loc}} = \\|\\Delta\\mu_x\\|^2 + \\lambda_v \\|\\Delta\\mu_v\\|^2 + b\\langle\\Delta\\mu_x, \\Delta\\mu_v\\rangle",
        "role": "Defines the location error component of the Wasserstein distance."
      },
      {
        "label": "eq-delta-mu-x",
        "latex": "\\Delta\\mu'_x = \\Delta\\mu_x + \\frac{1}{N}(x'_{1,i} - x_{1,i})",
        "role": "Describes barycenter change in worst-case cloning mismatch."
      },
      {
        "label": "eq-location-bound",
        "latex": "\\|\\Delta\\mu'_x - \\Delta\\mu_x\\| \\leq \\frac{2D_{\\text{valid}}}{N}",
        "role": "Bounds the change in position barycenter due to cloning."
      },
      {
        "label": "eq-desync-prob",
        "latex": "\\mathbb{E}[\\# desynchronized] \\leq \\sum_{i=1}^N |p_{1,i} - p_{2,i}|",
        "role": "Bounds the expected number of desynchronized cloning events."
      },
      {
        "label": "eq-clone-lip",
        "latex": "|p_{1,i} - p_{2,i}| \\leq L_{\\text{clone}} \\cdot d_{\\text{Disp}}(S_1, S_2)",
        "role": "Lipschitz bound on cloning probability differences."
      },
      {
        "label": "eq-vw-decomp",
        "latex": "V_W = V_{\\text{loc}} + V_{\\text{struct}}",
        "role": "Decomposition of Wasserstein distance used to combine error bounds."
      },
      {
        "label": "eq-final-bound",
        "latex": "\\mathbb{E}[\\Delta V_W] \\leq C_W",
        "role": "Final bounded expansion result."
      }
    ],
    "references": [
      "lem-wasserstein-decomposition"
    ],
    "math_tools": [
      {
        "toolName": "Wasserstein Distance",
        "field": "Optimal Transport",
        "description": "A metric measuring the distance between probability distributions based on optimal transport.",
        "roleInProof": "Decomposed into location and structural errors to bound inter-swarm divergence expansion.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Empirical Measure"
        ]
      },
      {
        "toolName": "Synchronous Coupling",
        "field": "Probability",
        "description": "A coupling method where random variables share the same randomness to minimize divergence.",
        "roleInProof": "Applied to the cloning operator to control divergence from shared randomness sources.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Gaussian Jitter"
        ]
      },
      {
        "toolName": "Lipschitz Continuity",
        "field": "Analysis",
        "description": "A property ensuring the variation of a function is controlled by the variation of its input.",
        "roleInProof": "Used to bound differences in cloning probabilities between swarms based on configuration distances.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Cloning Probability"
        ]
      },
      {
        "toolName": "Empirical Measure",
        "field": "Statistics",
        "description": "A discrete approximation of a probability distribution based on samples.",
        "roleInProof": "Represents the swarm configurations whose barycenters and centered measures are analyzed for divergence.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Wasserstein Distance"
        ]
      },
      {
        "toolName": "Gaussian Jitter",
        "field": "Probability",
        "description": "Addition of independent Gaussian noise to positions or variables.",
        "roleInProof": "Contributes to position divergence even under synchronized cloning decisions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Synchronous Coupling"
        ]
      }
    ],
    "cases": [
      {
        "name": "Synchronized cloning",
        "condition": "Both swarms select the same companion and make the same cloning decision for walker i",
        "summary": "Leads to minimal divergence in positions due to shared jitter and coupling."
      },
      {
        "name": "Desynchronized cloning",
        "condition": "Only one swarm clones walker i (due to probability or selection differences)",
        "summary": "Position divergence bounded by D_{valid}, contributing to structural error expansion."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The analysis assumes bounded swarm configurations to ensure d_{Disp}(S_1, S_2) is controlled, fitting the drift analysis regime."
      },
      {
        "type": "reference",
        "text": "Jitter constant C_{jitter} arises from independent Gaussian noise even under synchronization."
      }
    ],
    "gaps": [],
    "tags": [
      "stochastic-cloning",
      "inter-swarm-divergence",
      "wasserstein-distance",
      "bounded-expansion",
      "synchronous-coupling",
      "lipschitz-continuity",
      "empirical-measures",
      "drift-analysis"
    ]
  },
  {
    "label": "proof-thm-complete-wasserstein-drift",
    "proves": "thm-complete-wasserstein-drift",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof uses linearity of expectation on the Wasserstein decomposition to separate local and structural components, then applies established bounds to derive an overall constant bound on the expected drift.",
    "conclusion": {
      "text": "This establishes the combined drift bound \\(\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W\\).",
      "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "application",
        "text": "Apply linearity of expectation to the change in Wasserstein potential using the decomposition into local and structural components.",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]",
        "references": [
          "lem-wasserstein-decomposition"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}} + \\Delta V_{\\text{struct}}]"
      },
      {
        "order": 2,
        "kind": "separation",
        "text": "Separate the expectations of the components.",
        "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]",
        "references": [],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]"
      },
      {
        "order": 3,
        "kind": "bounding",
        "text": "Apply the component bounds from the corollary.",
        "latex": "\\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W",
        "references": [
          "cor-component-bounds-vw"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] \\leq C_W"
      },
      {
        "order": 4,
        "kind": "elaboration",
        "text": "Derive explicit form of C_loc from the referenced theorem's proof, bounding by domain diameter and selection variance.",
        "latex": "C_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)",
        "references": [
          "thm-inter-swarm-bounded-expansion"
        ],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "elaboration",
        "text": "Derive explicit form of C_struct, dominated by position jitter and cloning fraction.",
        "latex": "C_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})",
        "references": [
          "thm-inter-swarm-bounded-expansion"
        ],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-wasserstein-linearity",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_W] = \\mathbb{E}_{\\text{clone}}[\\Delta(V_{\\text{loc}} + V_{\\text{struct}})]",
        "role": "Initial application of linearity to decomposed potential"
      },
      {
        "label": "eq-component-separation",
        "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{loc}}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{struct}}]",
        "role": "Separation into analyzable components"
      },
      {
        "label": "eq-overall-bound",
        "latex": "\\leq C_{\\text{loc}} + C_{\\text{struct}} =: C_W",
        "role": "Combined bound establishing the result"
      },
      {
        "label": "eq-cloc-bound",
        "latex": "C_{\\text{loc}} = O\\left(\\mathbb{E}\\left[\\left\\|\\mathbb{E}_{c_1 \\sim \\mathcal{C}_i(S_1)}[x_{c_1}] - \\mathbb{E}_{c_2 \\sim \\mathcal{C}_i(S_2)}[x_{c_2}]\\right\\|^2\\right]\\right)",
        "role": "Explicit bound for location component"
      },
      {
        "label": "eq-cstruct-bound",
        "latex": "C_{\\text{struct}} = O(\\sigma_x^2 f_{\\text{clone}})",
        "role": "Explicit bound for structural component"
      }
    ],
    "references": [
      "lem-wasserstein-decomposition",
      "cor-component-bounds-vw",
      "thm-inter-swarm-bounded-expansion"
    ],
    "math_tools": [
      {
        "toolName": "Linearity of expectation",
        "field": "Probability",
        "description": "The property that the expectation of a sum of random variables equals the sum of their expectations, regardless of dependence.",
        "roleInProof": "Separates the expectation of the change in total Wasserstein potential into local and structural components.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Wasserstein decomposition"
        ]
      },
      {
        "toolName": "Wasserstein decomposition",
        "field": "Optimal Transport",
        "description": "Decomposition of the Wasserstein distance or potential into location-based and structural (e.g., matching) components.",
        "roleInProof": "Provides the breakdown of ΔV_W into ΔV_loc and ΔV_struct for separate analysis.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Linearity of expectation"
        ]
      },
      {
        "toolName": "Big O notation",
        "field": "Asymptotics",
        "description": "Notation for bounding the growth rate of functions.",
        "roleInProof": "Expresses the explicit constants C_loc and C_struct in terms of expectations and variances.",
        "levelOfAbstraction": "Notation",
        "relatedTools": []
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "explicit-constants",
        "text": "Constants derived from the proof of thm-inter-swarm-bounded-expansion."
      },
      {
        "type": "location-expansion",
        "text": "C_loc arises from differential expected clone positions between swarms, bounded by domain diameter and companion selection variance."
      },
      {
        "type": "structural-expansion",
        "text": "C_struct dominated by position jitter, where f_clone is the expected fraction of walkers that clone per step and sigma_x^2 is the jitter variance."
      }
    ],
    "gaps": [],
    "tags": [
      "Wasserstein distance",
      "drift bound",
      "linearity of expectation",
      "clone process",
      "swarm dynamics",
      "optimal transport",
      "position jitter"
    ]
  },
  {
    "label": "proof-thm-complete-cloning-drift",
    "proves": "thm-complete-cloning-drift",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof computes the expected total drift by summing the weighted expectations of individual component changes, substitutes upper bounds from referenced theorems for each term, rearranges to highlight the negative contraction terms versus positive constants, and establishes the condition under which the drift is negative, ensuring stability when variance and boundary potentials are sufficiently large.",
    "conclusion": {
      "text": "The total drift is negative when the contraction terms dominate the constants: c_V κ_x V_{Var,x} + c_B κ_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b. This holds when the weighted variance and boundary potential are sufficiently large.",
      "latex": "$c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b$"
    },
    "assumptions": [],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "Define the total drift as the weighted sum of component drifts.",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "decomposition",
        "text": "Decompose the variance drift into position and velocity components.",
        "latex": "= \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V (\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]) + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "bounding",
        "text": "Apply upper bounds from referenced theorems to each expectation term.",
        "latex": "\\leq C_W + c_V (-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B (-\\kappa_b W_b + C_b)",
        "references": [
          "thm-10.3.1",
          "thm-10.4.1",
          "thm-11.3.1",
          "thm-12.2.1"
        ],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "rearrangement",
        "text": "Rearrange the bounded expression to separate negative and positive terms.",
        "latex": "= -c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "sufficiency",
        "text": "The drift is negative if the negative terms dominate the constant term.",
        "latex": "c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b",
        "references": [],
        "derived_statement": "Drift < 0 under the inequality"
      }
    ],
    "key_equations": [
      {
        "label": "eq-total-drift-sum",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{total}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_W] + c_V \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] + c_B \\mathbb{E}_{\\text{clone}}[\\Delta W_b]",
        "role": "Initial expression for total drift"
      },
      {
        "label": "eq-var-decomp",
        "latex": "\\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var}}] = \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},x}] + \\mathbb{E}_{\\text{clone}}[\\Delta V_{\\text{Var},v}]",
        "role": "Decomposition of variance drift"
      },
      {
        "label": "eq-bounds-sub",
        "latex": "\\leq C_W + c_V(-\\kappa_x V_{\\text{Var},x} + C_x + C_v) + c_B(-\\kappa_b W_b + C_b)",
        "role": "Upper bound after substitution"
      },
      {
        "label": "eq-rearranged-drift",
        "latex": "-c_V \\kappa_x V_{\\text{Var},x} - c_B \\kappa_b W_b + (C_W + c_V C_x + c_V C_v + c_B C_b)",
        "role": "Rearranged bound"
      },
      {
        "label": "eq-negativity-cond",
        "latex": "c_V \\kappa_x V_{\\text{Var},x} + c_B \\kappa_b W_b > C_W + c_V C_x + c_V C_v + c_B C_b",
        "role": "Condition for negative drift"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Expectation Operator",
        "field": "Probability Theory",
        "description": "Computes the average value of a random variable, used here for drift analysis.",
        "roleInProof": "Calculates the expected change in the Lyapunov function components to form the total drift.",
        "levelOfAbstraction": "Notation",
        "relatedTools": [
          "Lyapunov Function"
        ]
      },
      {
        "toolName": "Lyapunov Drift Analysis",
        "field": "Stochastic Processes",
        "description": "A method to prove stability by showing that the expected change (drift) of a Lyapunov function is negative outside a compact set.",
        "roleInProof": "Bounds the total drift E[ΔV_total] to be negative under the given condition, implying convergence.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Expectation Operator"
        ]
      },
      {
        "toolName": "Inequality Bounding",
        "field": "Analysis",
        "description": "Technique for deriving upper or lower bounds on expressions using known inequalities.",
        "roleInProof": "Substitutes theorem-provided bounds into the drift expression to obtain an upper bound for E[ΔV_total].",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Lyapunov Drift Analysis"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "sufficiency",
        "text": "This holds when the weighted variance and boundary potential are sufficiently large."
      }
    ],
    "gaps": [],
    "tags": [
      "drift",
      "cloning",
      "variance",
      "boundary",
      "Lyapunov",
      "expectation",
      "contraction",
      "stability"
    ]
  },
  {
    "label": "proof-thm-synergistic-foster-lyapunov-preview",
    "proves": "thm-synergistic-foster-lyapunov",
    "proof_type": "reference",
    "proof_status": "sketch",
    "strategy_summary": "The proof synthesizes drift inequalities from the cloning operator (established in this document) and the kinetic operator (in the companion document) to construct a total Lyapunov function that exhibits net contraction, satisfying the Foster-Lyapunov condition for convergence.",
    "conclusion": {
      "text": "The total drift satisfies $\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}$ where $\\kappa_{\\text{total}} > 0$ and $C_{\\text{total}} < \\infty$, establishing the Foster-Lyapunov condition.",
      "latex": "\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}"
    },
    "assumptions": [
      {
        "text": "Appropriate choice of coupling constants $c_V$ and $c_B$ such that $c_V \\kappa_v > 1$ and other sufficient conditions for net contraction hold.",
        "latex": null
      },
      {
        "text": "Existence of parameters in the kinetic analysis ensuring $\\kappa_W > 0$ and bounded constants.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "analysis",
        "text": "Cloning stage: Apply drift inequalities from this document to bound $\\mathbb{E}_{\\text{clone}}[V_{\\text{total}}]$ in terms of contractions and bounded expansions.",
        "latex": null,
        "references": [
          "thm-positional-variance-contraction",
          "thm-velocity-variance-bounded-expansion",
          "thm-boundary-potential-contraction",
          "thm-inter-swarm-bounded-expansion"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{clone}}[V_{\\text{total}}] \\leq (1 - c_V \\kappa_x) V_{\\text{Var},x} + V_{\\text{Var},v} + V_W + (1 - c_B \\kappa_b) W_b + \\text{bounded terms}"
      },
      {
        "order": 2,
        "kind": "analysis",
        "text": "Kinetic stage: Apply drift inequalities from companion document to the post-cloning state, incorporating expansions and contractions.",
        "latex": null,
        "references": [
          "companion-kinetic-proofs"
        ],
        "derived_statement": "\\mathbb{E}_{\\text{kin}}[\\mathbb{E}_{\\text{clone}}[V_{\\text{total}}]] \\leq (1 - \\kappa_W) V_W + c_V (1 - \\kappa_v) V_{\\text{Var},v} + \\text{other contracted terms} + \\text{bounded terms}"
      },
      {
        "order": 3,
        "kind": "synthesis",
        "text": "Choose coupling constants $c_V, c_B$ and parameters to ensure net contraction across all components, yielding the total drift inequality.",
        "latex": null,
        "references": [],
        "derived_statement": "\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}"
      }
    ],
    "key_equations": [
      {
        "label": "eq-cloning-drift",
        "latex": "\\mathbb{E}_{\\text{clone}}[V_{\\text{total}}] \\leq (1 - c_V \\kappa_x) V_{\\text{Var},x} + V_{\\text{Var},v} + V_W + (1 - c_B \\kappa_b) W_b + C_W + c_V C_x + c_V C_v + c_B C_b",
        "role": "Bounds the Lyapunov function after cloning stage"
      },
      {
        "label": "eq-kinetic-drift",
        "latex": "\\mathbb{E}_{\\text{kin}}[\\mathbb{E}_{\\text{clone}}[V_{\\text{total}}]] \\leq (1 - c_V \\kappa_x) (V_{\\text{Var},x} + C'_x) + c_V(1 - \\kappa_v) V_{\\text{Var},v} + c_V C'_v + (1 - \\kappa_W)(V_W + C_W) + C'_W + (1 - c_B \\kappa_b)(W_b + C'_b) + c_B C_b + \\text{cross terms}",
        "role": "Applies kinetic drifts to post-cloning state"
      },
      {
        "label": "eq-total-drift",
        "latex": "\\mathbb{E}_{\\text{total}}[V_{\\text{total}}(S')] \\leq (1 - \\kappa_{\\text{total}}) V_{\\text{total}}(S) + C_{\\text{total}}",
        "role": "Final net contraction for the composed operator"
      }
    ],
    "references": [
      "thm-positional-variance-contraction",
      "thm-velocity-variance-bounded-expansion",
      "thm-boundary-potential-contraction",
      "thm-inter-swarm-bounded-expansion"
    ],
    "math_tools": [
      {
        "toolName": "Foster-Lyapunov Criterion",
        "field": "Stochastic Processes",
        "description": "A technique for proving ergodicity and convergence in Markov chains by showing that a Lyapunov function contracts on average outside a compact set.",
        "roleInProof": "Used to establish convergence via the total drift inequality for the composed system.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Lyapunov Function"
        ]
      },
      {
        "toolName": "Hypocoercivity",
        "field": "Partial Differential Equations",
        "description": "A method to prove exponential decay in underdamped systems by coupling coercive estimates across position and velocity variables.",
        "roleInProof": "Provides contraction in inter-swarm error and velocity dissipation for the kinetic operator.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Drift Analysis"
        ]
      },
      {
        "toolName": "Drift Analysis",
        "field": "Markov Chain Theory",
        "description": "Analysis of expected changes in Lyapunov functions to bound contraction or expansion rates.",
        "roleInProof": "Combines one-step expectations from cloning and kinetic stages to derive the total drift.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Foster-Lyapunov Criterion"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "note",
        "text": "This document proves cloning operator drifts (1-4); companion document proves kinetic operator drifts (5-8)."
      },
      {
        "type": "note",
        "text": "Explicit parameter construction for $\\kappa_{\\text{total}} > 0$ is provided in the companion document."
      }
    ],
    "gaps": [
      {
        "description": "Detailed proofs of kinetic operator drifts (items 5-8) are omitted and deferred to the companion document.",
        "severity": "major",
        "location_hint": "Companion document reference"
      }
    ],
    "tags": [
      "lyapunov",
      "drift",
      "contraction",
      "hypocoercivity",
      "cloning",
      "kinetic",
      "foster-lyapunov",
      "synthesis"
    ]
  },
  {
    "label": "proof-thm-main-results-summary",
    "proves": "thm-main-results-summary",
    "proof_type": "reference",
    "proof_status": "sketch",
    "strategy_summary": "This proof consolidates and verifies the five summary items of the main theorem by systematically citing corresponding proven theorems, lemmas, and axioms while confirming dependencies, N-uniformity of constants, and absence of circular reasoning or overclaiming.",
    "conclusion": {
      "text": "All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies (Axioms EG-0, EG-2, EG-3, EG-4) verified in Chapter 4.",
      "latex": null
    },
    "assumptions": [
      {
        "text": "Axiom EG-0: Framework foundational assumption.",
        "latex": null
      },
      {
        "text": "Axiom EG-2: Safe Harbor axiom for boundary behavior.",
        "latex": null
      },
      {
        "text": "Axiom EG-3: Framework dependency.",
        "latex": null
      },
      {
        "text": "Axiom EG-4: Velocity regularization axiom.",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "verification",
        "text": "Chapters 5-8 establish the four-link causal chain (variance → structure → fitness → pressure) culminating in the quantitative inequality (Keystone Lemma, Lines 4669-4683). Constants χ(ε) > 0 and g_max(ε) < ∞ are verified as N-uniform and constructive.",
        "latex": null,
        "references": [
          "lem-keystone"
        ],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "citation",
        "text": "{prf:ref}`thm-positional-variance-contraction` (Lines 6291-6293) rigorously proves the drift inequality using the Keystone Lemma as primary engine. Contraction rate κ_x = χ(ε) c_struct > 0 verified as N-uniform via variance decomposition.",
        "latex": null,
        "references": [
          "thm-positional-variance-contraction"
        ],
        "derived_statement": "κ_x = χ(ε) c_struct > 0 (N-uniform)"
      },
      {
        "order": 3,
        "kind": "citation",
        "text": "{prf:ref}`thm-velocity-variance-bounded-expansion` (Lines 6671-6673) establishes state-independent bound C_v = 4(1 + α_restitution)^2 V_max^2 via inelastic collision analysis and Axiom EG-4 (velocity regularization).",
        "latex": null,
        "references": [
          "thm-velocity-variance-bounded-expansion"
        ],
        "derived_statement": "C_v = 4(1 + α_restitution)^2 V_max^2"
      },
      {
        "order": 4,
        "kind": "verification",
        "text": "Chapter 11 (Lines 7212, 7232) proves contraction via Safe Harbor axiom (EG-2). Fitness deficit for boundary walkers creates systematic replacement, yielding κ_b = c_fit c_barrier > 0 (N-uniform).",
        "latex": null,
        "references": [
          "axiom-eg-2"
        ],
        "derived_statement": "κ_b = c_fit c_barrier > 0 (N-uniform)"
      },
      {
        "order": 5,
        "kind": "synthesis",
        "text": "Chapter 12 (Lines 8003-8334) synthesizes all results, verifies N-uniformity of all constants, confirms partial contraction structure (positions/boundary contract, velocities expand bounded), and correctly scopes synergy as foundation for companion document.",
        "latex": null,
        "references": [],
        "derived_statement": "Complete N-uniform partial contraction characterization"
      },
      {
        "order": 6,
        "kind": "final-check",
        "text": "All five items verified as accurate summaries of proven results. No circular reasoning (summary after components). No overclaiming (scope boundary clear). All framework dependencies verified.",
        "latex": null,
        "references": [
          "axiom-eg-0",
          "axiom-eg-2",
          "axiom-eg-3",
          "axiom-eg-4"
        ],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-keystone-constants",
        "latex": "\\chi(\\epsilon) > 0, \\ g_{\\max}(\\epsilon) < \\infty",
        "role": "N-uniform constants in causal chain"
      },
      {
        "label": "eq-kappa-x",
        "latex": "\\kappa_x = \\chi(\\epsilon) c_{\\text{struct}} > 0",
        "role": "Positional contraction rate"
      },
      {
        "label": "eq-c-v",
        "latex": "C_v = 4(1 + \\alpha_{\\text{restitution}})^2 V_{\\max}^2",
        "role": "Velocity variance bound"
      },
      {
        "label": "eq-kappa-b",
        "latex": "\\kappa_b = c_{\\text{fit}} c_{\\text{barrier}} > 0",
        "role": "Boundary contraction rate"
      }
    ],
    "references": [
      "thm-positional-variance-contraction",
      "thm-velocity-variance-bounded-expansion"
    ],
    "math_tools": [
      {
        "toolName": "Variance Decomposition",
        "field": "Probability Theory",
        "description": "Technique for breaking down total variance into components attributable to different sources.",
        "roleInProof": "Used to verify N-uniform contraction rate κ_x in positional variance.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Keystone Lemma"
        ]
      },
      {
        "toolName": "Keystone Lemma",
        "field": "Dynamical Systems",
        "description": "Quantitative inequality establishing a four-link causal chain from variance to selective pressure.",
        "roleInProof": "Primary engine for drift inequality in Step 1 and positional contraction in Step 2.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Variance Decomposition"
        ]
      },
      {
        "toolName": "Inelastic Collision Analysis",
        "field": "Physics/Mechanics",
        "description": "Modeling of energy dissipation in collisions to bound velocity changes.",
        "roleInProof": "Establishes state-independent bound C_v for velocity variance in Step 3.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Axiom EG-4"
        ]
      }
    ],
    "cases": [],
    "remarks": [
      {
        "type": "reference",
        "text": "Complete detailed proof (9/10 rigor, 850 lines) available in proofs/proof_20251025_0227_thm_main_results_summary.md."
      },
      {
        "type": "scope",
        "text": "Synergy scoped as foundation for companion document; partial contraction (positions/boundary contract, velocities bounded expand)."
      }
    ],
    "gaps": [
      {
        "description": "Full detailed proof omitted; only structure provided here with citations to external file.",
        "severity": "minor",
        "location_hint": "Entire proof structure"
      }
    ],
    "tags": [
      "meta-proof",
      "systematic-citation",
      "verification",
      "consolidation",
      "causal-chain",
      "N-uniformity",
      "contraction",
      "bounded-expansion"
    ]
  },
  {
    "label": "proof-lem-mass-conservation-transport",
    "proves": "lem-mass-conservation-transport",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "Integrate the equation defining the adjoint operator over the phase space domain Ω and apply the divergence theorem to convert the volume integral into a boundary flux integral. Show that the reflecting boundary conditions make the boundary integral vanish, yielding zero total flux and thus conservation.",
    "conclusion": {
      "text": "The boundary integral vanishes due to reflecting conditions, so ∫_Ω L† f dz = 0.",
      "latex": "\\int_\\Omega L^\\dagger f \\, \\mathrm{d}z = 0"
    },
    "assumptions": [
      {
        "text": "Reflecting boundary conditions: J_v · n_v = 0 on ∂V_alg (velocity reflection) and J_x · n_x = 0 on ∂X_valid (position reflection).",
        "latex": null
      },
      {
        "text": "The adjoint operator satisfies L† f = -∇ · J[f].",
        "latex": "L^\\dagger f = -\\nabla \\cdot J[f]"
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "integration",
        "text": "Integrate the equation L† f = -∇ · J[f] over the domain Ω.",
        "latex": "\\int_\\Omega L^\\dagger f \\, \\mathrm{d}z = \\int_\\Omega (-\\nabla \\cdot J[f]) \\, \\mathrm{d}z",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "theorem-application",
        "text": "Apply the divergence theorem to the right-hand side.",
        "latex": "\\int_\\Omega (-\\nabla \\cdot J[f]) \\, \\mathrm{d}z = - \\int_{\\partial \\Omega} J[f] \\cdot n \\, \\mathrm{d}S",
        "references": [],
        "derived_statement": "\\int_\\Omega L^\\dagger f \\, \\mathrm{d}z = - \\int_{\\partial \\Omega} J[f] \\cdot n \\, \\mathrm{d}S"
      },
      {
        "order": 3,
        "kind": "boundary-description",
        "text": "The boundary ∂Ω consists of (∂X_valid × V_alg) ∪ (X_valid × ∂V_alg).",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "boundary-evaluation",
        "text": "Under reflecting boundary conditions, the normal flux vanishes on both parts of the boundary.",
        "latex": null,
        "references": [],
        "derived_statement": "\\int_{\\partial \\Omega} J[f] \\cdot n \\, \\mathrm{d}S = 0"
      }
    ],
    "key_equations": [
      {
        "label": "eq-divergence-application",
        "latex": "\\int_\\Omega L^\\dagger f\\, \\mathrm{d}z = - \\int_{\\partial\\Omega} J[f] \\cdot n\\, \\mathrm{d}S",
        "role": "Key relation from integration and divergence theorem"
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Divergence Theorem",
        "field": "Vector Calculus",
        "description": "The theorem relates the flux of a vector field through a closed surface to the divergence of the field within the volume it encloses.",
        "roleInProof": "Converts the volume integral of the divergence of the flux J[f] into a surface integral over the boundary ∂Ω.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": []
      }
    ],
    "cases": [
      {
        "name": "Velocity boundary",
        "condition": "On ∂V_alg: J_v · n_v = 0 (velocity reflection)",
        "summary": "Ensures no flux through the velocity boundary."
      },
      {
        "name": "Position boundary",
        "condition": "On ∂X_valid: J_x · n_x = 0 (position reflection)",
        "summary": "Ensures no flux through the position boundary."
      }
    ],
    "remarks": [],
    "gaps": [],
    "tags": [
      "mass-conservation",
      "divergence-theorem",
      "boundary-conditions",
      "transport-equation",
      "reflecting-boundaries",
      "phase-space",
      "adjoint-operator"
    ]
  },
  {
    "label": "proof-thm-mass-conservation",
    "proves": "thm-mass-conservation",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof directly computes the time derivatives of the alive mass \\(m_a(t)\\) and dead mass \\(m_d(t)\\) by integrating the governing equations over the domain \\(\\Omega\\), applies properties of the transport, killing, revival, and cloning operators to simplify each term, and shows that the sum of the derivatives is zero, conserving total mass.",
    "conclusion": {},
    "assumptions": [],
    "steps": [],
    "key_equations": [
      {
        "label": "eq-da",
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t) = \\int_\\Omega L^\\dagger f \\, \\mathrm{d}z - \\int_\\Omega c(z) f \\, \\mathrm{d}z + \\int_\\Omega B[f, m_d] \\, \\mathrm{d}z + \\int_\\Omega S[f] \\, \\mathrm{d}z",
        "role": "Time derivative of alive mass"
      },
      {
        "label": "eq-simplified-da",
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t) = -k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)",
        "role": "Simplified alive mass derivative"
      },
      {
        "label": "eq-dd",
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)",
        "role": "Dead mass derivative"
      },
      {
        "label": "eq-total",
        "latex": "\\frac{\\mathrm{d}}{\\mathrm{d}t} [m_a(t) + m_d(t)] = 0",
        "role": "Conservation of total mass"
      }
    ],
    "references": [
      "lem-mass-conservation-transport",
      "def-revival-operator",
      "def-cloning-generator"
    ],
    "math_tools": [
      {
        "toolName": "Adjoint Transport Operator",
        "field": "Partial Differential Equations",
        "description": "The adjoint operator \\(L^\\dagger\\) associated with a transport equation, which preserves integrals under appropriate boundary conditions.",
        "roleInProof": "Used to show that the transport term integrates to zero over \\(\\Omega\\) due to reflective boundaries.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Divergence Theorem"
        ]
      },
      {
        "toolName": "Mass Conservation via Integration",
        "field": "Analysis",
        "description": "Integrating evolution equations over a domain to derive balance laws for total quantities like mass.",
        "roleInProof": "Applied to compute time derivatives of masses by integrating \\(\\partial_t f\\) and the dead mass equation.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Fundamental Theorem of Calculus"
        ]
      },
      {
        "toolName": "Linear Operators on Function Spaces",
        "field": "Functional Analysis",
        "description": "Operators such as killing, revival, and cloning that act linearly on densities and preserve or transfer mass.",
        "roleInProof": "Properties of these operators (e.g., integral of revival equals \\(\\lambda_{\text{rev}} m_d\\)) are used to evaluate terms in the mass derivatives.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Adjoint Transport Operator"
        ]
      }
    ],
    "cases": [
      {
        "name": "Alive mass",
        "condition": null,
        "summary": "Compute and simplify \\(\\frac{\\mathrm{d}}{\\mathrm{d}t} m_a(t)\\) using operator properties to get \\(-k_{\\text{killed}}[f] + \\lambda_{\\text{rev}} m_d(t)\\)."
      },
      {
        "name": "Dead mass",
        "condition": null,
        "summary": "Directly from the equation, \\(\\frac{\\mathrm{d}}{\\mathrm{d}t} m_d(t) = k_{\\text{killed}}[f] - \\lambda_{\\text{rev}} m_d(t)\\)."
      }
    ],
    "remarks": [
      {
        "type": "conclusion",
        "text": "This shows total mass conservation holds due to balancing of killing and revival terms."
      }
    ],
    "gaps": [],
    "tags": [
      "mass-conservation",
      "time-derivative",
      "integration",
      "transport-operator",
      "revival",
      "cloning",
      "conservation-law"
    ]
  },
  {
    "label": "proof-thm-killing-rate-consistency-part-i",
    "proves": "thm-killing-rate-consistency-part-i",
    "proof_type": "probabilistic",
    "proof_status": "complete",
    "strategy_summary": "The proof analyzes the one-step displacement under the BAOAB integrator as a Gaussian random variable, projects it onto the boundary normal to obtain the exit probability via the Gaussian tail integral, and computes the asymptotic limit of the normalized exit probability as tau approaches zero in interior and boundary layer regimes, yielding the ballistic killing rate in the drift-dominated case.",
    "conclusion": {
      "text": "Combining all cases: c(x,v) = v_n^+ / d(x) if d(x) < δ, else 0.",
      "latex": "c(x,v) = \\begin{cases} \\frac{v_n^+}{d(x)} & \\text{if } d(x) < \\delta \\\\ 0 & \\text{if } d(x) \\ge \\delta \\end{cases}"
    },
    "assumptions": [
      {
        "text": "Fixed (x,v) in Ω",
        "latex": null
      },
      {
        "text": "Small timestep τ → 0",
        "latex": null
      },
      {
        "text": "Boundary layer thickness δ > 0 fixed",
        "latex": null
      },
      {
        "text": "BAOAB integrator parameters: m, γ, Θ > 0",
        "latex": null
      },
      {
        "text": "ξ ~ N(0, I_d) independent Gaussian noise",
        "latex": null
      },
      {
        "text": "x in valid domain X_valid with distance d(x) to boundary",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "characterization",
        "text": "Characterize x+ as a Gaussian random variable by expanding the BAOAB update for small τ, identifying mean μ_x(τ) = x + vτ + O(τ²) and std dev σ_x(τ) = O(τ^{3/2}).",
        "latex": null,
        "references": [
          "def-baoab-update-rule"
        ],
        "derived_statement": "x^+ = μ_x(τ) + σ_x(τ) ξ"
      },
      {
        "order": 2,
        "kind": "formulation",
        "text": "Formulate the exit probability as a Gaussian tail integral in the normal direction Z_n with mean μ_n = v_n τ + O(τ²) and variance σ_n² = C_σ τ³ + O(τ⁴), where p_exit = (1/2) erfc( (d(x) - μ_n) / (√2 σ_n) ).",
        "latex": null,
        "references": [],
        "derived_statement": "p_exit(x,v,τ) = ½ erfc( (d(x) - μ_n) / (√2 σ_n) )"
      },
      {
        "order": 3,
        "kind": "limit computation",
        "text": "Compute lim_{τ→0} (1/τ) p_exit in different cases: super-exponential decay to 0 for interior and inward velocity cases; ballistic limit v_n / d(x) for outward velocity in boundary layer via asymptotic analysis of erfc in drift-dominated regime.",
        "latex": null,
        "references": [],
        "derived_statement": "lim_{τ→0} (1/τ) p_exit = c(x,v) = v_n^+ / d(x) if d(x) < δ, else 0"
      }
    ],
    "key_equations": [
      {
        "label": "eq-baoab-expansion",
        "latex": "x^+(\\tau; x,v) = x + v\\tau + \\frac{\\tau^2}{2m}F(x) + \\frac{\\tau}{2}u_{n+1/2} + \\frac{\\tau^{3/2}}{2}\\sigma_v\\sqrt{2\\gamma}\\,\\xi + O(\\tau^3)",
        "role": "Expansion of position update showing O(τ) drift and O(τ^{3/2}) noise"
      },
      {
        "label": "eq-gaussian-x",
        "latex": "x^+ = \\mu_x(\\tau) + \\sigma_x(\\tau)\\,\\xi",
        "role": "Gaussian form of displacement"
      },
      {
        "label": "eq-zn-params",
        "latex": "\\mu_n = v_n \\tau + O(\\tau^2), \\quad \\sigma_n^2 = C_\\sigma \\tau^3 + O(\\tau^4)",
        "role": "Parameters of normal displacement"
      },
      {
        "label": "eq-pexit-erfc",
        "latex": "p_{\\text{exit}}(x,v,\\tau) = \\frac{1}{2}\\text{erfc}\\left(\\frac{d(x) - \\mu_n}{\\sqrt{2}\\sigma_n}\\right)",
        "role": "Exit probability expression"
      },
      {
        "label": "eq-killing-rate",
        "latex": "c(x,v) = \\begin{cases} \\frac{v_n^+}{d(x)} & \\text{if } d(x) < \\delta \\\\ 0 & \\text{if } d(x) \\ge \\delta \\end{cases}",
        "role": "Final killing rate formula"
      }
    ],
    "references": [
      "def-baoab-update-rule"
    ],
    "math_tools": [
      {
        "toolName": "Gaussian Distribution",
        "field": "Probability",
        "description": "The normal distribution modeling the displacement after one timestep.",
        "roleInProof": "Used to characterize the stochastic update x+ and compute the exit probability as a tail probability.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Complementary Error Function"
        ]
      },
      {
        "toolName": "Complementary Error Function (erfc)",
        "field": "Special Functions",
        "description": "The integral representation of the Gaussian tail probability, with known asymptotic expansions for large arguments.",
        "roleInProof": "Formulates the exact exit probability p_exit and enables asymptotic analysis in drift-dominated and diffusive regimes.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Gaussian Distribution",
          "Asymptotic Expansion"
        ]
      },
      {
        "toolName": "Asymptotic Expansion",
        "field": "Analysis",
        "description": "Series approximations for small/large parameters, including Taylor expansions and tail asymptotics.",
        "roleInProof": "Approximates the BAOAB update for small tau and the erfc argument in various regimes to derive the limit of p_exit / tau.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Complementary Error Function"
        ]
      },
      {
        "toolName": "First-Passage Time Analysis",
        "field": "Stochastic Processes",
        "description": "Study of hitting times for stochastic processes, including ballistic and diffusive limits.",
        "roleInProof": "Provides the physical and mathematical framework for interpreting the killing rate c(x,v) as the continuous-time exit flux.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "Gaussian Distribution",
          "large deviations theory"
        ]
      }
    ],
    "cases": [
      {
        "name": "Interior Points",
        "condition": "d(x) ≥ δ",
        "summary": "Super-exponential decay of p_exit leads to lim (1/τ) p_exit = 0"
      },
      {
        "name": "Boundary Layer Inward Velocity",
        "condition": "d(x) < δ, v_n ≤ 0",
        "summary": "Drift away from boundary causes super-exponential decay, lim (1/τ) p_exit = 0"
      },
      {
        "name": "Boundary Layer Outward Velocity",
        "condition": "d(x) < δ, v_n > 0",
        "summary": "Drift-dominated regime with ballistic crossing, lim (1/τ) p_exit = v_n / d(x) via asymptotic erfc analysis"
      }
    ],
    "remarks": [
      {
        "type": "interpretation",
        "text": "The result corresponds to the ballistic limit in kinetic theory, where diffusion is negligible compared to deterministic drift, representing the instantaneous probability flux across the boundary."
      },
      {
        "type": "reference",
        "text": "See Risken (Ch. 5) for continuous-time flux, Gardiner (Sec. 5.3) for short-time asymptotics, Redner for physical introduction."
      }
    ],
    "gaps": [
      {
        "description": "Full rigor for the limit lim_{τ→0} (1/τ) erfc(...) in the ballistic regime relies on Laplace's method or large deviations theory, which is sketched but not fully derived here.",
        "severity": "medium",
        "location_hint": "Asymptotic Analysis of erfc subsection"
      }
    ],
    "tags": [
      "BAOAB integrator",
      "exit probability",
      "Gaussian displacement",
      "asymptotic analysis",
      "drift-dominated regime",
      "ballistic limit",
      "killing rate",
      "pointwise convergence"
    ]
  },
  {
    "label": "proof-thm-killing-rate-consistency-part-ii",
    "proves": "thm-killing-rate-consistency-part-ii",
    "proof_type": "direct",
    "proof_status": "complete",
    "strategy_summary": "The proof decomposes the error E(τ) into a pointwise rate error E1(τ) and a density approximation error E2(τ), bounding E2 using Hölder's inequality and the L1 convergence of densities, while splitting E1 into interior and boundary contributions; the interior error is super-exponentially small, and the boundary error is analyzed via asymptotic expansion of the erfc transition in the exit probability, yielding an O(√τ) bound that combines with the density term.",
    "conclusion": {
      "text": "|E(τ)| ≤ C(√τ + ||f^τ - f||_{L^1})",
      "latex": "|E(\\tau)| \\le C\\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)"
    },
    "assumptions": [
      {
        "text": "The killing rate c(x,v) is bounded: ||c||_{L^∞} ≤ M_v / δ, where M_v = ||v||_{max} and δ is the boundary layer thickness.",
        "latex": null
      },
      {
        "text": "The densities converge: ||f^τ - f||_{L^1} → 0 as τ → 0.",
        "latex": null
      },
      {
        "text": "The domain Ω has a smooth boundary, with d(x) the signed distance to the boundary, and velocities v with outward normal component v_n > 0 in the boundary layer.",
        "latex": null
      },
      {
        "text": "The drift term leads to Gaussian position noise of order O(τ^{3/2}) in the BAOAB scheme, resulting in transition width Δτ ~ O(√τ).",
        "latex": null
      }
    ],
    "steps": [
      {
        "order": 1,
        "kind": "definition",
        "text": "Define the error E(τ) as the difference between the discrete and continuous killing rates.",
        "latex": "E(\\tau) := \\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) - K_{\\text{continuous}}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 2,
        "kind": "decomposition",
        "text": "Decompose E(τ) into E1(τ) (pointwise rate error weighted by f^τ) and E2(τ) (density error weighted by c).",
        "latex": "E(\\tau) = E_1(\\tau) + E_2(\\tau)",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 3,
        "kind": "bound",
        "text": "Bound E2(τ) using Hölder's inequality and boundedness of c.",
        "latex": "|E_2(\\tau)| \\le \\frac{M_v}{\\delta} \\|f^\\tau - f\\|_{L^1}",
        "references": [],
        "derived_statement": null
      },
      {
        "order": 4,
        "kind": "split",
        "text": "Split E1(τ) into interior (d(x) ≥ δ) and boundary layer (d(x) < δ) integrals: E1 = E_{1,int} + E_{1,bd}.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 5,
        "kind": "analysis",
        "text": "In the interior, p_exit = o(τ^m) and c=0, so E_{1,int} = o(τ^m) for any m > 0.",
        "latex": null,
        "references": [],
        "derived_statement": "E_{1,\\text{int}} = o(\\tau^m)"
      },
      {
        "order": 6,
        "kind": "analysis",
        "text": "In the boundary layer, approximate p_exit via erfc transition from Part (i), compare to ballistic step function, and estimate pointwise error using asymptotic expansion.",
        "latex": "\\left|\\frac{1}{\\tau}p_{\\text{exit}} - c(x,v)\\right| \\le C_1 \\sqrt{\\tau}",
        "references": [
          "proof-thm-killing-rate-consistency-part-i"
        ],
        "derived_statement": null
      },
      {
        "order": 7,
        "kind": "integration",
        "text": "Integrate the pointwise bound over the boundary layer to bound |E_{1,bd}| ≤ C_1 √τ ⋅ M_f ⋅ |T_δ|.",
        "latex": null,
        "references": [],
        "derived_statement": null
      },
      {
        "order": 8,
        "kind": "combination",
        "text": "Combine all bounds to obtain the uniform error estimate.",
        "latex": "|E(\\tau)| \\le C\\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)",
        "references": [],
        "derived_statement": null
      }
    ],
    "key_equations": [
      {
        "label": "eq-error-def",
        "latex": "E(\\tau) := \\frac{1}{\\tau} K_{\\text{discrete}}(\\tau) - K_{\\text{continuous}}",
        "role": "Defines the main error term between discrete and continuous killing rates."
      },
      {
        "label": "eq-decomposition",
        "latex": "\\begin{aligned} E(\\tau) &= \\int_{\\Omega} \\left[\\frac{1}{\\tau} p_{\\text{exit}}(x,v,\\tau) - c(x,v)\\right] f^\\tau(x,v)\\,\\mathrm{d}x\\,\\mathrm{d}v \\\\ &\\quad + \\int_{\\Omega} c(x,v) [f^\\tau(x,v) - f(x,v)]\\,\\mathrm{d}x\\,\\mathrm{d}v \\\\ &=: E_1(\\tau) + E_2(\\tau) \\end{aligned}",
        "role": "Decomposes the error into pointwise and density components."
      },
      {
        "label": "eq-e2-bound",
        "latex": "|E_2(\\tau)| \\le \\|c\\|_{L^\\infty} \\|f^\\tau - f\\|_{L^1} \\le \\frac{M_v}{\\delta} \\|f^\\tau - f\\|_{L^1}",
        "role": "Provides the bound for the density error term."
      },
      {
        "label": "eq-pointwise-bound",
        "latex": "\\left|\\frac{1}{\\tau}p_{\\text{exit}}(x,v,\\tau) - c(x,v)\\right| \\le C_1 \\sqrt{\\tau}",
        "role": "Key pointwise error estimate in the boundary layer."
      },
      {
        "label": "eq-erfc-expansion",
        "latex": "\\text{erfc}(\\zeta) \\approx 1 - \\frac{2}{\\sqrt{\\pi}}\\zeta + O(\\zeta^2)",
        "role": "Asymptotic expansion used for the transition error analysis."
      },
      {
        "label": "eq-final-bound",
        "latex": "|E(\\tau)| \\le C\\left(\\sqrt{\\tau} + \\|f^\\tau - f\\|_{L^1}\\right)",
        "role": "Final uniform convergence bound with error rate."
      }
    ],
    "references": [],
    "math_tools": [
      {
        "toolName": "Hölder's Inequality",
        "field": "Functional Analysis",
        "description": "An inequality that bounds the L1 norm of a product of functions using their L1 and L∞ norms.",
        "roleInProof": "Used to bound the density error term |E2(τ)| ≤ ||c||_{L^∞} ||f^τ - f||_{L^1}.",
        "levelOfAbstraction": "Theorem/Lemma",
        "relatedTools": [
          "L1 norm",
          "L∞ norm"
        ]
      },
      {
        "toolName": "Complementary Error Function (erfc)",
        "field": "Special Functions",
        "description": "The complementary error function erfc(z) = (2/√π) ∫_z^∞ exp(-t²) dt, used to represent Gaussian tail probabilities.",
        "roleInProof": "Approximates the smooth transition in the exit probability p_exit(τ), enabling pointwise error estimates in the boundary layer.",
        "levelOfAbstraction": "Concept",
        "relatedTools": [
          "Gaussian integral",
          "asymptotic-expansion"
        ]
      },
      {
        "toolName": "Asymptotic Expansion",
        "field": "Asymptotics",
        "description": "A technique for approximating functions via series expansions in powers of a small parameter, often for error analysis.",
        "roleInProof": "Applied to expand erfc near the transition point ζ=0 and estimate the O(√τ) pointwise error in (1/τ)p_exit - c(x,v).",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "Taylor expansion",
          "erfc"
        ]
      },
      {
        "toolName": "Boundary Layer Analysis",
        "field": "Applied Mathematics",
        "description": "A method to handle rapid variations near boundaries by rescaling and asymptotic matching.",
        "roleInProof": "Splits the integral for E1(τ) into interior (small error) and boundary layer (O(√τ) error) regions.",
        "levelOfAbstraction": "Technique",
        "relatedTools": [
          "asymptotic-expansion",
          "erfc-approximation"
        ]
      }
    ],
    "cases": [
      {
        "name": "interior region",
        "condition": "d(x) \\ge \\delta",
        "summary": "Both p_exit and c are negligible (super-exponentially small), yielding E_{1,int} = o(\\tau^m) for any m > 0."
      },
      {
        "name": "boundary layer",
        "condition": "d(x) < \\delta and v_n > 0",
        "summary": "Exit probability transition analyzed via erfc approximation vs. ballistic step, leading to pointwise O(\\sqrt{\\tau}) error, integrated to bound E_{1,bd}."
      }
    ],
    "remarks": [
      {
        "type": "note",
        "text": "The √τ error arises from the Gaussian tail approximation in the drift-dominated regime. While the pointwise limit is exact (ballistic v_n/d(x)), the convergence rate is limited by the width of the transition region ∼ O(τ^{1/2}). This is the correct convergence rate for BAOAB with O(τ^{3/2}) position noise."
      }
    ],
    "gaps": [
      {
        "description": "Explicit dependence of constant C_1 on geometry and parameters (e.g., v_n / (d(x) √C_σ)) is sketched but not fully derived; relies on qualitative O(1) bounds in the transition region.",
        "severity": "minor",
        "location_hint": "Quantitative estimate in boundary layer, erfc expansion"
      }
    ],
    "tags": [
      "uniform-convergence",
      "error-bound",
      "exit-probability",
      "boundary-layer",
      "Holder-inequality",
      "erfc-approximation",
      "asymptotic-expansion",
      "BAOAB-scheme"
    ]
  }
]