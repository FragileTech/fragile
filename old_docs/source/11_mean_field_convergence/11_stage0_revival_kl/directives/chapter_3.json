{
  "chapter_index": 3,
  "section_id": "## 3. Direct Proof Attempts",
  "directive_count": 2,
  "hints": [
    {
      "directive_type": "problem",
      "label": "prob-explicit-kl-condition",
      "title": "Open Question from Explicit Calculation",
      "start_line": 339,
      "end_line": 359,
      "header_lines": [
        340
      ],
      "content_start": 342,
      "content_end": 358,
      "content": "342: :label: prob-explicit-kl-condition\n343: \n344: The KL-non-expansiveness of $\\mathcal{R}$ is equivalent to:\n345: \n346: $$\n347: \\lambda (1-m_\\rho) \\log \\frac{1-m_\\rho}{1-m_\\sigma} \\le m_\\rho \\log \\frac{m_\\rho}{m_\\sigma}\n348: $$\n349: \n350: plus a term involving the normalized KL-divergences.\n351: \n352: **Special case** ($m_\\rho = m_\\sigma$): Both log terms vanish, and we get:\n353: \n354: $$\n355: \\lambda (1-m_\\rho) D_{\\text{KL}}(\\tilde{\\rho} \\| \\tilde{\\sigma}) \\le m_\\rho D_{\\text{KL}}(\\tilde{\\rho} \\| \\tilde{\\sigma})\n356: $$\n357: \n358: This holds iff $\\lambda (1 - m_\\rho) \\le m_\\rho$, i.e., $\\lambda \\le \\frac{m_\\rho}{1 - m_\\rho}$.",
      "metadata": {
        "label": "prob-explicit-kl-condition"
      },
      "section": "## 3. Direct Proof Attempts",
      "raw_directive": "339: 3. Value of $\\lambda_{\\text{revive}}$\n340: \n341: :::{prf:problem} Open Question from Explicit Calculation\n342: :label: prob-explicit-kl-condition\n343: \n344: The KL-non-expansiveness of $\\mathcal{R}$ is equivalent to:\n345: \n346: $$\n347: \\lambda (1-m_\\rho) \\log \\frac{1-m_\\rho}{1-m_\\sigma} \\le m_\\rho \\log \\frac{m_\\rho}{m_\\sigma}\n348: $$\n349: \n350: plus a term involving the normalized KL-divergences.\n351: \n352: **Special case** ($m_\\rho = m_\\sigma$): Both log terms vanish, and we get:\n353: \n354: $$\n355: \\lambda (1-m_\\rho) D_{\\text{KL}}(\\tilde{\\rho} \\| \\tilde{\\sigma}) \\le m_\\rho D_{\\text{KL}}(\\tilde{\\rho} \\| \\tilde{\\sigma})\n356: $$\n357: \n358: This holds iff $\\lambda (1 - m_\\rho) \\le m_\\rho$, i.e., $\\lambda \\le \\frac{m_\\rho}{1 - m_\\rho}$.\n359: "
    },
    {
      "directive_type": "lemma",
      "label": "lem-wasserstein-revival",
      "title": "Wasserstein Contraction for Proportional Resampling (Conjecture)",
      "start_line": 391,
      "end_line": 403,
      "header_lines": [
        392
      ],
      "content_start": 394,
      "content_end": 402,
      "content": "394: :label: lem-wasserstein-revival\n395: \n396: If $\\mathcal{R}$ is viewed as resampling from $\\tilde{\\rho} = \\rho / \\|\\rho\\|_{L^1}$, then:\n397: \n398: $$\n399: W_2(\\mathcal{R}(\\rho), \\mathcal{R}(\\sigma)) \\le \\lambda (1-m) W_2(\\tilde{\\rho}, \\tilde{\\sigma})\n400: $$\n401: \n402: for some average dead mass $m \\approx (m_\\rho + m_\\sigma)/2$.",
      "metadata": {
        "label": "lem-wasserstein-revival"
      },
      "section": "## 3. Direct Proof Attempts",
      "raw_directive": "391: **Modified approach**: View $\\mathcal{R}$ as a **Markov kernel** (resampling) and use the Kantorovich duality for random maps.\n392: \n393: :::{prf:lemma} Wasserstein Contraction for Proportional Resampling (Conjecture)\n394: :label: lem-wasserstein-revival\n395: \n396: If $\\mathcal{R}$ is viewed as resampling from $\\tilde{\\rho} = \\rho / \\|\\rho\\|_{L^1}$, then:\n397: \n398: $$\n399: W_2(\\mathcal{R}(\\rho), \\mathcal{R}(\\sigma)) \\le \\lambda (1-m) W_2(\\tilde{\\rho}, \\tilde{\\sigma})\n400: $$\n401: \n402: for some average dead mass $m \\approx (m_\\rho + m_\\sigma)/2$.\n403: "
    }
  ],
  "validation": {
    "ok": true,
    "errors": []
  }
}