# Cost-optimized LLM configuration for proof sketcher pipeline
#
# Uses strong models (GPT-4, Claude Opus) for perspectives and synthesis,
# but cheap models (GPT-3.5) for simple extraction/formatting tasks.
# Estimated cost reduction: 40-50% vs. default.
#
# Best for: Production runs where budget matters but quality is still important

perspective_1_model:
  provider: "openai"
  model: "gpt-4-turbo-preview"
  temperature: 0.7
  max_tokens: 4000

perspective_2_model:
  provider: "anthropic"
  model: "claude-3-opus-20240229"
  temperature: 0.7
  max_tokens: 4000

synthesis_model:
  provider: "openai"
  model: "gpt-4"
  temperature: 0.5
  max_tokens: 3000

fast_model:
  provider: "openai"
  model: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 2000

claude_model_heavy: "sonnet"
claude_model_fast: "haiku"
